********************************************************************************************
** WARNING: 'The 'pre2019' module environment is deprecated. Please consider switching
             to the '2019' or '2020' module environment. You can read more about our
             software policy on this page:
             https://userinfo.surfsara.nl/documentation/software-policy-lisacartesius

             If you have any question, please contact us via http://servicedesk.surfsara.nl.'
********************************************************************************************
Training regression with following parameters:
dnn_hidden_units : 2000, 100, 16
dropout_probs : 0.0, 0.0
learning_rate : 0.001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : Adam
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : Bert
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=5376, out_features=2000, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=2000, out_features=100, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=100, out_features=16, bias=True)
  (9): Dropout(p=0, inplace=False)
  (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (11): LeakyReLU(negative_slope=0.02)
  (12): Linear(in_features=16, out_features=1, bias=True)
)

Epoch: 0
Training loss: 15.765700340270996 / Valid loss: 13.399635451180595
Model is saved in epoch 0, overall batch: 0
Training loss: 6.127030372619629 / Valid loss: 8.819717675163632
Model is saved in epoch 0, overall batch: 100
Training loss: 4.364099502563477 / Valid loss: 6.371737811678932
Model is saved in epoch 0, overall batch: 200
Training loss: 6.64052152633667 / Valid loss: 5.719195552099318
Model is saved in epoch 0, overall batch: 300
Training loss: 6.042747497558594 / Valid loss: 5.520333778290522
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 5.577243804931641 / Valid loss: 5.533714669091361
Training loss: 5.004234313964844 / Valid loss: 5.621288937614078
Training loss: 5.9308390617370605 / Valid loss: 5.55015804654076
Training loss: 4.668268203735352 / Valid loss: 5.53403328259786
Training loss: 4.401596546173096 / Valid loss: 5.578369969413394

Epoch: 2
Training loss: 6.164501190185547 / Valid loss: 5.500020435878208
Model is saved in epoch 2, overall batch: 1000
Training loss: 6.425787448883057 / Valid loss: 5.61622618720645
Training loss: 5.164256572723389 / Valid loss: 5.628493234089443
Training loss: 6.742783546447754 / Valid loss: 5.578919303984869
Training loss: 4.455643177032471 / Valid loss: 5.567807924179804

Epoch: 3
Training loss: 3.558081865310669 / Valid loss: 5.672660146440778
Training loss: 4.075849533081055 / Valid loss: 5.8182059742155525
Training loss: 5.273836135864258 / Valid loss: 5.57822737239656
Training loss: 3.2550714015960693 / Valid loss: 5.85000859215146
Training loss: 5.04761266708374 / Valid loss: 5.77729852994283

Epoch: 4
Training loss: 4.5832037925720215 / Valid loss: 5.890043653760638
Training loss: 4.638767242431641 / Valid loss: 5.875842223848616
Training loss: 4.182924270629883 / Valid loss: 5.857748565219698
Training loss: 5.140944480895996 / Valid loss: 5.778268911724999
Training loss: 4.2131147384643555 / Valid loss: 5.800540404092698

Epoch: 5
Training loss: 6.79914665222168 / Valid loss: 6.263358293260847
Training loss: 4.713563919067383 / Valid loss: 6.228647985912505
Training loss: 3.157804489135742 / Valid loss: 6.161113966078985
Training loss: 3.8821210861206055 / Valid loss: 5.930653780982608
Training loss: 3.887453556060791 / Valid loss: 5.941768146696544

Epoch: 6
Training loss: 6.122968673706055 / Valid loss: 6.3214335487002415
Training loss: 3.285597324371338 / Valid loss: 6.374911083493914
Training loss: 3.578014373779297 / Valid loss: 6.5801569416409444
Training loss: 3.965419292449951 / Valid loss: 6.214591870989119
Training loss: 3.384624719619751 / Valid loss: 6.468242118472145

Epoch: 7
Training loss: 3.21475887298584 / Valid loss: 6.497412256967454
Training loss: 2.1728620529174805 / Valid loss: 6.684479788371495
Training loss: 3.4841299057006836 / Valid loss: 6.710339098884946
Training loss: 4.321338653564453 / Valid loss: 6.417580468314035
Training loss: 2.972651481628418 / Valid loss: 6.868036967232114

Epoch: 8
Training loss: 1.7738990783691406 / Valid loss: 7.195124421800886
Training loss: 2.1441798210144043 / Valid loss: 6.642926300139655
Training loss: 3.251882553100586 / Valid loss: 6.759008693695068
Training loss: 4.096506118774414 / Valid loss: 6.78841270946321
Training loss: 3.183248519897461 / Valid loss: 6.636155123937698

Epoch: 9
Training loss: 2.029506206512451 / Valid loss: 6.818800658271426
Training loss: 2.288989543914795 / Valid loss: 6.828665347326369
Training loss: 3.3808815479278564 / Valid loss: 6.763192390260242
Training loss: 2.3981070518493652 / Valid loss: 7.739439296722412

Epoch: 10
Training loss: 1.4216480255126953 / Valid loss: 7.388351267860049
Training loss: 1.8197413682937622 / Valid loss: 7.151865641276042
Training loss: 1.5796442031860352 / Valid loss: 6.846092355818976
Training loss: 2.577202081680298 / Valid loss: 6.945623552231561
Training loss: 1.7377214431762695 / Valid loss: 7.782596015930176

Epoch: 11
Training loss: 1.0891811847686768 / Valid loss: 7.376577949523925
Training loss: 1.5657374858856201 / Valid loss: 7.172021066574823
Training loss: 1.6767587661743164 / Valid loss: 7.089032963344029
Training loss: 1.4473447799682617 / Valid loss: 7.44668386777242
Training loss: 2.353316307067871 / Valid loss: 7.667879840305873

Epoch: 12
Training loss: 0.8911303877830505 / Valid loss: 7.021634292602539
Training loss: 1.141905665397644 / Valid loss: 7.188700862157912
Training loss: 1.278510332107544 / Valid loss: 6.898002352033343
Training loss: 1.1357593536376953 / Valid loss: 7.265919263022287
Training loss: 1.4851073026657104 / Valid loss: 7.375135644276937

Epoch: 13
Training loss: 1.0675407648086548 / Valid loss: 7.076451192583357
Training loss: 1.0887376070022583 / Valid loss: 7.194370133536203
Training loss: 1.1945703029632568 / Valid loss: 7.195398943764823
Training loss: 1.4118218421936035 / Valid loss: 6.989992854708717
Training loss: 1.1957453489303589 / Valid loss: 7.465697842552548

Epoch: 14
Training loss: 0.9668686985969543 / Valid loss: 7.549950263613746
Training loss: 1.7238690853118896 / Valid loss: 7.141253562200637
Training loss: 1.3160755634307861 / Valid loss: 7.293925380706787
Training loss: 0.8440595865249634 / Valid loss: 7.21663301104591
Training loss: 1.5144141912460327 / Valid loss: 7.172609601702009

Epoch: 15
Training loss: 0.5426336526870728 / Valid loss: 7.424824369521368
Training loss: 1.441624641418457 / Valid loss: 7.28578322728475
Training loss: 0.6639300584793091 / Valid loss: 7.345029090699695
Training loss: 0.9602261185646057 / Valid loss: 7.381763621738979
Training loss: 1.199022650718689 / Valid loss: 7.348576191493443

Epoch: 16
Training loss: 0.8247591853141785 / Valid loss: 7.196861439659482
Training loss: 0.6559747457504272 / Valid loss: 7.253304481506348
Training loss: 0.5706334114074707 / Valid loss: 7.4278565043494815
Training loss: 1.1128830909729004 / Valid loss: 7.461133911496117
Training loss: 0.9497281312942505 / Valid loss: 7.330151507967995

Epoch: 17
Training loss: 1.0422170162200928 / Valid loss: 7.381999202001662
Training loss: 1.3179240226745605 / Valid loss: 7.1618699482509065
Training loss: 1.3021745681762695 / Valid loss: 7.322104590279715
Training loss: 0.7087141275405884 / Valid loss: 7.289461694444928
Training loss: 0.6131398677825928 / Valid loss: 7.1717011315482

Epoch: 18
Training loss: 0.6964162588119507 / Valid loss: 7.2683129946390785
Training loss: 0.7655309438705444 / Valid loss: 7.08795215969994
Training loss: 0.6940097808837891 / Valid loss: 7.168793280919393
Training loss: 0.9227856397628784 / Valid loss: 7.104040431976318
Training loss: 0.9503320455551147 / Valid loss: 7.439989203498477

Epoch: 19
Training loss: 1.2825490236282349 / Valid loss: 7.452070376986549
Training loss: 1.5297114849090576 / Valid loss: 7.438924239930652
Training loss: 1.0516955852508545 / Valid loss: 7.21810854048956
Training loss: 0.7481666803359985 / Valid loss: 7.474696667989095

Epoch: 20
Training loss: 0.5240218043327332 / Valid loss: 7.2247215861365905
Training loss: 1.0359026193618774 / Valid loss: 7.01406051544916
Training loss: 0.6213411688804626 / Valid loss: 7.096994400024414
Training loss: 1.0393610000610352 / Valid loss: 7.072528766450428
Training loss: 1.505245327949524 / Valid loss: 7.322477567763555

Epoch: 21
Training loss: 0.6410533785820007 / Valid loss: 7.139811697460356
Training loss: 0.5327749848365784 / Valid loss: 7.614635058811733
Training loss: 0.6896448135375977 / Valid loss: 7.432232411702474
Training loss: 0.7246840596199036 / Valid loss: 7.034297870454334
Training loss: 0.6732176542282104 / Valid loss: 7.112529209681919

Epoch: 22
Training loss: 0.7488296031951904 / Valid loss: 7.0415241922651015
Training loss: 0.43810153007507324 / Valid loss: 7.121858891986665
Training loss: 0.5923314094543457 / Valid loss: 7.196047010875883
Training loss: 1.1224586963653564 / Valid loss: 7.148241783323742
Training loss: 1.0960543155670166 / Valid loss: 7.282926409585135

Epoch: 23
Training loss: 0.6613410711288452 / Valid loss: 7.379645656404041
Training loss: 0.7701973915100098 / Valid loss: 7.032446177800496
Training loss: 0.7753510475158691 / Valid loss: 7.334156890142531
Training loss: 0.5383292436599731 / Valid loss: 7.004515000752041
Training loss: 0.7604090571403503 / Valid loss: 7.103110722133091

Epoch: 24
Training loss: 1.2114282846450806 / Valid loss: 6.867120738256546
Training loss: 0.5419753789901733 / Valid loss: 6.920538143884568
Training loss: 0.5897265672683716 / Valid loss: 7.347378356116159
Training loss: 0.8014463186264038 / Valid loss: 7.242246850331624
Training loss: 1.3461661338806152 / Valid loss: 7.075789029257638

Epoch: 25
Training loss: 0.6527553796768188 / Valid loss: 6.899279732931228
Training loss: 0.4484539330005646 / Valid loss: 6.924172608057658
Training loss: 0.7834568023681641 / Valid loss: 7.003453665687925
Training loss: 0.43774452805519104 / Valid loss: 7.3492748805454795
Training loss: 0.5079165101051331 / Valid loss: 7.132343700953892

Epoch: 26
Training loss: 1.0213607549667358 / Valid loss: 7.035318111238025
Training loss: 0.8303967118263245 / Valid loss: 6.960005424136207
Training loss: 0.6095854640007019 / Valid loss: 6.990484467006865
Training loss: 0.3739844560623169 / Valid loss: 6.997977036521548
Training loss: 0.6546720266342163 / Valid loss: 7.204307660602388

Epoch: 27
Training loss: 0.3490922451019287 / Valid loss: 6.8811381203787665
Training loss: 0.6245917081832886 / Valid loss: 6.948054860887074
Training loss: 0.6033289432525635 / Valid loss: 7.143658179328555
Training loss: 0.5362590551376343 / Valid loss: 7.027526187896728
Training loss: 0.6844990849494934 / Valid loss: 7.0928855169387095

Epoch: 28
Training loss: 0.5631611347198486 / Valid loss: 7.220712157658168
Training loss: 0.4681992828845978 / Valid loss: 6.9808939297993975
Training loss: 0.5096921920776367 / Valid loss: 7.013929980141776
Training loss: 0.3915059268474579 / Valid loss: 7.077820673443022
Training loss: 0.7864702939987183 / Valid loss: 7.266643333435058

Epoch: 29
Training loss: 0.7675877809524536 / Valid loss: 7.167349783579509
Training loss: 0.5293459892272949 / Valid loss: 6.968165688287645
Training loss: 0.42066216468811035 / Valid loss: 7.012243166423979
Training loss: 0.4675798714160919 / Valid loss: 7.008248878660656

Epoch: 30
Training loss: 0.689152717590332 / Valid loss: 7.069259302956717
Training loss: 0.4842417240142822 / Valid loss: 7.137249219985235
Training loss: 0.3676629364490509 / Valid loss: 7.02804977326166
Training loss: 0.5203980207443237 / Valid loss: 7.0413317816598076
Training loss: 0.3044419586658478 / Valid loss: 7.050244948977515

Epoch: 31
Training loss: 0.42016178369522095 / Valid loss: 6.902105474472046
Training loss: 0.4183787703514099 / Valid loss: 6.970627067202614
Training loss: 0.49750757217407227 / Valid loss: 7.0643341700236
Training loss: 0.37181830406188965 / Valid loss: 7.037158845719837
Training loss: 0.6152487993240356 / Valid loss: 7.122200321015858

Epoch: 32
Training loss: 0.3848465085029602 / Valid loss: 6.935148438953218
Training loss: 0.4010522961616516 / Valid loss: 6.868158136095319
Training loss: 0.2944841980934143 / Valid loss: 7.047273454212007
Training loss: 0.35725146532058716 / Valid loss: 6.8795719282967704
Training loss: 0.4350997805595398 / Valid loss: 7.101126832053775

Epoch: 33
Training loss: 0.3530556559562683 / Valid loss: 6.957195618039086
Training loss: 0.40896081924438477 / Valid loss: 7.0333207402910505
Training loss: 0.4382176399230957 / Valid loss: 6.992292533602034
Training loss: 0.43732786178588867 / Valid loss: 6.922511766070412
Training loss: 0.4189184010028839 / Valid loss: 6.986839857555571

Epoch: 34
Training loss: 0.8735959529876709 / Valid loss: 7.031001631418864
Training loss: 0.36404505372047424 / Valid loss: 6.8136503037952245
Training loss: 0.48089858889579773 / Valid loss: 6.983895229157947
Training loss: 0.33155110478401184 / Valid loss: 6.808161989847819
Training loss: 0.34232407808303833 / Valid loss: 6.949971784864153

Epoch: 35
Training loss: 0.9045617580413818 / Valid loss: 6.858074319930304
Training loss: 0.5713363289833069 / Valid loss: 7.007368051438105
Training loss: 0.4803009033203125 / Valid loss: 6.9159299123854865
Training loss: 0.41560590267181396 / Valid loss: 6.989744990212577
Training loss: 0.25549936294555664 / Valid loss: 7.076335602714902

Epoch: 36
Training loss: 0.43812042474746704 / Valid loss: 6.964874267578125
Training loss: 0.7390400171279907 / Valid loss: 6.944810256503877
Training loss: 0.6809818148612976 / Valid loss: 7.060747923169817
Training loss: 0.49954742193222046 / Valid loss: 7.173601718175979
Training loss: 0.5935614705085754 / Valid loss: 6.901555665334066

Epoch: 37
Training loss: 0.38267982006073 / Valid loss: 6.777287381035941
Training loss: 0.27827808260917664 / Valid loss: 7.029321152823312
Training loss: 0.5360932350158691 / Valid loss: 7.144682629903158
Training loss: 1.5006515979766846 / Valid loss: 6.902246284484863
Training loss: 0.6049326658248901 / Valid loss: 7.252998483748663

Epoch: 38
Training loss: 0.55263751745224 / Valid loss: 6.903541265215193
Training loss: 0.3912277817726135 / Valid loss: 7.067876543317523
Training loss: 0.4043325185775757 / Valid loss: 7.0610686211358935
Training loss: 0.4284650683403015 / Valid loss: 7.244679419199626
Training loss: 0.7228416204452515 / Valid loss: 7.018387458437965

Epoch: 39
Training loss: 0.4735035002231598 / Valid loss: 7.049049045926049
Training loss: 0.40887895226478577 / Valid loss: 6.9995390347072055
Training loss: 0.3522275984287262 / Valid loss: 6.915446358635312
Training loss: 0.269299179315567 / Valid loss: 7.012306485857282

Epoch: 40
Training loss: 0.46791696548461914 / Valid loss: 7.21376257623945
Training loss: 0.24236854910850525 / Valid loss: 7.250162551516579
Training loss: 0.5401368141174316 / Valid loss: 7.016613869439988
Training loss: 0.29310140013694763 / Valid loss: 6.90638062613351
Training loss: 0.28645098209381104 / Valid loss: 7.00866421744937

Epoch: 41
Training loss: 0.5362550616264343 / Valid loss: 6.995355810437884
Training loss: 0.27495113015174866 / Valid loss: 6.85082516670227
Training loss: 0.21118183434009552 / Valid loss: 6.991395550682431
Training loss: 1.0882055759429932 / Valid loss: 6.938548042660668
Training loss: 0.4951770007610321 / Valid loss: 6.982846600668771

Epoch: 42
Training loss: 0.3849049508571625 / Valid loss: 6.738570896784465
Training loss: 0.3295544683933258 / Valid loss: 6.960407647632417
Training loss: 0.403055876493454 / Valid loss: 6.893122212092082
Training loss: 0.4334084093570709 / Valid loss: 7.019912056695848
Training loss: 0.2634228467941284 / Valid loss: 6.813919103713262

Epoch: 43
Training loss: 0.3275986909866333 / Valid loss: 6.787533528464181
Training loss: 0.37901341915130615 / Valid loss: 6.7140169370742075
Training loss: 0.2204371690750122 / Valid loss: 6.905223751068116
Training loss: 0.5867722630500793 / Valid loss: 6.820777025676909
Training loss: 0.29604485630989075 / Valid loss: 6.878408391135079

Epoch: 44
Training loss: 0.4258541464805603 / Valid loss: 6.790409142630441
Training loss: 0.29014852643013 / Valid loss: 6.83801591963995
Training loss: 0.3502117991447449 / Valid loss: 6.908721901121593
Training loss: 0.3110758066177368 / Valid loss: 6.975122665223621
Training loss: 0.5069660544395447 / Valid loss: 6.998301328931536

Epoch: 45
Training loss: 0.22383712232112885 / Valid loss: 7.066485450381324
Training loss: 0.6398098468780518 / Valid loss: 6.908342568079631
Training loss: 0.5776716470718384 / Valid loss: 6.953870986756824
Training loss: 0.2700120806694031 / Valid loss: 6.669647546041579
Training loss: 0.3675152063369751 / Valid loss: 6.823161897205171

Epoch: 46
Training loss: 0.2949202060699463 / Valid loss: 6.878785646529424
Training loss: 0.245732843875885 / Valid loss: 6.792029535202753
Training loss: 0.6988308429718018 / Valid loss: 7.0100179922013055
Training loss: 0.20519594848155975 / Valid loss: 6.912310187021891
Training loss: 0.49549952149391174 / Valid loss: 6.97582597732544

Epoch: 47
Training loss: 0.27583441138267517 / Valid loss: 6.846087578364781
Training loss: 0.5250483751296997 / Valid loss: 6.914285911832537
Training loss: 0.36490076780319214 / Valid loss: 6.868118640354702
Training loss: 0.29066672921180725 / Valid loss: 6.962226640610468
Training loss: 0.4297463893890381 / Valid loss: 7.15857314609346

Epoch: 48
Training loss: 0.24943499267101288 / Valid loss: 6.807519131615049
Training loss: 0.4290311336517334 / Valid loss: 6.8909859975179035
Training loss: 0.48338553309440613 / Valid loss: 6.849553948356991
Training loss: 0.21784916520118713 / Valid loss: 6.697406864166259
Training loss: 0.395506352186203 / Valid loss: 6.838122831072126

Epoch: 49
Training loss: 0.4981532692909241 / Valid loss: 6.975083473750523
Training loss: 0.2853633165359497 / Valid loss: 6.841758741651263
Training loss: 0.2525501549243927 / Valid loss: 7.010902663639613
Training loss: 0.41843345761299133 / Valid loss: 6.8964976265316915

Epoch: 50
Training loss: 0.5022130608558655 / Valid loss: 6.791504832676479
Training loss: 0.4916205108165741 / Valid loss: 6.885678495679583
Training loss: 0.2293807715177536 / Valid loss: 6.683464994884672
Training loss: 0.321909099817276 / Valid loss: 6.89034925869533
Training loss: 0.4450467526912689 / Valid loss: 6.937083067212786

Epoch: 51
Training loss: 0.18771228194236755 / Valid loss: 7.028895478021531
Training loss: 0.31529486179351807 / Valid loss: 6.8530100686209545
Training loss: 0.2943069040775299 / Valid loss: 6.837882627759661
Training loss: 0.2967613935470581 / Valid loss: 6.755054414839972
Training loss: 0.39550405740737915 / Valid loss: 6.811524132319859

Epoch: 52
Training loss: 0.24211016297340393 / Valid loss: 6.751355534508114
Training loss: 0.24033130705356598 / Valid loss: 6.819704269227527
Training loss: 0.23116359114646912 / Valid loss: 6.808247516268776
Training loss: 0.22485482692718506 / Valid loss: 6.875391328902472
Training loss: 0.4469583034515381 / Valid loss: 6.884482138497489

Epoch: 53
Training loss: 0.24633878469467163 / Valid loss: 6.862690580458868
Training loss: 0.5703129768371582 / Valid loss: 6.873936871119908
Training loss: 0.304845929145813 / Valid loss: 6.933256898607526
Training loss: 0.5041393041610718 / Valid loss: 6.823003977820987
Training loss: 0.41058826446533203 / Valid loss: 6.761079093388148

Epoch: 54
Training loss: 0.3348295986652374 / Valid loss: 6.779568140847342
Training loss: 0.4200092554092407 / Valid loss: 6.920156251816523
Training loss: 0.2893892824649811 / Valid loss: 6.8204669112250915
Training loss: 0.23802801966667175 / Valid loss: 6.975771826789493
Training loss: 0.4505571722984314 / Valid loss: 6.8051290103367394

Epoch: 55
Training loss: 0.3780149221420288 / Valid loss: 6.833083665938604
Training loss: 0.2718570828437805 / Valid loss: 6.923740377880278
Training loss: 0.3408757150173187 / Valid loss: 6.843800490243094
Training loss: 0.3336857259273529 / Valid loss: 6.68986846833002
Training loss: 0.3254382610321045 / Valid loss: 6.798951798393613

Epoch: 56
Training loss: 0.44014471769332886 / Valid loss: 6.821119592303321
Training loss: 0.17795458436012268 / Valid loss: 6.901603821345738
Training loss: 0.24694913625717163 / Valid loss: 6.750751849583217
Training loss: 0.27183568477630615 / Valid loss: 6.82918301991054
Training loss: 0.34241318702697754 / Valid loss: 6.988560449509394

Epoch: 57
Training loss: 0.4569093585014343 / Valid loss: 6.757980333055769
Training loss: 0.45368272066116333 / Valid loss: 6.82969587416876
Training loss: 0.7224981784820557 / Valid loss: 7.009624817257836
Training loss: 0.4086109399795532 / Valid loss: 6.812248048328218
Training loss: 0.391318678855896 / Valid loss: 6.998959641229539

Epoch: 58
Training loss: 0.23931163549423218 / Valid loss: 6.773059245518276
Training loss: 0.6497039794921875 / Valid loss: 6.735242260070074
Training loss: 0.1888764351606369 / Valid loss: 6.947529449917021
Training loss: 0.4087572693824768 / Valid loss: 6.780976754143125
Training loss: 0.33315712213516235 / Valid loss: 6.876399639674595

Epoch: 59
Training loss: 0.2002645581960678 / Valid loss: 6.901693857283819
Training loss: 0.34995630383491516 / Valid loss: 6.677828107561384
Training loss: 0.22979050874710083 / Valid loss: 6.758138145719256
Training loss: 0.32330116629600525 / Valid loss: 6.634569581349691

Epoch: 60
Training loss: 0.3578627109527588 / Valid loss: 7.12086106254941
Training loss: 0.6669747829437256 / Valid loss: 6.771716644650414
Training loss: 0.19245126843452454 / Valid loss: 6.82211933590117
Training loss: 0.2516666650772095 / Valid loss: 6.69075095312936
Training loss: 0.14702095091342926 / Valid loss: 6.765072218577067

Epoch: 61
Training loss: 0.3248170018196106 / Valid loss: 6.743950496401106
Training loss: 0.27995240688323975 / Valid loss: 6.678152468090966
Training loss: 0.4588662385940552 / Valid loss: 6.967714439119612
Training loss: 0.40133923292160034 / Valid loss: 6.848690073830741
Training loss: 0.29317769408226013 / Valid loss: 6.791198185511997

Epoch: 62
Training loss: 0.19909627735614777 / Valid loss: 6.800127778734479
Training loss: 0.44061246514320374 / Valid loss: 6.722131906236921
Training loss: 0.23604106903076172 / Valid loss: 6.795142671040126
Training loss: 0.38966214656829834 / Valid loss: 6.858607907522292
Training loss: 0.3226313591003418 / Valid loss: 6.819323589688255

Epoch: 63
Training loss: 0.23920030891895294 / Valid loss: 6.770762143816267
Training loss: 0.330547034740448 / Valid loss: 6.9365644500369115
Training loss: 0.2723698019981384 / Valid loss: 6.823400374821254
Training loss: 0.3134589195251465 / Valid loss: 6.718061910356794
Training loss: 0.12761719524860382 / Valid loss: 6.753193528311593

Epoch: 64
Training loss: 0.2347167283296585 / Valid loss: 6.780518881479899
Training loss: 0.16747644543647766 / Valid loss: 6.8804623331342425
Training loss: 0.3943936228752136 / Valid loss: 6.802707978657314
Training loss: 0.2992875576019287 / Valid loss: 6.87196071715582
Training loss: 0.19548112154006958 / Valid loss: 6.8231279691060385

Epoch: 65
Training loss: 0.20990172028541565 / Valid loss: 6.825393622262137
Training loss: 0.47712793946266174 / Valid loss: 6.895734339668637
Training loss: 0.19779613614082336 / Valid loss: 6.770004054478236
Training loss: 0.20016932487487793 / Valid loss: 6.760459171022688
Training loss: 0.8677366971969604 / Valid loss: 6.886543026424589

Epoch: 66
Training loss: 0.23584794998168945 / Valid loss: 6.7338930629548575
Training loss: 0.2006128430366516 / Valid loss: 6.803289858500163
Training loss: 0.34674781560897827 / Valid loss: 6.847874723161969
Training loss: 0.26058679819107056 / Valid loss: 6.786290840875535
Training loss: 0.33887147903442383 / Valid loss: 6.937690108163016

Epoch: 67
Training loss: 0.2687024474143982 / Valid loss: 6.779158776147025
Training loss: 0.18528583645820618 / Valid loss: 6.715510313851492
Training loss: 0.28112515807151794 / Valid loss: 6.731954079582578
Training loss: 0.5666322708129883 / Valid loss: 6.993746739342099
Training loss: 0.23502834141254425 / Valid loss: 6.7815415632157094

Epoch: 68
Training loss: 0.27422475814819336 / Valid loss: 6.8047154381161645
Training loss: 0.2522346079349518 / Valid loss: 6.736034034547352
Training loss: 0.16804102063179016 / Valid loss: 6.993249725160145
Training loss: 0.27309340238571167 / Valid loss: 6.780811223529634
Training loss: 0.4907994270324707 / Valid loss: 6.722554315839495

Epoch: 69
Training loss: 0.270169734954834 / Valid loss: 6.654696362359183
Training loss: 0.2019234001636505 / Valid loss: 6.875401042756581
Training loss: 0.3915999233722687 / Valid loss: 6.744269698006766
Training loss: 0.3321993947029114 / Valid loss: 6.798256851377941

Epoch: 70
Training loss: 0.15277396142482758 / Valid loss: 6.799340075538272
Training loss: 0.35081416368484497 / Valid loss: 6.73735302289327
Training loss: 0.17039163410663605 / Valid loss: 6.786959520975748
Training loss: 0.24052681028842926 / Valid loss: 6.730819293430874
Training loss: 0.25248444080352783 / Valid loss: 6.694361055464972

Epoch: 71
Training loss: 0.3983907699584961 / Valid loss: 6.9452120917184015
Training loss: 0.33602553606033325 / Valid loss: 6.904700338272821
Training loss: 0.18474268913269043 / Valid loss: 6.745666780925933
Training loss: 0.15980398654937744 / Valid loss: 6.8464235532851445
Training loss: 0.41813355684280396 / Valid loss: 6.785341603415353

Epoch: 72
Training loss: 0.17966073751449585 / Valid loss: 6.752444514774141
Training loss: 0.4873162806034088 / Valid loss: 6.668183435712542
Training loss: 0.22473925352096558 / Valid loss: 6.703145335969471
Training loss: 0.2712843418121338 / Valid loss: 6.806968906947545
Training loss: 0.3317486047744751 / Valid loss: 6.703223964146205

Epoch: 73
Training loss: 0.30949437618255615 / Valid loss: 6.600711572737921
Training loss: 0.34906408190727234 / Valid loss: 6.796590920857021
Training loss: 0.3080303966999054 / Valid loss: 6.684067826043992
Training loss: 0.40322181582450867 / Valid loss: 6.775865743273781
Training loss: 0.1882997751235962 / Valid loss: 6.677812283379691

Epoch: 74
Training loss: 0.1359628140926361 / Valid loss: 6.681673930940174
Training loss: 0.2174985706806183 / Valid loss: 6.7226333345685685
Training loss: 0.3890039920806885 / Valid loss: 6.682108552115304
Training loss: 0.3262813985347748 / Valid loss: 6.710959348224458
Training loss: 0.3439076542854309 / Valid loss: 6.72366517384847

Epoch: 75
Training loss: 0.27852174639701843 / Valid loss: 6.707524295080276
Training loss: 0.2972131669521332 / Valid loss: 6.691528567813692
Training loss: 0.5231931209564209 / Valid loss: 6.7678989319574265
Training loss: 0.253578782081604 / Valid loss: 6.7402241343543645
Training loss: 0.33494675159454346 / Valid loss: 6.6984045028686525

Epoch: 76
Training loss: 0.29479843378067017 / Valid loss: 6.684396757398333
Training loss: 0.40875691175460815 / Valid loss: 6.647468303498767
Training loss: 0.18798518180847168 / Valid loss: 6.777016825903029
Training loss: 0.1941707581281662 / Valid loss: 6.7427805764334545
Training loss: 0.1324498951435089 / Valid loss: 6.849903701600574

Epoch: 77
Training loss: 0.1589755117893219 / Valid loss: 6.712900184449696
Training loss: 0.18605273962020874 / Valid loss: 6.854461313429333
Training loss: 0.2120855450630188 / Valid loss: 6.801223813919794
Training loss: 0.27976441383361816 / Valid loss: 6.685082281203497
Training loss: 0.39022016525268555 / Valid loss: 6.805451729184106

Epoch: 78
Training loss: 0.2694767713546753 / Valid loss: 6.734313583374023
Training loss: 0.1732800155878067 / Valid loss: 6.716629364376977
Training loss: 0.15089979767799377 / Valid loss: 6.769556488309588
Training loss: 0.18094484508037567 / Valid loss: 6.845108091263544
Training loss: 0.3911951184272766 / Valid loss: 6.6995929400126135

Epoch: 79
Training loss: 0.14435258507728577 / Valid loss: 6.638266211464291
Training loss: 0.2574714720249176 / Valid loss: 6.759087135678246
Training loss: 0.13571076095104218 / Valid loss: 6.740478238605317
Training loss: 0.26609545946121216 / Valid loss: 6.730795751299177
ModuleList(
  (0): Linear(in_features=5376, out_features=2000, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=2000, out_features=100, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=100, out_features=16, bias=True)
  (9): Dropout(p=0, inplace=False)
  (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (11): LeakyReLU(negative_slope=0.02)
  (12): Linear(in_features=16, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.325703477859497
Training regression with following parameters:
dnn_hidden_units : 300, 32
dropout_probs : 0.0, 0.0
learning_rate : 0.001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : Adam
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : Bert
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=5376, out_features=300, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=300, out_features=32, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=32, out_features=1, bias=True)
)

Epoch: 0
Training loss: 13.485506057739258 / Valid loss: 14.727781214032854
Model is saved in epoch 0, overall batch: 0
Training loss: 4.084541320800781 / Valid loss: 7.065146973019554
Model is saved in epoch 0, overall batch: 100
Training loss: 4.639308452606201 / Valid loss: 5.684344668615432
Model is saved in epoch 0, overall batch: 200
Training loss: 5.593152046203613 / Valid loss: 5.590488869803292
Model is saved in epoch 0, overall batch: 300
Training loss: 4.331737518310547 / Valid loss: 5.54173499970209
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 6.507933616638184 / Valid loss: 5.570422365551903
Training loss: 5.03676700592041 / Valid loss: 5.613300468808129
Training loss: 4.354218482971191 / Valid loss: 5.71876259077163
Training loss: 4.347367763519287 / Valid loss: 5.602560888017927
Training loss: 5.787589073181152 / Valid loss: 5.46172391573588
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 5.601531028747559 / Valid loss: 5.560890624636696
Training loss: 4.566441059112549 / Valid loss: 5.630791695912679
Training loss: 4.266874313354492 / Valid loss: 5.535887786320278
Training loss: 5.487154960632324 / Valid loss: 5.856110638663882
Training loss: 5.148183822631836 / Valid loss: 5.489890666235061

Epoch: 3
Training loss: 4.56959342956543 / Valid loss: 5.597435830888294
Training loss: 3.36702036857605 / Valid loss: 5.7787544409434
Training loss: 5.45075798034668 / Valid loss: 5.687821515401205
Training loss: 4.970407485961914 / Valid loss: 5.640556085677374
Training loss: 4.619922161102295 / Valid loss: 5.737907119024367

Epoch: 4
Training loss: 3.0268683433532715 / Valid loss: 5.809183036713373
Training loss: 4.513984680175781 / Valid loss: 5.79840285664513
Training loss: 4.119352340698242 / Valid loss: 5.854349147705805
Training loss: 4.55628776550293 / Valid loss: 5.841215242658342
Training loss: 5.38166618347168 / Valid loss: 5.795476002920242

Epoch: 5
Training loss: 4.772600173950195 / Valid loss: 6.085455853598458
Training loss: 4.2128167152404785 / Valid loss: 6.203831114087786
Training loss: 4.126201629638672 / Valid loss: 6.238782628377279
Training loss: 2.65157151222229 / Valid loss: 6.105154182797387
Training loss: 5.329333782196045 / Valid loss: 5.952133414858864

Epoch: 6
Training loss: 3.585573196411133 / Valid loss: 6.43375609261649
Training loss: 2.427706003189087 / Valid loss: 6.403943806602841
Training loss: 3.3778953552246094 / Valid loss: 6.320946638924735
Training loss: 3.4974899291992188 / Valid loss: 6.130150763193766
Training loss: 3.3988142013549805 / Valid loss: 6.184874364307949

Epoch: 7
Training loss: 3.1917731761932373 / Valid loss: 6.729487351008824
Training loss: 1.9710493087768555 / Valid loss: 7.1452867190043134
Training loss: 2.713913679122925 / Valid loss: 6.751288136981782
Training loss: 3.2826249599456787 / Valid loss: 6.547898006439209
Training loss: 2.231494665145874 / Valid loss: 6.945514420100621

Epoch: 8
Training loss: 2.974836587905884 / Valid loss: 6.786867232549758
Training loss: 2.6557254791259766 / Valid loss: 6.768648767471314
Training loss: 2.9730982780456543 / Valid loss: 7.706897853669666
Training loss: 2.9073212146759033 / Valid loss: 6.801637876601446
Training loss: 2.5893940925598145 / Valid loss: 7.0203120867411295

Epoch: 9
Training loss: 1.6607356071472168 / Valid loss: 7.250901344844273
Training loss: 3.003000259399414 / Valid loss: 6.903992203303746
Training loss: 3.6520400047302246 / Valid loss: 7.356825764973959
Training loss: 1.7452361583709717 / Valid loss: 6.900194976443336

Epoch: 10
Training loss: 1.921802043914795 / Valid loss: 7.28059497106643
Training loss: 1.554692268371582 / Valid loss: 7.1731242679414295
Training loss: 2.7501182556152344 / Valid loss: 7.04165206409636
Training loss: 2.2852447032928467 / Valid loss: 7.621666404179164
Training loss: 2.9342007637023926 / Valid loss: 7.024440788087391

Epoch: 11
Training loss: 2.339480400085449 / Valid loss: 6.744874077751523
Training loss: 1.7421303987503052 / Valid loss: 7.165397496450515
Training loss: 1.736325979232788 / Valid loss: 7.33206912449428
Training loss: 2.0836172103881836 / Valid loss: 7.296747003282819
Training loss: 1.9697494506835938 / Valid loss: 7.745774804978144

Epoch: 12
Training loss: 1.3215553760528564 / Valid loss: 7.607151340302967
Training loss: 1.428411602973938 / Valid loss: 7.986862193970453
Training loss: 1.7091624736785889 / Valid loss: 7.2623502595084055
Training loss: 1.4815216064453125 / Valid loss: 7.166558306557792
Training loss: 1.9444682598114014 / Valid loss: 7.124978444689796

Epoch: 13
Training loss: 1.3704614639282227 / Valid loss: 7.13262421517145
Training loss: 0.980102002620697 / Valid loss: 7.149479570842924
Training loss: 1.0197198390960693 / Valid loss: 7.261141899653843
Training loss: 1.221708059310913 / Valid loss: 7.5309386162530805
Training loss: 1.738562822341919 / Valid loss: 6.959201276870001

Epoch: 14
Training loss: 1.4852073192596436 / Valid loss: 7.160695253099714
Training loss: 1.3371450901031494 / Valid loss: 8.407311017172677
Training loss: 0.9767293930053711 / Valid loss: 7.4133056549798875
Training loss: 1.4024471044540405 / Valid loss: 7.186048607599168
Training loss: 1.7611618041992188 / Valid loss: 7.154868793487549

Epoch: 15
Training loss: 1.516613245010376 / Valid loss: 7.062687660398938
Training loss: 1.3272181749343872 / Valid loss: 7.227820796058292
Training loss: 1.1008169651031494 / Valid loss: 7.143176392146519
Training loss: 1.0648858547210693 / Valid loss: 7.34838190532866
Training loss: 0.9236446619033813 / Valid loss: 7.277192120324997

Epoch: 16
Training loss: 2.0853466987609863 / Valid loss: 7.230085974647885
Training loss: 0.9141938090324402 / Valid loss: 7.607573050544375
Training loss: 1.2358945608139038 / Valid loss: 7.554919978550502
Training loss: 1.314352035522461 / Valid loss: 7.44837680544172
Training loss: 1.3040990829467773 / Valid loss: 7.259091749645415

Epoch: 17
Training loss: 1.0369572639465332 / Valid loss: 7.429614614305042
Training loss: 1.2456907033920288 / Valid loss: 7.314611752827962
Training loss: 1.2524393796920776 / Valid loss: 7.294987238021124
Training loss: 1.3762683868408203 / Valid loss: 7.349094263712565
Training loss: 1.0622916221618652 / Valid loss: 7.503420838855562

Epoch: 18
Training loss: 0.816494345664978 / Valid loss: 7.219024774006435
Training loss: 0.8829970359802246 / Valid loss: 7.510570671444848
Training loss: 0.8666496276855469 / Valid loss: 7.326167765117827
Training loss: 1.204059362411499 / Valid loss: 7.660407593136742
Training loss: 1.2139842510223389 / Valid loss: 7.360418033599854

Epoch: 19
Training loss: 0.9616953730583191 / Valid loss: 7.192802383786156
Training loss: 1.204817295074463 / Valid loss: 7.173180861700149
Training loss: 1.1860488653182983 / Valid loss: 7.4403221130371096
Training loss: 1.0839942693710327 / Valid loss: 7.431657863798596

Epoch: 20
Training loss: 0.8600542545318604 / Valid loss: 7.495256378537133
Training loss: 0.7869523763656616 / Valid loss: 7.246940944308326
Training loss: 0.6944712400436401 / Valid loss: 7.228313782101586
Training loss: 1.2299251556396484 / Valid loss: 7.925821772075834
Training loss: 0.8115967512130737 / Valid loss: 8.324003664652507

Epoch: 21
Training loss: 0.6890562772750854 / Valid loss: 7.20938842410133
Training loss: 0.6995111703872681 / Valid loss: 7.513745326087588
Training loss: 1.0388389825820923 / Valid loss: 7.348260570707775
Training loss: 1.124869704246521 / Valid loss: 8.035612823849632
Training loss: 1.1026874780654907 / Valid loss: 7.896966162182036

Epoch: 22
Training loss: 0.8242351412773132 / Valid loss: 7.619624514806838
Training loss: 0.8992370367050171 / Valid loss: 7.281538513728551
Training loss: 1.1121529340744019 / Valid loss: 7.161973599025181
Training loss: 0.6095430254936218 / Valid loss: 7.395494274866014
Training loss: 0.6467241644859314 / Valid loss: 7.360105882372175

Epoch: 23
Training loss: 1.1472375392913818 / Valid loss: 7.451206856682187
Training loss: 1.1267988681793213 / Valid loss: 7.468046292804536
Training loss: 1.0119696855545044 / Valid loss: 7.463719613211495
Training loss: 0.949309766292572 / Valid loss: 8.038381431216285
Training loss: 0.9528309106826782 / Valid loss: 7.318645713442848

Epoch: 24
Training loss: 0.5348576307296753 / Valid loss: 7.237531734648205
Training loss: 0.8734790086746216 / Valid loss: 7.20814101809547
Training loss: 0.46205252408981323 / Valid loss: 7.154033719925653
Training loss: 0.7866871356964111 / Valid loss: 7.344131051926386
Training loss: 0.5544046759605408 / Valid loss: 7.448732548668271

Epoch: 25
Training loss: 0.5156476497650146 / Valid loss: 7.475396823883057
Training loss: 0.8292311429977417 / Valid loss: 7.285971968514579
Training loss: 0.8615312576293945 / Valid loss: 7.78051589784168
Training loss: 0.7361618876457214 / Valid loss: 7.462147490183512
Training loss: 0.7221405506134033 / Valid loss: 7.307742736453101

Epoch: 26
Training loss: 0.7038989067077637 / Valid loss: 7.061876887366886
Training loss: 0.6476266384124756 / Valid loss: 7.344306836809431
Training loss: 0.9572669267654419 / Valid loss: 7.69780109042213
Training loss: 0.58519446849823 / Valid loss: 7.353885945819673
Training loss: 1.2713624238967896 / Valid loss: 7.315994453430176

Epoch: 27
Training loss: 0.7807352542877197 / Valid loss: 7.120951389131092
Training loss: 0.5888660550117493 / Valid loss: 7.162556266784668
Training loss: 1.1513261795043945 / Valid loss: 7.4645621118091405
Training loss: 0.6299579739570618 / Valid loss: 7.43074598312378
Training loss: 0.6557662487030029 / Valid loss: 7.227800323849633

Epoch: 28
Training loss: 0.41298818588256836 / Valid loss: 7.119118032001314
Training loss: 0.43777579069137573 / Valid loss: 7.354726391746884
Training loss: 0.4716600477695465 / Valid loss: 7.99610416775658
Training loss: 0.6314114332199097 / Valid loss: 7.078541460491362
Training loss: 1.1770925521850586 / Valid loss: 7.222543339502244

Epoch: 29
Training loss: 0.6416466236114502 / Valid loss: 7.34916904540289
Training loss: 0.6902791857719421 / Valid loss: 7.111364568982806
Training loss: 0.6994762420654297 / Valid loss: 7.244328544253395
Training loss: 0.7707122564315796 / Valid loss: 7.413461916787284

Epoch: 30
Training loss: 0.6069107055664062 / Valid loss: 7.453847176688058
Training loss: 0.7636231184005737 / Valid loss: 7.141518506549653
Training loss: 0.511724054813385 / Valid loss: 7.313784290495373
Training loss: 0.6689708232879639 / Valid loss: 7.161179801395961
Training loss: 0.907219409942627 / Valid loss: 7.149088033040365

Epoch: 31
Training loss: 0.6110581159591675 / Valid loss: 7.229555370694115
Training loss: 1.2116092443466187 / Valid loss: 7.111853227161226
Training loss: 0.5267805457115173 / Valid loss: 7.169793283371698
Training loss: 0.7051632404327393 / Valid loss: 7.160288174947103
Training loss: 0.6829876899719238 / Valid loss: 7.180893857138497

Epoch: 32
Training loss: 0.3825839161872864 / Valid loss: 7.33749790645781
Training loss: 0.7912479043006897 / Valid loss: 7.228892115184239
Training loss: 0.6457353830337524 / Valid loss: 7.2153769311450775
Training loss: 0.4847678542137146 / Valid loss: 7.163332421439034
Training loss: 0.7592740058898926 / Valid loss: 7.037824826013474

Epoch: 33
Training loss: 0.6569952964782715 / Valid loss: 7.363598564692906
Training loss: 0.5387163758277893 / Valid loss: 7.18000347046625
Training loss: 0.7276545763015747 / Valid loss: 7.176579316457112
Training loss: 0.5158270597457886 / Valid loss: 7.227270716712589
Training loss: 0.6318497657775879 / Valid loss: 7.346579983120873

Epoch: 34
Training loss: 1.086794376373291 / Valid loss: 7.08503270149231
Training loss: 0.5708376169204712 / Valid loss: 7.116807065691266
Training loss: 0.5285670161247253 / Valid loss: 7.323873410906111
Training loss: 0.3875619173049927 / Valid loss: 7.180259091513498
Training loss: 1.0102839469909668 / Valid loss: 7.2381551015944705

Epoch: 35
Training loss: 0.5422807335853577 / Valid loss: 7.133153815496535
Training loss: 0.6607768535614014 / Valid loss: 7.2577286720275875
Training loss: 0.698561429977417 / Valid loss: 7.008691828591483
Training loss: 0.5954948663711548 / Valid loss: 7.218351636614118
Training loss: 0.5661472082138062 / Valid loss: 7.439202136085147

Epoch: 36
Training loss: 0.5922322869300842 / Valid loss: 7.027229204631987
Training loss: 0.4568168520927429 / Valid loss: 7.049499579838344
Training loss: 0.45074331760406494 / Valid loss: 7.080278451102121
Training loss: 0.9973118305206299 / Valid loss: 7.242448920295352
Training loss: 0.4830131530761719 / Valid loss: 7.197138232276553

Epoch: 37
Training loss: 0.5621105432510376 / Valid loss: 7.082863237744286
Training loss: 0.27124953269958496 / Valid loss: 7.125073641822452
Training loss: 0.4519268870353699 / Valid loss: 7.367381536392939
Training loss: 0.549884557723999 / Valid loss: 7.308317688533238
Training loss: 0.5428293943405151 / Valid loss: 7.16598939214434

Epoch: 38
Training loss: 0.4919784665107727 / Valid loss: 7.122518398648217
Training loss: 0.643317461013794 / Valid loss: 7.012989212217785
Training loss: 0.34803566336631775 / Valid loss: 7.0535520054045175
Training loss: 0.726897120475769 / Valid loss: 7.0877756482078915
Training loss: 1.1165282726287842 / Valid loss: 7.308023162115187

Epoch: 39
Training loss: 0.4511013925075531 / Valid loss: 7.21346648534139
Training loss: 0.4847315549850464 / Valid loss: 7.009142866588774
Training loss: 0.463386207818985 / Valid loss: 7.124725173768543
Training loss: 0.4445492625236511 / Valid loss: 7.365290523710705

Epoch: 40
Training loss: 0.45202410221099854 / Valid loss: 7.241439133598691
Training loss: 0.5226269960403442 / Valid loss: 7.144638597397577
Training loss: 0.6386280655860901 / Valid loss: 7.308258394967942
Training loss: 0.3442544639110565 / Valid loss: 7.22587224869501
Training loss: 0.4551568031311035 / Valid loss: 7.191685431344169

Epoch: 41
Training loss: 0.7065168619155884 / Valid loss: 7.2232937903631305
Training loss: 0.47886040806770325 / Valid loss: 7.126238191695441
Training loss: 0.6865750551223755 / Valid loss: 7.111755089532761
Training loss: 0.7259320616722107 / Valid loss: 7.171722017015729
Training loss: 0.4781244993209839 / Valid loss: 7.152496619451614

Epoch: 42
Training loss: 0.7617793679237366 / Valid loss: 7.324396828242711
Training loss: 0.45760804414749146 / Valid loss: 7.13462883404323
Training loss: 0.4986814260482788 / Valid loss: 7.11845984231858
Training loss: 0.6871617436408997 / Valid loss: 7.128456774212065
Training loss: 0.5502153635025024 / Valid loss: 7.097304748353504

Epoch: 43
Training loss: 0.3075898289680481 / Valid loss: 7.035324310121082
Training loss: 0.6175771951675415 / Valid loss: 7.201313046046666
Training loss: 0.5469199419021606 / Valid loss: 7.046229521433513
Training loss: 0.8807899355888367 / Valid loss: 7.072286932809012
Training loss: 0.42576995491981506 / Valid loss: 7.1356869901929585

Epoch: 44
Training loss: 0.8264761567115784 / Valid loss: 7.027447191874186
Training loss: 0.47436365485191345 / Valid loss: 6.986507363546462
Training loss: 0.30904608964920044 / Valid loss: 7.082839125678653
Training loss: 0.49671924114227295 / Valid loss: 7.045296260288784
Training loss: 0.4266201853752136 / Valid loss: 7.200265430268788

Epoch: 45
Training loss: 0.3420593738555908 / Valid loss: 6.96892716544015
Training loss: 0.8866965770721436 / Valid loss: 7.148566318693615
Training loss: 0.35008201003074646 / Valid loss: 6.970427703857422
Training loss: 0.6675114631652832 / Valid loss: 7.384948071979341
Training loss: 0.5537742376327515 / Valid loss: 7.047464302607945

Epoch: 46
Training loss: 0.6529148817062378 / Valid loss: 7.1688273202805295
Training loss: 0.5061618089675903 / Valid loss: 7.163072449820382
Training loss: 0.6972137689590454 / Valid loss: 7.150724220275879
Training loss: 0.7101724147796631 / Valid loss: 7.026378511247181
Training loss: 0.6430104374885559 / Valid loss: 7.159938753218878

Epoch: 47
Training loss: 0.49502456188201904 / Valid loss: 7.040430009932745
Training loss: 0.4982181787490845 / Valid loss: 7.107279241652716
Training loss: 0.35492444038391113 / Valid loss: 7.037732487633114
Training loss: 0.43151891231536865 / Valid loss: 7.147330906277611
Training loss: 0.4847729206085205 / Valid loss: 7.071575405484154

Epoch: 48
Training loss: 0.27018654346466064 / Valid loss: 7.036653627668108
Training loss: 0.36150795221328735 / Valid loss: 7.017284452347528
Training loss: 0.3678377866744995 / Valid loss: 7.058952497300647
Training loss: 0.7507993578910828 / Valid loss: 7.0929675283886136
Training loss: 0.456179678440094 / Valid loss: 6.9518960680280415

Epoch: 49
Training loss: 0.2753407955169678 / Valid loss: 7.013061618804931
Training loss: 0.6004347801208496 / Valid loss: 7.010322670709519
Training loss: 0.47834494709968567 / Valid loss: 7.176775019509452
Training loss: 0.43288880586624146 / Valid loss: 6.969916341418312

Epoch: 50
Training loss: 0.6398549675941467 / Valid loss: 7.155411965506417
Training loss: 0.21087896823883057 / Valid loss: 7.015075522377377
Training loss: 0.47761380672454834 / Valid loss: 7.030651160648891
Training loss: 0.4658735990524292 / Valid loss: 7.119956384386335
Training loss: 0.5717582702636719 / Valid loss: 7.1401199613298685

Epoch: 51
Training loss: 0.27227944135665894 / Valid loss: 7.056218115488688
Training loss: 0.3525180220603943 / Valid loss: 7.062676191329956
Training loss: 0.29828858375549316 / Valid loss: 7.10890611239842
Training loss: 0.6419237852096558 / Valid loss: 6.994474794751122
Training loss: 0.38082852959632874 / Valid loss: 7.020949272882371

Epoch: 52
Training loss: 0.4377608299255371 / Valid loss: 7.288638496398926
Training loss: 0.5702860355377197 / Valid loss: 7.012761878967285
Training loss: 0.3298307955265045 / Valid loss: 7.072763413474673
Training loss: 0.40358343720436096 / Valid loss: 6.964393665677025
Training loss: 0.2835208773612976 / Valid loss: 7.071341217131842

Epoch: 53
Training loss: 0.258201539516449 / Valid loss: 7.037922187078567
Training loss: 0.5239429473876953 / Valid loss: 6.981756982349214
Training loss: 0.606478750705719 / Valid loss: 7.054035604567755
Training loss: 0.45224469900131226 / Valid loss: 7.108963498615084
Training loss: 0.5302600860595703 / Valid loss: 7.032810974121094

Epoch: 54
Training loss: 0.38682764768600464 / Valid loss: 6.952868289039248
Training loss: 0.4749545753002167 / Valid loss: 6.966437998272124
Training loss: 0.5553140640258789 / Valid loss: 6.9668349992661245
Training loss: 0.2824774980545044 / Valid loss: 6.988076141902378
Training loss: 0.4488731026649475 / Valid loss: 7.133093706766764

Epoch: 55
Training loss: 0.31159764528274536 / Valid loss: 7.07416711080642
Training loss: 0.5596600770950317 / Valid loss: 7.013049202873593
Training loss: 0.5967314839363098 / Valid loss: 7.322330910818917
Training loss: 0.47165587544441223 / Valid loss: 6.9973256837754025
Training loss: 0.4763718545436859 / Valid loss: 7.260624099913097

Epoch: 56
Training loss: 0.45819953083992004 / Valid loss: 7.085880779084706
Training loss: 0.5259650349617004 / Valid loss: 6.970075902484712
Training loss: 0.39335960149765015 / Valid loss: 7.039112231844947
Training loss: 0.7469370365142822 / Valid loss: 7.470507476443336
Training loss: 0.4261351227760315 / Valid loss: 6.947467676798502

Epoch: 57
Training loss: 0.4736180603504181 / Valid loss: 6.878905487060547
Training loss: 0.5690332651138306 / Valid loss: 7.163592842647008
Training loss: 0.513219952583313 / Valid loss: 6.946059254237584
Training loss: 0.26179054379463196 / Valid loss: 6.9952223596118746
Training loss: 0.5697572231292725 / Valid loss: 7.081601111094157

Epoch: 58
Training loss: 0.3897135853767395 / Valid loss: 7.003435707092285
Training loss: 0.3321106433868408 / Valid loss: 7.03394813083467
Training loss: 0.4388018846511841 / Valid loss: 7.236183824993315
Training loss: 0.8321757912635803 / Valid loss: 7.134012812659854
Training loss: 0.4530526399612427 / Valid loss: 6.9854107765924365

Epoch: 59
Training loss: 0.22599691152572632 / Valid loss: 7.048785695575533
Training loss: 0.5570465326309204 / Valid loss: 7.003894705999465
Training loss: 0.3441157341003418 / Valid loss: 6.965288489205497
Training loss: 0.5910089015960693 / Valid loss: 6.988416639963786

Epoch: 60
Training loss: 0.3341352045536041 / Valid loss: 6.969937133789062
Training loss: 0.3152007758617401 / Valid loss: 6.969795592625936
Training loss: 0.624103307723999 / Valid loss: 6.954853471120199
Training loss: 0.3885156810283661 / Valid loss: 6.894863596416655
Training loss: 0.6573306322097778 / Valid loss: 6.967922013146537

Epoch: 61
Training loss: 0.3088635802268982 / Valid loss: 6.989152288436889
Training loss: 0.4686639606952667 / Valid loss: 6.929276784261067
Training loss: 0.5977362394332886 / Valid loss: 7.013901111057827
Training loss: 0.34330540895462036 / Valid loss: 7.0133185954321
Training loss: 0.3867443799972534 / Valid loss: 6.996802137011573

Epoch: 62
Training loss: 0.586713433265686 / Valid loss: 6.92028500693185
Training loss: 0.3141574263572693 / Valid loss: 6.928930425643921
Training loss: 0.308591365814209 / Valid loss: 7.0722944486708865
Training loss: 0.2859155535697937 / Valid loss: 7.011005415235247
Training loss: 0.6395134329795837 / Valid loss: 6.9650743915921165

Epoch: 63
Training loss: 0.5459712147712708 / Valid loss: 7.0308430285680865
Training loss: 0.4036872982978821 / Valid loss: 6.956458940960112
Training loss: 0.2526402473449707 / Valid loss: 7.02210073244004
Training loss: 0.44262000918388367 / Valid loss: 6.925826831091018
Training loss: 0.24483180046081543 / Valid loss: 7.1129485084896995

Epoch: 64
Training loss: 0.44801974296569824 / Valid loss: 6.939092813219343
Training loss: 0.3049088716506958 / Valid loss: 6.95027577082316
Training loss: 0.635897159576416 / Valid loss: 7.3215091546376545
Training loss: 0.5658682584762573 / Valid loss: 7.109311076572963
Training loss: 0.4639277458190918 / Valid loss: 6.941725381215414

Epoch: 65
Training loss: 0.9411354064941406 / Valid loss: 6.877575608662196
Training loss: 1.1633596420288086 / Valid loss: 6.944272717975434
Training loss: 0.377089262008667 / Valid loss: 6.977872980208624
Training loss: 0.795689582824707 / Valid loss: 6.908926591419038
Training loss: 0.2605937123298645 / Valid loss: 6.885127362750826

Epoch: 66
Training loss: 0.30086153745651245 / Valid loss: 6.886170568920317
Training loss: 0.40451759099960327 / Valid loss: 7.144439597356887
Training loss: 0.36003994941711426 / Valid loss: 6.966322492417835
Training loss: 0.3850792646408081 / Valid loss: 7.097378360657465
Training loss: 0.3733210563659668 / Valid loss: 6.87463477452596

Epoch: 67
Training loss: 0.21636873483657837 / Valid loss: 6.90333472206479
Training loss: 0.43091338872909546 / Valid loss: 6.920532576243082
Training loss: 0.7777900695800781 / Valid loss: 7.065713650839669
Training loss: 0.661109209060669 / Valid loss: 6.932679564612252
Training loss: 0.6401811838150024 / Valid loss: 6.929963461558024

Epoch: 68
Training loss: 0.3620857000350952 / Valid loss: 6.943323584965297
Training loss: 0.5161527991294861 / Valid loss: 7.013494600568499
Training loss: 0.51920485496521 / Valid loss: 6.92927482241676
Training loss: 0.4027827978134155 / Valid loss: 7.299617674237206
Training loss: 0.5851914882659912 / Valid loss: 6.995905499231248

Epoch: 69
Training loss: 0.5102679133415222 / Valid loss: 6.931759720756894
Training loss: 0.35859107971191406 / Valid loss: 6.987565154121036
Training loss: 0.3174092769622803 / Valid loss: 6.930487714494977
Training loss: 0.4574441611766815 / Valid loss: 6.8980596633184526

Epoch: 70
Training loss: 0.21549147367477417 / Valid loss: 6.858073627381097
Training loss: 0.4773949980735779 / Valid loss: 6.899029563722157
Training loss: 0.332181841135025 / Valid loss: 6.9863540513174875
Training loss: 0.3444325029850006 / Valid loss: 6.895694941566104
Training loss: 0.6115494966506958 / Valid loss: 7.168878346397763

Epoch: 71
Training loss: 0.41298243403434753 / Valid loss: 6.930273855300177
Training loss: 0.5340926051139832 / Valid loss: 6.881347174871536
Training loss: 0.36314141750335693 / Valid loss: 7.0320531935918895
Training loss: 0.27534911036491394 / Valid loss: 6.9586777550833565
Training loss: 0.39936214685440063 / Valid loss: 6.960580828076317

Epoch: 72
Training loss: 0.4996528923511505 / Valid loss: 6.8484534218197775
Training loss: 0.5640343427658081 / Valid loss: 6.841601712363107
Training loss: 0.31787440180778503 / Valid loss: 6.886362829662505
Training loss: 0.4020787179470062 / Valid loss: 6.9385406743912466
Training loss: 0.21433036029338837 / Valid loss: 6.998402198155721

Epoch: 73
Training loss: 0.5399027466773987 / Valid loss: 6.8421027410598025
Training loss: 0.46963584423065186 / Valid loss: 6.833613436562675
Training loss: 0.3449285924434662 / Valid loss: 6.847335415794736
Training loss: 0.2890165448188782 / Valid loss: 6.935156399863107
Training loss: 0.30915942788124084 / Valid loss: 7.01912723722912

Epoch: 74
Training loss: 0.4862862229347229 / Valid loss: 6.803499902997698
Training loss: 0.3316352069377899 / Valid loss: 6.944031992412749
Training loss: 0.5862665772438049 / Valid loss: 6.920544065747943
Training loss: 0.35017457604408264 / Valid loss: 6.90197186697097
Training loss: 0.230460524559021 / Valid loss: 6.8949984959193635

Epoch: 75
Training loss: 0.2228798270225525 / Valid loss: 6.860292995543707
Training loss: 0.34770452976226807 / Valid loss: 6.871143073127383
Training loss: 0.29460611939430237 / Valid loss: 6.816111410231818
Training loss: 0.27753210067749023 / Valid loss: 7.014367355619158
Training loss: 0.29548323154449463 / Valid loss: 7.030014178866431

Epoch: 76
Training loss: 0.2652123272418976 / Valid loss: 6.852843588874453
Training loss: 0.2907682955265045 / Valid loss: 7.168153117951893
Training loss: 0.1940714418888092 / Valid loss: 6.916398488907587
Training loss: 0.21328246593475342 / Valid loss: 6.9397598629906065
Training loss: 0.26449257135391235 / Valid loss: 6.904409458523705

Epoch: 77
Training loss: 0.40026941895484924 / Valid loss: 6.863991405850365
Training loss: 0.35160526633262634 / Valid loss: 6.9086152303786506
Training loss: 0.5304797887802124 / Valid loss: 6.877050572349912
Training loss: 0.36032170057296753 / Valid loss: 6.8987294333321705
Training loss: 0.4589739441871643 / Valid loss: 6.882414291018532

Epoch: 78
Training loss: 0.41137853264808655 / Valid loss: 6.945145629701161
Training loss: 0.8287795782089233 / Valid loss: 6.840659477597192
Training loss: 0.7622877955436707 / Valid loss: 7.012321540287563
Training loss: 0.3995341956615448 / Valid loss: 6.981730851672944
Training loss: 0.30614280700683594 / Valid loss: 6.916827460697719

Epoch: 79
Training loss: 0.2953917384147644 / Valid loss: 6.852517109825498
Training loss: 0.5810561180114746 / Valid loss: 6.950403908320836
Training loss: 0.3747260868549347 / Valid loss: 6.965258784521193
Training loss: 0.4440107047557831 / Valid loss: 6.862849934895833
ModuleList(
  (0): Linear(in_features=5376, out_features=300, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=300, out_features=32, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=32, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.326435997372582
Training regression with following parameters:
dnn_hidden_units : 248
dropout_probs : 0.0, 0.0
learning_rate : 0.001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : Adam
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : Bert
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=5376, out_features=248, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=248, out_features=1, bias=True)
)

Epoch: 0
Training loss: 20.62260627746582 / Valid loss: 13.353901926676432
Model is saved in epoch 0, overall batch: 0
Training loss: 6.209975242614746 / Valid loss: 5.938352648417155
Model is saved in epoch 0, overall batch: 100
Training loss: 6.657140731811523 / Valid loss: 5.6690251191457115
Model is saved in epoch 0, overall batch: 200
Training loss: 6.0860395431518555 / Valid loss: 5.649145680382138
Model is saved in epoch 0, overall batch: 300
Training loss: 8.649901390075684 / Valid loss: 5.861468551272438

Epoch: 1
Training loss: 5.354130268096924 / Valid loss: 5.59403352964492
Model is saved in epoch 1, overall batch: 500
Training loss: 5.722609043121338 / Valid loss: 5.7675690696353
Training loss: 6.917623996734619 / Valid loss: 5.58025381224496
Model is saved in epoch 1, overall batch: 700
Training loss: 6.027001857757568 / Valid loss: 5.6938111713954385
Training loss: 4.933468818664551 / Valid loss: 5.548583309991019
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 5.002928733825684 / Valid loss: 5.560127944038028
Training loss: 4.732935428619385 / Valid loss: 5.796114880698068
Training loss: 5.594146728515625 / Valid loss: 5.606353044509888
Training loss: 5.822414398193359 / Valid loss: 5.567305113020398
Training loss: 5.537273406982422 / Valid loss: 5.647305052621024

Epoch: 3
Training loss: 3.823054790496826 / Valid loss: 5.718273623784383
Training loss: 5.049328327178955 / Valid loss: 5.771990489959717
Training loss: 4.427206993103027 / Valid loss: 5.645728370121547
Training loss: 5.798254013061523 / Valid loss: 5.899954305376325
Training loss: 4.720412731170654 / Valid loss: 5.590448318208967

Epoch: 4
Training loss: 3.5838117599487305 / Valid loss: 5.629602745601109
Training loss: 4.065610885620117 / Valid loss: 5.675910640898205
Training loss: 4.036846160888672 / Valid loss: 5.795170277640933
Training loss: 4.963386535644531 / Valid loss: 5.828781543459211
Training loss: 7.163593292236328 / Valid loss: 5.716830062866211

Epoch: 5
Training loss: 3.495128631591797 / Valid loss: 5.864151777539934
Training loss: 3.4888532161712646 / Valid loss: 5.985439121155512
Training loss: 5.383694171905518 / Valid loss: 5.796123275302706
Training loss: 5.574288368225098 / Valid loss: 5.7908525535038535
Training loss: 6.91278076171875 / Valid loss: 6.362708786555699

Epoch: 6
Training loss: 4.081301212310791 / Valid loss: 5.947946185157413
Training loss: 3.5470738410949707 / Valid loss: 6.112155589603242
Training loss: 3.9780189990997314 / Valid loss: 5.8611877850123815
Training loss: 3.7408461570739746 / Valid loss: 6.07342255456107
Training loss: 3.112643003463745 / Valid loss: 5.89337387084961

Epoch: 7
Training loss: 2.6231627464294434 / Valid loss: 6.299786426907494
Training loss: 3.2061967849731445 / Valid loss: 6.275726904187883
Training loss: 3.86448335647583 / Valid loss: 6.139255510057722
Training loss: 4.203969478607178 / Valid loss: 6.142242656435285
Training loss: 4.170599937438965 / Valid loss: 6.186718143735614

Epoch: 8
Training loss: 3.2431578636169434 / Valid loss: 6.097833229246594
Training loss: 3.1231181621551514 / Valid loss: 6.105267070588612
Training loss: 4.691348075866699 / Valid loss: 6.269008257275536
Training loss: 3.699998140335083 / Valid loss: 6.730023118427821
Training loss: 3.2538070678710938 / Valid loss: 6.1342928568522135

Epoch: 9
Training loss: 3.135190010070801 / Valid loss: 6.307549242746262
Training loss: 3.7118332386016846 / Valid loss: 6.331766183035715
Training loss: 3.276899814605713 / Valid loss: 6.390090951465425
Training loss: 2.7179970741271973 / Valid loss: 6.393450441814604

Epoch: 10
Training loss: 2.623319149017334 / Valid loss: 6.388538560413179
Training loss: 2.446528911590576 / Valid loss: 6.383131576719738
Training loss: 2.99037504196167 / Valid loss: 6.476015390668596
Training loss: 2.648900032043457 / Valid loss: 6.372207532610212
Training loss: 3.119591474533081 / Valid loss: 7.101990036737352

Epoch: 11
Training loss: 2.794438362121582 / Valid loss: 7.4222832180204845
Training loss: 3.086254119873047 / Valid loss: 6.433704662322998
Training loss: 2.5391359329223633 / Valid loss: 7.5088509150913785
Training loss: 2.289174795150757 / Valid loss: 6.638603444326492
Training loss: 2.4202117919921875 / Valid loss: 6.719487567175002

Epoch: 12
Training loss: 2.5406594276428223 / Valid loss: 6.571852020990281
Training loss: 2.29537296295166 / Valid loss: 6.831959760756719
Training loss: 2.6605772972106934 / Valid loss: 6.773806095123291
Training loss: 2.3508501052856445 / Valid loss: 6.685031613849458
Training loss: 1.8600953817367554 / Valid loss: 6.736945224943615

Epoch: 13
Training loss: 2.169264793395996 / Valid loss: 6.714530447551183
Training loss: 1.85466468334198 / Valid loss: 6.9217297622135705
Training loss: 1.8603324890136719 / Valid loss: 7.396646767570859
Training loss: 1.9070500135421753 / Valid loss: 7.847225057511102
Training loss: 2.4426047801971436 / Valid loss: 7.129623226892381

Epoch: 14
Training loss: 1.9278308153152466 / Valid loss: 6.922301387786865
Training loss: 2.11203670501709 / Valid loss: 6.949532211394537
Training loss: 3.0372304916381836 / Valid loss: 6.890346735999698
Training loss: 2.2642130851745605 / Valid loss: 7.275088755289714
Training loss: 2.5430150032043457 / Valid loss: 7.476728898002988

Epoch: 15
Training loss: 1.373929738998413 / Valid loss: 6.961266086215065
Training loss: 2.4511141777038574 / Valid loss: 7.026880073547363
Training loss: 2.445409059524536 / Valid loss: 8.350712780725388
Training loss: 2.4700307846069336 / Valid loss: 7.113895016624814
Training loss: 1.7969317436218262 / Valid loss: 7.122629224686396

Epoch: 16
Training loss: 2.596043348312378 / Valid loss: 6.9939536957513715
Training loss: 1.7437063455581665 / Valid loss: 8.004189123426166
Training loss: 1.6254961490631104 / Valid loss: 7.436525594620478
Training loss: 2.5185835361480713 / Valid loss: 7.342761162349156
Training loss: 1.4941606521606445 / Valid loss: 8.309204705556233

Epoch: 17
Training loss: 1.6409211158752441 / Valid loss: 7.214138071877616
Training loss: 1.2705012559890747 / Valid loss: 7.644867747170585
Training loss: 1.8458242416381836 / Valid loss: 7.874201706477574
Training loss: 3.477997303009033 / Valid loss: 7.342672967910767
Training loss: 2.2723419666290283 / Valid loss: 7.704221798124768

Epoch: 18
Training loss: 1.8978021144866943 / Valid loss: 7.157495171683175
Training loss: 1.3347320556640625 / Valid loss: 7.3198031834193635
Training loss: 1.764765977859497 / Valid loss: 7.297768983386812
Training loss: 1.5336369276046753 / Valid loss: 7.377617758796329
Training loss: 2.1466546058654785 / Valid loss: 7.292234021141415

Epoch: 19
Training loss: 1.0225752592086792 / Valid loss: 7.458514318012056
Training loss: 1.466169834136963 / Valid loss: 7.536269351414272
Training loss: 1.7080810070037842 / Valid loss: 7.785770743233817
Training loss: 1.3061950206756592 / Valid loss: 7.79887417838687

Epoch: 20
Training loss: 1.3851466178894043 / Valid loss: 8.025678848084949
Training loss: 1.3684251308441162 / Valid loss: 7.481879938216436
Training loss: 1.4538863897323608 / Valid loss: 7.5011401358104886
Training loss: 0.9436802864074707 / Valid loss: 7.817584959665934
Training loss: 1.331653118133545 / Valid loss: 7.5005481220427015

Epoch: 21
Training loss: 1.1871711015701294 / Valid loss: 7.52879284449986
Training loss: 1.7626593112945557 / Valid loss: 7.457590589069185
Training loss: 1.2830915451049805 / Valid loss: 7.312341181437175
Training loss: 1.9131709337234497 / Valid loss: 7.491423802148728
Training loss: 1.3186510801315308 / Valid loss: 7.755304363795689

Epoch: 22
Training loss: 1.1764731407165527 / Valid loss: 8.564026296706427
Training loss: 1.4083671569824219 / Valid loss: 7.582614090329125
Training loss: 1.5111618041992188 / Valid loss: 8.225541932242256
Training loss: 1.6248233318328857 / Valid loss: 7.537430240994408
Training loss: 1.3273184299468994 / Valid loss: 7.634362011864072

Epoch: 23
Training loss: 0.7913104295730591 / Valid loss: 8.049646250406902
Training loss: 1.5149190425872803 / Valid loss: 8.403768825531007
Training loss: 1.2592211961746216 / Valid loss: 7.522228835877918
Training loss: 1.1059577465057373 / Valid loss: 7.388544963655018
Training loss: 0.8670718669891357 / Valid loss: 7.570934763408842

Epoch: 24
Training loss: 0.9996305108070374 / Valid loss: 7.698445188431513
Training loss: 1.3092812299728394 / Valid loss: 7.537623573484875
Training loss: 1.0210673809051514 / Valid loss: 7.474541237240746
Training loss: 0.7686432600021362 / Valid loss: 7.5173091797601606
Training loss: 1.112255573272705 / Valid loss: 8.002359326680502

Epoch: 25
Training loss: 0.8525614738464355 / Valid loss: 7.529256339300247
Training loss: 0.9037367701530457 / Valid loss: 7.58769854363941
Training loss: 1.4796773195266724 / Valid loss: 7.671196210952032
Training loss: 1.0481916666030884 / Valid loss: 7.62433446702503
Training loss: 1.2217562198638916 / Valid loss: 7.451361833299909

Epoch: 26
Training loss: 0.8761177659034729 / Valid loss: 7.406520384833926
Training loss: 0.7000260353088379 / Valid loss: 7.482192856924875
Training loss: 0.7811130285263062 / Valid loss: 7.611166590736026
Training loss: 0.8605505228042603 / Valid loss: 8.093085833958217
Training loss: 0.7834279537200928 / Valid loss: 7.438080506097703

Epoch: 27
Training loss: 0.893368124961853 / Valid loss: 7.428994260515485
Training loss: 1.0406368970870972 / Valid loss: 7.525310888744536
Training loss: 1.1294852495193481 / Valid loss: 7.588510209038144
Training loss: 0.8173052072525024 / Valid loss: 8.362544295901344
Training loss: 1.0240179300308228 / Valid loss: 7.515252985273089

Epoch: 28
Training loss: 0.602420449256897 / Valid loss: 7.567193794250488
Training loss: 0.7199393510818481 / Valid loss: 7.672983060564314
Training loss: 0.7237443923950195 / Valid loss: 7.517080683935256
Training loss: 1.1661889553070068 / Valid loss: 7.546648777098882
Training loss: 1.3271983861923218 / Valid loss: 8.093311332520985

Epoch: 29
Training loss: 0.7113842964172363 / Valid loss: 7.613020615350632
Training loss: 0.7784661054611206 / Valid loss: 7.6118932088216145
Training loss: 0.7533011436462402 / Valid loss: 7.628197188604446
Training loss: 0.8483590483665466 / Valid loss: 7.553379849025181

Epoch: 30
Training loss: 0.7243969440460205 / Valid loss: 7.498639942350842
Training loss: 0.8754979372024536 / Valid loss: 7.930885056086949
Training loss: 0.6403606534004211 / Valid loss: 8.651221951984224
Training loss: 0.8927487730979919 / Valid loss: 8.568883932204473
Training loss: 0.7910208702087402 / Valid loss: 9.489842210497175

Epoch: 31
Training loss: 0.8403601050376892 / Valid loss: 7.560801783062163
Training loss: 0.7941187620162964 / Valid loss: 7.754811275573004
Training loss: 0.9217752814292908 / Valid loss: 7.484380753835042
Training loss: 0.7902774810791016 / Valid loss: 7.720435001736596
Training loss: 0.8364449143409729 / Valid loss: 7.565843068985712

Epoch: 32
Training loss: 0.6388891935348511 / Valid loss: 7.465995143708729
Training loss: 0.5080510377883911 / Valid loss: 7.5541713941664925
Training loss: 0.744195818901062 / Valid loss: 8.16216893877302
Training loss: 0.8352315425872803 / Valid loss: 7.465145960308257
Training loss: 0.7278221845626831 / Valid loss: 8.455036762782505

Epoch: 33
Training loss: 0.6818739175796509 / Valid loss: 7.6341467902773905
Training loss: 0.8490628004074097 / Valid loss: 7.84659484681629
Training loss: 0.7665888071060181 / Valid loss: 7.82878063746861
Training loss: 0.5771690607070923 / Valid loss: 8.203138455890475
Training loss: 0.7682756185531616 / Valid loss: 7.696637598673503

Epoch: 34
Training loss: 0.5671889185905457 / Valid loss: 8.131012471516927
Training loss: 0.9935504198074341 / Valid loss: 7.550223091670445
Training loss: 0.571969747543335 / Valid loss: 7.703635115850539
Training loss: 0.7800058126449585 / Valid loss: 7.617918677557082
Training loss: 0.8880445957183838 / Valid loss: 7.4995071547372

Epoch: 35
Training loss: 0.6003599762916565 / Valid loss: 7.526818466186524
Training loss: 0.7571032047271729 / Valid loss: 7.623536445980981
Training loss: 0.6221694946289062 / Valid loss: 7.573490047454834
Training loss: 0.7256249189376831 / Valid loss: 7.56898483094715
Training loss: 0.812381386756897 / Valid loss: 7.518256832304455

Epoch: 36
Training loss: 0.8720254898071289 / Valid loss: 7.565527257465181
Training loss: 1.0495654344558716 / Valid loss: 7.523851083573841
Training loss: 0.64485764503479 / Valid loss: 7.680352015722366
Training loss: 0.6913378238677979 / Valid loss: 7.600678443908691
Training loss: 0.823438286781311 / Valid loss: 7.519838174184163

Epoch: 37
Training loss: 1.0217512845993042 / Valid loss: 8.063836878821963
Training loss: 0.794847309589386 / Valid loss: 7.64351148151216
Training loss: 1.0612019300460815 / Valid loss: 7.573200012388684
Training loss: 0.4978829324245453 / Valid loss: 7.538867895943778
Training loss: 0.8021085262298584 / Valid loss: 7.539363447825114

Epoch: 38
Training loss: 0.6747452616691589 / Valid loss: 8.160835901896158
Training loss: 0.8938506245613098 / Valid loss: 7.502346474783761
Training loss: 0.4844370484352112 / Valid loss: 7.557532437642416
Training loss: 0.834474503993988 / Valid loss: 7.594464756193615
Training loss: 0.7538855671882629 / Valid loss: 9.150615138099306

Epoch: 39
Training loss: 0.764763355255127 / Valid loss: 7.532930978139242
Training loss: 0.6772017478942871 / Valid loss: 7.522938278743199
Training loss: 0.5443825721740723 / Valid loss: 7.6536134946913945
Training loss: 0.3740144371986389 / Valid loss: 7.563319456009638

Epoch: 40
Training loss: 0.40613240003585815 / Valid loss: 7.580890392121814
Training loss: 0.7219766974449158 / Valid loss: 7.592285319737026
Training loss: 0.6322829723358154 / Valid loss: 7.910309596288772
Training loss: 0.6393642425537109 / Valid loss: 7.5259387425013955
Training loss: 0.779167890548706 / Valid loss: 7.487067672184535

Epoch: 41
Training loss: 0.5788890719413757 / Valid loss: 7.75743080774943
Training loss: 0.3988704979419708 / Valid loss: 7.474617149716332
Training loss: 0.5514578819274902 / Valid loss: 7.553475579761323
Training loss: 0.6046928763389587 / Valid loss: 7.679783716655913
Training loss: 0.7815932035446167 / Valid loss: 7.506122639065697

Epoch: 42
Training loss: 0.5262960195541382 / Valid loss: 7.740157649630592
Training loss: 0.7715356349945068 / Valid loss: 7.6576399394444055
Training loss: 0.5826473236083984 / Valid loss: 7.4507461956569125
Training loss: 0.6914682388305664 / Valid loss: 7.41436456044515
Training loss: 0.5831773281097412 / Valid loss: 7.48810719989595

Epoch: 43
Training loss: 0.6337589621543884 / Valid loss: 7.623062878563291
Training loss: 0.593593180179596 / Valid loss: 7.466857619512648
Training loss: 0.5104614496231079 / Valid loss: 7.4154830705551875
Training loss: 0.6542592644691467 / Valid loss: 9.107908716655913
Training loss: 0.49641355872154236 / Valid loss: 7.5298187505631216

Epoch: 44
Training loss: 0.5524061918258667 / Valid loss: 7.954023120516823
Training loss: 0.48450157046318054 / Valid loss: 7.903314749399821
Training loss: 0.5397012233734131 / Valid loss: 7.407194727943057
Training loss: 0.5569109916687012 / Valid loss: 7.969482589903332
Training loss: 0.681328535079956 / Valid loss: 7.501300584702265

Epoch: 45
Training loss: 0.5417355895042419 / Valid loss: 7.531317038763137
Training loss: 0.6261724829673767 / Valid loss: 7.5184781392415365
Training loss: 0.559485137462616 / Valid loss: 8.415679068792434
Training loss: 0.6586920619010925 / Valid loss: 7.769798110780262
Training loss: 0.328304648399353 / Valid loss: 7.482751110621861

Epoch: 46
Training loss: 0.5508260130882263 / Valid loss: 7.50960047131493
Training loss: 0.5291040539741516 / Valid loss: 7.469563257126581
Training loss: 0.6168185472488403 / Valid loss: 7.34770560718718
Training loss: 0.705290675163269 / Valid loss: 7.531135009583973
Training loss: 0.6773694157600403 / Valid loss: 7.5284033820742655

Epoch: 47
Training loss: 0.2954117953777313 / Valid loss: 7.6235265595572335
Training loss: 0.3477068841457367 / Valid loss: 7.463776951744443
Training loss: 0.43922460079193115 / Valid loss: 7.420777230035691
Training loss: 0.5324721336364746 / Valid loss: 7.738933890206473
Training loss: 0.58421391248703 / Valid loss: 8.156427283514114

Epoch: 48
Training loss: 0.6132097840309143 / Valid loss: 7.422133963448661
Training loss: 0.46294188499450684 / Valid loss: 7.61433470589774
Training loss: 0.6084787249565125 / Valid loss: 7.420159685044061
Training loss: 0.5458526611328125 / Valid loss: 7.680059328533354
Training loss: 0.4284780025482178 / Valid loss: 7.501597159249442

Epoch: 49
Training loss: 0.4777366518974304 / Valid loss: 7.703308827536446
Training loss: 0.6166287660598755 / Valid loss: 7.471202005658831
Training loss: 0.5129070281982422 / Valid loss: 7.434820170629592
Training loss: 0.7004848718643188 / Valid loss: 7.5322159540085565

Epoch: 50
Training loss: 0.49018365144729614 / Valid loss: 7.451570778801328
Training loss: 0.30985480546951294 / Valid loss: 7.664536998385475
Training loss: 0.41101422905921936 / Valid loss: 7.374521232786632
Training loss: 0.6328479647636414 / Valid loss: 7.320364693232945
Training loss: 0.49153122305870056 / Valid loss: 7.500949060349237

Epoch: 51
Training loss: 0.6557443141937256 / Valid loss: 7.3997209412711005
Training loss: 0.6895040273666382 / Valid loss: 7.361561598096575
Training loss: 0.5612908601760864 / Valid loss: 7.362642097473144
Training loss: 0.5313329100608826 / Valid loss: 7.472945994422549
Training loss: 0.7551156282424927 / Valid loss: 7.434838388079688

Epoch: 52
Training loss: 0.6412807106971741 / Valid loss: 7.745969990321568
Training loss: 0.5278929471969604 / Valid loss: 7.380203219822475
Training loss: 0.5199698805809021 / Valid loss: 7.631131176721482
Training loss: 0.6692668199539185 / Valid loss: 7.667203403654552
Training loss: 0.5555310845375061 / Valid loss: 7.3654548304421565

Epoch: 53
Training loss: 0.5723004341125488 / Valid loss: 7.319396827334449
Training loss: 0.46253275871276855 / Valid loss: 7.3674030803498765
Training loss: 0.8709276914596558 / Valid loss: 7.372212755112421
Training loss: 0.4894881248474121 / Valid loss: 7.594802935918172
Training loss: 0.8552794456481934 / Valid loss: 7.349572122664679

Epoch: 54
Training loss: 0.4862036108970642 / Valid loss: 7.3909163020905995
Training loss: 0.44767847657203674 / Valid loss: 7.401438849312918
Training loss: 0.6154769062995911 / Valid loss: 7.6404307774135045
Training loss: 0.6069607734680176 / Valid loss: 7.311006046476818
Training loss: 0.6109963655471802 / Valid loss: 7.594382513137091

Epoch: 55
Training loss: 0.4455103874206543 / Valid loss: 7.431194900331043
Training loss: 0.7544823288917542 / Valid loss: 7.443691757747105
Training loss: 0.7187867164611816 / Valid loss: 7.557792154947917
Training loss: 1.0444579124450684 / Valid loss: 7.463717151823498
Training loss: 0.5230802893638611 / Valid loss: 7.306065482185001

Epoch: 56
Training loss: 0.6105136275291443 / Valid loss: 7.662596866062709
Training loss: 0.47873154282569885 / Valid loss: 7.403126798357282
Training loss: 0.5975677967071533 / Valid loss: 7.450557676951091
Training loss: 0.48469093441963196 / Valid loss: 7.435563591548375
Training loss: 0.3202703595161438 / Valid loss: 7.670831239791143

Epoch: 57
Training loss: 0.3650924265384674 / Valid loss: 7.3045878455752415
Training loss: 0.4222967028617859 / Valid loss: 7.436734017871675
Training loss: 0.3200012445449829 / Valid loss: 7.4980136598859515
Training loss: 0.3159991502761841 / Valid loss: 7.361001714070638
Training loss: 0.32683542370796204 / Valid loss: 7.444204421270461

Epoch: 58
Training loss: 0.6410629153251648 / Valid loss: 7.6289667220342725
Training loss: 0.256954550743103 / Valid loss: 7.488431362878709
Training loss: 0.35518884658813477 / Valid loss: 7.384739598773774
Training loss: 0.5438058376312256 / Valid loss: 7.482475852966308
Training loss: 0.9724822640419006 / Valid loss: 7.573304353441511

Epoch: 59
Training loss: 0.37682199478149414 / Valid loss: 7.3214278993152435
Training loss: 0.348940908908844 / Valid loss: 7.318196137746175
Training loss: 0.3139793276786804 / Valid loss: 7.377735880443028
Training loss: 0.5559165477752686 / Valid loss: 7.948057174682617

Epoch: 60
Training loss: 0.6726424098014832 / Valid loss: 7.321264553070068
Training loss: 0.4443565607070923 / Valid loss: 7.24849112374442
Training loss: 0.4304170310497284 / Valid loss: 7.543290814899263
Training loss: 0.5442520380020142 / Valid loss: 7.292405750637963
Training loss: 0.3414258062839508 / Valid loss: 7.655455766405378

Epoch: 61
Training loss: 0.5159144401550293 / Valid loss: 7.698840808868408
Training loss: 0.8474655151367188 / Valid loss: 7.299232914334252
Training loss: 0.4603050947189331 / Valid loss: 7.561813794998896
Training loss: 0.4569946229457855 / Valid loss: 7.448968873705183
Training loss: 0.41661888360977173 / Valid loss: 7.5457995414733885

Epoch: 62
Training loss: 0.369986355304718 / Valid loss: 7.313317852928525
Training loss: 0.32597389817237854 / Valid loss: 7.263020951407296
Training loss: 0.45329147577285767 / Valid loss: 7.962377212161109
Training loss: 0.35650601983070374 / Valid loss: 7.233741814749582
Training loss: 0.4534306824207306 / Valid loss: 7.422263867514474

Epoch: 63
Training loss: 0.3249672055244446 / Valid loss: 7.36311677751087
Training loss: 0.4926829934120178 / Valid loss: 7.539996151697068
Training loss: 0.3386504352092743 / Valid loss: 7.52810731615339
Training loss: 0.3901705741882324 / Valid loss: 7.315370963868641
Training loss: 0.43495285511016846 / Valid loss: 7.418370215098063

Epoch: 64
Training loss: 0.5117467045783997 / Valid loss: 7.497722085316976
Training loss: 0.6501638293266296 / Valid loss: 7.400719833374024
Training loss: 0.3036997318267822 / Valid loss: 7.287291240692139
Training loss: 0.7174125909805298 / Valid loss: 7.245749314626058
Training loss: 0.7538111209869385 / Valid loss: 7.419943991161528

Epoch: 65
Training loss: 0.32629501819610596 / Valid loss: 7.234516865866524
Training loss: 0.40474647283554077 / Valid loss: 7.4057525180635
Training loss: 0.7527768015861511 / Valid loss: 7.373915790376209
Training loss: 0.5224199295043945 / Valid loss: 7.407852463495164
Training loss: 0.45590895414352417 / Valid loss: 7.581451075417655

Epoch: 66
Training loss: 0.4473847448825836 / Valid loss: 7.3335972649710515
Training loss: 0.38597699999809265 / Valid loss: 7.873803520202637
Training loss: 0.38724029064178467 / Valid loss: 7.297423196974255
Training loss: 0.31909024715423584 / Valid loss: 7.30829344249907
Training loss: 0.32784801721572876 / Valid loss: 7.312200732458205

Epoch: 67
Training loss: 0.5292161703109741 / Valid loss: 7.635357230050223
Training loss: 0.4221031069755554 / Valid loss: 7.556214055560884
Training loss: 0.37658199667930603 / Valid loss: 7.652301838284447
Training loss: 0.34254080057144165 / Valid loss: 7.2788311413356235
Training loss: 0.7050473690032959 / Valid loss: 7.446253445034936

Epoch: 68
Training loss: 0.5207086205482483 / Valid loss: 7.954557523273286
Training loss: 0.26184290647506714 / Valid loss: 7.379327492486863
Training loss: 0.4569396376609802 / Valid loss: 7.299937666030157
Training loss: 0.3198601007461548 / Valid loss: 7.229963152749198
Training loss: 0.5990797281265259 / Valid loss: 7.323185007912772

Epoch: 69
Training loss: 0.5651882886886597 / Valid loss: 8.233328860146658
Training loss: 0.3336310088634491 / Valid loss: 7.535447025299073
Training loss: 0.4808070659637451 / Valid loss: 7.42628976504008
Training loss: 0.572691023349762 / Valid loss: 8.192960071563721

Epoch: 70
Training loss: 0.29189881682395935 / Valid loss: 7.2757795061383925
Training loss: 0.3231908082962036 / Valid loss: 7.469738151913598
Training loss: 0.8980094790458679 / Valid loss: 7.229698135739281
Training loss: 0.4929410219192505 / Valid loss: 7.2034705570765905
Training loss: 0.3860655426979065 / Valid loss: 7.445477930704753

Epoch: 71
Training loss: 0.3015163540840149 / Valid loss: 7.483933196749006
Training loss: 0.8408895134925842 / Valid loss: 7.204848391669137
Training loss: 0.4915907680988312 / Valid loss: 7.280962271917434
Training loss: 0.5598665475845337 / Valid loss: 7.2754261016845705
Training loss: 0.40390545129776 / Valid loss: 7.439493311019171

Epoch: 72
Training loss: 0.4594185948371887 / Valid loss: 7.731753149486724
Training loss: 0.2931280732154846 / Valid loss: 7.3940115156627835
Training loss: 0.23598362505435944 / Valid loss: 7.199164790198917
Training loss: 0.5385138392448425 / Valid loss: 7.467432448977516
Training loss: 0.41393762826919556 / Valid loss: 7.251748766217913

Epoch: 73
Training loss: 0.31427884101867676 / Valid loss: 7.301890722910563
Training loss: 0.33811095356941223 / Valid loss: 7.791247177124023
Training loss: 0.48108235001564026 / Valid loss: 7.223538276127407
Training loss: 0.4674625098705292 / Valid loss: 7.362200405484154
Training loss: 0.5149283409118652 / Valid loss: 7.254220147359939

Epoch: 74
Training loss: 0.5082433223724365 / Valid loss: 7.293417294820149
Training loss: 0.3736015260219574 / Valid loss: 7.199403263273693
Training loss: 0.4666738510131836 / Valid loss: 7.305674135117304
Training loss: 0.3591345548629761 / Valid loss: 7.307855020250593
Training loss: 0.5645784139633179 / Valid loss: 7.346162094388689

Epoch: 75
Training loss: 0.4180968403816223 / Valid loss: 7.20473324911935
Training loss: 0.3780387043952942 / Valid loss: 7.219318444388254
Training loss: 0.32905298471450806 / Valid loss: 7.224802239735921
Training loss: 0.5529695153236389 / Valid loss: 7.271545046851749
Training loss: 0.46542778611183167 / Valid loss: 7.23566441763015

Epoch: 76
Training loss: 0.29529786109924316 / Valid loss: 7.327097048078264
Training loss: 0.31137293577194214 / Valid loss: 7.592475872948056
Training loss: 0.516556978225708 / Valid loss: 7.17506685256958
Training loss: 0.3613697290420532 / Valid loss: 7.595705842971801
Training loss: 0.35531705617904663 / Valid loss: 7.72619439079648

Epoch: 77
Training loss: 0.366016685962677 / Valid loss: 7.506279255094983
Training loss: 0.3197211027145386 / Valid loss: 7.193546458653041
Training loss: 0.339796781539917 / Valid loss: 7.245644637516567
Training loss: 0.4436025619506836 / Valid loss: 7.247147310347784
Training loss: 0.2798384726047516 / Valid loss: 7.163613396599179

Epoch: 78
Training loss: 0.42856886982917786 / Valid loss: 7.385160936628069
Training loss: 0.3281904458999634 / Valid loss: 7.154027743566604
Training loss: 0.3463914692401886 / Valid loss: 7.258822827112107
Training loss: 0.5633119344711304 / Valid loss: 7.22088037672497
Training loss: 0.43515485525131226 / Valid loss: 7.170070107777914

Epoch: 79
Training loss: 0.3178649842739105 / Valid loss: 7.133466320946103
Training loss: 0.4604276120662689 / Valid loss: 7.227645170120966
Training loss: 0.27219879627227783 / Valid loss: 7.785069215865362
Training loss: 0.602176308631897 / Valid loss: 7.1589580967312765
ModuleList(
  (0): Linear(in_features=5376, out_features=248, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=248, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.373084047862462
Training regression with following parameters:
dnn_hidden_units : 
dropout_probs : 0.0, 0.0
learning_rate : 0.001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : Adam
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : Bert
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=5376, out_features=1, bias=True)
)

Epoch: 0
Training loss: 19.044994354248047 / Valid loss: 8.092049033301217
Model is saved in epoch 0, overall batch: 0
Training loss: 6.148061275482178 / Valid loss: 5.701571578071231
Model is saved in epoch 0, overall batch: 100
Training loss: 6.170613765716553 / Valid loss: 5.706854659035092
Training loss: 5.879120826721191 / Valid loss: 5.595105975014823
Model is saved in epoch 0, overall batch: 300
Training loss: 3.643350601196289 / Valid loss: 5.651296942574637

Epoch: 1
Training loss: 6.716653823852539 / Valid loss: 5.643029271988642
Training loss: 4.63120174407959 / Valid loss: 5.664374035880679
Training loss: 7.421722888946533 / Valid loss: 5.6524987833840505
Training loss: 4.275517463684082 / Valid loss: 6.113039071219308
Training loss: 4.8520708084106445 / Valid loss: 5.763112172626314

Epoch: 2
Training loss: 5.925057411193848 / Valid loss: 5.749677099500384
Training loss: 4.9208879470825195 / Valid loss: 5.655369467962355
Training loss: 5.841879367828369 / Valid loss: 5.649617410841442
Training loss: 3.730836868286133 / Valid loss: 5.665140671957107
Training loss: 4.4928975105285645 / Valid loss: 5.711184247334798

Epoch: 3
Training loss: 5.076797962188721 / Valid loss: 5.838827771232242
Training loss: 3.914113998413086 / Valid loss: 5.850191699890863
Training loss: 7.669660568237305 / Valid loss: 5.634028825305757
Training loss: 3.9252095222473145 / Valid loss: 5.771666631244478
Training loss: 5.706540107727051 / Valid loss: 5.748425783429827

Epoch: 4
Training loss: 5.83389949798584 / Valid loss: 5.7714359646751765
Training loss: 4.679776191711426 / Valid loss: 5.84993695077442
Training loss: 4.836705207824707 / Valid loss: 5.799211063839141
Training loss: 4.255773067474365 / Valid loss: 5.715037952150618
Training loss: 5.0942487716674805 / Valid loss: 5.631516508829026

Epoch: 5
Training loss: 6.93311882019043 / Valid loss: 5.809188656579881
Training loss: 5.0931243896484375 / Valid loss: 5.7080225694747195
Training loss: 5.0434346199035645 / Valid loss: 6.587805811564127
Training loss: 5.392146110534668 / Valid loss: 5.744984515508016
Training loss: 6.84440803527832 / Valid loss: 6.254306716010684

Epoch: 6
Training loss: 4.845000743865967 / Valid loss: 5.7676647208985825
Training loss: 5.218272686004639 / Valid loss: 5.975734853744507
Training loss: 5.098257064819336 / Valid loss: 5.766922655559721
Training loss: 4.618958950042725 / Valid loss: 5.737967459360759
Training loss: 6.732781410217285 / Valid loss: 5.823581641060965

Epoch: 7
Training loss: 4.464107513427734 / Valid loss: 5.711232609975905
Training loss: 3.9775307178497314 / Valid loss: 5.8027155944279265
Training loss: 6.677234649658203 / Valid loss: 5.787251688185192
Training loss: 5.358392715454102 / Valid loss: 5.688670378639585
Training loss: 5.044065475463867 / Valid loss: 5.7349123137337825

Epoch: 8
Training loss: 5.617430686950684 / Valid loss: 6.440773282732282
Training loss: 4.527408599853516 / Valid loss: 5.818193703606015
Training loss: 4.710190773010254 / Valid loss: 5.680916209447951
Training loss: 4.812481880187988 / Valid loss: 5.796826117379325
Training loss: 2.8229005336761475 / Valid loss: 5.865010665711902

Epoch: 9
Training loss: 3.912248373031616 / Valid loss: 5.704276062193371
Training loss: 5.340813636779785 / Valid loss: 5.725011128471011
Training loss: 7.440926551818848 / Valid loss: 5.881696909949893
Training loss: 6.299976825714111 / Valid loss: 6.293206001463391

Epoch: 10
Training loss: 3.9053196907043457 / Valid loss: 5.75392249198187
Training loss: 4.644098281860352 / Valid loss: 5.802572266260783
Training loss: 5.324538230895996 / Valid loss: 6.320408167157854
Training loss: 5.224365711212158 / Valid loss: 5.755738828295753
Training loss: 5.087753772735596 / Valid loss: 6.023292282649449

Epoch: 11
Training loss: 5.310728073120117 / Valid loss: 5.790553238278344
Training loss: 5.442705154418945 / Valid loss: 5.861511141913278
Training loss: 4.663771629333496 / Valid loss: 6.007434070677984
Training loss: 8.038566589355469 / Valid loss: 5.749161609013876
Training loss: 4.973113059997559 / Valid loss: 5.868695799509684

Epoch: 12
Training loss: 5.370931625366211 / Valid loss: 5.7683356012616835
Training loss: 6.095061302185059 / Valid loss: 5.800792759940737
Training loss: 3.7065019607543945 / Valid loss: 6.37833370027088
Training loss: 4.6184611320495605 / Valid loss: 5.76563591048831
Training loss: 4.034323692321777 / Valid loss: 5.813520851589384

Epoch: 13
Training loss: 4.606281757354736 / Valid loss: 5.772801673979986
Training loss: 4.794265270233154 / Valid loss: 6.3341354029519215
Training loss: 5.5112457275390625 / Valid loss: 5.8656221162705195
Training loss: 6.008370876312256 / Valid loss: 5.846045564469837
Training loss: 5.050445556640625 / Valid loss: 5.738816152300154

Epoch: 14
Training loss: 5.622304916381836 / Valid loss: 5.879973481950306
Training loss: 5.061078071594238 / Valid loss: 6.158573893138341
Training loss: 5.400570392608643 / Valid loss: 6.0460967994871595
Training loss: 3.6927876472473145 / Valid loss: 5.9460766270047145
Training loss: 5.562653541564941 / Valid loss: 6.952265875680106

Epoch: 15
Training loss: 5.764951705932617 / Valid loss: 5.872303647086734
Training loss: 5.777360916137695 / Valid loss: 5.787015031632923
Training loss: 4.667038440704346 / Valid loss: 5.848612882977441
Training loss: 5.417726993560791 / Valid loss: 5.87546596754165
Training loss: 4.996523857116699 / Valid loss: 5.940417855126517

Epoch: 16
Training loss: 4.851752281188965 / Valid loss: 5.864849126906622
Training loss: 4.116241931915283 / Valid loss: 7.265185574122838
Training loss: 4.945643424987793 / Valid loss: 5.8271178654261995
Training loss: 5.652191162109375 / Valid loss: 5.951425911131359
Training loss: 4.79814338684082 / Valid loss: 5.973514690853301

Epoch: 17
Training loss: 6.198210716247559 / Valid loss: 5.98662496294294
Training loss: 4.798887252807617 / Valid loss: 5.768560536702474
Training loss: 4.883077621459961 / Valid loss: 5.907729943593343
Training loss: 4.899740219116211 / Valid loss: 5.788184592837379
Training loss: 6.758345127105713 / Valid loss: 5.877930048533848

Epoch: 18
Training loss: 5.285200119018555 / Valid loss: 5.824147767112368
Training loss: 4.055123329162598 / Valid loss: 5.952373702185494
Training loss: 5.305145263671875 / Valid loss: 5.770377863021124
Training loss: 4.127040386199951 / Valid loss: 5.882430246898106
Training loss: 5.8969526290893555 / Valid loss: 5.8303480670565655

Epoch: 19
Training loss: 3.942387342453003 / Valid loss: 5.9011060237884525
Training loss: 4.236052513122559 / Valid loss: 5.834990294774373
Training loss: 4.804897308349609 / Valid loss: 5.837910981405349
Training loss: 4.012368679046631 / Valid loss: 5.942165129525321

Epoch: 20
Training loss: 4.617002964019775 / Valid loss: 5.998691299983434
Training loss: 5.120438575744629 / Valid loss: 5.981664587202526
Training loss: 3.671104669570923 / Valid loss: 6.06591109321231
Training loss: 3.308212995529175 / Valid loss: 5.818291257676624
Training loss: 4.81234073638916 / Valid loss: 5.8642415523529055

Epoch: 21
Training loss: 5.0070953369140625 / Valid loss: 6.014344013304937
Training loss: 6.309192657470703 / Valid loss: 6.0186362493605845
Training loss: 5.51052188873291 / Valid loss: 5.823638141722906
Training loss: 8.042821884155273 / Valid loss: 6.294996584029425
Training loss: 6.2492356300354 / Valid loss: 6.05375330334618

Epoch: 22
Training loss: 5.210292339324951 / Valid loss: 5.811033775692894
Training loss: 4.102896690368652 / Valid loss: 5.841734284446353
Training loss: 6.051554203033447 / Valid loss: 6.460799562363397
Training loss: 6.0299859046936035 / Valid loss: 5.931363214765276
Training loss: 4.529183387756348 / Valid loss: 5.9970928555443175

Epoch: 23
Training loss: 5.61714506149292 / Valid loss: 6.019429819924491
Training loss: 6.1220197677612305 / Valid loss: 6.013706770397368
Training loss: 5.066226959228516 / Valid loss: 5.864154529571533
Training loss: 4.791457176208496 / Valid loss: 5.882568479719616
Training loss: 6.942785739898682 / Valid loss: 6.186320899781727

Epoch: 24
Training loss: 6.200743675231934 / Valid loss: 6.409553293954758
Training loss: 5.291129112243652 / Valid loss: 5.914675244830904
Training loss: 5.3759026527404785 / Valid loss: 5.842975750423613
Training loss: 6.812552452087402 / Valid loss: 5.8731634821210585
Training loss: 3.611746311187744 / Valid loss: 6.301804172425043

Epoch: 25
Training loss: 3.581059694290161 / Valid loss: 5.906401382173811
Training loss: 3.0479977130889893 / Valid loss: 5.93978153410412
Training loss: 3.291269540786743 / Valid loss: 5.941342040470668
Training loss: 6.784536361694336 / Valid loss: 5.8635130019415
Training loss: 3.76632022857666 / Valid loss: 6.033148520333427

Epoch: 26
Training loss: 5.237804889678955 / Valid loss: 6.097309634799049
Training loss: 5.990858554840088 / Valid loss: 5.9426726114182244
Training loss: 6.037245273590088 / Valid loss: 5.933407556442988
Training loss: 5.629202842712402 / Valid loss: 5.982494379225232
Training loss: 5.496949195861816 / Valid loss: 5.974891828355335

Epoch: 27
Training loss: 8.645611763000488 / Valid loss: 6.147190300623576
Training loss: 4.596233367919922 / Valid loss: 5.990616877873738
Training loss: 5.177696704864502 / Valid loss: 5.926581739244007
Training loss: 6.417768478393555 / Valid loss: 5.94234904561724
Training loss: 5.8664116859436035 / Valid loss: 6.0675470238640195

Epoch: 28
Training loss: 4.160120964050293 / Valid loss: 5.871920701435634
Training loss: 3.899186372756958 / Valid loss: 6.179511347271148
Training loss: 5.370606422424316 / Valid loss: 6.546277727399554
Training loss: 4.721887588500977 / Valid loss: 5.936180541628883
Training loss: 5.337785720825195 / Valid loss: 5.834978471483503

Epoch: 29
Training loss: 6.1667585372924805 / Valid loss: 6.1867830957685195
Training loss: 5.113041877746582 / Valid loss: 5.935310899643671
Training loss: 6.116176605224609 / Valid loss: 5.944210020701091
Training loss: 6.307999610900879 / Valid loss: 6.00272907983689

Epoch: 30
Training loss: 6.525237083435059 / Valid loss: 6.533971250624884
Training loss: 5.228156089782715 / Valid loss: 5.983588404882521
Training loss: 4.700456142425537 / Valid loss: 6.245771353585379
Training loss: 5.0748395919799805 / Valid loss: 5.9786736806233725
Training loss: 4.536952972412109 / Valid loss: 5.904327051980155

Epoch: 31
Training loss: 5.218457221984863 / Valid loss: 5.924519961220877
Training loss: 5.628563404083252 / Valid loss: 6.12874634152367
Training loss: 4.6537604331970215 / Valid loss: 5.936181747345698
Training loss: 5.031530380249023 / Valid loss: 5.951277001698812
Training loss: 6.155279636383057 / Valid loss: 5.9404415448506676

Epoch: 32
Training loss: 5.7674384117126465 / Valid loss: 5.984739482970465
Training loss: 5.677141189575195 / Valid loss: 5.929248657680693
Training loss: 5.271806716918945 / Valid loss: 6.13948142187936
Training loss: 4.207383155822754 / Valid loss: 6.2536865279788065
Training loss: 7.375938892364502 / Valid loss: 5.9504937671479725

Epoch: 33
Training loss: 4.052079200744629 / Valid loss: 5.894197475342524
Training loss: 5.699511528015137 / Valid loss: 5.922623974936349
Training loss: 6.435791492462158 / Valid loss: 6.042905587241763
Training loss: 5.091592788696289 / Valid loss: 6.09133951323373
Training loss: 6.601558685302734 / Valid loss: 6.004621710096087

Epoch: 34
Training loss: 4.540563583374023 / Valid loss: 6.007995398839315
Training loss: 6.6331915855407715 / Valid loss: 6.009093913577852
Training loss: 5.542844772338867 / Valid loss: 6.43756688890003
Training loss: 5.831785678863525 / Valid loss: 6.781958443777902
Training loss: 3.873655319213867 / Valid loss: 6.176143796103341

Epoch: 35
Training loss: 5.702544212341309 / Valid loss: 6.479782495044526
Training loss: 4.708370685577393 / Valid loss: 5.925800209953671
Training loss: 5.703458786010742 / Valid loss: 5.906815256391253
Training loss: 4.780970096588135 / Valid loss: 6.026541782560803
Training loss: 4.953135013580322 / Valid loss: 6.11766867410569

Epoch: 36
Training loss: 3.8349859714508057 / Valid loss: 5.976738471076602
Training loss: 5.54894495010376 / Valid loss: 6.632401346025013
Training loss: 4.035051345825195 / Valid loss: 6.028754436402094
Training loss: 5.862283706665039 / Valid loss: 5.956950648625692
Training loss: 4.006731986999512 / Valid loss: 6.0086198352632065

Epoch: 37
Training loss: 5.232735633850098 / Valid loss: 5.951650887443906
Training loss: 4.093378067016602 / Valid loss: 6.001308584213257
Training loss: 4.18829870223999 / Valid loss: 5.990319429125105
Training loss: 6.093557357788086 / Valid loss: 6.0585090410141715
Training loss: 5.811321258544922 / Valid loss: 5.9185517901466005

Epoch: 38
Training loss: 5.709674835205078 / Valid loss: 6.16407946632022
Training loss: 6.062976837158203 / Valid loss: 6.134016727265857
Training loss: 5.398240089416504 / Valid loss: 6.109620602925618
Training loss: 4.647353649139404 / Valid loss: 5.960933769316901
Training loss: 4.389507293701172 / Valid loss: 5.929902898697626

Epoch: 39
Training loss: 4.218158721923828 / Valid loss: 5.874821124758039
Training loss: 5.0196380615234375 / Valid loss: 6.162768229984102
Training loss: 5.976421356201172 / Valid loss: 5.974669558661325
Training loss: 5.157122611999512 / Valid loss: 6.173231960478283

Epoch: 40
Training loss: 3.9267640113830566 / Valid loss: 5.956478900001162
Training loss: 5.681957244873047 / Valid loss: 6.335491266704741
Training loss: 4.013633728027344 / Valid loss: 6.167349583762032
Training loss: 4.782371997833252 / Valid loss: 5.971450063160487
Training loss: 3.4850332736968994 / Valid loss: 6.197949366342454

Epoch: 41
Training loss: 4.372819900512695 / Valid loss: 6.00939908027649
Training loss: 4.898906230926514 / Valid loss: 6.119108131953648
Training loss: 4.095206260681152 / Valid loss: 5.932092789241246
Training loss: 6.767749309539795 / Valid loss: 6.006005343936739
Training loss: 4.777054786682129 / Valid loss: 6.364337850752331

Epoch: 42
Training loss: 3.2513041496276855 / Valid loss: 5.950024523053851
Training loss: 4.7479352951049805 / Valid loss: 5.953655692509242
Training loss: 5.888693332672119 / Valid loss: 5.990976499375843
Training loss: 4.27401876449585 / Valid loss: 5.950998424348377
Training loss: 3.259373664855957 / Valid loss: 6.054451031911941

Epoch: 43
Training loss: 5.069516181945801 / Valid loss: 5.941861806597029
Training loss: 4.694148063659668 / Valid loss: 6.123070439838227
Training loss: 5.69645881652832 / Valid loss: 5.900658468973069
Training loss: 5.160250663757324 / Valid loss: 5.9682503495897565
Training loss: 6.109087944030762 / Valid loss: 6.158991595676967

Epoch: 44
Training loss: 4.499476432800293 / Valid loss: 6.320401820682344
Training loss: 4.283590316772461 / Valid loss: 5.982635502588181
Training loss: 5.442533493041992 / Valid loss: 6.233094251723516
Training loss: 6.378522872924805 / Valid loss: 5.986998308272589
Training loss: 5.928299903869629 / Valid loss: 5.973590287708101

Epoch: 45
Training loss: 4.172019004821777 / Valid loss: 6.0455645606631325
Training loss: 4.161314010620117 / Valid loss: 5.923841226668585
Training loss: 3.5131702423095703 / Valid loss: 6.155871811367216
Training loss: 5.458660125732422 / Valid loss: 6.031438041868664
Training loss: 4.339425563812256 / Valid loss: 6.004731348582676

Epoch: 46
Training loss: 6.299060821533203 / Valid loss: 6.072993941534133
Training loss: 6.073396682739258 / Valid loss: 5.99526210739499
Training loss: 4.744773864746094 / Valid loss: 6.077119286855062
Training loss: 4.909592151641846 / Valid loss: 5.924679719834101
Training loss: 4.860255241394043 / Valid loss: 6.205485130491711

Epoch: 47
Training loss: 3.144726514816284 / Valid loss: 5.977515479496547
Training loss: 4.1600565910339355 / Valid loss: 6.139053287960234
Training loss: 4.936363697052002 / Valid loss: 6.131355644407726
Training loss: 7.466708183288574 / Valid loss: 6.219308040255592
Training loss: 5.621877670288086 / Valid loss: 5.961581754684448

Epoch: 48
Training loss: 4.8230204582214355 / Valid loss: 5.8862781297592885
Training loss: 4.191694259643555 / Valid loss: 5.955908643631708
Training loss: 4.1886138916015625 / Valid loss: 6.023395835785639
Training loss: 5.958001136779785 / Valid loss: 5.966312235877627
Training loss: 4.716708660125732 / Valid loss: 5.946255742935907

Epoch: 49
Training loss: 7.214226722717285 / Valid loss: 6.406862917400542
Training loss: 5.398114204406738 / Valid loss: 5.989204978942871
Training loss: 4.996038436889648 / Valid loss: 5.9690306118556435
Training loss: 4.027602672576904 / Valid loss: 5.965274125053769

Epoch: 50
Training loss: 4.462789535522461 / Valid loss: 6.215769556590489
Training loss: 3.1373085975646973 / Valid loss: 5.973920903887067
Training loss: 4.1104302406311035 / Valid loss: 6.029767996924264
Training loss: 5.618537425994873 / Valid loss: 6.074410808654059
Training loss: 6.727622985839844 / Valid loss: 6.128770773751395

Epoch: 51
Training loss: 4.471912384033203 / Valid loss: 5.954519367218017
Training loss: 3.1901302337646484 / Valid loss: 6.196636526925223
Training loss: 6.081297874450684 / Valid loss: 6.033890917187645
Training loss: 3.71513032913208 / Valid loss: 5.980891416186378
Training loss: 4.718349456787109 / Valid loss: 6.0030290898822605

Epoch: 52
Training loss: 4.499314785003662 / Valid loss: 6.167036808104742
Training loss: 4.650478363037109 / Valid loss: 6.263454532623291
Training loss: 4.419271469116211 / Valid loss: 6.044492703392392
Training loss: 4.082910537719727 / Valid loss: 6.1617602984110516
Training loss: 4.5309624671936035 / Valid loss: 6.021642589569092

Epoch: 53
Training loss: 4.499166488647461 / Valid loss: 5.939686375572568
Training loss: 4.876021862030029 / Valid loss: 6.2514532180059526
Training loss: 10.450045585632324 / Valid loss: 5.976187905811128
Training loss: 5.552204608917236 / Valid loss: 6.3988344192504885
Training loss: 5.794244289398193 / Valid loss: 5.948371360415504

Epoch: 54
Training loss: 4.360764503479004 / Valid loss: 6.023470356350853
Training loss: 4.390899658203125 / Valid loss: 6.155510436920893
Training loss: 3.612760305404663 / Valid loss: 6.003359206517538
Training loss: 5.130157470703125 / Valid loss: 6.311183963503156
Training loss: 4.328385353088379 / Valid loss: 6.247444234575544

Epoch: 55
Training loss: 4.488533973693848 / Valid loss: 5.9574324335370745
Training loss: 4.4755024909973145 / Valid loss: 6.541808214641753
Training loss: 4.304159164428711 / Valid loss: 6.0610825652167915
Training loss: 4.950105667114258 / Valid loss: 6.052139645531064
Training loss: 4.169395446777344 / Valid loss: 6.023018039975848

Epoch: 56
Training loss: 4.080417633056641 / Valid loss: 6.045116933186849
Training loss: 4.945318222045898 / Valid loss: 6.002435413996379
Training loss: 3.5846598148345947 / Valid loss: 5.986289814540318
Training loss: 7.198953628540039 / Valid loss: 6.081817549750919
Training loss: 4.784177780151367 / Valid loss: 6.0004101162865044

Epoch: 57
Training loss: 4.0850019454956055 / Valid loss: 6.202094155266171
Training loss: 4.164226531982422 / Valid loss: 6.245820758456276
Training loss: 4.812915802001953 / Valid loss: 6.0243460518973215
Training loss: 4.535365581512451 / Valid loss: 6.03952856972104
Training loss: 5.131882190704346 / Valid loss: 5.989534319014776

Epoch: 58
Training loss: 3.7984519004821777 / Valid loss: 6.409759530566988
Training loss: 5.224802494049072 / Valid loss: 6.022015299115862
Training loss: 3.619755268096924 / Valid loss: 6.0124253613608225
Training loss: 5.411703586578369 / Valid loss: 6.051364921388172
Training loss: 5.5870137214660645 / Valid loss: 6.008240447725568

Epoch: 59
Training loss: 3.1825523376464844 / Valid loss: 6.441108739943731
Training loss: 4.599349021911621 / Valid loss: 5.940061094647362
Training loss: 4.352652549743652 / Valid loss: 6.109747913905553
Training loss: 2.4179046154022217 / Valid loss: 5.988066850389753

Epoch: 60
Training loss: 6.006667137145996 / Valid loss: 6.061569770177205
Training loss: 3.2047410011291504 / Valid loss: 6.066127777099609
Training loss: 6.0409255027771 / Valid loss: 6.157751850854783
Training loss: 5.538994789123535 / Valid loss: 5.998906626020159
Training loss: 5.637063503265381 / Valid loss: 6.163203770773752

Epoch: 61
Training loss: 4.9142279624938965 / Valid loss: 6.178003383818127
Training loss: 3.99993634223938 / Valid loss: 6.032659541992914
Training loss: 6.589118957519531 / Valid loss: 6.157969138735816
Training loss: 5.065197944641113 / Valid loss: 6.069045173554193
Training loss: 7.053989887237549 / Valid loss: 6.237028358096168

Epoch: 62
Training loss: 4.817002773284912 / Valid loss: 6.985858047576178
Training loss: 3.124455213546753 / Valid loss: 6.031321425664992
Training loss: 4.940903663635254 / Valid loss: 6.061028278441656
Training loss: 5.689296722412109 / Valid loss: 6.012373022806077
Training loss: 7.011548042297363 / Valid loss: 6.1023214839753654

Epoch: 63
Training loss: 3.7971417903900146 / Valid loss: 6.029038261231922
Training loss: 5.919741153717041 / Valid loss: 6.047976359866914
Training loss: 5.359299182891846 / Valid loss: 6.0433878898620605
Training loss: 5.338707447052002 / Valid loss: 6.209903090340751
Training loss: 3.7235302925109863 / Valid loss: 6.086028083165487

Epoch: 64
Training loss: 3.9102869033813477 / Valid loss: 6.548410765329996
Training loss: 5.517982482910156 / Valid loss: 6.05489052817935
Training loss: 5.1115217208862305 / Valid loss: 6.230683774039859
Training loss: 4.447772026062012 / Valid loss: 6.3286551679883685
Training loss: 4.641169548034668 / Valid loss: 6.218721719015212

Epoch: 65
Training loss: 3.6912102699279785 / Valid loss: 6.010271581013997
Training loss: 6.592769145965576 / Valid loss: 6.175229699271066
Training loss: 7.187665939331055 / Valid loss: 6.567496815181914
Training loss: 4.83257532119751 / Valid loss: 6.048905915305728
Training loss: 5.529338836669922 / Valid loss: 6.194449063709804

Epoch: 66
Training loss: 3.8475165367126465 / Valid loss: 6.024968671798706
Training loss: 5.016117095947266 / Valid loss: 6.0346486863635835
Training loss: 3.714191436767578 / Valid loss: 6.028497032892137
Training loss: 5.781105995178223 / Valid loss: 6.112315034866333
Training loss: 3.716890573501587 / Valid loss: 6.162878672281901

Epoch: 67
Training loss: 4.895915985107422 / Valid loss: 6.014619252795264
Training loss: 6.330824851989746 / Valid loss: 6.06313233148484
Training loss: 4.934613227844238 / Valid loss: 6.057281925564721
Training loss: 6.387911319732666 / Valid loss: 6.212206820079259
Training loss: 4.310154914855957 / Valid loss: 6.432462769462949

Epoch: 68
Training loss: 5.065706253051758 / Valid loss: 6.020903301239014
Training loss: 5.951714038848877 / Valid loss: 6.093181523822603
Training loss: 4.551393508911133 / Valid loss: 6.090193430582683
Training loss: 4.200821876525879 / Valid loss: 6.327207812808809
Training loss: 4.451110363006592 / Valid loss: 6.498891689663842

Epoch: 69
Training loss: 5.851945877075195 / Valid loss: 6.170871369043986
Training loss: 3.8080713748931885 / Valid loss: 6.317053572336833
Training loss: 5.515836715698242 / Valid loss: 6.281148774283273
Training loss: 5.371906280517578 / Valid loss: 6.228473763238816

Epoch: 70
Training loss: 4.932586669921875 / Valid loss: 6.029100629261562
Training loss: 5.448404312133789 / Valid loss: 6.379996699378604
Training loss: 4.723610877990723 / Valid loss: 6.062586580004011
Training loss: 6.165177345275879 / Valid loss: 6.080608817509242
Training loss: 5.350181579589844 / Valid loss: 6.320598856608073

Epoch: 71
Training loss: 5.332968711853027 / Valid loss: 6.090166657311576
Training loss: 3.51210355758667 / Valid loss: 6.151077615647089
Training loss: 5.232804775238037 / Valid loss: 6.102458899361746
Training loss: 7.090074062347412 / Valid loss: 6.26175191515968
Training loss: 5.88178014755249 / Valid loss: 6.000608948298863

Epoch: 72
Training loss: 3.943023443222046 / Valid loss: 6.1592112813677105
Training loss: 5.777607440948486 / Valid loss: 6.050137047540574
Training loss: 4.016451835632324 / Valid loss: 6.104556092761812
Training loss: 5.772377967834473 / Valid loss: 6.143185660952613
Training loss: 5.834637641906738 / Valid loss: 6.068378873098464

Epoch: 73
Training loss: 3.744645118713379 / Valid loss: 6.061950018292381
Training loss: 5.534254550933838 / Valid loss: 6.231230115890503
Training loss: 5.335447788238525 / Valid loss: 6.037769328980219
Training loss: 6.429990768432617 / Valid loss: 6.4668131374177475
Training loss: 5.108513832092285 / Valid loss: 6.057776360284715

Epoch: 74
Training loss: 4.881984710693359 / Valid loss: 6.064607795079549
Training loss: 4.924952507019043 / Valid loss: 6.37818884622483
Training loss: 4.104987621307373 / Valid loss: 6.131264037177676
Training loss: 5.774389266967773 / Valid loss: 6.491036222094581
Training loss: 5.551938056945801 / Valid loss: 6.1081888970874605

Epoch: 75
Training loss: 4.161020755767822 / Valid loss: 6.303567255110968
Training loss: 3.886726140975952 / Valid loss: 6.038469173794701
Training loss: 4.2633185386657715 / Valid loss: 6.138832887013753
Training loss: 4.6241631507873535 / Valid loss: 6.088023907797677
Training loss: 4.250770568847656 / Valid loss: 6.064554632277716

Epoch: 76
Training loss: 3.0207512378692627 / Valid loss: 6.09817852973938
Training loss: 4.01295280456543 / Valid loss: 6.186288508914766
Training loss: 5.2136125564575195 / Valid loss: 6.0719946770440965
Training loss: 5.016615867614746 / Valid loss: 6.144816298711867
Training loss: 3.0826573371887207 / Valid loss: 6.209364019121442

Epoch: 77
Training loss: 4.778347969055176 / Valid loss: 6.258268828619094
Training loss: 5.030977725982666 / Valid loss: 6.241916016169957
Training loss: 6.394366264343262 / Valid loss: 6.7266812460763115
Training loss: 4.453179359436035 / Valid loss: 6.147522960390363
Training loss: 3.966914176940918 / Valid loss: 6.069102882203602

Epoch: 78
Training loss: 3.5156350135803223 / Valid loss: 6.098723388853527
Training loss: 5.323702812194824 / Valid loss: 6.147698413758051
Training loss: 3.5790646076202393 / Valid loss: 6.127887203579857
Training loss: 6.225471019744873 / Valid loss: 6.079136037826538
Training loss: 6.911253452301025 / Valid loss: 6.048519023259481

Epoch: 79
Training loss: 4.266661643981934 / Valid loss: 6.157249448412941
Training loss: 4.086951732635498 / Valid loss: 6.301396031606765
Training loss: 4.188612937927246 / Valid loss: 6.500278027852376
Training loss: 6.474842071533203 / Valid loss: 6.147324085235596
ModuleList(
  (0): Linear(in_features=5376, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.451294317699614
Training regression with following parameters:
dnn_hidden_units : 2000, 100, 16
dropout_probs : 0.0, 0.0
learning_rate : 0.0001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : Adam
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : Bert
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=5376, out_features=2000, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=2000, out_features=100, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=100, out_features=16, bias=True)
  (9): Dropout(p=0, inplace=False)
  (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (11): LeakyReLU(negative_slope=0.02)
  (12): Linear(in_features=16, out_features=1, bias=True)
)

Epoch: 0
Training loss: 15.765700340270996 / Valid loss: 15.114407076154436
Model is saved in epoch 0, overall batch: 0
Training loss: 8.912009239196777 / Valid loss: 12.768657457260858
Model is saved in epoch 0, overall batch: 100
Training loss: 9.925810813903809 / Valid loss: 12.196747702643984
Model is saved in epoch 0, overall batch: 200
Training loss: 15.783401489257812 / Valid loss: 11.78140204747518
Model is saved in epoch 0, overall batch: 300
Training loss: 11.472275733947754 / Valid loss: 11.121726526532854
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 9.930368423461914 / Valid loss: 10.86008365267799
Model is saved in epoch 1, overall batch: 500
Training loss: 9.093926429748535 / Valid loss: 10.686255200703938
Model is saved in epoch 1, overall batch: 600
Training loss: 8.314817428588867 / Valid loss: 10.258468723297119
Model is saved in epoch 1, overall batch: 700
Training loss: 8.375079154968262 / Valid loss: 9.384540948413667
Model is saved in epoch 1, overall batch: 800
Training loss: 6.540190696716309 / Valid loss: 9.523321387881325

Epoch: 2
Training loss: 9.234378814697266 / Valid loss: 8.769821966262091
Model is saved in epoch 2, overall batch: 1000
Training loss: 9.167750358581543 / Valid loss: 8.570415982745942
Model is saved in epoch 2, overall batch: 1100
Training loss: 8.85214614868164 / Valid loss: 8.411143775213333
Model is saved in epoch 2, overall batch: 1200
Training loss: 9.604043006896973 / Valid loss: 7.723625689461118
Model is saved in epoch 2, overall batch: 1300
Training loss: 5.110571384429932 / Valid loss: 7.415789735884894
Model is saved in epoch 2, overall batch: 1400

Epoch: 3
Training loss: 4.846023082733154 / Valid loss: 7.009148602258591
Model is saved in epoch 3, overall batch: 1500
Training loss: 3.8052730560302734 / Valid loss: 6.786819939386277
Model is saved in epoch 3, overall batch: 1600
Training loss: 6.784642219543457 / Valid loss: 6.671425762630644
Model is saved in epoch 3, overall batch: 1700
Training loss: 3.459716796875 / Valid loss: 6.495018087114606
Model is saved in epoch 3, overall batch: 1800
Training loss: 4.784595489501953 / Valid loss: 6.455052934374128
Model is saved in epoch 3, overall batch: 1900

Epoch: 4
Training loss: 5.4322004318237305 / Valid loss: 7.28327697572254
Training loss: 3.8479514122009277 / Valid loss: 6.66725393931071
Training loss: 4.175478458404541 / Valid loss: 6.828827540079753
Training loss: 4.428637981414795 / Valid loss: 6.515154436656407
Training loss: 3.4555511474609375 / Valid loss: 6.198425113587152
Model is saved in epoch 4, overall batch: 2400

Epoch: 5
Training loss: 5.734418869018555 / Valid loss: 6.558657866432553
Training loss: 3.515838146209717 / Valid loss: 6.385780620574951
Training loss: 2.704442024230957 / Valid loss: 6.671769423711868
Training loss: 3.083517074584961 / Valid loss: 6.238934716724214
Training loss: 3.3447868824005127 / Valid loss: 6.271911857241676

Epoch: 6
Training loss: 5.0640363693237305 / Valid loss: 7.03444573538644
Training loss: 2.181051254272461 / Valid loss: 6.528518865222023
Training loss: 3.046281337738037 / Valid loss: 7.094282913208008
Training loss: 3.0997061729431152 / Valid loss: 6.523180414381481
Training loss: 2.9891488552093506 / Valid loss: 6.588962502706618

Epoch: 7
Training loss: 2.6797165870666504 / Valid loss: 6.758096204485212
Training loss: 1.6568546295166016 / Valid loss: 6.918168528874715
Training loss: 2.4585399627685547 / Valid loss: 6.7552470752171105
Training loss: 2.754788398742676 / Valid loss: 6.856639943804059
Training loss: 2.473010540008545 / Valid loss: 6.809998221624465

Epoch: 8
Training loss: 0.8977401256561279 / Valid loss: 6.755013095764887
Training loss: 1.413731575012207 / Valid loss: 6.647775027865455
Training loss: 1.7390714883804321 / Valid loss: 6.902055279413859
Training loss: 2.391519546508789 / Valid loss: 6.718315172195434
Training loss: 2.360682487487793 / Valid loss: 6.881375512622651

Epoch: 9
Training loss: 1.6765280961990356 / Valid loss: 6.831627114613851
Training loss: 1.7128515243530273 / Valid loss: 6.944666762579055
Training loss: 2.782789707183838 / Valid loss: 8.034859157743908
Training loss: 2.0937094688415527 / Valid loss: 6.823229158492316

Epoch: 10
Training loss: 0.936830461025238 / Valid loss: 6.9010133402688165
Training loss: 1.2471961975097656 / Valid loss: 6.960337920415969
Training loss: 0.9596741199493408 / Valid loss: 7.017917206173851
Training loss: 1.8208965063095093 / Valid loss: 6.903125983192807
Training loss: 1.0655286312103271 / Valid loss: 7.356153034028553

Epoch: 11
Training loss: 0.6359700560569763 / Valid loss: 6.962087163471041
Training loss: 1.1494207382202148 / Valid loss: 6.8070917992364794
Training loss: 1.145169734954834 / Valid loss: 6.811951723552886
Training loss: 0.8636291027069092 / Valid loss: 7.136697780518305
Training loss: 1.28263521194458 / Valid loss: 7.200314989544096

Epoch: 12
Training loss: 0.808957576751709 / Valid loss: 6.973334121704101
Training loss: 0.8647042512893677 / Valid loss: 6.900782355808077
Training loss: 0.964614748954773 / Valid loss: 6.726683991295951
Training loss: 1.211578369140625 / Valid loss: 6.901320968355451
Training loss: 1.184460163116455 / Valid loss: 7.090978935786656

Epoch: 13
Training loss: 0.785484790802002 / Valid loss: 7.72143703188215
Training loss: 0.8137133717536926 / Valid loss: 6.860293036415463
Training loss: 0.9294409155845642 / Valid loss: 7.357797645387196
Training loss: 0.8816201090812683 / Valid loss: 6.893089180900937
Training loss: 0.7556352019309998 / Valid loss: 7.004174990881057

Epoch: 14
Training loss: 0.9726812243461609 / Valid loss: 7.121114428838094
Training loss: 0.6533987522125244 / Valid loss: 6.785783045632499
Training loss: 1.1122817993164062 / Valid loss: 6.872415744690668
Training loss: 0.6795768737792969 / Valid loss: 7.161128947848366
Training loss: 1.2054206132888794 / Valid loss: 7.020729609898159

Epoch: 15
Training loss: 0.6204168796539307 / Valid loss: 6.883711839857556
Training loss: 1.2871613502502441 / Valid loss: 7.012847995758056
Training loss: 0.8659645318984985 / Valid loss: 6.839447852543422
Training loss: 0.9139481782913208 / Valid loss: 6.939008117857433
Training loss: 0.8593806028366089 / Valid loss: 6.802086017245338

Epoch: 16
Training loss: 0.53940749168396 / Valid loss: 6.9785969370887395
Training loss: 0.5532370805740356 / Valid loss: 6.923516591389974
Training loss: 0.6132656335830688 / Valid loss: 6.90730920065017
Training loss: 0.6715787053108215 / Valid loss: 6.915744472685314
Training loss: 0.5064013004302979 / Valid loss: 7.258493564242408

Epoch: 17
Training loss: 0.8739537596702576 / Valid loss: 6.999483746574039
Training loss: 1.2047475576400757 / Valid loss: 6.833454740615118
Training loss: 0.814422070980072 / Valid loss: 7.017788610004243
Training loss: 0.5512487888336182 / Valid loss: 6.942955316816057
Training loss: 0.7930984497070312 / Valid loss: 6.872358394804455

Epoch: 18
Training loss: 0.6464129686355591 / Valid loss: 6.939476201647804
Training loss: 0.8608871698379517 / Valid loss: 7.0141416322617305
Training loss: 0.7545645236968994 / Valid loss: 7.13192974726359
Training loss: 0.7856454253196716 / Valid loss: 6.881633154551188
Training loss: 1.0869135856628418 / Valid loss: 7.21874339239938

Epoch: 19
Training loss: 1.059412956237793 / Valid loss: 7.130672954377674
Training loss: 1.1742831468582153 / Valid loss: 6.99260645820981
Training loss: 0.7287744879722595 / Valid loss: 6.95410057703654
Training loss: 0.663609504699707 / Valid loss: 6.842352708180745

Epoch: 20
Training loss: 0.5677882432937622 / Valid loss: 6.791662020910354
Training loss: 1.2225005626678467 / Valid loss: 6.889434378487723
Training loss: 0.47219428420066833 / Valid loss: 6.808534442810785
Training loss: 0.8761451840400696 / Valid loss: 6.8158988135201595
Training loss: 1.0279066562652588 / Valid loss: 6.7720060007912775

Epoch: 21
Training loss: 0.4475374221801758 / Valid loss: 6.937840098426456
Training loss: 0.5406501293182373 / Valid loss: 7.365072645459857
Training loss: 0.6003029346466064 / Valid loss: 7.08115739368257
Training loss: 0.7370328903198242 / Valid loss: 6.987155205862862
Training loss: 0.6210228204727173 / Valid loss: 6.9006127198537195

Epoch: 22
Training loss: 0.7910249829292297 / Valid loss: 6.7880048751831055
Training loss: 0.38785022497177124 / Valid loss: 6.869932310921805
Training loss: 0.6510220766067505 / Valid loss: 6.9390557062058225
Training loss: 1.272037386894226 / Valid loss: 6.995921611785889
Training loss: 0.9684562087059021 / Valid loss: 7.202456410725912

Epoch: 23
Training loss: 0.5385011434555054 / Valid loss: 6.851070585704985
Training loss: 1.321436882019043 / Valid loss: 6.890108635312035
Training loss: 0.9871132969856262 / Valid loss: 6.8747127146947955
Training loss: 0.6911038756370544 / Valid loss: 7.021406166894096
Training loss: 0.7842404842376709 / Valid loss: 6.97103283745902

Epoch: 24
Training loss: 0.8393596410751343 / Valid loss: 6.838232290177118
Training loss: 0.6872751712799072 / Valid loss: 6.7430394081842335
Training loss: 0.6175047159194946 / Valid loss: 6.862519613901774
Training loss: 0.6735203266143799 / Valid loss: 6.916020125434512
Training loss: 0.992667555809021 / Valid loss: 7.099601443608602

Epoch: 25
Training loss: 0.6753808856010437 / Valid loss: 6.762231259118943
Training loss: 0.43187612295150757 / Valid loss: 6.86820308140346
Training loss: 1.1698179244995117 / Valid loss: 6.860477633703322
Training loss: 0.4223865270614624 / Valid loss: 6.918870467231387
Training loss: 0.669593095779419 / Valid loss: 7.029194404965355

Epoch: 26
Training loss: 0.9046597480773926 / Valid loss: 6.797090825580415
Training loss: 1.0334348678588867 / Valid loss: 6.761004184541248
Training loss: 0.34703996777534485 / Valid loss: 6.90616911479405
Training loss: 0.3122824430465698 / Valid loss: 6.86344967796689
Training loss: 0.48323753476142883 / Valid loss: 7.03172699383327

Epoch: 27
Training loss: 0.36437496542930603 / Valid loss: 6.933468312308902
Training loss: 0.6029342412948608 / Valid loss: 6.901174036661784
Training loss: 0.614423394203186 / Valid loss: 6.947794346582322
Training loss: 0.4617449939250946 / Valid loss: 6.9538627465566
Training loss: 0.6803674697875977 / Valid loss: 7.0249468712579635

Epoch: 28
Training loss: 0.387935996055603 / Valid loss: 6.901970599946521
Training loss: 0.6165776252746582 / Valid loss: 6.909543144135248
Training loss: 0.5400832891464233 / Valid loss: 6.861772092183431
Training loss: 0.3511140048503876 / Valid loss: 7.040414101736886
Training loss: 0.539892315864563 / Valid loss: 6.983102199009487

Epoch: 29
Training loss: 0.5058392882347107 / Valid loss: 6.861928603762672
Training loss: 0.7486938238143921 / Valid loss: 7.155505398341588
Training loss: 0.3672358989715576 / Valid loss: 6.811366380964007
Training loss: 0.3118017911911011 / Valid loss: 6.879478425071353

Epoch: 30
Training loss: 0.6928936243057251 / Valid loss: 7.0182854947589695
Training loss: 0.44543325901031494 / Valid loss: 6.757925156184605
Training loss: 0.3234328627586365 / Valid loss: 7.008895224616641
Training loss: 0.45212942361831665 / Valid loss: 6.878146564392816
Training loss: 0.3734869956970215 / Valid loss: 6.909860987890334

Epoch: 31
Training loss: 0.35912203788757324 / Valid loss: 6.911509184610276
Training loss: 0.43792688846588135 / Valid loss: 7.023451936812628
Training loss: 0.5828892588615417 / Valid loss: 6.85651330947876
Training loss: 0.4035741984844208 / Valid loss: 7.197467427026658
Training loss: 0.5325425267219543 / Valid loss: 6.896336519150507

Epoch: 32
Training loss: 0.46798238158226013 / Valid loss: 6.920280415671212
Training loss: 0.5129421949386597 / Valid loss: 6.855489594595773
Training loss: 0.3181908130645752 / Valid loss: 6.914389796484084
Training loss: 0.29038310050964355 / Valid loss: 6.8406507128760925
Training loss: 0.5647710561752319 / Valid loss: 6.835189873831613

Epoch: 33
Training loss: 0.4031444489955902 / Valid loss: 6.939921156565348
Training loss: 0.49439507722854614 / Valid loss: 6.8127959501175654
Training loss: 0.36235883831977844 / Valid loss: 6.861376587549845
Training loss: 0.572578489780426 / Valid loss: 6.858007941927228
Training loss: 0.45658621191978455 / Valid loss: 6.850246170588902

Epoch: 34
Training loss: 0.6909438371658325 / Valid loss: 6.767181632632301
Training loss: 0.3100060224533081 / Valid loss: 6.902636882237026
Training loss: 0.48002326488494873 / Valid loss: 6.956700111570813
Training loss: 0.33002769947052 / Valid loss: 6.885793299902053
Training loss: 0.4485366642475128 / Valid loss: 7.008176167805989

Epoch: 35
Training loss: 0.9865694046020508 / Valid loss: 6.830015218825567
Training loss: 0.5776498913764954 / Valid loss: 6.897862325395857
Training loss: 0.5171666741371155 / Valid loss: 6.8616849853878925
Training loss: 0.3185175657272339 / Valid loss: 6.861160954974946
Training loss: 0.4183725118637085 / Valid loss: 6.805342181523641

Epoch: 36
Training loss: 0.4354248046875 / Valid loss: 6.7071679569426035
Training loss: 0.6866554021835327 / Valid loss: 6.8485821383340015
Training loss: 0.4942253530025482 / Valid loss: 6.748570701054164
Training loss: 0.30083948373794556 / Valid loss: 6.890221507208688
Training loss: 0.4545312523841858 / Valid loss: 6.851118828001477

Epoch: 37
Training loss: 0.5846376419067383 / Valid loss: 7.004612102962676
Training loss: 0.25425416231155396 / Valid loss: 6.803554030827113
Training loss: 0.46477121114730835 / Valid loss: 6.90566330864316
Training loss: 0.9308645725250244 / Valid loss: 6.774234317597889
Training loss: 0.6394990086555481 / Valid loss: 6.859247870672316

Epoch: 38
Training loss: 0.5229790806770325 / Valid loss: 6.859157198951358
Training loss: 0.4742722511291504 / Valid loss: 6.826846862974621
Training loss: 0.46572309732437134 / Valid loss: 6.895450078873408
Training loss: 0.3612024188041687 / Valid loss: 6.895119044894264
Training loss: 0.7249857187271118 / Valid loss: 6.882613790602911

Epoch: 39
Training loss: 0.46001923084259033 / Valid loss: 6.975711663564046
Training loss: 0.3459772765636444 / Valid loss: 6.810472106933593
Training loss: 0.4002076983451843 / Valid loss: 6.844748805818104
Training loss: 0.3169283866882324 / Valid loss: 6.756377181552705

Epoch: 40
Training loss: 0.3688444197177887 / Valid loss: 6.988716581889562
Training loss: 0.31692153215408325 / Valid loss: 6.891211704980759
Training loss: 0.3872334361076355 / Valid loss: 6.786558782486688
Training loss: 0.2691856026649475 / Valid loss: 6.79910143897647
Training loss: 0.2676779329776764 / Valid loss: 6.852081425984701

Epoch: 41
Training loss: 0.584932804107666 / Valid loss: 6.849190176100958
Training loss: 0.4023456275463104 / Valid loss: 6.797752480279832
Training loss: 0.30325448513031006 / Valid loss: 6.947733865465437
Training loss: 1.2078900337219238 / Valid loss: 6.976276002611432
Training loss: 0.4149470925331116 / Valid loss: 6.876149756567819

Epoch: 42
Training loss: 0.39032602310180664 / Valid loss: 6.709031223115467
Training loss: 0.3001871705055237 / Valid loss: 6.800860221045358
Training loss: 0.4784907400608063 / Valid loss: 6.735300522758847
Training loss: 0.40767455101013184 / Valid loss: 6.84482813108535
Training loss: 0.4310424327850342 / Valid loss: 6.958239301045736

Epoch: 43
Training loss: 0.4082128703594208 / Valid loss: 6.715197015943981
Training loss: 0.37803182005882263 / Valid loss: 6.753293100992838
Training loss: 0.16625966131687164 / Valid loss: 6.765981011163621
Training loss: 0.49290910363197327 / Valid loss: 7.081740915207636
Training loss: 0.5333818197250366 / Valid loss: 6.968315097263881

Epoch: 44
Training loss: 0.28737175464630127 / Valid loss: 6.7073313486008415
Training loss: 0.1722629964351654 / Valid loss: 6.769401248296102
Training loss: 0.47909608483314514 / Valid loss: 6.752234554290771
Training loss: 0.2275506556034088 / Valid loss: 6.687825638907296
Training loss: 0.5222076773643494 / Valid loss: 6.724186658859253

Epoch: 45
Training loss: 0.32304131984710693 / Valid loss: 6.887733316421508
Training loss: 0.5832504630088806 / Valid loss: 6.705071138200306
Training loss: 0.5492264628410339 / Valid loss: 6.7909575462341305
Training loss: 0.4111666977405548 / Valid loss: 6.701044732048398
Training loss: 0.36251306533813477 / Valid loss: 6.762984625498453

Epoch: 46
Training loss: 0.2727862000465393 / Valid loss: 6.678364667438325
Training loss: 0.32198768854141235 / Valid loss: 6.721526586441767
Training loss: 0.48535650968551636 / Valid loss: 6.803485983893985
Training loss: 0.3723664879798889 / Valid loss: 6.8428798766363235
Training loss: 0.6073732972145081 / Valid loss: 6.881512941632952

Epoch: 47
Training loss: 0.23989813029766083 / Valid loss: 6.78193108694894
Training loss: 0.4724132716655731 / Valid loss: 6.708305699484689
Training loss: 0.5187866687774658 / Valid loss: 6.682447340374901
Training loss: 0.3214375972747803 / Valid loss: 6.768702675047375
Training loss: 0.3901714086532593 / Valid loss: 6.913385995229086

Epoch: 48
Training loss: 0.253079354763031 / Valid loss: 6.744001343136742
Training loss: 0.5310543179512024 / Valid loss: 6.735933394659133
Training loss: 0.5105814933776855 / Valid loss: 6.80726622626895
Training loss: 0.3190954327583313 / Valid loss: 6.706569435482933
Training loss: 0.3793792128562927 / Valid loss: 6.774620124271938

Epoch: 49
Training loss: 0.4124816358089447 / Valid loss: 6.680840501331148
Training loss: 0.31002432107925415 / Valid loss: 6.703553254263742
Training loss: 0.24713607132434845 / Valid loss: 6.760096391042073
Training loss: 0.30090177059173584 / Valid loss: 6.810816387903123

Epoch: 50
Training loss: 0.3706962764263153 / Valid loss: 6.827458272661482
Training loss: 0.38320428133010864 / Valid loss: 6.750355111984979
Training loss: 0.2868631184101105 / Valid loss: 6.659401076180594
Training loss: 0.2883872389793396 / Valid loss: 6.748834330695016
Training loss: 0.562008261680603 / Valid loss: 6.719065700258527

Epoch: 51
Training loss: 0.2471512109041214 / Valid loss: 6.74639112381708
Training loss: 0.3177463412284851 / Valid loss: 6.718392630985805
Training loss: 0.289815753698349 / Valid loss: 6.743921348026821
Training loss: 0.3917962908744812 / Valid loss: 6.61454481851487
Training loss: 0.40255868434906006 / Valid loss: 6.645039985293434

Epoch: 52
Training loss: 0.20757117867469788 / Valid loss: 6.723773229689825
Training loss: 0.33904463052749634 / Valid loss: 6.709273937770298
Training loss: 0.30311405658721924 / Valid loss: 6.691586217426118
Training loss: 0.22939956188201904 / Valid loss: 6.632260150001162
Training loss: 0.4663572907447815 / Valid loss: 6.685382527396793

Epoch: 53
Training loss: 0.3068365454673767 / Valid loss: 6.78039832569304
Training loss: 0.5012734532356262 / Valid loss: 6.738596139635359
Training loss: 0.27735966444015503 / Valid loss: 6.5801393554324195
Training loss: 0.6502377986907959 / Valid loss: 6.822552317664737
Training loss: 0.35023748874664307 / Valid loss: 6.792698387872605

Epoch: 54
Training loss: 0.41845959424972534 / Valid loss: 6.687618705204555
Training loss: 0.463904470205307 / Valid loss: 6.762713443665278
Training loss: 0.22641977667808533 / Valid loss: 6.850458449409121
Training loss: 0.35759979486465454 / Valid loss: 6.697037674131847
Training loss: 0.4495754837989807 / Valid loss: 6.746020112718854

Epoch: 55
Training loss: 0.563720166683197 / Valid loss: 6.671433485121954
Training loss: 0.47859108448028564 / Valid loss: 6.6954275948660715
Training loss: 0.3678862452507019 / Valid loss: 6.809267498198009
Training loss: 0.4210607409477234 / Valid loss: 6.791607280004592
Training loss: 0.33094897866249084 / Valid loss: 6.717492662157331

Epoch: 56
Training loss: 0.6248446702957153 / Valid loss: 6.727197819664365
Training loss: 0.20745807886123657 / Valid loss: 6.7060022444952105
Training loss: 0.2868157625198364 / Valid loss: 6.61083265032087
Training loss: 0.22298631072044373 / Valid loss: 6.6888314065479095
Training loss: 0.3402419984340668 / Valid loss: 6.873394670940581

Epoch: 57
Training loss: 0.5975265502929688 / Valid loss: 6.7056925660087945
Training loss: 0.6231029629707336 / Valid loss: 6.654087171100435
Training loss: 0.39805570244789124 / Valid loss: 6.702675823938279
Training loss: 0.5699640512466431 / Valid loss: 6.68742641721453
Training loss: 0.4310111701488495 / Valid loss: 6.810134297325497

Epoch: 58
Training loss: 0.33928000926971436 / Valid loss: 6.7944656871614
Training loss: 0.5132818222045898 / Valid loss: 6.822099140712193
Training loss: 0.1570674031972885 / Valid loss: 6.769105379922049
Training loss: 0.442685067653656 / Valid loss: 6.637626884097145
Training loss: 0.2664511203765869 / Valid loss: 6.698658707028343

Epoch: 59
Training loss: 0.30701684951782227 / Valid loss: 6.684155486878895
Training loss: 0.49762654304504395 / Valid loss: 6.594595109848749
Training loss: 0.20613618195056915 / Valid loss: 6.642565118698847
Training loss: 0.31091612577438354 / Valid loss: 6.763343325115385

Epoch: 60
Training loss: 0.3153267502784729 / Valid loss: 7.0421697026207335
Training loss: 0.6598629951477051 / Valid loss: 6.864576725732713
Training loss: 0.2438582330942154 / Valid loss: 6.6290724572681246
Training loss: 0.3429989814758301 / Valid loss: 6.618421645391555
Training loss: 0.21515816450119019 / Valid loss: 6.674779733022054

Epoch: 61
Training loss: 0.3506452143192291 / Valid loss: 6.654799041293916
Training loss: 0.28080666065216064 / Valid loss: 6.598044009435744
Training loss: 0.6038864850997925 / Valid loss: 6.712476226261684
Training loss: 0.36101478338241577 / Valid loss: 6.689102495284308
Training loss: 0.19444799423217773 / Valid loss: 6.755177529652913

Epoch: 62
Training loss: 0.21449124813079834 / Valid loss: 6.597038614182245
Training loss: 0.59621661901474 / Valid loss: 6.688204840251378
Training loss: 0.2546719014644623 / Valid loss: 6.592263884771437
Training loss: 0.3417029082775116 / Valid loss: 6.633792804536365
Training loss: 0.29332274198532104 / Valid loss: 6.718352778752645

Epoch: 63
Training loss: 0.3389047384262085 / Valid loss: 6.622619578951881
Training loss: 0.3676445782184601 / Valid loss: 6.581061167944045
Training loss: 0.17669038474559784 / Valid loss: 6.6130304086776
Training loss: 0.40068429708480835 / Valid loss: 6.686364096686954
Training loss: 0.17529423534870148 / Valid loss: 6.713154234204974

Epoch: 64
Training loss: 0.2943063974380493 / Valid loss: 6.490254159200759
Training loss: 0.1906624585390091 / Valid loss: 6.567365957441784
Training loss: 0.5505138039588928 / Valid loss: 6.621095884413946
Training loss: 0.23796790838241577 / Valid loss: 6.766010693141392
Training loss: 0.24791644513607025 / Valid loss: 6.822465442475819

Epoch: 65
Training loss: 0.2073822319507599 / Valid loss: 6.5285111404600595
Training loss: 0.39523953199386597 / Valid loss: 6.591360870997111
Training loss: 0.3413603901863098 / Valid loss: 6.745652353195917
Training loss: 0.30060210824012756 / Valid loss: 6.671729065123058
Training loss: 1.2290129661560059 / Valid loss: 6.700179517836798

Epoch: 66
Training loss: 0.35805588960647583 / Valid loss: 6.5398833978743784
Training loss: 0.26997658610343933 / Valid loss: 6.533526207151867
Training loss: 0.5388424396514893 / Valid loss: 6.652726566223871
Training loss: 0.18387764692306519 / Valid loss: 6.598471357708886
Training loss: 0.4257374703884125 / Valid loss: 6.709581393287295

Epoch: 67
Training loss: 0.342794805765152 / Valid loss: 6.653990073431106
Training loss: 0.18486344814300537 / Valid loss: 6.5737508796510244
Training loss: 0.19393864274024963 / Valid loss: 6.728783398582822
Training loss: 0.741718053817749 / Valid loss: 6.671461654844738
Training loss: 0.1896497756242752 / Valid loss: 6.588567275092715

Epoch: 68
Training loss: 0.25574779510498047 / Valid loss: 6.738128162565685
Training loss: 0.32374680042266846 / Valid loss: 6.723837298438663
Training loss: 0.23225489258766174 / Valid loss: 6.698892003013974
Training loss: 0.2614475190639496 / Valid loss: 6.671468932288033
Training loss: 0.4797174334526062 / Valid loss: 6.680914987836565

Epoch: 69
Training loss: 0.37791913747787476 / Valid loss: 6.580595207214356
Training loss: 0.18169423937797546 / Valid loss: 6.662476162683396
Training loss: 0.3053697347640991 / Valid loss: 6.743009045010521
Training loss: 0.2857421040534973 / Valid loss: 6.680840984980265

Epoch: 70
Training loss: 0.15205365419387817 / Valid loss: 6.652647699628558
Training loss: 0.42214784026145935 / Valid loss: 6.69452851159232
Training loss: 0.27521079778671265 / Valid loss: 6.634945447104318
Training loss: 0.2875935435295105 / Valid loss: 6.692101669311524
Training loss: 0.34156426787376404 / Valid loss: 6.719008218674433

Epoch: 71
Training loss: 0.3640439510345459 / Valid loss: 6.77816378729684
Training loss: 0.48805707693099976 / Valid loss: 6.650673938932873
Training loss: 0.27437493205070496 / Valid loss: 6.5628108887445356
Training loss: 0.2233055830001831 / Valid loss: 6.581970973241897
Training loss: 0.47270312905311584 / Valid loss: 6.63338741120838

Epoch: 72
Training loss: 0.19438359141349792 / Valid loss: 6.579217956179664
Training loss: 0.433140367269516 / Valid loss: 6.6487732115246
Training loss: 0.2627412676811218 / Valid loss: 6.624934677850632
Training loss: 0.2024679183959961 / Valid loss: 6.592256541479202
Training loss: 0.49399858713150024 / Valid loss: 6.767768255869547

Epoch: 73
Training loss: 0.45087727904319763 / Valid loss: 6.652540788196382
Training loss: 0.3708835244178772 / Valid loss: 6.635646942683628
Training loss: 0.2231827676296234 / Valid loss: 6.662844662439255
Training loss: 0.2669631242752075 / Valid loss: 6.646315860748291
Training loss: 0.23651760816574097 / Valid loss: 6.730236961728051

Epoch: 74
Training loss: 0.19732210040092468 / Valid loss: 6.656298237755185
Training loss: 0.3130336403846741 / Valid loss: 6.5522129967099145
Training loss: 0.44681164622306824 / Valid loss: 6.492975929805211
Training loss: 0.31222066283226013 / Valid loss: 6.663017520450411
Training loss: 0.20401397347450256 / Valid loss: 6.589029700415475

Epoch: 75
Training loss: 0.4409768581390381 / Valid loss: 6.595940844217936
Training loss: 0.32814905047416687 / Valid loss: 6.648918533325196
Training loss: 0.5441973209381104 / Valid loss: 6.6851639066423685
Training loss: 0.2011454999446869 / Valid loss: 6.55321284702846
Training loss: 0.4068012833595276 / Valid loss: 6.61397309530349

Epoch: 76
Training loss: 0.3210447430610657 / Valid loss: 6.533609689985003
Training loss: 0.4163230061531067 / Valid loss: 6.5234950837634855
Training loss: 0.22019372880458832 / Valid loss: 6.769771466936384
Training loss: 0.28016138076782227 / Valid loss: 6.584591182072957
Training loss: 0.20006026327610016 / Valid loss: 6.623555912290301

Epoch: 77
Training loss: 0.19589956104755402 / Valid loss: 6.520887567883446
Training loss: 0.2464345097541809 / Valid loss: 6.551894231069656
Training loss: 0.4143565595149994 / Valid loss: 6.629134019215901
Training loss: 0.40897876024246216 / Valid loss: 6.619436840783982
Training loss: 0.5242934226989746 / Valid loss: 6.673334307897658

Epoch: 78
Training loss: 0.2526826560497284 / Valid loss: 6.635404759361631
Training loss: 0.15289264917373657 / Valid loss: 6.574841299511138
Training loss: 0.2966405153274536 / Valid loss: 6.5411285854521255
Training loss: 0.21035808324813843 / Valid loss: 6.629784123102824
Training loss: 0.4658309817314148 / Valid loss: 6.577439689636231

Epoch: 79
Training loss: 0.15384513139724731 / Valid loss: 6.599957752227783
Training loss: 0.31102845072746277 / Valid loss: 6.582543940771194
Training loss: 0.25043123960494995 / Valid loss: 6.562869358062744
Training loss: 0.2823439836502075 / Valid loss: 6.599431051526751
ModuleList(
  (0): Linear(in_features=5376, out_features=2000, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=2000, out_features=100, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=100, out_features=16, bias=True)
  (9): Dropout(p=0, inplace=False)
  (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (11): LeakyReLU(negative_slope=0.02)
  (12): Linear(in_features=16, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.965176051003592
Training regression with following parameters:
dnn_hidden_units : 300, 32
dropout_probs : 0.0, 0.0
learning_rate : 0.0001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : Adam
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : Bert
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=5376, out_features=300, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=300, out_features=32, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=32, out_features=1, bias=True)
)

Epoch: 0
Training loss: 13.485506057739258 / Valid loss: 16.552648362659273
Model is saved in epoch 0, overall batch: 0
Training loss: 8.22925853729248 / Valid loss: 13.865889921642484
Model is saved in epoch 0, overall batch: 100
Training loss: 10.241255760192871 / Valid loss: 11.969333176385788
Model is saved in epoch 0, overall batch: 200
Training loss: 10.358463287353516 / Valid loss: 11.150789619627453
Model is saved in epoch 0, overall batch: 300
Training loss: 8.018839836120605 / Valid loss: 10.345452067965553
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 11.759272575378418 / Valid loss: 10.256315503801618
Model is saved in epoch 1, overall batch: 500
Training loss: 7.6574249267578125 / Valid loss: 9.549156325204033
Model is saved in epoch 1, overall batch: 600
Training loss: 6.881555557250977 / Valid loss: 8.997743847256615
Model is saved in epoch 1, overall batch: 700
Training loss: 5.406282424926758 / Valid loss: 8.67201589856829
Model is saved in epoch 1, overall batch: 800
Training loss: 8.251249313354492 / Valid loss: 7.469128517877488
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 6.6019368171691895 / Valid loss: 7.3130986032031835
Model is saved in epoch 2, overall batch: 1000
Training loss: 5.7315545082092285 / Valid loss: 7.0377616178421745
Model is saved in epoch 2, overall batch: 1100
Training loss: 5.523411750793457 / Valid loss: 6.408396620977492
Model is saved in epoch 2, overall batch: 1200
Training loss: 7.067471027374268 / Valid loss: 6.80925285021464
Training loss: 5.424326419830322 / Valid loss: 6.043492312658401
Model is saved in epoch 2, overall batch: 1400

Epoch: 3
Training loss: 4.345699787139893 / Valid loss: 6.195551611128307
Training loss: 3.6437573432922363 / Valid loss: 5.968315624055409
Model is saved in epoch 3, overall batch: 1600
Training loss: 6.085458755493164 / Valid loss: 5.953125179381598
Model is saved in epoch 3, overall batch: 1700
Training loss: 4.98327112197876 / Valid loss: 5.703778941290719
Model is saved in epoch 3, overall batch: 1800
Training loss: 4.883328437805176 / Valid loss: 5.83619107291812

Epoch: 4
Training loss: 2.928367853164673 / Valid loss: 5.942903162184216
Training loss: 3.861752510070801 / Valid loss: 5.812351724079677
Training loss: 4.301368713378906 / Valid loss: 5.991074403127034
Training loss: 4.796445369720459 / Valid loss: 5.775556686946324
Training loss: 5.227199554443359 / Valid loss: 5.77493687130156

Epoch: 5
Training loss: 4.842301845550537 / Valid loss: 5.890214225224086
Training loss: 4.513247013092041 / Valid loss: 5.931133249827794
Training loss: 3.9927265644073486 / Valid loss: 6.126261865525018
Training loss: 3.022768497467041 / Valid loss: 5.953989676066807
Training loss: 5.63494873046875 / Valid loss: 5.93120668502081

Epoch: 6
Training loss: 3.519346237182617 / Valid loss: 6.162134722300938
Training loss: 2.181300640106201 / Valid loss: 6.641494087945848
Training loss: 3.228849172592163 / Valid loss: 6.266521072387695
Training loss: 3.8385419845581055 / Valid loss: 6.138916531063262
Training loss: 3.5695643424987793 / Valid loss: 6.055485391616822

Epoch: 7
Training loss: 3.3118791580200195 / Valid loss: 6.782407374609084
Training loss: 1.7126188278198242 / Valid loss: 6.7648180371239075
Training loss: 2.619924545288086 / Valid loss: 6.315358772731963
Training loss: 3.4696474075317383 / Valid loss: 6.319690504528228
Training loss: 2.5432019233703613 / Valid loss: 6.735626838320777

Epoch: 8
Training loss: 2.498527765274048 / Valid loss: 7.006040059952509
Training loss: 2.7935991287231445 / Valid loss: 6.519283594403948
Training loss: 2.7384846210479736 / Valid loss: 7.590093176705497
Training loss: 2.713926315307617 / Valid loss: 6.501419051488241
Training loss: 3.2345125675201416 / Valid loss: 6.783861187526158

Epoch: 9
Training loss: 1.8865268230438232 / Valid loss: 6.789982500530424
Training loss: 3.0342159271240234 / Valid loss: 6.640279615493048
Training loss: 2.889190196990967 / Valid loss: 6.722147680464245
Training loss: 2.381490468978882 / Valid loss: 6.610790752229237

Epoch: 10
Training loss: 1.9844849109649658 / Valid loss: 6.814388954071772
Training loss: 1.961834192276001 / Valid loss: 6.682680452437628
Training loss: 2.622610330581665 / Valid loss: 6.772887584141323
Training loss: 2.3413150310516357 / Valid loss: 6.7594170615786595
Training loss: 2.4844555854797363 / Valid loss: 7.032551565624419

Epoch: 11
Training loss: 2.1771810054779053 / Valid loss: 6.772368540082659
Training loss: 1.747480869293213 / Valid loss: 6.786648530051822
Training loss: 2.035036087036133 / Valid loss: 6.800640919094994
Training loss: 2.247866153717041 / Valid loss: 8.502589162190755
Training loss: 1.629194974899292 / Valid loss: 7.138380890800839

Epoch: 12
Training loss: 1.3229968547821045 / Valid loss: 6.90823104495094
Training loss: 1.3064475059509277 / Valid loss: 6.834156631288074
Training loss: 1.6528788805007935 / Valid loss: 6.8817662988390245
Training loss: 1.6349018812179565 / Valid loss: 6.7977943602062405
Training loss: 1.834486484527588 / Valid loss: 6.892977734974452

Epoch: 13
Training loss: 1.4515258073806763 / Valid loss: 6.925282762164161
Training loss: 0.9892738461494446 / Valid loss: 6.737036541530064
Training loss: 1.2237510681152344 / Valid loss: 6.832575679960705
Training loss: 1.617051124572754 / Valid loss: 6.972277604965937
Training loss: 1.6354531049728394 / Valid loss: 6.948142210642497

Epoch: 14
Training loss: 1.5422146320343018 / Valid loss: 6.929645819891067
Training loss: 1.1413692235946655 / Valid loss: 7.430246914000739
Training loss: 1.0408620834350586 / Valid loss: 7.226158954983666
Training loss: 1.4732259511947632 / Valid loss: 7.049402055286226
Training loss: 1.0832334756851196 / Valid loss: 7.056605307261149

Epoch: 15
Training loss: 1.4463310241699219 / Valid loss: 7.056347061338879
Training loss: 1.392120599746704 / Valid loss: 7.028835360209147
Training loss: 1.381845474243164 / Valid loss: 7.00615059080578
Training loss: 1.2854466438293457 / Valid loss: 7.165252717336019
Training loss: 0.9642549157142639 / Valid loss: 6.984876187642415

Epoch: 16
Training loss: 1.7979986667633057 / Valid loss: 7.022317790985108
Training loss: 0.9639847278594971 / Valid loss: 7.687846615200951
Training loss: 1.0207526683807373 / Valid loss: 6.983453950427827
Training loss: 1.276789665222168 / Valid loss: 7.175333799634661
Training loss: 1.0586168766021729 / Valid loss: 7.093871171133859

Epoch: 17
Training loss: 0.8097612857818604 / Valid loss: 7.145289323443458
Training loss: 1.0120124816894531 / Valid loss: 7.111357359659104
Training loss: 1.1571483612060547 / Valid loss: 7.0435736315590995
Training loss: 1.1842131614685059 / Valid loss: 7.513935820261637
Training loss: 1.1856135129928589 / Valid loss: 7.122999186742874

Epoch: 18
Training loss: 0.7470845580101013 / Valid loss: 7.047831644330706
Training loss: 1.7169713973999023 / Valid loss: 6.960775597890218
Training loss: 1.107414960861206 / Valid loss: 7.3154444376627605
Training loss: 1.3543950319290161 / Valid loss: 7.177393761135283
Training loss: 1.103412389755249 / Valid loss: 7.190662670135498

Epoch: 19
Training loss: 0.9500818252563477 / Valid loss: 7.1410319691612605
Training loss: 1.1481575965881348 / Valid loss: 7.713646866026378
Training loss: 1.1512280702590942 / Valid loss: 7.430515271141416
Training loss: 1.027085781097412 / Valid loss: 7.135754585266113

Epoch: 20
Training loss: 0.6493785381317139 / Valid loss: 7.32870687303089
Training loss: 0.7466704249382019 / Valid loss: 7.259115550631568
Training loss: 0.6110968589782715 / Valid loss: 7.039972468784877
Training loss: 1.2642333507537842 / Valid loss: 7.216489147004627
Training loss: 0.767075777053833 / Valid loss: 7.309171785627092

Epoch: 21
Training loss: 0.9578944444656372 / Valid loss: 7.160520712534587
Training loss: 0.7571823000907898 / Valid loss: 7.195709632691883
Training loss: 1.0136897563934326 / Valid loss: 7.722887284415108
Training loss: 0.9289685487747192 / Valid loss: 7.965741816021147
Training loss: 1.06260085105896 / Valid loss: 7.220825708480108

Epoch: 22
Training loss: 0.6888749599456787 / Valid loss: 7.270315247490292
Training loss: 0.9841432571411133 / Valid loss: 7.112723355066208
Training loss: 1.0290039777755737 / Valid loss: 7.1294762202671595
Training loss: 0.5544905662536621 / Valid loss: 7.600159050169445
Training loss: 0.8756568431854248 / Valid loss: 7.307432665143694

Epoch: 23
Training loss: 0.6414084434509277 / Valid loss: 7.440625068119594
Training loss: 1.2075589895248413 / Valid loss: 7.042097436814081
Training loss: 1.1824485063552856 / Valid loss: 7.17326511655535
Training loss: 0.9570131301879883 / Valid loss: 7.246788924080985
Training loss: 0.8180095553398132 / Valid loss: 7.272665212267921

Epoch: 24
Training loss: 0.4693340063095093 / Valid loss: 7.131731868925549
Training loss: 1.2630606889724731 / Valid loss: 7.427453399839855
Training loss: 0.5064395070075989 / Valid loss: 7.133121535891578
Training loss: 0.8948311805725098 / Valid loss: 7.236420740400042
Training loss: 0.8293712139129639 / Valid loss: 7.657892454238165

Epoch: 25
Training loss: 0.8017382621765137 / Valid loss: 7.972182192121234
Training loss: 1.0829272270202637 / Valid loss: 7.186772895994641
Training loss: 0.6860487461090088 / Valid loss: 7.254732486179897
Training loss: 0.9759463667869568 / Valid loss: 7.462377439226423
Training loss: 0.7795689105987549 / Valid loss: 7.3229260262988864

Epoch: 26
Training loss: 0.8743743896484375 / Valid loss: 7.318362367720831
Training loss: 0.5629526972770691 / Valid loss: 7.507926577613468
Training loss: 1.0308730602264404 / Valid loss: 7.104080717904227
Training loss: 0.7438271045684814 / Valid loss: 7.224047570001511
Training loss: 0.7149567604064941 / Valid loss: 7.22013585681007

Epoch: 27
Training loss: 0.633277177810669 / Valid loss: 7.240124997638521
Training loss: 0.36785125732421875 / Valid loss: 7.15103455498105
Training loss: 1.3982067108154297 / Valid loss: 7.446244058154878
Training loss: 0.8192980885505676 / Valid loss: 7.142419499442691
Training loss: 0.4749196171760559 / Valid loss: 7.587369369325184

Epoch: 28
Training loss: 0.417674720287323 / Valid loss: 7.17670928864252
Training loss: 0.4325339198112488 / Valid loss: 7.198163420813424
Training loss: 0.5170741677284241 / Valid loss: 7.337751075199672
Training loss: 0.5556463003158569 / Valid loss: 7.16787778763544
Training loss: 0.8508818745613098 / Valid loss: 7.218611197244553

Epoch: 29
Training loss: 0.7658052444458008 / Valid loss: 7.8699110076541
Training loss: 0.43019384145736694 / Valid loss: 7.208646924155099
Training loss: 0.6360567808151245 / Valid loss: 7.166488633837019
Training loss: 0.9754325747489929 / Valid loss: 7.958179646446592

Epoch: 30
Training loss: 0.6516331434249878 / Valid loss: 7.184434105101086
Training loss: 1.042105793952942 / Valid loss: 7.287758318583171
Training loss: 0.38020944595336914 / Valid loss: 7.184267679850261
Training loss: 0.40461450815200806 / Valid loss: 7.1868491445268905
Training loss: 0.9297048449516296 / Valid loss: 7.262267684936523

Epoch: 31
Training loss: 0.5271829962730408 / Valid loss: 7.225095362890334
Training loss: 1.0828704833984375 / Valid loss: 7.038180510203044
Training loss: 0.6640037298202515 / Valid loss: 7.464965470631918
Training loss: 0.6236491203308105 / Valid loss: 7.207226385389055
Training loss: 0.7305420637130737 / Valid loss: 7.1773869332813085

Epoch: 32
Training loss: 0.44706854224205017 / Valid loss: 7.336225650424049
Training loss: 0.5903486609458923 / Valid loss: 7.258548872811454
Training loss: 0.5245429873466492 / Valid loss: 7.433815270378476
Training loss: 0.4944256544113159 / Valid loss: 7.2644818442208425
Training loss: 0.6380219459533691 / Valid loss: 7.259572880608695

Epoch: 33
Training loss: 0.43161541223526 / Valid loss: 7.156936986105783
Training loss: 0.7766989469528198 / Valid loss: 7.146816571553548
Training loss: 0.6814211010932922 / Valid loss: 7.217694150833856
Training loss: 0.5528929233551025 / Valid loss: 7.294396620705014
Training loss: 0.5293247699737549 / Valid loss: 7.887059643155053

Epoch: 34
Training loss: 0.9457837343215942 / Valid loss: 7.343801707313174
Training loss: 0.4446396231651306 / Valid loss: 7.141716107868013
Training loss: 0.45383015275001526 / Valid loss: 7.200739792415074
Training loss: 0.5024568438529968 / Valid loss: 7.176289213271368
Training loss: 0.9410631656646729 / Valid loss: 7.338185214996338

Epoch: 35
Training loss: 0.6484671235084534 / Valid loss: 7.190289193107969
Training loss: 0.4244862198829651 / Valid loss: 7.455016070320493
Training loss: 0.45706620812416077 / Valid loss: 7.186460681188674
Training loss: 0.4246668517589569 / Valid loss: 7.246242066792079
Training loss: 0.3787277340888977 / Valid loss: 7.626142179398309

Epoch: 36
Training loss: 0.4324735403060913 / Valid loss: 7.327129990713937
Training loss: 0.5639158487319946 / Valid loss: 7.17691102709089
Training loss: 0.7515487670898438 / Valid loss: 7.11541629972912
Training loss: 0.7582157850265503 / Valid loss: 7.0456661633082796
Training loss: 0.49600932002067566 / Valid loss: 7.089993554069882

Epoch: 37
Training loss: 0.5421404838562012 / Valid loss: 7.134672391982305
Training loss: 0.4929816722869873 / Valid loss: 7.109780783880325
Training loss: 0.35245025157928467 / Valid loss: 7.17235689163208
Training loss: 0.5098813772201538 / Valid loss: 7.212559504736038
Training loss: 0.5391055941581726 / Valid loss: 7.169134303501674

Epoch: 38
Training loss: 0.5214968323707581 / Valid loss: 7.059951950254894
Training loss: 0.3965655565261841 / Valid loss: 7.032583027794248
Training loss: 0.5592663288116455 / Valid loss: 7.165171423412505
Training loss: 0.8139569759368896 / Valid loss: 7.136174667449224
Training loss: 1.2661253213882446 / Valid loss: 7.20857055300758

Epoch: 39
Training loss: 0.26306453347206116 / Valid loss: 7.247021166483561
Training loss: 0.43685781955718994 / Valid loss: 7.041598769596645
Training loss: 0.31398433446884155 / Valid loss: 7.853271511622838
Training loss: 0.3933102488517761 / Valid loss: 7.141638324374244

Epoch: 40
Training loss: 0.40636104345321655 / Valid loss: 7.237096073513939
Training loss: 0.41994142532348633 / Valid loss: 7.013765434991746
Training loss: 0.5130747556686401 / Valid loss: 7.243311482384091
Training loss: 0.30321717262268066 / Valid loss: 7.085739494505383
Training loss: 0.433379203081131 / Valid loss: 7.175466387612479

Epoch: 41
Training loss: 0.6816391944885254 / Valid loss: 7.170818437848772
Training loss: 0.6741217374801636 / Valid loss: 7.0775970186506
Training loss: 0.6565911173820496 / Valid loss: 7.142997137705485
Training loss: 0.839560329914093 / Valid loss: 7.097274344308036
Training loss: 0.3475450277328491 / Valid loss: 7.509514399937221

Epoch: 42
Training loss: 0.6666176319122314 / Valid loss: 7.041676126207624
Training loss: 0.45025497674942017 / Valid loss: 6.991559525898524
Training loss: 0.7290557622909546 / Valid loss: 7.631070731935047
Training loss: 0.3627805709838867 / Valid loss: 7.026871118091401
Training loss: 0.5730393528938293 / Valid loss: 7.163066596076602

Epoch: 43
Training loss: 0.5115251541137695 / Valid loss: 7.304672077723912
Training loss: 0.7815093994140625 / Valid loss: 7.313245909554618
Training loss: 0.7226842641830444 / Valid loss: 7.044915871393113
Training loss: 1.189978837966919 / Valid loss: 7.152727899097261
Training loss: 0.6602848768234253 / Valid loss: 7.478931949252174

Epoch: 44
Training loss: 0.6218006610870361 / Valid loss: 7.193476817721412
Training loss: 0.306934118270874 / Valid loss: 6.964347830272856
Training loss: 0.8090451955795288 / Valid loss: 7.692579809824625
Training loss: 0.37748610973358154 / Valid loss: 7.016822574252174
Training loss: 0.4449232220649719 / Valid loss: 7.978857866923014

Epoch: 45
Training loss: 0.37415656447410583 / Valid loss: 7.22911817459833
Training loss: 0.7822514176368713 / Valid loss: 7.065892115093413
Training loss: 0.5702424645423889 / Valid loss: 7.190709109533401
Training loss: 0.6088656783103943 / Valid loss: 7.098036856878371
Training loss: 0.446061372756958 / Valid loss: 7.219434461139497

Epoch: 46
Training loss: 0.484383761882782 / Valid loss: 7.031720197768438
Training loss: 0.5090129375457764 / Valid loss: 7.1566730499267575
Training loss: 0.4875900447368622 / Valid loss: 7.145297229857672
Training loss: 0.4394127130508423 / Valid loss: 7.066010509218488
Training loss: 0.8006414175033569 / Valid loss: 7.115484877995082

Epoch: 47
Training loss: 0.5141521692276001 / Valid loss: 7.038325277964274
Training loss: 0.4992489218711853 / Valid loss: 7.0692479587736585
Training loss: 0.2574266493320465 / Valid loss: 6.959195645650228
Training loss: 0.4415140151977539 / Valid loss: 7.205719979604085
Training loss: 0.6547490358352661 / Valid loss: 7.255238637470064

Epoch: 48
Training loss: 0.33514371514320374 / Valid loss: 7.032606846945626
Training loss: 0.34973207116127014 / Valid loss: 7.217961347670782
Training loss: 0.3202575743198395 / Valid loss: 7.040045120602563
Training loss: 0.8819045424461365 / Valid loss: 7.289717401776995
Training loss: 0.4482842683792114 / Valid loss: 7.204492991311209

Epoch: 49
Training loss: 0.4178394079208374 / Valid loss: 7.093422508239746
Training loss: 0.6880998611450195 / Valid loss: 7.125930104936872
Training loss: 0.4290180206298828 / Valid loss: 7.07842074348813
Training loss: 0.37880849838256836 / Valid loss: 7.073765986306327

Epoch: 50
Training loss: 0.5622730851173401 / Valid loss: 7.146819618770055
Training loss: 0.43465113639831543 / Valid loss: 7.009046245756603
Training loss: 0.48140305280685425 / Valid loss: 7.106653547286987
Training loss: 0.35995155572891235 / Valid loss: 7.172739514850435
Training loss: 0.393032431602478 / Valid loss: 7.020440333230155

Epoch: 51
Training loss: 0.34157851338386536 / Valid loss: 7.040830807458787
Training loss: 0.2498546987771988 / Valid loss: 7.1207255908421105
Training loss: 0.3573892116546631 / Valid loss: 7.598138019016811
Training loss: 0.7060039043426514 / Valid loss: 7.523833956037249
Training loss: 0.37092703580856323 / Valid loss: 7.201797349112375

Epoch: 52
Training loss: 0.46780461072921753 / Valid loss: 7.260138756888253
Training loss: 0.517809271812439 / Valid loss: 7.30215620313372
Training loss: 0.38768088817596436 / Valid loss: 7.458974910917736
Training loss: 0.4470059871673584 / Valid loss: 7.495853088015601
Training loss: 0.3682680130004883 / Valid loss: 7.385082446961176

Epoch: 53
Training loss: 0.325044184923172 / Valid loss: 7.798708443414597
Training loss: 0.4273512661457062 / Valid loss: 7.010699839819045
Training loss: 0.5373608469963074 / Valid loss: 7.152216402689616
Training loss: 0.45513489842414856 / Valid loss: 7.1090602148146855
Training loss: 0.4536907374858856 / Valid loss: 7.13160472143264

Epoch: 54
Training loss: 0.47427672147750854 / Valid loss: 6.982970396677653
Training loss: 0.5328158736228943 / Valid loss: 6.993403557368687
Training loss: 0.546023964881897 / Valid loss: 6.985285715829758
Training loss: 0.40855467319488525 / Valid loss: 7.096398880368187
Training loss: 0.3669481873512268 / Valid loss: 7.176253527686709

Epoch: 55
Training loss: 0.22086137533187866 / Valid loss: 7.309250924700782
Training loss: 0.38456490635871887 / Valid loss: 7.351333136785598
Training loss: 0.5526068210601807 / Valid loss: 7.198538398742675
Training loss: 0.5637142658233643 / Valid loss: 7.012301940009707
Training loss: 0.49666646122932434 / Valid loss: 7.342152886163621

Epoch: 56
Training loss: 0.3276900053024292 / Valid loss: 7.119364084516253
Training loss: 0.558796763420105 / Valid loss: 7.112289910089402
Training loss: 0.3697497248649597 / Valid loss: 6.99215456644694
Training loss: 0.6993527412414551 / Valid loss: 7.3321836471557615
Training loss: 0.5078305006027222 / Valid loss: 7.027176137197586

Epoch: 57
Training loss: 0.5101423263549805 / Valid loss: 7.039335471107846
Training loss: 0.683842122554779 / Valid loss: 7.171831526075091
Training loss: 0.4774046838283539 / Valid loss: 7.004156716664633
Training loss: 0.3999171257019043 / Valid loss: 6.969603329613095
Training loss: 0.6961308717727661 / Valid loss: 7.048035065333049

Epoch: 58
Training loss: 0.35944074392318726 / Valid loss: 7.0327493145352316
Training loss: 0.4009038805961609 / Valid loss: 7.00906023979187
Training loss: 0.6216621994972229 / Valid loss: 7.185669036138625
Training loss: 0.58864426612854 / Valid loss: 7.529734897613525
Training loss: 0.3521537482738495 / Valid loss: 7.005510375613258

Epoch: 59
Training loss: 0.248367041349411 / Valid loss: 7.002582168579101
Training loss: 0.5306150913238525 / Valid loss: 7.01078718276251
Training loss: 0.3636283576488495 / Valid loss: 7.1560272761753625
Training loss: 0.614877462387085 / Valid loss: 7.09161407379877

Epoch: 60
Training loss: 0.43643584847450256 / Valid loss: 7.059632478441511
Training loss: 0.33343422412872314 / Valid loss: 7.309878458295549
Training loss: 0.5441653728485107 / Valid loss: 6.96987760407584
Training loss: 0.3353337049484253 / Valid loss: 6.9210684140523275
Training loss: 0.5830079913139343 / Valid loss: 7.277833529881069

Epoch: 61
Training loss: 0.4223649799823761 / Valid loss: 7.107553223201207
Training loss: 0.41863906383514404 / Valid loss: 7.026759345190865
Training loss: 0.7377012968063354 / Valid loss: 6.960854475838797
Training loss: 0.4057496190071106 / Valid loss: 7.200962443578811
Training loss: 0.3954938054084778 / Valid loss: 7.0199742680504205

Epoch: 62
Training loss: 0.42132776975631714 / Valid loss: 7.113548078991118
Training loss: 0.22417384386062622 / Valid loss: 6.960001214345296
Training loss: 0.5263669490814209 / Valid loss: 7.053594748179118
Training loss: 0.2975061535835266 / Valid loss: 7.724872053237188
Training loss: 0.6355141997337341 / Valid loss: 6.9794122559683665

Epoch: 63
Training loss: 0.7040436267852783 / Valid loss: 7.1703076271783734
Training loss: 0.27081942558288574 / Valid loss: 7.020102328345889
Training loss: 0.4429219365119934 / Valid loss: 7.086340597697666
Training loss: 0.43258678913116455 / Valid loss: 7.150651109786261
Training loss: 0.34044286608695984 / Valid loss: 7.096336487361363

Epoch: 64
Training loss: 0.4155799150466919 / Valid loss: 6.99486818540664
Training loss: 0.33120471239089966 / Valid loss: 6.928445552644275
Training loss: 0.48190248012542725 / Valid loss: 7.207620021275112
Training loss: 0.7207440733909607 / Valid loss: 7.151358220690772
Training loss: 0.5872200727462769 / Valid loss: 7.042740812755766

Epoch: 65
Training loss: 0.8638954162597656 / Valid loss: 6.9067539169674825
Training loss: 1.080848217010498 / Valid loss: 6.936885161626907
Training loss: 0.28632083535194397 / Valid loss: 7.08702118737357
Training loss: 0.8418132662773132 / Valid loss: 6.9655355476197744
Training loss: 0.31886225938796997 / Valid loss: 7.211433542342413

Epoch: 66
Training loss: 0.23249147832393646 / Valid loss: 7.133314809345063
Training loss: 0.4578816890716553 / Valid loss: 6.991160665239606
Training loss: 0.42023855447769165 / Valid loss: 7.045126251947313
Training loss: 0.2688828706741333 / Valid loss: 7.02109275772458
Training loss: 0.3097619116306305 / Valid loss: 7.034061454591297

Epoch: 67
Training loss: 0.22867166996002197 / Valid loss: 6.94937337693714
Training loss: 0.306943416595459 / Valid loss: 7.03049543925694
Training loss: 0.880386233329773 / Valid loss: 6.967599237532843
Training loss: 0.40545937418937683 / Valid loss: 7.148779464903332
Training loss: 0.6532101631164551 / Valid loss: 6.979838848114014

Epoch: 68
Training loss: 0.25748732686042786 / Valid loss: 7.0580970287323
Training loss: 0.652129054069519 / Valid loss: 7.060212044488816
Training loss: 0.38673245906829834 / Valid loss: 7.085378546941848
Training loss: 0.2861093282699585 / Valid loss: 7.164349674043201
Training loss: 0.31972968578338623 / Valid loss: 6.902882725851876

Epoch: 69
Training loss: 0.6497220396995544 / Valid loss: 6.9496759505498975
Training loss: 0.3304334580898285 / Valid loss: 6.921778642563593
Training loss: 0.30830666422843933 / Valid loss: 6.941526356197539
Training loss: 0.41288718581199646 / Valid loss: 7.000683997926258

Epoch: 70
Training loss: 0.26838600635528564 / Valid loss: 7.213895507085891
Training loss: 0.29374754428863525 / Valid loss: 7.098291306268601
Training loss: 0.33305972814559937 / Valid loss: 6.991543065933954
Training loss: 0.2519958019256592 / Valid loss: 7.022150848025367
Training loss: 0.4450641870498657 / Valid loss: 7.058964752015614

Epoch: 71
Training loss: 0.4073164463043213 / Valid loss: 6.933645818347022
Training loss: 0.39000648260116577 / Valid loss: 6.997271991911388
Training loss: 0.31565532088279724 / Valid loss: 6.947981825329008
Training loss: 0.32382524013519287 / Valid loss: 7.34891334261213
Training loss: 0.413042813539505 / Valid loss: 7.0908952213469005

Epoch: 72
Training loss: 0.45639026165008545 / Valid loss: 7.29620928537278
Training loss: 0.4604869484901428 / Valid loss: 6.932806562242054
Training loss: 0.3179725110530853 / Valid loss: 7.324370861053467
Training loss: 0.30033138394355774 / Valid loss: 7.190966933114188
Training loss: 0.23980402946472168 / Valid loss: 7.122395628974552

Epoch: 73
Training loss: 0.6863141059875488 / Valid loss: 7.043910907563709
Training loss: 0.38957419991493225 / Valid loss: 6.985725087211246
Training loss: 0.29979008436203003 / Valid loss: 6.888182726360503
Training loss: 0.32347482442855835 / Valid loss: 7.450706895192464
Training loss: 0.2559865117073059 / Valid loss: 7.060148622876122

Epoch: 74
Training loss: 0.4878944158554077 / Valid loss: 7.161877436864944
Training loss: 0.269671231508255 / Valid loss: 7.065273875281925
Training loss: 0.5087729692459106 / Valid loss: 6.968735983258202
Training loss: 0.25266364216804504 / Valid loss: 7.016425736745199
Training loss: 0.367840051651001 / Valid loss: 6.9370230901808965

Epoch: 75
Training loss: 0.2722077965736389 / Valid loss: 7.125996049245199
Training loss: 0.2495739758014679 / Valid loss: 7.105411202566964
Training loss: 0.41244322061538696 / Valid loss: 6.931828348977225
Training loss: 0.30425217747688293 / Valid loss: 6.98498577844529
Training loss: 0.22217217087745667 / Valid loss: 7.151988687969389

Epoch: 76
Training loss: 0.2781796455383301 / Valid loss: 6.885833488191877
Training loss: 0.2961457669734955 / Valid loss: 6.9954720360892155
Training loss: 0.20429132878780365 / Valid loss: 7.1439091500781835
Training loss: 0.4531988501548767 / Valid loss: 7.027013755979992
Training loss: 0.3473389744758606 / Valid loss: 6.949981226239886

Epoch: 77
Training loss: 0.2844838500022888 / Valid loss: 7.205246802738735
Training loss: 0.34113240242004395 / Valid loss: 7.065843046279181
Training loss: 0.42307528853416443 / Valid loss: 6.9454713003976005
Training loss: 0.2905142605304718 / Valid loss: 6.944412662869408
Training loss: 0.33899474143981934 / Valid loss: 6.950108201163156

Epoch: 78
Training loss: 0.351818323135376 / Valid loss: 7.5214973699478875
Training loss: 0.6281399726867676 / Valid loss: 6.877816377367292
Training loss: 0.6685627698898315 / Valid loss: 7.584133307139079
Training loss: 0.543691873550415 / Valid loss: 6.952484843844459
Training loss: 0.430601567029953 / Valid loss: 6.954355482828049

Epoch: 79
Training loss: 0.2522149682044983 / Valid loss: 6.826865561803182
Training loss: 0.4830111265182495 / Valid loss: 7.166527048746745
Training loss: 0.34370923042297363 / Valid loss: 7.032048518317087
Training loss: 0.6293383836746216 / Valid loss: 7.040246091570173
ModuleList(
  (0): Linear(in_features=5376, out_features=300, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=300, out_features=32, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=32, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.547655848094395
Training regression with following parameters:
dnn_hidden_units : 248
dropout_probs : 0.0, 0.0
learning_rate : 0.0001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : Adam
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : Bert
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=5376, out_features=248, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=248, out_features=1, bias=True)
)

Epoch: 0
Training loss: 20.62260627746582 / Valid loss: 16.113272512526738
Model is saved in epoch 0, overall batch: 0
Training loss: 11.981375694274902 / Valid loss: 11.816666507720948
Model is saved in epoch 0, overall batch: 100
Training loss: 8.561663627624512 / Valid loss: 7.799813327335176
Model is saved in epoch 0, overall batch: 200
Training loss: 6.4559478759765625 / Valid loss: 5.887999884287516
Model is saved in epoch 0, overall batch: 300
Training loss: 9.441091537475586 / Valid loss: 5.689365643546695
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 5.431851863861084 / Valid loss: 5.8672060194469635
Training loss: 5.661279678344727 / Valid loss: 5.838317135402135
Training loss: 6.85526704788208 / Valid loss: 5.729833997998919
Training loss: 6.035687446594238 / Valid loss: 5.881188433510917
Training loss: 5.18850040435791 / Valid loss: 5.561653956912813
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 4.818472385406494 / Valid loss: 5.588327001390003
Training loss: 4.661823749542236 / Valid loss: 5.776552708943685
Training loss: 5.4140472412109375 / Valid loss: 5.572110557556153
Training loss: 5.84920597076416 / Valid loss: 5.576434644063314
Training loss: 5.569860935211182 / Valid loss: 5.630689695903233

Epoch: 3
Training loss: 3.614938735961914 / Valid loss: 5.933127235230946
Training loss: 4.91295051574707 / Valid loss: 5.622013923100063
Training loss: 4.247612953186035 / Valid loss: 5.652283409663609
Training loss: 5.518445014953613 / Valid loss: 5.776180637450445
Training loss: 4.575778961181641 / Valid loss: 5.53904952548799
Model is saved in epoch 3, overall batch: 1900

Epoch: 4
Training loss: 3.341827154159546 / Valid loss: 5.602780684970674
Training loss: 4.05409574508667 / Valid loss: 5.5975323677062985
Training loss: 3.8735411167144775 / Valid loss: 5.718776400883993
Training loss: 4.754057884216309 / Valid loss: 5.779694623038882
Training loss: 7.144676208496094 / Valid loss: 5.759812005360922

Epoch: 5
Training loss: 3.581448793411255 / Valid loss: 5.6877969492049445
Training loss: 3.308439254760742 / Valid loss: 5.753117713474092
Training loss: 5.523226261138916 / Valid loss: 5.689309249605452
Training loss: 5.694096088409424 / Valid loss: 5.736040231159755
Training loss: 6.5392866134643555 / Valid loss: 6.408744539533343

Epoch: 6
Training loss: 4.041530609130859 / Valid loss: 5.744074785141718
Training loss: 3.524935722351074 / Valid loss: 5.954942033404396
Training loss: 4.325168609619141 / Valid loss: 5.709680548168364
Training loss: 3.6437253952026367 / Valid loss: 5.906825769515264
Training loss: 3.0654921531677246 / Valid loss: 5.752376072747367

Epoch: 7
Training loss: 2.5358660221099854 / Valid loss: 6.314314011165074
Training loss: 3.2677907943725586 / Valid loss: 6.180979742322649
Training loss: 3.811722993850708 / Valid loss: 5.92688649041312
Training loss: 4.092374324798584 / Valid loss: 5.8820614269801546
Training loss: 4.191745758056641 / Valid loss: 5.928286877132598

Epoch: 8
Training loss: 3.3860950469970703 / Valid loss: 5.875133246467227
Training loss: 3.183361768722534 / Valid loss: 5.933499127342587
Training loss: 4.466777801513672 / Valid loss: 6.045709796178908
Training loss: 3.800304412841797 / Valid loss: 6.733478566578456
Training loss: 3.4802680015563965 / Valid loss: 5.857598309289841

Epoch: 9
Training loss: 3.1472668647766113 / Valid loss: 5.96273167246864
Training loss: 3.541856288909912 / Valid loss: 5.972053991045271
Training loss: 3.5373716354370117 / Valid loss: 6.088474984396072
Training loss: 2.7156848907470703 / Valid loss: 6.145434127535139

Epoch: 10
Training loss: 2.926503896713257 / Valid loss: 5.881049306052072
Training loss: 2.663496971130371 / Valid loss: 6.067717704318818
Training loss: 3.4793288707733154 / Valid loss: 6.361605794089181
Training loss: 3.2300314903259277 / Valid loss: 6.172431389490764
Training loss: 2.955963611602783 / Valid loss: 6.078214036850702

Epoch: 11
Training loss: 3.321547508239746 / Valid loss: 6.237705718903315
Training loss: 3.4064183235168457 / Valid loss: 6.215869930812291
Training loss: 2.7536144256591797 / Valid loss: 6.568471801848639
Training loss: 2.3717148303985596 / Valid loss: 6.136764492307391
Training loss: 2.8886327743530273 / Valid loss: 6.432164539609636

Epoch: 12
Training loss: 3.2298026084899902 / Valid loss: 6.065426047643026
Training loss: 2.9477248191833496 / Valid loss: 6.21222190402803
Training loss: 3.460266351699829 / Valid loss: 6.2207722618466335
Training loss: 2.850217819213867 / Valid loss: 6.200380902063279
Training loss: 2.1150879859924316 / Valid loss: 6.172502286093575

Epoch: 13
Training loss: 2.536099433898926 / Valid loss: 6.159731556120373
Training loss: 2.3612265586853027 / Valid loss: 6.387197285606748
Training loss: 2.2422685623168945 / Valid loss: 6.278357101622082
Training loss: 1.9804513454437256 / Valid loss: 7.4339762188139415
Training loss: 2.3795342445373535 / Valid loss: 6.340870201020014

Epoch: 14
Training loss: 1.9998698234558105 / Valid loss: 6.2935458887191045
Training loss: 2.6144165992736816 / Valid loss: 6.325336612973895
Training loss: 3.364734172821045 / Valid loss: 6.920889554704939
Training loss: 2.7031164169311523 / Valid loss: 6.418536186218262
Training loss: 2.646881341934204 / Valid loss: 6.622565414792016

Epoch: 15
Training loss: 1.6465891599655151 / Valid loss: 6.458289779935565
Training loss: 3.325824737548828 / Valid loss: 6.353709166390555
Training loss: 2.807063102722168 / Valid loss: 7.018291441599528
Training loss: 3.156320571899414 / Valid loss: 6.571274137496948
Training loss: 2.353762149810791 / Valid loss: 6.3464444001515705

Epoch: 16
Training loss: 2.838454246520996 / Valid loss: 6.447871866680327
Training loss: 2.054107189178467 / Valid loss: 7.025777044750395
Training loss: 1.6957250833511353 / Valid loss: 6.5024159703935895
Training loss: 2.757199287414551 / Valid loss: 6.359470821562267
Training loss: 2.1010870933532715 / Valid loss: 7.670064590090797

Epoch: 17
Training loss: 2.343766212463379 / Valid loss: 6.437376692181542
Training loss: 1.624578595161438 / Valid loss: 6.931774516332717
Training loss: 1.7253838777542114 / Valid loss: 6.857915551321847
Training loss: 4.290212631225586 / Valid loss: 6.504991245269776
Training loss: 2.145789384841919 / Valid loss: 6.659347665877569

Epoch: 18
Training loss: 1.759606122970581 / Valid loss: 6.466680706114996
Training loss: 1.4555472135543823 / Valid loss: 6.719832976659139
Training loss: 2.205173969268799 / Valid loss: 6.5625967752365835
Training loss: 1.7020766735076904 / Valid loss: 7.11601338613601
Training loss: 2.1983354091644287 / Valid loss: 6.577837365014212

Epoch: 19
Training loss: 1.0433483123779297 / Valid loss: 6.538500835782005
Training loss: 1.825883388519287 / Valid loss: 6.8521539642697284
Training loss: 2.1499006748199463 / Valid loss: 6.759799898238409
Training loss: 1.9177496433258057 / Valid loss: 6.935376880282448

Epoch: 20
Training loss: 1.7521512508392334 / Valid loss: 7.333484427134196
Training loss: 1.4996287822723389 / Valid loss: 6.873306969233922
Training loss: 1.5622040033340454 / Valid loss: 6.685383204051426
Training loss: 1.4596693515777588 / Valid loss: 7.983153388613746
Training loss: 1.2330151796340942 / Valid loss: 6.6697809105827695

Epoch: 21
Training loss: 1.6315827369689941 / Valid loss: 6.719668456486294
Training loss: 1.8557543754577637 / Valid loss: 6.887356208619617
Training loss: 1.7816932201385498 / Valid loss: 6.618310701279413
Training loss: 2.309722661972046 / Valid loss: 6.824562776656378
Training loss: 1.5546085834503174 / Valid loss: 7.077516576222011

Epoch: 22
Training loss: 1.1125141382217407 / Valid loss: 6.764394026710874
Training loss: 1.3339630365371704 / Valid loss: 7.212054525102888
Training loss: 1.8221278190612793 / Valid loss: 7.246674546741304
Training loss: 1.9226226806640625 / Valid loss: 6.649495070321219
Training loss: 1.5396450757980347 / Valid loss: 6.8369166419619605

Epoch: 23
Training loss: 1.0215978622436523 / Valid loss: 7.985856596628825
Training loss: 1.799208641052246 / Valid loss: 6.962226386297317
Training loss: 1.8007278442382812 / Valid loss: 6.918149398622059
Training loss: 1.4581668376922607 / Valid loss: 6.6818988936288015
Training loss: 1.1291555166244507 / Valid loss: 6.933845819745745

Epoch: 24
Training loss: 1.077491044998169 / Valid loss: 6.86520120984032
Training loss: 1.7446300983428955 / Valid loss: 6.811778159368606
Training loss: 1.4313552379608154 / Valid loss: 7.056212239038377
Training loss: 1.0099647045135498 / Valid loss: 6.891221268971761
Training loss: 1.4899396896362305 / Valid loss: 7.267281981876918

Epoch: 25
Training loss: 1.0751252174377441 / Valid loss: 6.887645362672352
Training loss: 0.8662316799163818 / Valid loss: 6.80979867435637
Training loss: 2.0769174098968506 / Valid loss: 7.772428839547294
Training loss: 1.3807885646820068 / Valid loss: 6.947183599926176
Training loss: 1.514533519744873 / Valid loss: 7.560202553158715

Epoch: 26
Training loss: 0.8501127362251282 / Valid loss: 7.360404777526855
Training loss: 0.876375675201416 / Valid loss: 6.904012223652431
Training loss: 0.9560344219207764 / Valid loss: 7.014984130859375
Training loss: 1.292166829109192 / Valid loss: 7.291907424018497
Training loss: 0.9584882259368896 / Valid loss: 6.949136833917527

Epoch: 27
Training loss: 1.12650465965271 / Valid loss: 6.878521569569906
Training loss: 0.992019534111023 / Valid loss: 6.868228776114328
Training loss: 1.3238856792449951 / Valid loss: 7.155717268444243
Training loss: 0.9730052947998047 / Valid loss: 7.198199063255673
Training loss: 1.4724560976028442 / Valid loss: 6.816399426687331

Epoch: 28
Training loss: 0.910829484462738 / Valid loss: 7.004383441380092
Training loss: 1.0024888515472412 / Valid loss: 7.004966608683268
Training loss: 1.0626568794250488 / Valid loss: 7.500833974565778
Training loss: 1.5328798294067383 / Valid loss: 6.963663469042097
Training loss: 0.9688473343849182 / Valid loss: 7.540891429356166

Epoch: 29
Training loss: 0.7330912351608276 / Valid loss: 6.934893462771461
Training loss: 0.7065658569335938 / Valid loss: 7.0368758428664435
Training loss: 1.331263542175293 / Valid loss: 7.502609979538691
Training loss: 1.1337894201278687 / Valid loss: 7.0096500215076265

Epoch: 30
Training loss: 0.5737733840942383 / Valid loss: 7.119925542104812
Training loss: 1.0138765573501587 / Valid loss: 7.24058209827968
Training loss: 0.6251097321510315 / Valid loss: 7.425715460096087
Training loss: 0.8038676977157593 / Valid loss: 7.041635295322963
Training loss: 0.7657690644264221 / Valid loss: 7.060984193711054

Epoch: 31
Training loss: 1.041504144668579 / Valid loss: 7.22672366187686
Training loss: 0.7323285937309265 / Valid loss: 6.920971597943987
Training loss: 0.9599181413650513 / Valid loss: 8.33665433157058
Training loss: 1.3180525302886963 / Valid loss: 6.999262196677072
Training loss: 1.2455828189849854 / Valid loss: 9.074341492425829

Epoch: 32
Training loss: 0.6012609004974365 / Valid loss: 7.2263910157339915
Training loss: 0.5022282600402832 / Valid loss: 7.165269002460298
Training loss: 0.662506103515625 / Valid loss: 7.188229270208449
Training loss: 0.8724859356880188 / Valid loss: 7.062272457849412
Training loss: 1.1619799137115479 / Valid loss: 8.443371786390031

Epoch: 33
Training loss: 0.6405733823776245 / Valid loss: 7.059629771822975
Training loss: 0.5651752352714539 / Valid loss: 7.54728361311413
Training loss: 1.0588269233703613 / Valid loss: 6.986931714557466
Training loss: 0.7190341949462891 / Valid loss: 7.181868948255267
Training loss: 1.0092896223068237 / Valid loss: 7.268625500088646

Epoch: 34
Training loss: 0.7248278856277466 / Valid loss: 7.323709728604271
Training loss: 1.3226895332336426 / Valid loss: 7.3575912203107565
Training loss: 0.5890219807624817 / Valid loss: 7.0245438121614
Training loss: 1.020698070526123 / Valid loss: 7.50722633089338
Training loss: 0.7777308225631714 / Valid loss: 7.167212418147495

Epoch: 35
Training loss: 0.9040263295173645 / Valid loss: 7.090397866566976
Training loss: 0.9612382650375366 / Valid loss: 7.139593662534441
Training loss: 0.8291218280792236 / Valid loss: 7.078316947392055
Training loss: 0.7749821543693542 / Valid loss: 7.595890031542097
Training loss: 1.2079875469207764 / Valid loss: 7.855515193939209

Epoch: 36
Training loss: 0.9758793115615845 / Valid loss: 7.121148381914411
Training loss: 1.1229145526885986 / Valid loss: 7.02674674987793
Training loss: 0.7529170513153076 / Valid loss: 7.114006814502535
Training loss: 0.651924192905426 / Valid loss: 7.120406573159354
Training loss: 0.9762295484542847 / Valid loss: 7.43028557187035

Epoch: 37
Training loss: 1.395491123199463 / Valid loss: 7.1707258179074245
Training loss: 0.9791371822357178 / Valid loss: 7.246573900041126
Training loss: 1.083543300628662 / Valid loss: 7.212270863850912
Training loss: 0.5844866037368774 / Valid loss: 7.182545952569871
Training loss: 0.7231588363647461 / Valid loss: 7.2324102447146466

Epoch: 38
Training loss: 0.5437463521957397 / Valid loss: 7.076689397721063
Training loss: 0.7325360774993896 / Valid loss: 7.071402590615409
Training loss: 0.5430324077606201 / Valid loss: 7.259533418927874
Training loss: 0.943889856338501 / Valid loss: 7.187190008163452
Training loss: 0.723518967628479 / Valid loss: 7.238671184721447

Epoch: 39
Training loss: 0.6689614057540894 / Valid loss: 7.166225478762672
Training loss: 0.6974279284477234 / Valid loss: 7.119683951423282
Training loss: 0.7966050505638123 / Valid loss: 7.691759929202852
Training loss: 0.8888695240020752 / Valid loss: 7.258959679376511

Epoch: 40
Training loss: 0.6980445384979248 / Valid loss: 7.194759146372477
Training loss: 0.9454244375228882 / Valid loss: 7.603038492656889
Training loss: 0.4694203734397888 / Valid loss: 7.567837315513974
Training loss: 0.7117137908935547 / Valid loss: 7.278976631164551
Training loss: 0.8886685371398926 / Valid loss: 7.314621934436617

Epoch: 41
Training loss: 0.6171396374702454 / Valid loss: 7.080976036616734
Training loss: 0.5849217176437378 / Valid loss: 7.095435732886905
Training loss: 0.6718699932098389 / Valid loss: 7.142456540607271
Training loss: 0.5258327722549438 / Valid loss: 7.341863786606561
Training loss: 0.8079695701599121 / Valid loss: 7.196188236418225

Epoch: 42
Training loss: 0.6759546995162964 / Valid loss: 7.25311225709461
Training loss: 0.6452537775039673 / Valid loss: 7.153743466876802
Training loss: 0.7542501091957092 / Valid loss: 7.165779799506778
Training loss: 0.6909060478210449 / Valid loss: 7.257571065993536
Training loss: 0.7543542385101318 / Valid loss: 7.862029320853097

Epoch: 43
Training loss: 0.8171498775482178 / Valid loss: 7.363203843434651
Training loss: 0.7298451662063599 / Valid loss: 7.191511063348679
Training loss: 0.5647649765014648 / Valid loss: 7.490689774921962
Training loss: 0.8518213629722595 / Valid loss: 7.483932971954346
Training loss: 0.35038304328918457 / Valid loss: 7.198243590763637

Epoch: 44
Training loss: 0.7135277986526489 / Valid loss: 7.161867573147728
Training loss: 0.7758976221084595 / Valid loss: 7.531571052187965
Training loss: 0.6084163784980774 / Valid loss: 7.226712826320103
Training loss: 0.4317396879196167 / Valid loss: 7.509962517874581
Training loss: 0.6015646457672119 / Valid loss: 7.185458809988839

Epoch: 45
Training loss: 0.41977083683013916 / Valid loss: 7.227802303859166
Training loss: 0.8034083843231201 / Valid loss: 7.323133668445405
Training loss: 0.5963022708892822 / Valid loss: 7.127920232500348
Training loss: 0.47376397252082825 / Valid loss: 7.164049475533622
Training loss: 0.39688819646835327 / Valid loss: 7.580177520570301

Epoch: 46
Training loss: 0.6535561084747314 / Valid loss: 7.184273810613723
Training loss: 0.5343261957168579 / Valid loss: 7.300022524879092
Training loss: 0.6931212544441223 / Valid loss: 7.095786462511335
Training loss: 0.7278209328651428 / Valid loss: 7.4406728835332965
Training loss: 0.647931694984436 / Valid loss: 7.213903790428525

Epoch: 47
Training loss: 0.3193492293357849 / Valid loss: 7.277092297871907
Training loss: 0.6300084590911865 / Valid loss: 7.729672568184989
Training loss: 0.6111387610435486 / Valid loss: 7.211484775089082
Training loss: 0.4608461856842041 / Valid loss: 7.263978971753802
Training loss: 0.6619886159896851 / Valid loss: 7.546279303232828

Epoch: 48
Training loss: 0.6314418315887451 / Valid loss: 7.669256743930635
Training loss: 0.38860151171684265 / Valid loss: 7.823961516789027
Training loss: 0.6322895288467407 / Valid loss: 7.439558960142589
Training loss: 0.7078611254692078 / Valid loss: 7.327202261061895
Training loss: 0.41129469871520996 / Valid loss: 7.12607561747233

Epoch: 49
Training loss: 0.6484709978103638 / Valid loss: 7.683157198769706
Training loss: 0.6254496574401855 / Valid loss: 7.3982317288716635
Training loss: 0.42287692427635193 / Valid loss: 7.203900166920254
Training loss: 0.5713838338851929 / Valid loss: 7.254266539074126

Epoch: 50
Training loss: 0.7996330261230469 / Valid loss: 7.23153661546253
Training loss: 0.31375330686569214 / Valid loss: 7.1401701836358935
Training loss: 0.7060637474060059 / Valid loss: 7.127284336090088
Training loss: 0.591112494468689 / Valid loss: 7.234680543627058
Training loss: 0.5270369052886963 / Valid loss: 7.292212554386684

Epoch: 51
Training loss: 0.8019607067108154 / Valid loss: 7.188970279693604
Training loss: 0.6570839285850525 / Valid loss: 7.272666853950137
Training loss: 0.7201600074768066 / Valid loss: 7.239600113459995
Training loss: 0.5467078685760498 / Valid loss: 7.270254012516567
Training loss: 0.66357421875 / Valid loss: 7.089816992623465

Epoch: 52
Training loss: 0.5340877175331116 / Valid loss: 7.465338257380894
Training loss: 0.4615743160247803 / Valid loss: 7.166981102171398
Training loss: 0.6448974609375 / Valid loss: 7.22480776650565
Training loss: 0.9692267179489136 / Valid loss: 7.457941949935186
Training loss: 0.5397871136665344 / Valid loss: 7.189929167429606

Epoch: 53
Training loss: 0.6504071354866028 / Valid loss: 7.4766639119102845
Training loss: 0.40383297204971313 / Valid loss: 7.259814103444417
Training loss: 1.1174578666687012 / Valid loss: 7.210250795455206
Training loss: 0.5966501235961914 / Valid loss: 8.164542924790155
Training loss: 0.7559309005737305 / Valid loss: 7.2315581094651

Epoch: 54
Training loss: 0.4996899962425232 / Valid loss: 7.219336986541748
Training loss: 0.46305370330810547 / Valid loss: 7.195035030728294
Training loss: 0.48595288395881653 / Valid loss: 7.625635469527472
Training loss: 0.6632598638534546 / Valid loss: 7.2909579095386325
Training loss: 0.6331150531768799 / Valid loss: 7.216096324012393

Epoch: 55
Training loss: 0.3759262263774872 / Valid loss: 7.194861012413388
Training loss: 0.48292046785354614 / Valid loss: 7.1586411294483
Training loss: 0.7525680065155029 / Valid loss: 7.332380344754173
Training loss: 1.0134055614471436 / Valid loss: 7.699355697631836
Training loss: 0.39143621921539307 / Valid loss: 7.169679105849493

Epoch: 56
Training loss: 0.6167423129081726 / Valid loss: 7.3603469803219745
Training loss: 0.6175165772438049 / Valid loss: 7.202419276464553
Training loss: 0.8225699067115784 / Valid loss: 8.347808769771031
Training loss: 0.5825395584106445 / Valid loss: 7.346225992838542
Training loss: 0.47952908277511597 / Valid loss: 7.492623029436384

Epoch: 57
Training loss: 0.5027871131896973 / Valid loss: 7.693874835968018
Training loss: 0.3863804042339325 / Valid loss: 7.36704223269508
Training loss: 0.35216957330703735 / Valid loss: 7.213490563347226
Training loss: 0.35669052600860596 / Valid loss: 7.272902806599935
Training loss: 0.41860154271125793 / Valid loss: 7.3563692774091445

Epoch: 58
Training loss: 0.5608874559402466 / Valid loss: 7.339780771164667
Training loss: 0.4570312201976776 / Valid loss: 7.2228620211283365
Training loss: 0.468562513589859 / Valid loss: 7.336855774834042
Training loss: 0.5199884176254272 / Valid loss: 7.15898174558367
Training loss: 0.7567902207374573 / Valid loss: 7.1929575624920075

Epoch: 59
Training loss: 0.37325072288513184 / Valid loss: 7.315645735604423
Training loss: 0.523514449596405 / Valid loss: 7.211734848930722
Training loss: 0.6244392395019531 / Valid loss: 7.197886480603899
Training loss: 0.3445804715156555 / Valid loss: 7.369115965706961

Epoch: 60
Training loss: 0.690711259841919 / Valid loss: 7.312566298530215
Training loss: 0.5230316519737244 / Valid loss: 7.438195469265892
Training loss: 0.2886776328086853 / Valid loss: 7.6304241589137485
Training loss: 0.5439709424972534 / Valid loss: 7.2284777641296385
Training loss: 0.49936193227767944 / Valid loss: 7.2277710914611815

Epoch: 61
Training loss: 0.5562336444854736 / Valid loss: 7.329011976151239
Training loss: 0.6536878347396851 / Valid loss: 7.194716258276077
Training loss: 0.5053520202636719 / Valid loss: 7.262200385048276
Training loss: 0.4838238060474396 / Valid loss: 7.276044663928804
Training loss: 0.6088395714759827 / Valid loss: 7.6699956530616396

Epoch: 62
Training loss: 0.43837234377861023 / Valid loss: 7.254148156302316
Training loss: 0.40148964524269104 / Valid loss: 7.243830508277529
Training loss: 0.42787373065948486 / Valid loss: 7.206139496394566
Training loss: 0.5445802211761475 / Valid loss: 7.3799746740432015
Training loss: 0.6877113580703735 / Valid loss: 7.158132080804734

Epoch: 63
Training loss: 0.45946019887924194 / Valid loss: 7.462803064073835
Training loss: 0.30825674533843994 / Valid loss: 7.172964311781383
Training loss: 0.38701921701431274 / Valid loss: 7.20955917040507
Training loss: 0.24397405982017517 / Valid loss: 7.140356658753895
Training loss: 0.41566646099090576 / Valid loss: 7.286188234601702

Epoch: 64
Training loss: 0.4749959111213684 / Valid loss: 7.258933957417806
Training loss: 0.4692794680595398 / Valid loss: 7.152068222136725
Training loss: 0.37998226284980774 / Valid loss: 7.209733177366711
Training loss: 0.3610354959964752 / Valid loss: 7.199093387240455
Training loss: 0.9641669988632202 / Valid loss: 7.487693977355957

Epoch: 65
Training loss: 0.41737937927246094 / Valid loss: 7.437053108215332
Training loss: 0.29659271240234375 / Valid loss: 7.269970317113967
Training loss: 0.34956657886505127 / Valid loss: 7.288514396122523
Training loss: 0.37222862243652344 / Valid loss: 8.078109900156656
Training loss: 0.5653012990951538 / Valid loss: 7.168660204751151

Epoch: 66
Training loss: 0.3974098861217499 / Valid loss: 7.215800784883045
Training loss: 0.498779833316803 / Valid loss: 7.230865632920038
Training loss: 0.673423707485199 / Valid loss: 7.6946310134161084
Training loss: 0.3348606824874878 / Valid loss: 7.472827098483131
Training loss: 0.4406595826148987 / Valid loss: 7.278890387217204

Epoch: 67
Training loss: 0.44554752111434937 / Valid loss: 7.440555229641142
Training loss: 0.4349662661552429 / Valid loss: 7.22332235517956
Training loss: 0.33455437421798706 / Valid loss: 7.173307119097029
Training loss: 0.39717379212379456 / Valid loss: 7.171432704017276
Training loss: 0.8884539604187012 / Valid loss: 7.936654708499

Epoch: 68
Training loss: 0.35939037799835205 / Valid loss: 7.176960504622686
Training loss: 0.46064841747283936 / Valid loss: 7.310965288253057
Training loss: 0.3856079578399658 / Valid loss: 7.413747194835118
Training loss: 0.3907676041126251 / Valid loss: 7.82490017754691
Training loss: 0.39480799436569214 / Valid loss: 7.207448368980771

Epoch: 69
Training loss: 0.3374535143375397 / Valid loss: 7.183606501988002
Training loss: 0.3918163776397705 / Valid loss: 7.226430361611502
Training loss: 0.36283639073371887 / Valid loss: 7.153190762656076
Training loss: 0.42943274974823 / Valid loss: 7.33155168351673

Epoch: 70
Training loss: 0.34085744619369507 / Valid loss: 7.227498381478446
Training loss: 0.35032719373703003 / Valid loss: 7.1938735825674875
Training loss: 0.49167323112487793 / Valid loss: 7.1913111277988975
Training loss: 0.47137412428855896 / Valid loss: 7.348134499504453
Training loss: 0.5437495112419128 / Valid loss: 7.249134036472865

Epoch: 71
Training loss: 0.3063819408416748 / Valid loss: 7.199413167862665
Training loss: 0.7570093274116516 / Valid loss: 8.037266644977388
Training loss: 0.6008262634277344 / Valid loss: 7.421257577623639
Training loss: 0.4763985276222229 / Valid loss: 7.165623360588437
Training loss: 0.4337184727191925 / Valid loss: 7.225594261714391

Epoch: 72
Training loss: 0.3469230532646179 / Valid loss: 7.146659051804315
Training loss: 0.40962404012680054 / Valid loss: 7.646703002566383
Training loss: 0.30413004755973816 / Valid loss: 7.172470574151902
Training loss: 0.41738376021385193 / Valid loss: 7.184684653509231
Training loss: 0.38963475823402405 / Valid loss: 7.186636195863996

Epoch: 73
Training loss: 0.3634227216243744 / Valid loss: 7.224246392931257
Training loss: 0.31265076994895935 / Valid loss: 7.223368908110119
Training loss: 0.3072633147239685 / Valid loss: 7.323676188786824
Training loss: 0.47333067655563354 / Valid loss: 7.428538653964088
Training loss: 0.5516581535339355 / Valid loss: 7.23002283459618

Epoch: 74
Training loss: 0.5525522232055664 / Valid loss: 7.287277035486131
Training loss: 0.41367030143737793 / Valid loss: 7.521229503268287
Training loss: 0.45315903425216675 / Valid loss: 7.217331915809995
Training loss: 0.46325454115867615 / Valid loss: 7.216620027451288
Training loss: 0.33113333582878113 / Valid loss: 7.459683854239327

Epoch: 75
Training loss: 0.5799258947372437 / Valid loss: 7.21336966923305
Training loss: 0.3597698211669922 / Valid loss: 7.255965800512405
Training loss: 0.4789552390575409 / Valid loss: 7.3971037183489114
Training loss: 0.5618990063667297 / Valid loss: 7.239201538903373
Training loss: 0.4616062045097351 / Valid loss: 7.331559689839681

Epoch: 76
Training loss: 0.32485508918762207 / Valid loss: 7.4751791045779274
Training loss: 0.3952614367008209 / Valid loss: 7.14559245790754
Training loss: 0.46204620599746704 / Valid loss: 7.896274607522147
Training loss: 0.3581950068473816 / Valid loss: 7.155316162109375
Training loss: 0.4481227695941925 / Valid loss: 7.612860529763358

Epoch: 77
Training loss: 0.2892689108848572 / Valid loss: 7.236908948989141
Training loss: 0.42516496777534485 / Valid loss: 7.247394811539423
Training loss: 0.4215075969696045 / Valid loss: 7.168804686410087
Training loss: 0.5368880033493042 / Valid loss: 7.168264802296957
Training loss: 0.27375149726867676 / Valid loss: 7.106964651743571

Epoch: 78
Training loss: 0.33537113666534424 / Valid loss: 7.207849602472215
Training loss: 0.3956388533115387 / Valid loss: 7.240888250441778
Training loss: 0.5930895805358887 / Valid loss: 7.198379023869832
Training loss: 0.4305923283100128 / Valid loss: 7.166093158721924
Training loss: 0.43114206194877625 / Valid loss: 7.646275792803083

Epoch: 79
Training loss: 0.31359535455703735 / Valid loss: 7.905020550319127
Training loss: 0.2819693088531494 / Valid loss: 7.181798576173328
Training loss: 0.34579354524612427 / Valid loss: 7.2106571333748954
Training loss: 0.42978233098983765 / Valid loss: 7.19329724538894
ModuleList(
  (0): Linear(in_features=5376, out_features=248, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=248, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.393075336728777
Training regression with following parameters:
dnn_hidden_units : 
dropout_probs : 0.0, 0.0
learning_rate : 0.0001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : Adam
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : Bert
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=5376, out_features=1, bias=True)
)

Epoch: 0
Training loss: 19.044994354248047 / Valid loss: 13.129112924848284
Model is saved in epoch 0, overall batch: 0
Training loss: 6.268510341644287 / Valid loss: 5.8205156326293945
Model is saved in epoch 0, overall batch: 100
Training loss: 6.482045650482178 / Valid loss: 5.7145655087062295
Model is saved in epoch 0, overall batch: 200
Training loss: 6.4690752029418945 / Valid loss: 5.665916363398234
Model is saved in epoch 0, overall batch: 300
Training loss: 3.6255550384521484 / Valid loss: 5.637516623451596
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 6.443761825561523 / Valid loss: 5.609866176332746
Model is saved in epoch 1, overall batch: 500
Training loss: 4.7841267585754395 / Valid loss: 5.5921299866267615
Model is saved in epoch 1, overall batch: 600
Training loss: 7.218555450439453 / Valid loss: 5.586084322702317
Model is saved in epoch 1, overall batch: 700
Training loss: 4.095907688140869 / Valid loss: 5.571328869320097
Model is saved in epoch 1, overall batch: 800
Training loss: 4.74068546295166 / Valid loss: 5.552520856403169
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 6.120925426483154 / Valid loss: 5.546814684640793
Model is saved in epoch 2, overall batch: 1000
Training loss: 5.0970916748046875 / Valid loss: 5.534237298511323
Model is saved in epoch 2, overall batch: 1100
Training loss: 6.080886363983154 / Valid loss: 5.5331135182153615
Model is saved in epoch 2, overall batch: 1200
Training loss: 3.88415265083313 / Valid loss: 5.579568043209258
Training loss: 4.344699859619141 / Valid loss: 5.516222374779837
Model is saved in epoch 2, overall batch: 1400

Epoch: 3
Training loss: 5.916259765625 / Valid loss: 5.53867780140468
Training loss: 3.5796151161193848 / Valid loss: 5.518697895322528
Training loss: 7.339484214782715 / Valid loss: 5.511235825220743
Model is saved in epoch 3, overall batch: 1700
Training loss: 4.794491291046143 / Valid loss: 5.514074486777896
Training loss: 5.8917107582092285 / Valid loss: 5.529173412777129

Epoch: 4
Training loss: 6.055139064788818 / Valid loss: 5.536274101620629
Training loss: 4.793487071990967 / Valid loss: 5.518998761404128
Training loss: 4.535486698150635 / Valid loss: 5.5861195314498175
Training loss: 4.011403560638428 / Valid loss: 5.534883851096744
Training loss: 5.778960227966309 / Valid loss: 5.55570441427685

Epoch: 5
Training loss: 7.063654899597168 / Valid loss: 5.516865762074788
Training loss: 4.327145576477051 / Valid loss: 5.539654397964478
Training loss: 4.952714443206787 / Valid loss: 5.595981927145095
Training loss: 5.049341201782227 / Valid loss: 5.501711470740182
Model is saved in epoch 5, overall batch: 2800
Training loss: 6.2344770431518555 / Valid loss: 5.510142964408511

Epoch: 6
Training loss: 5.0662384033203125 / Valid loss: 5.4874446596418105
Model is saved in epoch 6, overall batch: 3000
Training loss: 6.036526679992676 / Valid loss: 5.505000191643124
Training loss: 5.344539642333984 / Valid loss: 5.5053633735293435
Training loss: 4.25537633895874 / Valid loss: 5.524209683282034
Training loss: 6.428157806396484 / Valid loss: 5.505239736466181

Epoch: 7
Training loss: 4.6567277908325195 / Valid loss: 5.518920868919009
Training loss: 4.213170528411865 / Valid loss: 5.501404419399443
Training loss: 5.8086090087890625 / Valid loss: 5.505869574773879
Training loss: 5.825793743133545 / Valid loss: 5.5119145961034866
Training loss: 5.194054126739502 / Valid loss: 5.502476953324818

Epoch: 8
Training loss: 4.835441589355469 / Valid loss: 5.48497557867141
Model is saved in epoch 8, overall batch: 4000
Training loss: 4.053650856018066 / Valid loss: 5.498404793512254
Training loss: 4.095859050750732 / Valid loss: 5.493126862389701
Training loss: 5.022775650024414 / Valid loss: 5.499519100643339
Training loss: 2.6940689086914062 / Valid loss: 5.501133705320813

Epoch: 9
Training loss: 4.0135393142700195 / Valid loss: 5.4889376367841445
Training loss: 5.218151092529297 / Valid loss: 5.478999215080624
Model is saved in epoch 9, overall batch: 4600
Training loss: 5.491938591003418 / Valid loss: 5.5104269118536084
Training loss: 6.224542617797852 / Valid loss: 5.506803882689703

Epoch: 10
Training loss: 4.1341047286987305 / Valid loss: 5.487884723572504
Training loss: 4.633673667907715 / Valid loss: 5.527044861657279
Training loss: 5.282918930053711 / Valid loss: 5.526882793789818
Training loss: 5.384278297424316 / Valid loss: 5.491148147128877
Training loss: 4.473493576049805 / Valid loss: 5.516018792561122

Epoch: 11
Training loss: 5.273750305175781 / Valid loss: 5.489752204077584
Training loss: 5.445207595825195 / Valid loss: 5.495031992594401
Training loss: 5.2608208656311035 / Valid loss: 5.484736969357445
Training loss: 7.819828987121582 / Valid loss: 5.511496355420067
Training loss: 5.1529998779296875 / Valid loss: 5.519785049983433

Epoch: 12
Training loss: 5.55267858505249 / Valid loss: 5.487533539817447
Training loss: 5.931863784790039 / Valid loss: 5.513217551367624
Training loss: 3.0109381675720215 / Valid loss: 5.527037622815087
Training loss: 4.458852767944336 / Valid loss: 5.494683054515294
Training loss: 4.160806655883789 / Valid loss: 5.532824573062715

Epoch: 13
Training loss: 4.795235633850098 / Valid loss: 5.493209411984398
Training loss: 4.42280912399292 / Valid loss: 5.496695173354376
Training loss: 6.058815002441406 / Valid loss: 5.497058398383004
Training loss: 5.800127029418945 / Valid loss: 5.504653739929199
Training loss: 4.990700721740723 / Valid loss: 5.495164746329898

Epoch: 14
Training loss: 5.980562686920166 / Valid loss: 5.499074563525972
Training loss: 5.388096332550049 / Valid loss: 5.506236426035563
Training loss: 5.679879188537598 / Valid loss: 5.5305070945194785
Training loss: 3.6280717849731445 / Valid loss: 5.5039329392569405
Training loss: 6.403841495513916 / Valid loss: 5.555675760904948

Epoch: 15
Training loss: 5.6831159591674805 / Valid loss: 5.491502559752691
Training loss: 5.444645881652832 / Valid loss: 5.532701278868176
Training loss: 4.500951766967773 / Valid loss: 5.514413054784139
Training loss: 6.080845832824707 / Valid loss: 5.492932158424741
Training loss: 4.98651123046875 / Valid loss: 5.58355773062933

Epoch: 16
Training loss: 4.450146675109863 / Valid loss: 5.5850849583035425
Training loss: 4.064596176147461 / Valid loss: 5.515714961006528
Training loss: 5.195715427398682 / Valid loss: 5.500394485110328
Training loss: 5.634490966796875 / Valid loss: 5.51566132363819
Training loss: 4.791279315948486 / Valid loss: 5.508806492033459

Epoch: 17
Training loss: 6.07611608505249 / Valid loss: 5.508183349881853
Training loss: 4.807071208953857 / Valid loss: 5.497280806586856
Training loss: 4.749369144439697 / Valid loss: 5.494707318714687
Training loss: 4.445265769958496 / Valid loss: 5.527152386165801
Training loss: 6.917873382568359 / Valid loss: 5.500626055399577

Epoch: 18
Training loss: 5.5816264152526855 / Valid loss: 5.536000994273595
Training loss: 4.919910430908203 / Valid loss: 5.501510670071556
Training loss: 5.456050395965576 / Valid loss: 5.50867877914792
Training loss: 4.318901538848877 / Valid loss: 5.514297841844105
Training loss: 4.957220554351807 / Valid loss: 5.494834661483765

Epoch: 19
Training loss: 4.0728960037231445 / Valid loss: 5.50114909807841
Training loss: 4.450469017028809 / Valid loss: 5.5084503083002
Training loss: 4.642572402954102 / Valid loss: 5.5274520646958125
Training loss: 4.006056308746338 / Valid loss: 5.498200875236875

Epoch: 20
Training loss: 4.780317306518555 / Valid loss: 5.522902073178972
Training loss: 5.044918060302734 / Valid loss: 5.497278040931338
Training loss: 3.100444793701172 / Valid loss: 5.5013368152436755
Training loss: 3.4275035858154297 / Valid loss: 5.501223997842698
Training loss: 4.943571090698242 / Valid loss: 5.508132285163516

Epoch: 21
Training loss: 4.771770477294922 / Valid loss: 5.520339513960339
Training loss: 6.298006057739258 / Valid loss: 5.501045778819493
Training loss: 5.7888312339782715 / Valid loss: 5.497353424344744
Training loss: 7.512767791748047 / Valid loss: 5.526576314653669
Training loss: 6.246817111968994 / Valid loss: 5.510463725952875

Epoch: 22
Training loss: 5.530355453491211 / Valid loss: 5.504226539248512
Training loss: 4.263248443603516 / Valid loss: 5.511502613340105
Training loss: 6.270808219909668 / Valid loss: 5.508685245968047
Training loss: 5.725137710571289 / Valid loss: 5.523370204653059
Training loss: 4.258124351501465 / Valid loss: 5.509586518151419

Epoch: 23
Training loss: 4.622230052947998 / Valid loss: 5.502703628085908
Training loss: 6.170592308044434 / Valid loss: 5.519173799242292
Training loss: 5.101165771484375 / Valid loss: 5.529845737275624
Training loss: 5.174187660217285 / Valid loss: 5.507236637387957
Training loss: 7.119589805603027 / Valid loss: 5.510544229689098

Epoch: 24
Training loss: 6.778641700744629 / Valid loss: 5.504507360004244
Training loss: 5.259664535522461 / Valid loss: 5.521439434233166
Training loss: 5.107412338256836 / Valid loss: 5.5151001044682095
Training loss: 7.081623077392578 / Valid loss: 5.515357444399879
Training loss: 3.416452646255493 / Valid loss: 5.530098544983637

Epoch: 25
Training loss: 3.8697829246520996 / Valid loss: 5.512104568027315
Training loss: 3.0461795330047607 / Valid loss: 5.606189927600679
Training loss: 3.6160924434661865 / Valid loss: 5.5069590863727385
Training loss: 6.993940353393555 / Valid loss: 5.521378131139846
Training loss: 3.4260261058807373 / Valid loss: 5.587253861200242

Epoch: 26
Training loss: 5.084988594055176 / Valid loss: 5.536805845442272
Training loss: 5.9992241859436035 / Valid loss: 5.516297742298671
Training loss: 5.955102920532227 / Valid loss: 5.517522534869966
Training loss: 5.6151580810546875 / Valid loss: 5.511801111130487
Training loss: 5.491486549377441 / Valid loss: 5.518405600956508

Epoch: 27
Training loss: 7.488737106323242 / Valid loss: 5.564374574025472
Training loss: 3.9674577713012695 / Valid loss: 5.512214106605167
Training loss: 5.03518009185791 / Valid loss: 5.500758152916318
Training loss: 6.0767717361450195 / Valid loss: 5.533495262690953
Training loss: 5.380934715270996 / Valid loss: 5.520670409429641

Epoch: 28
Training loss: 4.2744364738464355 / Valid loss: 5.516549787067231
Training loss: 4.072740077972412 / Valid loss: 5.553780837286086
Training loss: 4.98328971862793 / Valid loss: 5.525267712275187
Training loss: 4.614954471588135 / Valid loss: 5.5224081221080965
Training loss: 4.936821937561035 / Valid loss: 5.507197604860578

Epoch: 29
Training loss: 6.33676815032959 / Valid loss: 5.527415600277129
Training loss: 4.81869649887085 / Valid loss: 5.567223864509946
Training loss: 6.137674331665039 / Valid loss: 5.540587041491554
Training loss: 6.442243576049805 / Valid loss: 5.528965171178182

Epoch: 30
Training loss: 5.802284240722656 / Valid loss: 5.517720444997152
Training loss: 5.423418998718262 / Valid loss: 5.5279397169748945
Training loss: 4.733315467834473 / Valid loss: 5.643057432628813
Training loss: 4.590944766998291 / Valid loss: 5.547746220089141
Training loss: 4.800641059875488 / Valid loss: 5.5132416952224

Epoch: 31
Training loss: 5.096055030822754 / Valid loss: 5.526119436536517
Training loss: 5.332942008972168 / Valid loss: 5.521084333601452
Training loss: 4.379380702972412 / Valid loss: 5.518132116681054
Training loss: 5.007322788238525 / Valid loss: 5.542387549082438
Training loss: 6.223616600036621 / Valid loss: 5.525224488122123

Epoch: 32
Training loss: 6.002929210662842 / Valid loss: 5.521798013505482
Training loss: 6.241118431091309 / Valid loss: 5.567694057737078
Training loss: 4.749967575073242 / Valid loss: 5.531640154974801
Training loss: 4.273419380187988 / Valid loss: 5.628891944885254
Training loss: 7.390601634979248 / Valid loss: 5.522909125827607

Epoch: 33
Training loss: 3.979701519012451 / Valid loss: 5.513824835277739
Training loss: 6.375411033630371 / Valid loss: 5.5398459797813775
Training loss: 5.3277387619018555 / Valid loss: 5.5338926542372935
Training loss: 5.723964214324951 / Valid loss: 5.5660005365099225
Training loss: 6.629269123077393 / Valid loss: 5.527509525844029

Epoch: 34
Training loss: 4.85612678527832 / Valid loss: 5.533028816041492
Training loss: 6.279994487762451 / Valid loss: 5.555670461200532
Training loss: 6.139142990112305 / Valid loss: 5.536818218231201
Training loss: 6.134142875671387 / Valid loss: 5.525154238655453
Training loss: 3.979020357131958 / Valid loss: 5.5308452946799145

Epoch: 35
Training loss: 5.268239974975586 / Valid loss: 5.525958892277309
Training loss: 4.516629219055176 / Valid loss: 5.535664910361881
Training loss: 5.780996799468994 / Valid loss: 5.52758130573091
Training loss: 4.945207595825195 / Valid loss: 5.526650453749157
Training loss: 4.417022228240967 / Valid loss: 5.539230065118699

Epoch: 36
Training loss: 3.4599626064300537 / Valid loss: 5.56433214914231
Training loss: 6.484819412231445 / Valid loss: 5.542939733323597
Training loss: 3.449998378753662 / Valid loss: 5.537906953266689
Training loss: 6.162271499633789 / Valid loss: 5.53772162482852
Training loss: 3.9243721961975098 / Valid loss: 5.5482591470082605

Epoch: 37
Training loss: 5.30237340927124 / Valid loss: 5.550707360676356
Training loss: 3.893655776977539 / Valid loss: 5.5844385623931885
Training loss: 4.670575141906738 / Valid loss: 5.56959540730431
Training loss: 5.773092269897461 / Valid loss: 5.543593238648914
Training loss: 5.506038188934326 / Valid loss: 5.550005206607637

Epoch: 38
Training loss: 5.291510581970215 / Valid loss: 5.540982464381627
Training loss: 5.561369895935059 / Valid loss: 5.562149658657256
Training loss: 5.51554536819458 / Valid loss: 5.535958017621722
Training loss: 4.773528575897217 / Valid loss: 5.550307017280942
Training loss: 4.122597694396973 / Valid loss: 5.538489005679176

Epoch: 39
Training loss: 4.301779270172119 / Valid loss: 5.537814835139684
Training loss: 5.4082560539245605 / Valid loss: 5.553432008198329
Training loss: 5.64979362487793 / Valid loss: 5.548604047866094
Training loss: 5.012576580047607 / Valid loss: 5.546905983062017

Epoch: 40
Training loss: 4.234749794006348 / Valid loss: 5.5337633110228035
Training loss: 5.4871673583984375 / Valid loss: 5.53420767329988
Training loss: 4.018970489501953 / Valid loss: 5.548644905998593
Training loss: 4.679477214813232 / Valid loss: 5.592910287493751
Training loss: 3.921609878540039 / Valid loss: 5.535746964954194

Epoch: 41
Training loss: 3.9951424598693848 / Valid loss: 5.534206438064575
Training loss: 5.14202880859375 / Valid loss: 5.557938398633684
Training loss: 4.442836284637451 / Valid loss: 5.538710071927025
Training loss: 6.807930946350098 / Valid loss: 5.547572422027588
Training loss: 3.978180408477783 / Valid loss: 5.542928048542568

Epoch: 42
Training loss: 3.2319366931915283 / Valid loss: 5.537375622703916
Training loss: 4.6524434089660645 / Valid loss: 5.537522141138712
Training loss: 6.2938079833984375 / Valid loss: 5.547724396841867
Training loss: 4.366973876953125 / Valid loss: 5.542724246070499
Training loss: 3.940472364425659 / Valid loss: 5.556344025475639

Epoch: 43
Training loss: 5.467159748077393 / Valid loss: 5.538928538277036
Training loss: 4.510066032409668 / Valid loss: 5.54208251181103
Training loss: 5.766755104064941 / Valid loss: 5.538600917089553
Training loss: 5.074177265167236 / Valid loss: 5.536534609113421
Training loss: 6.219257831573486 / Valid loss: 5.558918432962327

Epoch: 44
Training loss: 4.6608967781066895 / Valid loss: 5.563035127094814
Training loss: 4.845986366271973 / Valid loss: 5.556047782443819
Training loss: 5.246848106384277 / Valid loss: 5.539307587487357
Training loss: 6.093208312988281 / Valid loss: 5.540275305793399
Training loss: 5.323326110839844 / Valid loss: 5.541326847530547

Epoch: 45
Training loss: 4.087479591369629 / Valid loss: 5.544758760361445
Training loss: 4.414223670959473 / Valid loss: 5.538433858326504
Training loss: 3.69020414352417 / Valid loss: 5.6767901534125915
Training loss: 5.623407363891602 / Valid loss: 5.56660433723813
Training loss: 4.589151382446289 / Valid loss: 5.5418642702556795

Epoch: 46
Training loss: 5.937435150146484 / Valid loss: 5.550122261047363
Training loss: 5.081526279449463 / Valid loss: 5.559211590176537
Training loss: 5.180676460266113 / Valid loss: 5.549287012645176
Training loss: 5.217685699462891 / Valid loss: 5.733403641836984
Training loss: 4.950830459594727 / Valid loss: 5.5432162103198825

Epoch: 47
Training loss: 2.6792519092559814 / Valid loss: 5.554983186721802
Training loss: 4.03995943069458 / Valid loss: 5.555281936554682
Training loss: 5.110133171081543 / Valid loss: 5.5488830725351965
Training loss: 6.198402404785156 / Valid loss: 5.563612179529099
Training loss: 5.884947776794434 / Valid loss: 5.560671225048247

Epoch: 48
Training loss: 4.902179718017578 / Valid loss: 5.615463299978347
Training loss: 4.551407337188721 / Valid loss: 5.5502357641855875
Training loss: 4.008413314819336 / Valid loss: 5.5550188632238475
Training loss: 5.330992221832275 / Valid loss: 5.546856371561686
Training loss: 4.416406154632568 / Valid loss: 5.555302751631964

Epoch: 49
Training loss: 6.848857879638672 / Valid loss: 5.607013198307582
Training loss: 5.1101508140563965 / Valid loss: 5.596517335800898
Training loss: 4.764434814453125 / Valid loss: 5.562255053293137
Training loss: 4.089353561401367 / Valid loss: 5.542191219329834

Epoch: 50
Training loss: 4.719763278961182 / Valid loss: 5.5828419776189895
Training loss: 3.291001081466675 / Valid loss: 5.544988986424038
Training loss: 4.424117088317871 / Valid loss: 5.547086910974412
Training loss: 5.063505172729492 / Valid loss: 5.582153193155924
Training loss: 6.961791515350342 / Valid loss: 5.563337419146583

Epoch: 51
Training loss: 5.107960224151611 / Valid loss: 5.550413129443214
Training loss: 3.214745283126831 / Valid loss: 5.551479162488665
Training loss: 6.627513885498047 / Valid loss: 5.5576653435116725
Training loss: 4.129751205444336 / Valid loss: 5.560864777792068
Training loss: 4.629809856414795 / Valid loss: 5.554580052693685

Epoch: 52
Training loss: 4.81398868560791 / Valid loss: 5.572154853457496
Training loss: 4.784414291381836 / Valid loss: 5.559934266408285
Training loss: 4.564147472381592 / Valid loss: 5.610540330977667
Training loss: 4.378947734832764 / Valid loss: 5.600897237232753
Training loss: 4.797054290771484 / Valid loss: 5.560198284330822

Epoch: 53
Training loss: 5.127857208251953 / Valid loss: 5.611429421106974
Training loss: 4.673030376434326 / Valid loss: 5.55994455019633
Training loss: 9.382926940917969 / Valid loss: 5.563554840996152
Training loss: 5.352948188781738 / Valid loss: 5.565205181212653
Training loss: 5.607209205627441 / Valid loss: 5.547218452181135

Epoch: 54
Training loss: 4.017524719238281 / Valid loss: 5.551028619493757
Training loss: 4.370095252990723 / Valid loss: 5.557440483002436
Training loss: 3.8304433822631836 / Valid loss: 5.556561306544713
Training loss: 4.297408103942871 / Valid loss: 5.5609827223278225
Training loss: 4.429200649261475 / Valid loss: 5.5573742457798545

Epoch: 55
Training loss: 4.149243354797363 / Valid loss: 5.543677856808617
Training loss: 5.310502529144287 / Valid loss: 5.5623752276102705
Training loss: 3.989082098007202 / Valid loss: 5.569949390774681
Training loss: 4.604704856872559 / Valid loss: 5.577134949820382
Training loss: 4.05421257019043 / Valid loss: 5.555090461458478

Epoch: 56
Training loss: 4.114194393157959 / Valid loss: 5.657624380929129
Training loss: 4.799633026123047 / Valid loss: 5.559781083606539
Training loss: 3.0324411392211914 / Valid loss: 5.558923015140352
Training loss: 6.631318092346191 / Valid loss: 5.568131891886393
Training loss: 4.691740036010742 / Valid loss: 5.5916977246602375

Epoch: 57
Training loss: 4.106681823730469 / Valid loss: 5.55786771774292
Training loss: 4.093466758728027 / Valid loss: 5.55949133237203
Training loss: 5.039675235748291 / Valid loss: 5.565016276495797
Training loss: 4.806833744049072 / Valid loss: 5.58227029755002
Training loss: 4.900691509246826 / Valid loss: 5.578930044174195

Epoch: 58
Training loss: 3.6734254360198975 / Valid loss: 5.563910291308448
Training loss: 4.780981063842773 / Valid loss: 5.561571493602934
Training loss: 3.6165060997009277 / Valid loss: 5.568858314695812
Training loss: 5.144540309906006 / Valid loss: 5.558254191988991
Training loss: 5.330763816833496 / Valid loss: 5.591324377059936

Epoch: 59
Training loss: 3.3523101806640625 / Valid loss: 5.633190207254319
Training loss: 4.897985458374023 / Valid loss: 5.612695852915446
Training loss: 3.816530704498291 / Valid loss: 5.585194998695737
Training loss: 2.2149055004119873 / Valid loss: 5.581450632640293

Epoch: 60
Training loss: 5.729769229888916 / Valid loss: 5.583296260379609
Training loss: 3.2948977947235107 / Valid loss: 5.576558147157941
Training loss: 5.0597333908081055 / Valid loss: 5.561858974184308
Training loss: 5.005020618438721 / Valid loss: 5.556345151719593
Training loss: 4.8651628494262695 / Valid loss: 5.5603461242857435

Epoch: 61
Training loss: 4.835761547088623 / Valid loss: 5.575547733761016
Training loss: 4.005519866943359 / Valid loss: 5.603193573724656
Training loss: 5.726869583129883 / Valid loss: 5.59660564831325
Training loss: 5.114340305328369 / Valid loss: 5.5689254488263815
Training loss: 5.813440322875977 / Valid loss: 5.666021889731997

Epoch: 62
Training loss: 4.376605033874512 / Valid loss: 5.578920723143078
Training loss: 3.362459421157837 / Valid loss: 5.593840117681594
Training loss: 4.5295023918151855 / Valid loss: 5.579613233747937
Training loss: 5.4646830558776855 / Valid loss: 5.570550407682147
Training loss: 6.793548583984375 / Valid loss: 5.584099329085577

Epoch: 63
Training loss: 3.9282419681549072 / Valid loss: 5.568959567660377
Training loss: 6.071471214294434 / Valid loss: 5.587555267697289
Training loss: 5.257451057434082 / Valid loss: 5.5978137969970705
Training loss: 5.030014991760254 / Valid loss: 5.609584694816952
Training loss: 3.512805938720703 / Valid loss: 5.589801461356027

Epoch: 64
Training loss: 4.111606121063232 / Valid loss: 5.591767685753958
Training loss: 5.33513879776001 / Valid loss: 5.574411539804368
Training loss: 5.1164116859436035 / Valid loss: 5.5695042973472955
Training loss: 4.079943656921387 / Valid loss: 5.571228324799311
Training loss: 4.523146629333496 / Valid loss: 5.586432309377761

Epoch: 65
Training loss: 4.078637599945068 / Valid loss: 5.569686453683036
Training loss: 6.394761085510254 / Valid loss: 5.609444870267596
Training loss: 5.83243989944458 / Valid loss: 5.571406450725737
Training loss: 4.892607688903809 / Valid loss: 5.585536470867338
Training loss: 5.065053939819336 / Valid loss: 5.582222752344041

Epoch: 66
Training loss: 4.213592529296875 / Valid loss: 5.574741960707165
Training loss: 4.8477463722229 / Valid loss: 5.59439302399045
Training loss: 4.080077171325684 / Valid loss: 5.586771551767985
Training loss: 6.64024543762207 / Valid loss: 5.577924903233846
Training loss: 4.032623291015625 / Valid loss: 5.582079698925926

Epoch: 67
Training loss: 4.964107513427734 / Valid loss: 5.573110332943144
Training loss: 6.403579235076904 / Valid loss: 5.647554179600307
Training loss: 4.629511833190918 / Valid loss: 5.582871393930344
Training loss: 5.969256401062012 / Valid loss: 5.573348152069818
Training loss: 3.889784336090088 / Valid loss: 5.581769800186157

Epoch: 68
Training loss: 4.949929237365723 / Valid loss: 5.569688179379418
Training loss: 5.400790691375732 / Valid loss: 5.596278038479033
Training loss: 5.228841781616211 / Valid loss: 5.572107623872303
Training loss: 4.971337795257568 / Valid loss: 5.589948236374628
Training loss: 4.1119489669799805 / Valid loss: 5.571967658542452

Epoch: 69
Training loss: 5.811205863952637 / Valid loss: 5.648643332435971
Training loss: 3.6023881435394287 / Valid loss: 5.583428514571417
Training loss: 4.613860607147217 / Valid loss: 5.58410013516744
Training loss: 5.282801151275635 / Valid loss: 5.579581776119414

Epoch: 70
Training loss: 5.4440507888793945 / Valid loss: 5.579475809278942
Training loss: 6.034744739532471 / Valid loss: 5.592271684464954
Training loss: 4.6943678855896 / Valid loss: 5.586209957940238
Training loss: 5.447342395782471 / Valid loss: 5.562545074735369
Training loss: 5.066566467285156 / Valid loss: 5.59726098151434

Epoch: 71
Training loss: 5.120297431945801 / Valid loss: 5.63105115209307
Training loss: 3.4457521438598633 / Valid loss: 5.590648771467663
Training loss: 5.1188249588012695 / Valid loss: 5.587166647684007
Training loss: 6.617063522338867 / Valid loss: 5.584408576147897
Training loss: 6.264003753662109 / Valid loss: 5.57084440730867

Epoch: 72
Training loss: 4.046216011047363 / Valid loss: 5.5810758477165585
Training loss: 6.648517608642578 / Valid loss: 5.629896245683942
Training loss: 3.903346061706543 / Valid loss: 5.582966230029151
Training loss: 5.803437232971191 / Valid loss: 5.585395983287266
Training loss: 5.121427536010742 / Valid loss: 5.579769926979428

Epoch: 73
Training loss: 3.576427936553955 / Valid loss: 5.5787738436744325
Training loss: 5.356878757476807 / Valid loss: 5.590930375598726
Training loss: 5.065274715423584 / Valid loss: 5.603330457778204
Training loss: 5.995582580566406 / Valid loss: 5.59000400588626
Training loss: 5.138211250305176 / Valid loss: 5.58477965763637

Epoch: 74
Training loss: 4.95145320892334 / Valid loss: 5.592077477773031
Training loss: 4.997357368469238 / Valid loss: 5.594388525826591
Training loss: 3.7756810188293457 / Valid loss: 5.594409293220156
Training loss: 5.199776649475098 / Valid loss: 5.586521972928728
Training loss: 5.232019424438477 / Valid loss: 5.581690808704921

Epoch: 75
Training loss: 3.9443752765655518 / Valid loss: 5.574948819478353
Training loss: 3.984621524810791 / Valid loss: 5.61332433337257
Training loss: 4.577366352081299 / Valid loss: 5.586851272128877
Training loss: 4.710002899169922 / Valid loss: 5.5929530915759855
Training loss: 4.1023101806640625 / Valid loss: 5.604065845126198

Epoch: 76
Training loss: 3.261610507965088 / Valid loss: 5.585912961051577
Training loss: 4.149363994598389 / Valid loss: 5.580389817555745
Training loss: 5.3103156089782715 / Valid loss: 5.658448312396095
Training loss: 5.073686599731445 / Valid loss: 5.613702935264224
Training loss: 2.9721570014953613 / Valid loss: 5.5964850630079

Epoch: 77
Training loss: 4.404271602630615 / Valid loss: 5.607350503830682
Training loss: 4.976722240447998 / Valid loss: 5.586672142573765
Training loss: 6.762515068054199 / Valid loss: 5.615571873528617
Training loss: 4.041391372680664 / Valid loss: 5.634305988039289
Training loss: 3.971113443374634 / Valid loss: 5.594557680402484

Epoch: 78
Training loss: 3.692769765853882 / Valid loss: 5.590995675041562
Training loss: 5.6439056396484375 / Valid loss: 5.588461898622059
Training loss: 3.390575647354126 / Valid loss: 5.627602327437628
Training loss: 5.789488792419434 / Valid loss: 5.583787239165533
Training loss: 7.146523475646973 / Valid loss: 5.587610837391445

Epoch: 79
Training loss: 4.141792297363281 / Valid loss: 5.5900250434875485
Training loss: 4.347823143005371 / Valid loss: 5.592054326193673
Training loss: 3.7281417846679688 / Valid loss: 5.602218596140544
Training loss: 6.602774620056152 / Valid loss: 5.589895670754569
ModuleList(
  (0): Linear(in_features=5376, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.3178695224580315
Training regression with following parameters:
dnn_hidden_units : 2000, 100, 16
dropout_probs : 0.0, 0.0
learning_rate : 0.001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : Adam
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : TFIDF
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=31191, out_features=2000, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=2000, out_features=100, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=100, out_features=16, bias=True)
  (9): Dropout(p=0, inplace=False)
  (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (11): LeakyReLU(negative_slope=0.02)
  (12): Linear(in_features=16, out_features=1, bias=True)
)

Epoch: 0
Training loss: 17.8549747467041 / Valid loss: 16.974769047328405
Model is saved in epoch 0, overall batch: 0
Training loss: 13.96962833404541 / Valid loss: 11.932385876065208
Model is saved in epoch 0, overall batch: 100
Training loss: 7.026939868927002 / Valid loss: 7.509492842356364
Model is saved in epoch 0, overall batch: 200
Training loss: 5.229887962341309 / Valid loss: 5.984595482689993
Model is saved in epoch 0, overall batch: 300
Training loss: 6.353970050811768 / Valid loss: 5.807947649274554
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 3.773589611053467 / Valid loss: 5.667540706907
Model is saved in epoch 1, overall batch: 500
Training loss: 4.42996072769165 / Valid loss: 6.222200836454119
Training loss: 3.811056613922119 / Valid loss: 6.161750929696219
Training loss: 3.053370714187622 / Valid loss: 6.100447379975092
Training loss: 3.9689249992370605 / Valid loss: 6.293189001083374

Epoch: 2
Training loss: 2.730053424835205 / Valid loss: 6.401859733036586
Training loss: 1.6549737453460693 / Valid loss: 6.494033204941522
Training loss: 2.4211606979370117 / Valid loss: 6.7184971219017395
Training loss: 2.061708450317383 / Valid loss: 6.582486581802368
Training loss: 2.170557737350464 / Valid loss: 6.37138108980088

Epoch: 3
Training loss: 2.2084319591522217 / Valid loss: 6.661845416114444
Training loss: 2.039992332458496 / Valid loss: 6.60088370186942
Training loss: 1.8702974319458008 / Valid loss: 6.7366766884213405
Training loss: 1.3679521083831787 / Valid loss: 6.890186745779855
Training loss: 1.6138741970062256 / Valid loss: 6.644277213868641

Epoch: 4
Training loss: 1.7200782299041748 / Valid loss: 6.730484226771764
Training loss: 1.3341643810272217 / Valid loss: 6.811494775045485
Training loss: 0.8126428127288818 / Valid loss: 6.694632707323347
Training loss: 1.234389305114746 / Valid loss: 6.872702723457699
Training loss: 2.4009461402893066 / Valid loss: 6.889894803365071

Epoch: 5
Training loss: 0.7232390642166138 / Valid loss: 6.8080869424910775
Training loss: 0.6595641374588013 / Valid loss: 6.854381293342227
Training loss: 1.7364425659179688 / Valid loss: 6.893139503115699
Training loss: 1.5202198028564453 / Valid loss: 6.945148268200103
Training loss: 1.0105502605438232 / Valid loss: 7.081467483157203

Epoch: 6
Training loss: 0.7913210391998291 / Valid loss: 6.759181658426921
Training loss: 0.7923386096954346 / Valid loss: 6.771300134204683
Training loss: 0.6582398414611816 / Valid loss: 6.865367464792161
Training loss: 1.100479006767273 / Valid loss: 6.97673867997669
Training loss: 0.902996301651001 / Valid loss: 7.041066601162865

Epoch: 7
Training loss: 0.7045547366142273 / Valid loss: 6.797640650612967
Training loss: 0.8662700653076172 / Valid loss: 6.908676581155686
Training loss: 0.4174552261829376 / Valid loss: 6.842948999859038
Training loss: 0.5487631559371948 / Valid loss: 7.133337842850458
Training loss: 0.7183629274368286 / Valid loss: 7.036370018550328

Epoch: 8
Training loss: 0.962117612361908 / Valid loss: 6.988359385445005
Training loss: 0.8230038285255432 / Valid loss: 6.834904007684617
Training loss: 0.5811324119567871 / Valid loss: 6.9924082211085725
Training loss: 0.9246580600738525 / Valid loss: 6.8792292095365974
Training loss: 0.5284697413444519 / Valid loss: 6.948527681259882

Epoch: 9
Training loss: 0.3660949170589447 / Valid loss: 6.788198693593343
Training loss: 1.0461244583129883 / Valid loss: 6.822217939013527
Training loss: 1.13827645778656 / Valid loss: 6.898030898684547
Training loss: 0.5707057118415833 / Valid loss: 6.874756136394683

Epoch: 10
Training loss: 0.6397074460983276 / Valid loss: 6.714658096858433
Training loss: 0.5138578414916992 / Valid loss: 6.839397280556815
Training loss: 0.5082765817642212 / Valid loss: 6.871613913490659
Training loss: 0.5378353595733643 / Valid loss: 6.8626499857221335
Training loss: 0.3901427984237671 / Valid loss: 6.7626752807980495

Epoch: 11
Training loss: 0.46203652024269104 / Valid loss: 6.981022562299456
Training loss: 0.39341360330581665 / Valid loss: 6.953226407368978
Training loss: 0.26623910665512085 / Valid loss: 6.811293869926816
Training loss: 0.7252601385116577 / Valid loss: 6.8185479482014975
Training loss: 0.4471498131752014 / Valid loss: 6.956808623813448

Epoch: 12
Training loss: 0.3791780471801758 / Valid loss: 6.8764405023484
Training loss: 0.33632606267929077 / Valid loss: 6.8381615729559035
Training loss: 0.40234485268592834 / Valid loss: 6.825390511467344
Training loss: 0.6113224625587463 / Valid loss: 7.071878701164609
Training loss: 0.5121588706970215 / Valid loss: 6.983513318924677

Epoch: 13
Training loss: 0.5181628465652466 / Valid loss: 6.874415116083054
Training loss: 0.2841576635837555 / Valid loss: 6.882711805616107
Training loss: 0.28228825330734253 / Valid loss: 6.796470991770426
Training loss: 0.44527286291122437 / Valid loss: 7.033678574789138
Training loss: 0.7262670397758484 / Valid loss: 6.831825642358689

Epoch: 14
Training loss: 0.42486584186553955 / Valid loss: 6.875460270472935
Training loss: 0.5629675388336182 / Valid loss: 6.7810702187674385
Training loss: 0.386993944644928 / Valid loss: 7.0293294702257425
Training loss: 0.4425731897354126 / Valid loss: 6.889694279716128
Training loss: 0.5111596584320068 / Valid loss: 6.886731402079264

Epoch: 15
Training loss: 0.21653884649276733 / Valid loss: 6.805733029047648
Training loss: 0.38869601488113403 / Valid loss: 6.847716013590495
Training loss: 0.3845527768135071 / Valid loss: 6.887755303155808
Training loss: 0.3671751618385315 / Valid loss: 6.9443237667992
Training loss: 0.31838154792785645 / Valid loss: 6.982695886066982

Epoch: 16
Training loss: 0.24128147959709167 / Valid loss: 6.820712666284471
Training loss: 0.7222154140472412 / Valid loss: 6.908604167756581
Training loss: 0.416519433259964 / Valid loss: 7.0592114448547365
Training loss: 0.49863624572753906 / Valid loss: 7.070145109721593
Training loss: 0.4504089653491974 / Valid loss: 6.935830976849511

Epoch: 17
Training loss: 0.5156701803207397 / Valid loss: 6.985035305931454
Training loss: 0.1796080768108368 / Valid loss: 6.886530072348458
Training loss: 0.28460341691970825 / Valid loss: 6.784751151856922
Training loss: 0.25598302483558655 / Valid loss: 6.809001570656186
Training loss: 0.4747069478034973 / Valid loss: 6.812047935667492

Epoch: 18
Training loss: 0.4359683096408844 / Valid loss: 6.885851312818981
Training loss: 0.48908233642578125 / Valid loss: 6.983775497618176
Training loss: 0.1868511289358139 / Valid loss: 7.085348374502999
Training loss: 0.1604190617799759 / Valid loss: 6.881528241293771
Training loss: 0.33009952306747437 / Valid loss: 6.761141098113287

Epoch: 19
Training loss: 0.38465821743011475 / Valid loss: 6.8104134287152975
Training loss: 0.1966273933649063 / Valid loss: 6.845876062484015
Training loss: 0.5568547248840332 / Valid loss: 6.871862143561954
Training loss: 0.3409462571144104 / Valid loss: 6.937699084054856

Epoch: 20
Training loss: 0.22443214058876038 / Valid loss: 6.974955940246582
Training loss: 0.8298752307891846 / Valid loss: 6.825992588769822
Training loss: 0.4374881386756897 / Valid loss: 7.067449079241071
Training loss: 0.39287829399108887 / Valid loss: 6.819914533978417
Training loss: 0.22177501022815704 / Valid loss: 7.00377539225987

Epoch: 21
Training loss: 0.5696954727172852 / Valid loss: 7.051890591212682
Training loss: 0.5311688780784607 / Valid loss: 6.941854050045921
Training loss: 0.20971344411373138 / Valid loss: 6.8748203572772795
Training loss: 0.18545615673065186 / Valid loss: 6.92478688785008
Training loss: 0.2007129192352295 / Valid loss: 6.931965015048072

Epoch: 22
Training loss: 0.2286049723625183 / Valid loss: 7.03446455683027
Training loss: 0.4473211169242859 / Valid loss: 6.907368006025042
Training loss: 0.596305251121521 / Valid loss: 7.059801764715285
Training loss: 0.1882912814617157 / Valid loss: 6.911761840184529
Training loss: 0.4502078890800476 / Valid loss: 6.910237609772455

Epoch: 23
Training loss: 0.43237268924713135 / Valid loss: 6.887611909139724
Training loss: 0.3731710612773895 / Valid loss: 6.982212786447434
Training loss: 0.25550517439842224 / Valid loss: 6.8952160222189764
Training loss: 0.21175917983055115 / Valid loss: 6.864488483610607
Training loss: 0.26271212100982666 / Valid loss: 6.92677499680292

Epoch: 24
Training loss: 0.17805179953575134 / Valid loss: 6.953252805982317
Training loss: 0.22969603538513184 / Valid loss: 6.807367772147769
Training loss: 0.21033765375614166 / Valid loss: 7.024310988471622
Training loss: 0.16775605082511902 / Valid loss: 6.878455093928745
Training loss: 0.49908459186553955 / Valid loss: 6.908572128840855

Epoch: 25
Training loss: 0.24523970484733582 / Valid loss: 7.042650013878232
Training loss: 0.26725947856903076 / Valid loss: 6.957899288904099
Training loss: 0.2511305809020996 / Valid loss: 6.898936827977498
Training loss: 0.18283960223197937 / Valid loss: 6.943476972125826
Training loss: 0.25116050243377686 / Valid loss: 6.998228699820382

Epoch: 26
Training loss: 0.1638905107975006 / Valid loss: 6.827079772949219
Training loss: 0.6310980319976807 / Valid loss: 6.784702646164667
Training loss: 0.15258458256721497 / Valid loss: 6.921503439403716
Training loss: 0.22920949757099152 / Valid loss: 7.091877578553699
Training loss: 0.26612359285354614 / Valid loss: 7.03202797571818

Epoch: 27
Training loss: 0.1043216735124588 / Valid loss: 6.9108947708493185
Training loss: 0.22139763832092285 / Valid loss: 7.1278859297434485
Training loss: 0.390315979719162 / Valid loss: 6.9367271968296595
Training loss: 0.15940353274345398 / Valid loss: 6.942324288686117
Training loss: 0.12748128175735474 / Valid loss: 7.055759879520961

Epoch: 28
Training loss: 0.17050188779830933 / Valid loss: 6.911635632742019
Training loss: 0.17568275332450867 / Valid loss: 6.889032216299148
Training loss: 0.5433291792869568 / Valid loss: 6.962091963631766
Training loss: 0.1752215027809143 / Valid loss: 6.886219839822679
Training loss: 0.1644473373889923 / Valid loss: 7.01680485861642

Epoch: 29
Training loss: 0.19860610365867615 / Valid loss: 6.913442734309605
Training loss: 0.19516737759113312 / Valid loss: 7.0246130534580775
Training loss: 0.18017424643039703 / Valid loss: 7.013794860385713
Training loss: 0.40308699011802673 / Valid loss: 6.943145102546328

Epoch: 30
Training loss: 0.1073141023516655 / Valid loss: 7.09362093153454
Training loss: 0.5590545535087585 / Valid loss: 7.000029600234258
Training loss: 0.3073664903640747 / Valid loss: 7.0249346778506325
Training loss: 0.2923542261123657 / Valid loss: 6.909485648927235
Training loss: 0.33443281054496765 / Valid loss: 6.977350416637602

Epoch: 31
Training loss: 0.12776674330234528 / Valid loss: 7.086714894430978
Training loss: 0.18158316612243652 / Valid loss: 6.972035267239526
Training loss: 0.29204821586608887 / Valid loss: 7.0939789999099006
Training loss: 0.08199670165777206 / Valid loss: 7.016810178756714
Training loss: 0.2604881227016449 / Valid loss: 7.084262684413365

Epoch: 32
Training loss: 0.24063202738761902 / Valid loss: 7.141737567810785
Training loss: 0.234274223446846 / Valid loss: 7.0331819579714825
Training loss: 0.2071111649274826 / Valid loss: 7.050380348023914
Training loss: 0.22041618824005127 / Valid loss: 6.876171557108561
Training loss: 0.13131260871887207 / Valid loss: 7.006029269808814

Epoch: 33
Training loss: 0.14103229343891144 / Valid loss: 6.9805631319681805
Training loss: 0.13580869138240814 / Valid loss: 6.896853397006081
Training loss: 0.11168328672647476 / Valid loss: 6.9228622118632
Training loss: 0.08689545094966888 / Valid loss: 6.845611231667655
Training loss: 0.17038866877555847 / Valid loss: 7.1044649941580635

Epoch: 34
Training loss: 0.1886788010597229 / Valid loss: 7.151003644579933
Training loss: 0.2085399329662323 / Valid loss: 7.022111670176188
Training loss: 0.15724869072437286 / Valid loss: 6.954712459019253
Training loss: 0.13877813518047333 / Valid loss: 6.912409251076834
Training loss: 0.26939666271209717 / Valid loss: 6.919051456451416

Epoch: 35
Training loss: 0.15313158929347992 / Valid loss: 6.937540817260742
Training loss: 0.11604170501232147 / Valid loss: 6.925864959898449
Training loss: 0.13419970870018005 / Valid loss: 6.977060828890119
Training loss: 0.19794024527072906 / Valid loss: 6.987786436080933
Training loss: 0.1780630499124527 / Valid loss: 7.0341133208501905

Epoch: 36
Training loss: 0.3160252869129181 / Valid loss: 6.971670055389405
Training loss: 0.5965589284896851 / Valid loss: 7.147240161895752
Training loss: 0.7073046565055847 / Valid loss: 6.9712114288693385
Training loss: 0.41634753346443176 / Valid loss: 7.050921535491943
Training loss: 0.18115264177322388 / Valid loss: 6.931022943769182

Epoch: 37
Training loss: 0.08028087764978409 / Valid loss: 6.911332409722465
Training loss: 0.1650528907775879 / Valid loss: 7.059201133818854
Training loss: 0.20936602354049683 / Valid loss: 6.935306746619088
Training loss: 0.5773135423660278 / Valid loss: 7.052749043419247
Training loss: 0.285707950592041 / Valid loss: 7.001244649432954

Epoch: 38
Training loss: 0.16202068328857422 / Valid loss: 7.03424585887364
Training loss: 0.1104569062590599 / Valid loss: 7.054315339951288
Training loss: 0.2690185308456421 / Valid loss: 6.925544629778181
Training loss: 0.24906687438488007 / Valid loss: 6.991949490138462
Training loss: 0.3112507462501526 / Valid loss: 6.955429808298747

Epoch: 39
Training loss: 0.0957954078912735 / Valid loss: 7.00460033416748
Training loss: 0.17185944318771362 / Valid loss: 6.996263876415434
Training loss: 0.10470522940158844 / Valid loss: 6.971412320364089
Training loss: 0.09794867038726807 / Valid loss: 6.941170692443848

Epoch: 40
Training loss: 0.12136027216911316 / Valid loss: 7.269398244222005
Training loss: 0.683131217956543 / Valid loss: 7.049326460702079
Training loss: 0.3609772324562073 / Valid loss: 7.01166181564331
Training loss: 0.191694438457489 / Valid loss: 6.8828477291833785
Training loss: 0.09334512054920197 / Valid loss: 6.964823014395577

Epoch: 41
Training loss: 0.09268676489591599 / Valid loss: 7.026741976965042
Training loss: 0.15446820855140686 / Valid loss: 7.097458457946777
Training loss: 0.1283191442489624 / Valid loss: 6.934433346702939
Training loss: 0.19725772738456726 / Valid loss: 7.094697793324788
Training loss: 0.41941192746162415 / Valid loss: 6.992434696924119

Epoch: 42
Training loss: 0.10945607721805573 / Valid loss: 7.136849398840042
Training loss: 0.10073345899581909 / Valid loss: 7.013419930140177
Training loss: 0.1405196487903595 / Valid loss: 7.027715446835472
Training loss: 0.11024986952543259 / Valid loss: 7.052060558682396
Training loss: 0.12113597244024277 / Valid loss: 7.036973131270636

Epoch: 43
Training loss: 0.10371436178684235 / Valid loss: 7.0701570874168755
Training loss: 0.07614292204380035 / Valid loss: 6.911426639556884
Training loss: 0.1843850463628769 / Valid loss: 7.015317090352377
Training loss: 0.12213699519634247 / Valid loss: 7.086838604155041
Training loss: 0.08590635657310486 / Valid loss: 6.97167417435419

Epoch: 44
Training loss: 0.08619605004787445 / Valid loss: 6.991622332164219
Training loss: 0.1883014738559723 / Valid loss: 7.154387671606881
Training loss: 0.82207190990448 / Valid loss: 7.025708287102836
Training loss: 0.15360090136528015 / Valid loss: 7.1529250281197685
Training loss: 0.17226360738277435 / Valid loss: 7.21703766868228

Epoch: 45
Training loss: 0.09802882373332977 / Valid loss: 7.067419524419876
Training loss: 0.0754375085234642 / Valid loss: 6.960625750677926
Training loss: 0.17001864314079285 / Valid loss: 7.0828793957119895
Training loss: 0.1265854388475418 / Valid loss: 7.184007531120663
Training loss: 0.0686558336019516 / Valid loss: 6.989337435222807

Epoch: 46
Training loss: 0.10773779451847076 / Valid loss: 7.165537552606492
Training loss: 0.17200647294521332 / Valid loss: 6.920468779972621
Training loss: 0.11229442059993744 / Valid loss: 7.161818606512887
Training loss: 0.11214730143547058 / Valid loss: 7.121817532039824
Training loss: 0.18516655266284943 / Valid loss: 7.128597073327928

Epoch: 47
Training loss: 0.1157965362071991 / Valid loss: 7.118964451835269
Training loss: 0.1457509696483612 / Valid loss: 7.2397506827399845
Training loss: 0.13367696106433868 / Valid loss: 7.066534544172741
Training loss: 0.06168987601995468 / Valid loss: 7.01856963293893
Training loss: 0.09173163771629333 / Valid loss: 7.005618781135196

Epoch: 48
Training loss: 0.23098906874656677 / Valid loss: 7.349956203642345
Training loss: 0.22453945875167847 / Valid loss: 6.934696824210031
Training loss: 0.20594938099384308 / Valid loss: 7.038392350787208
Training loss: 0.20815584063529968 / Valid loss: 6.882216839563279
Training loss: 0.09604164958000183 / Valid loss: 7.1603719484238395

Epoch: 49
Training loss: 0.29674479365348816 / Valid loss: 7.061264283316476
Training loss: 0.11253058910369873 / Valid loss: 7.093748574029831
Training loss: 0.09083215147256851 / Valid loss: 6.8806313787187845
Training loss: 0.09861910343170166 / Valid loss: 7.064824206488473

Epoch: 50
Training loss: 0.13177411258220673 / Valid loss: 7.174401987166632
Training loss: 0.13975243270397186 / Valid loss: 6.938296649569557
Training loss: 0.1088465005159378 / Valid loss: 7.195773297264463
Training loss: 0.22925622761249542 / Valid loss: 7.158986727396647
Training loss: 0.10332353413105011 / Valid loss: 6.972229735056559

Epoch: 51
Training loss: 0.10783903300762177 / Valid loss: 7.099476282937186
Training loss: 0.3223786950111389 / Valid loss: 7.02485891977946
Training loss: 0.1179235577583313 / Valid loss: 7.0835696311224075
Training loss: 0.0777512788772583 / Valid loss: 7.260306408291771
Training loss: 0.1187555119395256 / Valid loss: 7.059872738520304

Epoch: 52
Training loss: 0.1473846733570099 / Valid loss: 7.159697110312326
Training loss: 0.12195518612861633 / Valid loss: 7.104376792907715
Training loss: 0.13145631551742554 / Valid loss: 6.8920467013404485
Training loss: 0.16045601665973663 / Valid loss: 7.137745543888637
Training loss: 0.11135407537221909 / Valid loss: 7.010499638602847

Epoch: 53
Training loss: 0.08465657383203506 / Valid loss: 7.076923252287365
Training loss: 0.21776115894317627 / Valid loss: 7.1946787243797665
Training loss: 0.19300520420074463 / Valid loss: 7.145321242014567
Training loss: 0.1706589311361313 / Valid loss: 7.229300639742896
Training loss: 0.5210516452789307 / Valid loss: 7.138732260749453

Epoch: 54
Training loss: 0.08511795103549957 / Valid loss: 6.968511286235991
Training loss: 0.07530976831912994 / Valid loss: 7.098473710105533
Training loss: 0.10982943326234818 / Valid loss: 6.85535627092634
Training loss: 0.18773521482944489 / Valid loss: 7.004245726267497
Training loss: 0.045766234397888184 / Valid loss: 7.042629768734886

Epoch: 55
Training loss: 0.08022846281528473 / Valid loss: 7.248099881126767
Training loss: 0.0714489296078682 / Valid loss: 7.116480034873599
Training loss: 0.15181387960910797 / Valid loss: 7.029557568686349
Training loss: 0.09850132465362549 / Valid loss: 7.018007482801165
Training loss: 0.08196315914392471 / Valid loss: 7.055222915467762

Epoch: 56
Training loss: 0.14590588212013245 / Valid loss: 6.997784278506324
Training loss: 0.1368708610534668 / Valid loss: 7.109882450103759
Training loss: 0.10331177711486816 / Valid loss: 7.0925448054359075
Training loss: 0.10912561416625977 / Valid loss: 7.044911657060895
Training loss: 0.06877157837152481 / Valid loss: 7.196622621445429

Epoch: 57
Training loss: 0.10020725429058075 / Valid loss: 7.085537279219855
Training loss: 0.07854963839054108 / Valid loss: 7.027739820026216
Training loss: 0.12596485018730164 / Valid loss: 7.143445005871
Training loss: 0.08623280376195908 / Valid loss: 7.142903555007208
Training loss: 0.2327488213777542 / Valid loss: 6.952582218533471

Epoch: 58
Training loss: 0.059935491532087326 / Valid loss: 7.104801405043829
Training loss: 0.0968431606888771 / Valid loss: 7.097423884982154
Training loss: 0.1156880110502243 / Valid loss: 7.167763262703305
Training loss: 0.10416429489850998 / Valid loss: 7.144120223181588
Training loss: 0.07092609256505966 / Valid loss: 7.207579703558059

Epoch: 59
Training loss: 0.18007826805114746 / Valid loss: 7.05837067649478
Training loss: 0.07304320484399796 / Valid loss: 7.046595555260068
Training loss: 0.10259409248828888 / Valid loss: 7.109425478889829
Training loss: 0.05948113650083542 / Valid loss: 7.036624268123082

Epoch: 60
Training loss: 0.21350423991680145 / Valid loss: 7.20299818402245
Training loss: 0.03213409334421158 / Valid loss: 7.059144733065651
Training loss: 0.10377541929483414 / Valid loss: 7.189866483779181
Training loss: 0.08042742311954498 / Valid loss: 7.135881083352225
Training loss: 0.08826392889022827 / Valid loss: 7.062336499350412

Epoch: 61
Training loss: 0.08008037507534027 / Valid loss: 7.1234333696819485
Training loss: 0.09262838214635849 / Valid loss: 7.146705336797805
Training loss: 0.18312811851501465 / Valid loss: 7.136550948733375
Training loss: 0.15043598413467407 / Valid loss: 7.086080346788679
Training loss: 0.17435616254806519 / Valid loss: 7.211411725907099

Epoch: 62
Training loss: 0.13529488444328308 / Valid loss: 7.07551376024882
Training loss: 0.059585846960544586 / Valid loss: 7.03234829221453
Training loss: 0.0792059451341629 / Valid loss: 7.066659564063663
Training loss: 0.11449875682592392 / Valid loss: 7.116702154704503
Training loss: 0.1130480170249939 / Valid loss: 7.184750248136974

Epoch: 63
Training loss: 0.06088881567120552 / Valid loss: 7.1722597258431575
Training loss: 0.06702174246311188 / Valid loss: 7.17387618564424
Training loss: 0.13603562116622925 / Valid loss: 7.27507301058088
Training loss: 0.05136330798268318 / Valid loss: 7.069830706006004
Training loss: 0.12371914088726044 / Valid loss: 7.127914033617292

Epoch: 64
Training loss: 0.08112168312072754 / Valid loss: 7.094253206253052
Training loss: 0.19517634809017181 / Valid loss: 6.912207680656796
Training loss: 0.06650139391422272 / Valid loss: 7.126239885602678
Training loss: 0.09949805587530136 / Valid loss: 7.119564960116432
Training loss: 0.26286447048187256 / Valid loss: 6.974182206108456

Epoch: 65
Training loss: 0.05694662034511566 / Valid loss: 7.269133912949335
Training loss: 0.10426931083202362 / Valid loss: 7.019113465717861
Training loss: 0.06447705626487732 / Valid loss: 7.206734779902867
Training loss: 0.04520002752542496 / Valid loss: 7.0662021046593075
Training loss: 0.18671610951423645 / Valid loss: 7.236776915050688

Epoch: 66
Training loss: 0.07119033485651016 / Valid loss: 7.068334284282866
Training loss: 0.08176229894161224 / Valid loss: 7.039949619202387
Training loss: 0.06537195295095444 / Valid loss: 7.147912191209339
Training loss: 0.10533013194799423 / Valid loss: 7.1581528345743815
Training loss: 0.08362244069576263 / Valid loss: 7.089631589253743

Epoch: 67
Training loss: 0.10329940915107727 / Valid loss: 7.104164700281053
Training loss: 0.15628834068775177 / Valid loss: 7.0210010528564455
Training loss: 0.07393902540206909 / Valid loss: 6.983728254409064
Training loss: 0.06742050498723984 / Valid loss: 6.9603483063834055
Training loss: 0.07529901713132858 / Valid loss: 7.056510162353516

Epoch: 68
Training loss: 0.11545516550540924 / Valid loss: 6.98538753872826
Training loss: 0.06755153834819794 / Valid loss: 7.167136678241548
Training loss: 0.06746802479028702 / Valid loss: 7.199271261124384
Training loss: 0.07994358241558075 / Valid loss: 7.13313491003854
Training loss: 0.06307423114776611 / Valid loss: 7.045264843532017

Epoch: 69
Training loss: 0.062066175043582916 / Valid loss: 7.063366036188035
Training loss: 0.054967328906059265 / Valid loss: 7.182807690756661
Training loss: 0.17985573410987854 / Valid loss: 7.182548967997233
Training loss: 0.26000192761421204 / Valid loss: 7.302541378566197

Epoch: 70
Training loss: 0.06458418071269989 / Valid loss: 7.259918662479945
Training loss: 0.054229579865932465 / Valid loss: 7.055564594268799
Training loss: 0.06245604157447815 / Valid loss: 7.151504539308094
Training loss: 0.04723464697599411 / Valid loss: 7.211274864560082
Training loss: 0.1550719141960144 / Valid loss: 7.235122451328096

Epoch: 71
Training loss: 0.0660097748041153 / Valid loss: 7.133212916056315
Training loss: 0.09716292470693588 / Valid loss: 7.087163852509998
Training loss: 0.0898347869515419 / Valid loss: 7.073983156113398
Training loss: 0.4012801945209503 / Valid loss: 7.083557844161987
Training loss: 0.07339395582675934 / Valid loss: 7.232816414606003

Epoch: 72
Training loss: 0.04679424315690994 / Valid loss: 7.0832763808114185
Training loss: 0.052353642880916595 / Valid loss: 7.134800661177862
Training loss: 0.05608436465263367 / Valid loss: 7.060794553302583
Training loss: 0.05872488021850586 / Valid loss: 7.134005903062366
Training loss: 0.04705709591507912 / Valid loss: 7.145736126672654

Epoch: 73
Training loss: 0.06502042710781097 / Valid loss: 7.163469305492582
Training loss: 0.22277012467384338 / Valid loss: 7.123628807067871
Training loss: 0.09901904314756393 / Valid loss: 7.1177020935785205
Training loss: 0.07750438153743744 / Valid loss: 7.127928188868931
Training loss: 0.04086008667945862 / Valid loss: 7.055163208643595

Epoch: 74
Training loss: 0.1204715371131897 / Valid loss: 7.031525184994652
Training loss: 0.08622616529464722 / Valid loss: 7.190710921514602
Training loss: 0.060940325260162354 / Valid loss: 7.097304058074951
Training loss: 0.09545805305242538 / Valid loss: 7.195249126071022
Training loss: 0.07886603474617004 / Valid loss: 7.0628886154719765

Epoch: 75
Training loss: 0.06645257025957108 / Valid loss: 7.169090818223499
Training loss: 0.07889522612094879 / Valid loss: 7.198962801978702
Training loss: 0.04958897829055786 / Valid loss: 7.191216561907813
Training loss: 0.049867771565914154 / Valid loss: 7.277481042771113
Training loss: 0.06845565140247345 / Valid loss: 7.172958553405035

Epoch: 76
Training loss: 0.038115065544843674 / Valid loss: 7.131737927028111
Training loss: 0.0655597597360611 / Valid loss: 7.196356423695883
Training loss: 0.050818100571632385 / Valid loss: 7.2526076067061656
Training loss: 0.05670919269323349 / Valid loss: 7.115447126116071
Training loss: 0.081300288438797 / Valid loss: 7.1283630348387215

Epoch: 77
Training loss: 0.06364162266254425 / Valid loss: 7.215824560892014
Training loss: 0.11403806507587433 / Valid loss: 7.233923348926362
Training loss: 0.4285963773727417 / Valid loss: 7.299075453622001
Training loss: 0.1451554149389267 / Valid loss: 7.148700891222273
Training loss: 0.10417284071445465 / Valid loss: 7.137447121029808

Epoch: 78
Training loss: 0.0922926813364029 / Valid loss: 7.13927667708624
Training loss: 0.09793044626712799 / Valid loss: 7.096033636728922
Training loss: 0.05537893623113632 / Valid loss: 7.220354227792649
Training loss: 0.041442081332206726 / Valid loss: 7.165144511631557
Training loss: 0.048649054020643234 / Valid loss: 7.129175817398798

Epoch: 79
Training loss: 0.08310691267251968 / Valid loss: 7.177973220461891
Training loss: 0.06190023571252823 / Valid loss: 7.271286834989275
Training loss: 0.1997525542974472 / Valid loss: 7.2029631569272
Training loss: 0.06492969393730164 / Valid loss: 7.232073216211228
ModuleList(
  (0): Linear(in_features=31191, out_features=2000, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=2000, out_features=100, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=100, out_features=16, bias=True)
  (9): Dropout(p=0, inplace=False)
  (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (11): LeakyReLU(negative_slope=0.02)
  (12): Linear(in_features=16, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.597928714752197
Training regression with following parameters:
dnn_hidden_units : 300, 32
dropout_probs : 0.0, 0.0
learning_rate : 0.001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : Adam
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : TFIDF
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=31191, out_features=300, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=300, out_features=32, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=32, out_features=1, bias=True)
)

Epoch: 0
Training loss: 14.313697814941406 / Valid loss: 15.73991907210577
Model is saved in epoch 0, overall batch: 0
Training loss: 8.40890121459961 / Valid loss: 9.4806762332008
Model is saved in epoch 0, overall batch: 100
Training loss: 4.984809875488281 / Valid loss: 6.232872719991775
Model is saved in epoch 0, overall batch: 200
Training loss: 3.5381689071655273 / Valid loss: 5.799423308599563
Model is saved in epoch 0, overall batch: 300
Training loss: 4.798099994659424 / Valid loss: 5.810558014824277

Epoch: 1
Training loss: 2.6791176795959473 / Valid loss: 5.723253969919114
Model is saved in epoch 1, overall batch: 500
Training loss: 3.695173740386963 / Valid loss: 5.991147717975434
Training loss: 4.615135192871094 / Valid loss: 5.954994383312407
Training loss: 3.6704447269439697 / Valid loss: 5.915320269266764
Training loss: 3.3417553901672363 / Valid loss: 5.991847238086518

Epoch: 2
Training loss: 1.4023618698120117 / Valid loss: 6.0816789150238035
Training loss: 1.4669214487075806 / Valid loss: 6.185417633964902
Training loss: 1.289663553237915 / Valid loss: 6.192259034656343
Training loss: 1.9312435388565063 / Valid loss: 6.186007694970994
Training loss: 2.37886643409729 / Valid loss: 6.164050113587153

Epoch: 3
Training loss: 1.6129900217056274 / Valid loss: 6.302328754606701
Training loss: 1.4630627632141113 / Valid loss: 6.351364730653309
Training loss: 1.689437747001648 / Valid loss: 6.301615315391904
Training loss: 2.1336328983306885 / Valid loss: 6.3544138885679695
Training loss: 2.385084629058838 / Valid loss: 6.385943249293736

Epoch: 4
Training loss: 1.0838344097137451 / Valid loss: 6.362908501852126
Training loss: 1.2128567695617676 / Valid loss: 6.408136783327375
Training loss: 1.3405842781066895 / Valid loss: 6.4409437792641775
Training loss: 1.3168511390686035 / Valid loss: 6.483259332747687
Training loss: 1.4557595252990723 / Valid loss: 6.478509367079962

Epoch: 5
Training loss: 0.7768599987030029 / Valid loss: 6.4534630116962255
Training loss: 1.006778359413147 / Valid loss: 6.480068297613235
Training loss: 1.1578760147094727 / Valid loss: 6.589505826859247
Training loss: 1.4145357608795166 / Valid loss: 6.497722089858282
Training loss: 1.1406645774841309 / Valid loss: 6.555000727517264

Epoch: 6
Training loss: 0.6252282857894897 / Valid loss: 6.490207663036528
Training loss: 0.9738853573799133 / Valid loss: 6.42975203423273
Training loss: 0.8263851404190063 / Valid loss: 6.570233472188314
Training loss: 0.681787371635437 / Valid loss: 6.649770623161679
Training loss: 0.801228404045105 / Valid loss: 6.678307542346773

Epoch: 7
Training loss: 0.6101146340370178 / Valid loss: 6.557184410095215
Training loss: 0.4471314549446106 / Valid loss: 6.6082686878386
Training loss: 0.727195143699646 / Valid loss: 6.614833009810675
Training loss: 0.7662248015403748 / Valid loss: 6.603225190298898
Training loss: 0.8377729654312134 / Valid loss: 6.533628829320272

Epoch: 8
Training loss: 0.6186429858207703 / Valid loss: 6.5926420030139745
Training loss: 0.6510307192802429 / Valid loss: 6.678785269601004
Training loss: 0.8761587142944336 / Valid loss: 6.588997379938761
Training loss: 0.4162680208683014 / Valid loss: 6.698398892084757
Training loss: 1.440967082977295 / Valid loss: 6.640564482552665

Epoch: 9
Training loss: 0.486930787563324 / Valid loss: 6.508606842585972
Training loss: 0.5336995124816895 / Valid loss: 6.540756666092646
Training loss: 0.9384230971336365 / Valid loss: 6.581932213192895
Training loss: 1.4331897497177124 / Valid loss: 6.628418082282657

Epoch: 10
Training loss: 0.638803243637085 / Valid loss: 6.611548451014928
Training loss: 0.4260116219520569 / Valid loss: 6.535487588246664
Training loss: 0.6661106944084167 / Valid loss: 6.617378648122152
Training loss: 0.4572290778160095 / Valid loss: 6.650396385647002
Training loss: 0.3525533080101013 / Valid loss: 6.647109717414493

Epoch: 11
Training loss: 0.7119911313056946 / Valid loss: 6.657587416966757
Training loss: 0.6103796362876892 / Valid loss: 6.5970988228207545
Training loss: 0.5087476968765259 / Valid loss: 6.709380678903489
Training loss: 0.6136796474456787 / Valid loss: 6.722576338904244
Training loss: 1.1439074277877808 / Valid loss: 6.59838429632641

Epoch: 12
Training loss: 0.625397264957428 / Valid loss: 6.5311532247634165
Training loss: 0.3849097788333893 / Valid loss: 6.5661600385393415
Training loss: 0.37115514278411865 / Valid loss: 6.648841233480544
Training loss: 0.7514262795448303 / Valid loss: 6.601895854586647
Training loss: 0.6375773549079895 / Valid loss: 6.709498228345598

Epoch: 13
Training loss: 0.7873992323875427 / Valid loss: 6.615289837973458
Training loss: 0.2394002377986908 / Valid loss: 6.582247043791272
Training loss: 0.4573310911655426 / Valid loss: 6.596089399428594
Training loss: 0.2799321711063385 / Valid loss: 6.653177551996141
Training loss: 0.3437681794166565 / Valid loss: 6.776682306471325

Epoch: 14
Training loss: 0.54777991771698 / Valid loss: 6.579004598799206
Training loss: 0.6812235116958618 / Valid loss: 6.617688315255301
Training loss: 0.5322567224502563 / Valid loss: 6.6904401824587865
Training loss: 0.6580634117126465 / Valid loss: 6.83607227688744
Training loss: 0.32422125339508057 / Valid loss: 6.72278428985959

Epoch: 15
Training loss: 0.5442158579826355 / Valid loss: 6.5887664885748
Training loss: 0.3646785020828247 / Valid loss: 6.665944871448335
Training loss: 1.5878313779830933 / Valid loss: 6.548986748286656
Training loss: 0.4322943091392517 / Valid loss: 6.678675476710001
Training loss: 1.9529753923416138 / Valid loss: 6.573012342907133

Epoch: 16
Training loss: 0.3928823471069336 / Valid loss: 6.5291276386805945
Training loss: 0.6051234602928162 / Valid loss: 6.5402542477562315
Training loss: 0.6202605962753296 / Valid loss: 6.6218590100606285
Training loss: 0.6963316202163696 / Valid loss: 6.723020006361462
Training loss: 0.47581684589385986 / Valid loss: 6.702125531151181

Epoch: 17
Training loss: 0.3743319511413574 / Valid loss: 6.632891028267997
Training loss: 0.22276532649993896 / Valid loss: 6.626405234563919
Training loss: 0.2875671982765198 / Valid loss: 6.687446971166701
Training loss: 0.619154691696167 / Valid loss: 6.726940754481724
Training loss: 0.3085215091705322 / Valid loss: 6.684088361830939

Epoch: 18
Training loss: 0.3016131520271301 / Valid loss: 6.59991363797869
Training loss: 0.4550592303276062 / Valid loss: 6.565271182287307
Training loss: 0.3518061339855194 / Valid loss: 6.519142611821493
Training loss: 0.3986769914627075 / Valid loss: 6.650240380423409
Training loss: 0.40623047947883606 / Valid loss: 6.561153779711042

Epoch: 19
Training loss: 0.6762123107910156 / Valid loss: 6.5188436008635025
Training loss: 0.396135151386261 / Valid loss: 6.581314366204398
Training loss: 0.272052526473999 / Valid loss: 6.666329379308792
Training loss: 0.2706495225429535 / Valid loss: 6.684407844997588

Epoch: 20
Training loss: 0.7736315727233887 / Valid loss: 6.7960758300054644
Training loss: 0.43375614285469055 / Valid loss: 6.559721642448789
Training loss: 0.5999448895454407 / Valid loss: 6.642843723297119
Training loss: 0.20184500515460968 / Valid loss: 6.601582820074899
Training loss: 0.3043774962425232 / Valid loss: 6.592939762842088

Epoch: 21
Training loss: 0.21849963068962097 / Valid loss: 6.597026990708851
Training loss: 0.3632775545120239 / Valid loss: 6.621979184377761
Training loss: 0.3112579882144928 / Valid loss: 6.507816130774362
Training loss: 0.2957606315612793 / Valid loss: 6.57359520594279
Training loss: 0.16084055602550507 / Valid loss: 6.580228249231975

Epoch: 22
Training loss: 0.34962785243988037 / Valid loss: 6.539291981288365
Training loss: 0.2718020975589752 / Valid loss: 6.6234647660028365
Training loss: 0.3797575831413269 / Valid loss: 6.56092803137643
Training loss: 0.42752617597579956 / Valid loss: 6.681999924069359
Training loss: 0.2981768846511841 / Valid loss: 6.66985247248695

Epoch: 23
Training loss: 0.22484847903251648 / Valid loss: 6.61436269850958
Training loss: 0.6339343786239624 / Valid loss: 6.574477581750779
Training loss: 1.169053554534912 / Valid loss: 6.518374170575823
Training loss: 0.3663841485977173 / Valid loss: 6.577614143916539
Training loss: 0.3050418496131897 / Valid loss: 6.630430739266532

Epoch: 24
Training loss: 0.3260456919670105 / Valid loss: 6.549938338143485
Training loss: 0.19813978672027588 / Valid loss: 6.582036408923921
Training loss: 0.5853467583656311 / Valid loss: 6.553005765733265
Training loss: 0.2618502974510193 / Valid loss: 6.613737601325625
Training loss: 0.5559120774269104 / Valid loss: 6.5638774871826175

Epoch: 25
Training loss: 0.6842944025993347 / Valid loss: 6.575691536494664
Training loss: 0.2718721926212311 / Valid loss: 6.554750374385288
Training loss: 0.21671858429908752 / Valid loss: 6.578230578558785
Training loss: 0.4131704866886139 / Valid loss: 6.601097885767619
Training loss: 0.3749891519546509 / Valid loss: 6.577929914565313

Epoch: 26
Training loss: 0.4192836582660675 / Valid loss: 6.515279154550462
Training loss: 0.2707139849662781 / Valid loss: 6.55296825681414
Training loss: 0.17949077486991882 / Valid loss: 6.572997392926897
Training loss: 0.2101268619298935 / Valid loss: 6.609686831065587
Training loss: 0.33889567852020264 / Valid loss: 6.5303938048226495

Epoch: 27
Training loss: 0.34801244735717773 / Valid loss: 6.550583526066371
Training loss: 0.3886342942714691 / Valid loss: 6.594682502746582
Training loss: 0.36056533455848694 / Valid loss: 6.5384062176659
Training loss: 0.21550002694129944 / Valid loss: 6.532033529735747
Training loss: 0.25549113750457764 / Valid loss: 6.51823072660537

Epoch: 28
Training loss: 0.17685770988464355 / Valid loss: 6.5035898344857355
Training loss: 0.2825200855731964 / Valid loss: 6.538754136221749
Training loss: 0.6514204740524292 / Valid loss: 6.5004965123676115
Training loss: 0.26376885175704956 / Valid loss: 6.549692571730841
Training loss: 0.2610223889350891 / Valid loss: 6.574190839131673

Epoch: 29
Training loss: 0.17651797831058502 / Valid loss: 6.551645033700126
Training loss: 0.24120815098285675 / Valid loss: 6.531851409730457
Training loss: 0.476404070854187 / Valid loss: 6.547164258502779
Training loss: 0.24811026453971863 / Valid loss: 6.559592810131255

Epoch: 30
Training loss: 0.3522603511810303 / Valid loss: 6.595011129833403
Training loss: 0.3103052079677582 / Valid loss: 6.4731142044067385
Training loss: 0.2525861859321594 / Valid loss: 6.492270401545933
Training loss: 0.2768222689628601 / Valid loss: 6.586585748763311
Training loss: 0.37941211462020874 / Valid loss: 6.59259276617141

Epoch: 31
Training loss: 0.5438792705535889 / Valid loss: 6.502590560913086
Training loss: 0.15075400471687317 / Valid loss: 6.519992764790853
Training loss: 0.258847177028656 / Valid loss: 6.567941615695045
Training loss: 0.23240149021148682 / Valid loss: 6.568245388212658
Training loss: 0.28295207023620605 / Valid loss: 6.498840465999785

Epoch: 32
Training loss: 0.30784904956817627 / Valid loss: 6.590494748524257
Training loss: 0.3257867693901062 / Valid loss: 6.567096496763684
Training loss: 0.39575690031051636 / Valid loss: 6.51065229688372
Training loss: 0.3870706558227539 / Valid loss: 6.484798781077067
Training loss: 0.21107986569404602 / Valid loss: 6.5615439732869465

Epoch: 33
Training loss: 0.21984897553920746 / Valid loss: 6.537792201269241
Training loss: 0.2512127161026001 / Valid loss: 6.526321215856643
Training loss: 0.25203558802604675 / Valid loss: 6.485603664034889
Training loss: 0.14274337887763977 / Valid loss: 6.509571077710106
Training loss: 0.22682499885559082 / Valid loss: 6.50188897450765

Epoch: 34
Training loss: 0.5924068689346313 / Valid loss: 6.510288115910122
Training loss: 0.17585602402687073 / Valid loss: 6.5544995625813804
Training loss: 0.23843979835510254 / Valid loss: 6.523374884469169
Training loss: 0.2622915208339691 / Valid loss: 6.464280266988845
Training loss: 0.2514393925666809 / Valid loss: 6.513839912414551

Epoch: 35
Training loss: 0.1398164927959442 / Valid loss: 6.534541581925891
Training loss: 0.23858940601348877 / Valid loss: 6.551083389918009
Training loss: 0.2720387279987335 / Valid loss: 6.608319695790609
Training loss: 0.17078348994255066 / Valid loss: 6.531014449255807
Training loss: 0.5329785943031311 / Valid loss: 6.5561517715454105

Epoch: 36
Training loss: 0.2029581516981125 / Valid loss: 6.527612486339751
Training loss: 0.4194025695323944 / Valid loss: 6.5568323317028225
Training loss: 0.26481515169143677 / Valid loss: 6.532453982035319
Training loss: 0.27702078223228455 / Valid loss: 6.532191601253691
Training loss: 0.25558939576148987 / Valid loss: 6.555987196876889

Epoch: 37
Training loss: 0.20501577854156494 / Valid loss: 6.599065989539737
Training loss: 0.21734437346458435 / Valid loss: 6.4774463154020765
Training loss: 0.5347420573234558 / Valid loss: 6.54412149247669
Training loss: 0.2255886048078537 / Valid loss: 6.522966048831031
Training loss: 0.32522982358932495 / Valid loss: 6.583573171070644

Epoch: 38
Training loss: 0.185095876455307 / Valid loss: 6.526794803710211
Training loss: 0.22719457745552063 / Valid loss: 6.507651079268682
Training loss: 0.2521217167377472 / Valid loss: 6.570317014058431
Training loss: 0.17851977050304413 / Valid loss: 6.5618193876175654
Training loss: 0.154308021068573 / Valid loss: 6.589817989440191

Epoch: 39
Training loss: 0.26257145404815674 / Valid loss: 6.532779141834804
Training loss: 0.26046887040138245 / Valid loss: 6.5549737748645605
Training loss: 0.14716210961341858 / Valid loss: 6.486575941812425
Training loss: 0.13739848136901855 / Valid loss: 6.488957777477446

Epoch: 40
Training loss: 0.14022201299667358 / Valid loss: 6.5227523622058685
Training loss: 0.3509502708911896 / Valid loss: 6.51221995580764
Training loss: 0.1527928113937378 / Valid loss: 6.5147778511047365
Training loss: 0.1673065423965454 / Valid loss: 6.593126240230742
Training loss: 0.2594726085662842 / Valid loss: 6.590606317066011

Epoch: 41
Training loss: 0.5941668152809143 / Valid loss: 6.487167678560529
Training loss: 0.18529263138771057 / Valid loss: 6.516886674790156
Training loss: 0.14838027954101562 / Valid loss: 6.560278492882138
Training loss: 0.24735194444656372 / Valid loss: 6.496426427932013
Training loss: 0.4333096146583557 / Valid loss: 6.57857704389663

Epoch: 42
Training loss: 0.16878384351730347 / Valid loss: 6.591632965632847
Training loss: 0.12423621118068695 / Valid loss: 6.580226766495477
Training loss: 0.22622212767601013 / Valid loss: 6.486962985992432
Training loss: 0.1718352735042572 / Valid loss: 6.552469394320533
Training loss: 0.22251123189926147 / Valid loss: 6.615065601893834

Epoch: 43
Training loss: 0.12845921516418457 / Valid loss: 6.452545352209182
Training loss: 0.1082414761185646 / Valid loss: 6.5147631622496105
Training loss: 0.1276865452528 / Valid loss: 6.544276687077113
Training loss: 0.115903839468956 / Valid loss: 6.475790368942987
Training loss: 0.21843767166137695 / Valid loss: 6.54783307484218

Epoch: 44
Training loss: 0.14273764193058014 / Valid loss: 6.567022587004162
Training loss: 0.18356046080589294 / Valid loss: 6.557413207916986
Training loss: 0.279585063457489 / Valid loss: 6.521738392966134
Training loss: 0.21631993353366852 / Valid loss: 6.589592311495826
Training loss: 0.10788612067699432 / Valid loss: 6.512438104266212

Epoch: 45
Training loss: 0.10347087681293488 / Valid loss: 6.533380660556611
Training loss: 0.22328178584575653 / Valid loss: 6.586333002362933
Training loss: 0.1514194905757904 / Valid loss: 6.503261961255755
Training loss: 0.12404963374137878 / Valid loss: 6.472420790081933
Training loss: 0.2084456980228424 / Valid loss: 6.576284165609451

Epoch: 46
Training loss: 0.3887731432914734 / Valid loss: 6.493061810448056
Training loss: 0.27292248606681824 / Valid loss: 6.5579225585574195
Training loss: 0.17615735530853271 / Valid loss: 6.487603178478422
Training loss: 0.20787504315376282 / Valid loss: 6.52490249588376
Training loss: 0.17956070601940155 / Valid loss: 6.589404748734974

Epoch: 47
Training loss: 0.1933046579360962 / Valid loss: 6.50652163369315
Training loss: 0.11206921190023422 / Valid loss: 6.492436799548921
Training loss: 0.13815876841545105 / Valid loss: 6.531344438734509
Training loss: 0.14516837894916534 / Valid loss: 6.61075028691973
Training loss: 0.11559934169054031 / Valid loss: 6.535051064264207

Epoch: 48
Training loss: 0.16800478100776672 / Valid loss: 6.530868051165626
Training loss: 0.17112065851688385 / Valid loss: 6.510638341449556
Training loss: 0.23038250207901 / Valid loss: 6.522901503245036
Training loss: 0.10595729202032089 / Valid loss: 6.505254450298491
Training loss: 0.11023896932601929 / Valid loss: 6.559093459447225

Epoch: 49
Training loss: 0.16063424944877625 / Valid loss: 6.576064050765265
Training loss: 0.15236181020736694 / Valid loss: 6.535413614908854
Training loss: 0.116183340549469 / Valid loss: 6.541434696742466
Training loss: 0.18525895476341248 / Valid loss: 6.54142092750186

Epoch: 50
Training loss: 0.12808901071548462 / Valid loss: 6.541025881540207
Training loss: 0.23391824960708618 / Valid loss: 6.534489247912452
Training loss: 0.31487998366355896 / Valid loss: 6.531190847215198
Training loss: 0.17150823771953583 / Valid loss: 6.549224780854725
Training loss: 0.1905020922422409 / Valid loss: 6.617087822868711

Epoch: 51
Training loss: 0.19861167669296265 / Valid loss: 6.547117292313349
Training loss: 0.19196459650993347 / Valid loss: 6.520629805610294
Training loss: 0.15523380041122437 / Valid loss: 6.504770969209217
Training loss: 0.1438601016998291 / Valid loss: 6.5412947359539215
Training loss: 0.11379984766244888 / Valid loss: 6.513705927985055

Epoch: 52
Training loss: 0.3664745092391968 / Valid loss: 6.509389350527809
Training loss: 0.15612788498401642 / Valid loss: 6.501862475985573
Training loss: 0.1129733994603157 / Valid loss: 6.551472064426967
Training loss: 0.21265944838523865 / Valid loss: 6.526131686710176
Training loss: 0.17338323593139648 / Valid loss: 6.579028220403762

Epoch: 53
Training loss: 0.3601171374320984 / Valid loss: 6.5270950271969745
Training loss: 0.2719686031341553 / Valid loss: 6.498455821900141
Training loss: 0.13347536325454712 / Valid loss: 6.598317073640369
Training loss: 0.2378150373697281 / Valid loss: 6.572071863356091
Training loss: 0.1965968757867813 / Valid loss: 6.520236312775385

Epoch: 54
Training loss: 0.09957604110240936 / Valid loss: 6.4684372220720565
Training loss: 0.34161221981048584 / Valid loss: 6.5845595019204275
Training loss: 0.17652258276939392 / Valid loss: 6.5062914530436196
Training loss: 0.24514281749725342 / Valid loss: 6.521976818357195
Training loss: 0.2156205028295517 / Valid loss: 6.572893299375262

Epoch: 55
Training loss: 0.2373075634241104 / Valid loss: 6.547916537239438
Training loss: 0.2212424874305725 / Valid loss: 6.519576842444284
Training loss: 0.08572839200496674 / Valid loss: 6.499267051333473
Training loss: 0.17664286494255066 / Valid loss: 6.545052962076096
Training loss: 0.3313065469264984 / Valid loss: 6.500480229513986

Epoch: 56
Training loss: 0.21974116563796997 / Valid loss: 6.5215832755679175
Training loss: 0.14157071709632874 / Valid loss: 6.4988912582397464
Training loss: 0.13266143202781677 / Valid loss: 6.468375855400449
Training loss: 0.1808442920446396 / Valid loss: 6.487461314882551
Training loss: 0.34373021125793457 / Valid loss: 6.5564199084327335

Epoch: 57
Training loss: 0.14542236924171448 / Valid loss: 6.510458837236677
Training loss: 0.15580052137374878 / Valid loss: 6.513321204412551
Training loss: 0.2236550897359848 / Valid loss: 6.501238636743455
Training loss: 0.16834983229637146 / Valid loss: 6.52964205514817
Training loss: 0.19348102807998657 / Valid loss: 6.566646326155889

Epoch: 58
Training loss: 0.09104342013597488 / Valid loss: 6.49000783874875
Training loss: 0.20963835716247559 / Valid loss: 6.485191145397368
Training loss: 0.3858624994754791 / Valid loss: 6.500048137846447
Training loss: 0.11211021989583969 / Valid loss: 6.547165970575242
Training loss: 0.11811192333698273 / Valid loss: 6.543606735411144

Epoch: 59
Training loss: 0.1320791244506836 / Valid loss: 6.520303853352865
Training loss: 0.19920361042022705 / Valid loss: 6.528236977259318
Training loss: 0.17195075750350952 / Valid loss: 6.555501447405134
Training loss: 0.13307970762252808 / Valid loss: 6.531146935054234

Epoch: 60
Training loss: 0.12874352931976318 / Valid loss: 6.536880536306472
Training loss: 0.1890934407711029 / Valid loss: 6.495168318067278
Training loss: 0.13497164845466614 / Valid loss: 6.557352804002308
Training loss: 0.5586889982223511 / Valid loss: 6.546955101830619
Training loss: 0.10149570554494858 / Valid loss: 6.604965618678501

Epoch: 61
Training loss: 0.2028617411851883 / Valid loss: 6.554905423663912
Training loss: 0.4808543920516968 / Valid loss: 6.5585140591575986
Training loss: 0.13375452160835266 / Valid loss: 6.584508555276053
Training loss: 0.14511175453662872 / Valid loss: 6.578025997252691
Training loss: 0.3663140833377838 / Valid loss: 6.571521186828614

Epoch: 62
Training loss: 0.18665985763072968 / Valid loss: 6.521912154697237
Training loss: 0.32768696546554565 / Valid loss: 6.504663381122407
Training loss: 0.07126588374376297 / Valid loss: 6.58304158619472
Training loss: 0.18925167620182037 / Valid loss: 6.554077595756167
Training loss: 0.0886140912771225 / Valid loss: 6.555715124947684

Epoch: 63
Training loss: 0.1506578028202057 / Valid loss: 6.49508163134257
Training loss: 0.13852351903915405 / Valid loss: 6.566234965551467
Training loss: 0.18204468488693237 / Valid loss: 6.530619970957438
Training loss: 0.15034548938274384 / Valid loss: 6.535199210757301
Training loss: 0.15291306376457214 / Valid loss: 6.542866384415399

Epoch: 64
Training loss: 0.19254419207572937 / Valid loss: 6.555633994511195
Training loss: 0.19273105263710022 / Valid loss: 6.470532181149437
Training loss: 0.10426013916730881 / Valid loss: 6.489356213524228
Training loss: 0.1499468982219696 / Valid loss: 6.470203370139712
Training loss: 0.154514342546463 / Valid loss: 6.54731665565854

Epoch: 65
Training loss: 0.11986448615789413 / Valid loss: 6.567722447713217
Training loss: 0.15551713109016418 / Valid loss: 6.547119817279634
Training loss: 0.0893944576382637 / Valid loss: 6.519400115240188
Training loss: 0.10152120888233185 / Valid loss: 6.533875419980004
Training loss: 0.170183926820755 / Valid loss: 6.5497179689861476

Epoch: 66
Training loss: 0.1031288430094719 / Valid loss: 6.479979292551676
Training loss: 0.16179630160331726 / Valid loss: 6.512858981177921
Training loss: 0.11109141260385513 / Valid loss: 6.5221774328322635
Training loss: 0.10581888258457184 / Valid loss: 6.47475943792434
Training loss: 0.09671077132225037 / Valid loss: 6.509833681015741

Epoch: 67
Training loss: 0.23271207511425018 / Valid loss: 6.510095959617978
Training loss: 0.18856507539749146 / Valid loss: 6.622113945370629
Training loss: 0.20763611793518066 / Valid loss: 6.526387282780239
Training loss: 0.2627275586128235 / Valid loss: 6.530526147569929
Training loss: 0.07411324232816696 / Valid loss: 6.525943660736084

Epoch: 68
Training loss: 0.24222123622894287 / Valid loss: 6.554144691285633
Training loss: 0.2224915772676468 / Valid loss: 6.560095257986159
Training loss: 0.3778831958770752 / Valid loss: 6.523065153757731
Training loss: 0.0772102102637291 / Valid loss: 6.560000660305931
Training loss: 0.24625049531459808 / Valid loss: 6.544360260736375

Epoch: 69
Training loss: 0.13376827538013458 / Valid loss: 6.485635126204718
Training loss: 0.15557372570037842 / Valid loss: 6.524719728742327
Training loss: 0.15193119645118713 / Valid loss: 6.557049451555525
Training loss: 0.44139042496681213 / Valid loss: 6.490237285977318

Epoch: 70
Training loss: 0.10930851846933365 / Valid loss: 6.503946644919259
Training loss: 0.18384848535060883 / Valid loss: 6.591119194030762
Training loss: 0.19769227504730225 / Valid loss: 6.484090936751593
Training loss: 0.22441957890987396 / Valid loss: 6.544971459252494
Training loss: 0.0821184366941452 / Valid loss: 6.4955497650873095

Epoch: 71
Training loss: 0.1713346242904663 / Valid loss: 6.505913634527297
Training loss: 0.201870858669281 / Valid loss: 6.56371389343625
Training loss: 0.11373700201511383 / Valid loss: 6.547092533111572
Training loss: 0.12039739638566971 / Valid loss: 6.519383044469924
Training loss: 0.10687017440795898 / Valid loss: 6.4948759919121155

Epoch: 72
Training loss: 0.1860838234424591 / Valid loss: 6.532227398100353
Training loss: 0.22552502155303955 / Valid loss: 6.5821997256506055
Training loss: 0.2091565728187561 / Valid loss: 6.536382343655541
Training loss: 0.20261183381080627 / Valid loss: 6.56146639415196
Training loss: 0.24270343780517578 / Valid loss: 6.508932449704125

Epoch: 73
Training loss: 0.14774782955646515 / Valid loss: 6.624310150600615
Training loss: 0.11220918595790863 / Valid loss: 6.561066963559106
Training loss: 0.18773822486400604 / Valid loss: 6.5482916786557155
Training loss: 0.11993846297264099 / Valid loss: 6.549684799285162
Training loss: 0.14262306690216064 / Valid loss: 6.570374420710972

Epoch: 74
Training loss: 0.13968899846076965 / Valid loss: 6.567860455740066
Training loss: 0.17590448260307312 / Valid loss: 6.592517589387439
Training loss: 0.1330624520778656 / Valid loss: 6.564328688666934
Training loss: 0.2558335065841675 / Valid loss: 6.581977376483736
Training loss: 0.3979097604751587 / Valid loss: 6.551258886428107

Epoch: 75
Training loss: 0.11243070662021637 / Valid loss: 6.519254489172073
Training loss: 0.17745822668075562 / Valid loss: 6.525382763998849
Training loss: 0.2858877182006836 / Valid loss: 6.522035405749366
Training loss: 0.1261669397354126 / Valid loss: 6.606420902978806
Training loss: 0.15634378790855408 / Valid loss: 6.558670584360758

Epoch: 76
Training loss: 0.0875903069972992 / Valid loss: 6.527736949920654
Training loss: 0.3646377921104431 / Valid loss: 6.508876046680268
Training loss: 0.6008657813072205 / Valid loss: 6.578387691861107
Training loss: 0.0905008539557457 / Valid loss: 6.597287400563558
Training loss: 0.17032265663146973 / Valid loss: 6.533237918217977

Epoch: 77
Training loss: 0.287321537733078 / Valid loss: 6.5681204523359025
Training loss: 0.3211468458175659 / Valid loss: 6.550698001044137
Training loss: 0.09863001108169556 / Valid loss: 6.508717173621768
Training loss: 0.1800003945827484 / Valid loss: 6.557463609604609
Training loss: 0.10772198438644409 / Valid loss: 6.559389852342152

Epoch: 78
Training loss: 0.24141480028629303 / Valid loss: 6.511668627602713
Training loss: 0.2861703336238861 / Valid loss: 6.500247769128709
Training loss: 0.09537684917449951 / Valid loss: 6.565849867321196
Training loss: 0.2470400482416153 / Valid loss: 6.497022090639387
Training loss: 0.3333859443664551 / Valid loss: 6.510926051366897

Epoch: 79
Training loss: 0.12007223814725876 / Valid loss: 6.520892944790068
Training loss: 0.1871071457862854 / Valid loss: 6.505055722736177
Training loss: 0.12893721461296082 / Valid loss: 6.540772447131929
Training loss: 0.260985404253006 / Valid loss: 6.554689741134643
ModuleList(
  (0): Linear(in_features=31191, out_features=300, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=300, out_features=32, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=32, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.61936419804891
Training regression with following parameters:
dnn_hidden_units : 248
dropout_probs : 0.0, 0.0
learning_rate : 0.001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : Adam
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : TFIDF
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=31191, out_features=248, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=248, out_features=1, bias=True)
)

Epoch: 0
Training loss: 15.220863342285156 / Valid loss: 16.406339981442407
Model is saved in epoch 0, overall batch: 0
Training loss: 7.161015033721924 / Valid loss: 6.829741114661807
Model is saved in epoch 0, overall batch: 100
Training loss: 5.48242712020874 / Valid loss: 6.842602175757999
Training loss: 5.094162940979004 / Valid loss: 6.712977336701893
Model is saved in epoch 0, overall batch: 300
Training loss: 7.588825225830078 / Valid loss: 6.531738331204369
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 4.257430076599121 / Valid loss: 6.265892367135911
Model is saved in epoch 1, overall batch: 500
Training loss: 3.536505937576294 / Valid loss: 6.262178652627128
Model is saved in epoch 1, overall batch: 600
Training loss: 2.896556854248047 / Valid loss: 6.4458493073781336
Training loss: 4.152067184448242 / Valid loss: 6.363753613971529
Training loss: 4.274667739868164 / Valid loss: 6.353168934867496

Epoch: 2
Training loss: 1.7083919048309326 / Valid loss: 6.293895324071248
Training loss: 3.0117597579956055 / Valid loss: 6.63429609934489
Training loss: 2.2811644077301025 / Valid loss: 6.473323790232341
Training loss: 2.4323031902313232 / Valid loss: 6.482635622932797
Training loss: 2.1768102645874023 / Valid loss: 6.464260900588263

Epoch: 3
Training loss: 1.7394853830337524 / Valid loss: 6.577650206429618
Training loss: 1.9787509441375732 / Valid loss: 6.645025718779791
Training loss: 2.73429536819458 / Valid loss: 6.6776993115743
Training loss: 1.907366394996643 / Valid loss: 6.699671375183832
Training loss: 3.0475220680236816 / Valid loss: 6.722275824773879

Epoch: 4
Training loss: 1.6508030891418457 / Valid loss: 6.816239802042643
Training loss: 1.7953108549118042 / Valid loss: 6.858878063020252
Training loss: 2.113997459411621 / Valid loss: 6.844531981150309
Training loss: 2.4683265686035156 / Valid loss: 6.906167191550845
Training loss: 1.5686132907867432 / Valid loss: 6.93701050167992

Epoch: 5
Training loss: 1.3866811990737915 / Valid loss: 6.961434214455741
Training loss: 2.0947365760803223 / Valid loss: 6.942538735980079
Training loss: 1.1516486406326294 / Valid loss: 6.978683508010137
Training loss: 2.439023494720459 / Valid loss: 6.963300891149611
Training loss: 2.1955699920654297 / Valid loss: 6.935974339076451

Epoch: 6
Training loss: 1.0904830694198608 / Valid loss: 7.016772860572452
Training loss: 1.9534082412719727 / Valid loss: 6.909561593191964
Training loss: 2.1746134757995605 / Valid loss: 6.967873085112799
Training loss: 1.5537831783294678 / Valid loss: 7.033780418123517
Training loss: 2.8911101818084717 / Valid loss: 7.0342209498087565

Epoch: 7
Training loss: 1.6612199544906616 / Valid loss: 6.995692866189139
Training loss: 1.1583504676818848 / Valid loss: 7.105394640423003
Training loss: 1.3204238414764404 / Valid loss: 7.107662863958449
Training loss: 1.3471977710723877 / Valid loss: 7.173334346498762
Training loss: 1.521538496017456 / Valid loss: 7.235638768332345

Epoch: 8
Training loss: 1.0863385200500488 / Valid loss: 7.142251650492351
Training loss: 1.2083277702331543 / Valid loss: 7.166301418486095
Training loss: 1.1464766263961792 / Valid loss: 7.257538768223354
Training loss: 1.0640822649002075 / Valid loss: 7.300285909289405
Training loss: 1.1532434225082397 / Valid loss: 7.4000195821126304

Epoch: 9
Training loss: 0.9190365076065063 / Valid loss: 7.226581891377767
Training loss: 1.163602590560913 / Valid loss: 7.300419902801513
Training loss: 0.9489127993583679 / Valid loss: 7.294905194782076
Training loss: 0.9125964641571045 / Valid loss: 7.287169420151484

Epoch: 10
Training loss: 0.8415749669075012 / Valid loss: 7.316340296609061
Training loss: 0.787870466709137 / Valid loss: 7.3429105122884115
Training loss: 0.5133730173110962 / Valid loss: 7.177202551705497
Training loss: 1.587038278579712 / Valid loss: 7.335528455461774
Training loss: 1.3203620910644531 / Valid loss: 7.393686221894764

Epoch: 11
Training loss: 0.5217010974884033 / Valid loss: 7.403841568174816
Training loss: 0.6330167055130005 / Valid loss: 7.371284278233846
Training loss: 0.6165683269500732 / Valid loss: 7.410258465721494
Training loss: 0.8320856094360352 / Valid loss: 7.385245064326695
Training loss: 1.1556389331817627 / Valid loss: 7.48827688126337

Epoch: 12
Training loss: 0.8847454786300659 / Valid loss: 7.387408043089367
Training loss: 0.579796314239502 / Valid loss: 7.410102031344459
Training loss: 1.0434216260910034 / Valid loss: 7.477159827096122
Training loss: 0.8428254723548889 / Valid loss: 7.4443498066493445
Training loss: 0.7214807271957397 / Valid loss: 7.4211649940127415

Epoch: 13
Training loss: 0.8455866575241089 / Valid loss: 7.39572064990089
Training loss: 0.6811468601226807 / Valid loss: 7.40983220963251
Training loss: 0.6514315009117126 / Valid loss: 7.525778434390113
Training loss: 0.35091209411621094 / Valid loss: 7.519331198646909
Training loss: 1.0620653629302979 / Valid loss: 7.4719294093904045

Epoch: 14
Training loss: 0.7512069940567017 / Valid loss: 7.506759670802525
Training loss: 0.6037793159484863 / Valid loss: 7.441931288582938
Training loss: 0.6154974699020386 / Valid loss: 7.514321486155192
Training loss: 0.5960752964019775 / Valid loss: 7.452915645781017
Training loss: 0.600487470626831 / Valid loss: 7.530923875172933

Epoch: 15
Training loss: 0.7203777432441711 / Valid loss: 7.414179150263468
Training loss: 0.6944214105606079 / Valid loss: 7.4165420850118
Training loss: 0.6178058385848999 / Valid loss: 7.437822836921328
Training loss: 1.0864132642745972 / Valid loss: 7.535951210203625
Training loss: 0.4323809742927551 / Valid loss: 7.49625156493414

Epoch: 16
Training loss: 0.9036523699760437 / Valid loss: 7.586697047097342
Training loss: 0.6040761470794678 / Valid loss: 7.3765093757992695
Training loss: 0.4614761471748352 / Valid loss: 7.618459052131289
Training loss: 0.45828503370285034 / Valid loss: 7.460265622820173
Training loss: 1.0039186477661133 / Valid loss: 7.46705044791812

Epoch: 17
Training loss: 0.585974395275116 / Valid loss: 7.458680098397391
Training loss: 0.3186744153499603 / Valid loss: 7.424227310362316
Training loss: 0.6327090859413147 / Valid loss: 7.45323219753447
Training loss: 0.4785842299461365 / Valid loss: 7.53771922701881
Training loss: 0.523917555809021 / Valid loss: 7.414876765296572

Epoch: 18
Training loss: 0.8476210832595825 / Valid loss: 7.449094150179908
Training loss: 0.6828955411911011 / Valid loss: 7.381050346011207
Training loss: 0.7395994067192078 / Valid loss: 7.559427502041771
Training loss: 0.5592176914215088 / Valid loss: 7.545882202330089
Training loss: 0.6515995860099792 / Valid loss: 7.5362390018644785

Epoch: 19
Training loss: 0.630841076374054 / Valid loss: 7.45865280060541
Training loss: 0.520824670791626 / Valid loss: 7.455388868422736
Training loss: 0.8571003675460815 / Valid loss: 7.495466027941022
Training loss: 0.9296776652336121 / Valid loss: 7.466138249351864

Epoch: 20
Training loss: 0.3825340270996094 / Valid loss: 7.494428484780448
Training loss: 0.7067073583602905 / Valid loss: 7.434899702526274
Training loss: 0.4571859836578369 / Valid loss: 7.490297589983259
Training loss: 0.4461238384246826 / Valid loss: 7.512708005451021
Training loss: 0.443108469247818 / Valid loss: 7.487663655054002

Epoch: 21
Training loss: 0.3015860617160797 / Valid loss: 7.552160776229131
Training loss: 0.4499332904815674 / Valid loss: 7.588216200329009
Training loss: 0.576903223991394 / Valid loss: 7.542056192670549
Training loss: 0.6802764534950256 / Valid loss: 7.5032143365769155
Training loss: 0.43251168727874756 / Valid loss: 7.517552561987014

Epoch: 22
Training loss: 0.4837122857570648 / Valid loss: 7.483543609437488
Training loss: 0.31554239988327026 / Valid loss: 7.470666690099807
Training loss: 0.8010107278823853 / Valid loss: 7.579455552782331
Training loss: 0.4986330568790436 / Valid loss: 7.511228375207811
Training loss: 0.33561766147613525 / Valid loss: 7.5298532803853355

Epoch: 23
Training loss: 0.2757553458213806 / Valid loss: 7.584067117600214
Training loss: 0.28668496012687683 / Valid loss: 7.510986459822882
Training loss: 0.490731418132782 / Valid loss: 7.4345036915370395
Training loss: 0.8279364109039307 / Valid loss: 7.587390304747082
Training loss: 0.5678966045379639 / Valid loss: 7.611192909876506

Epoch: 24
Training loss: 0.3252212405204773 / Valid loss: 7.5097644306364515
Training loss: 0.5032528638839722 / Valid loss: 7.565078267597017
Training loss: 0.7749044299125671 / Valid loss: 7.5218780267806284
Training loss: 0.5245333909988403 / Valid loss: 7.559136504218692
Training loss: 0.3712834417819977 / Valid loss: 7.537616284688314

Epoch: 25
Training loss: 0.615050196647644 / Valid loss: 7.524170575823103
Training loss: 0.3435818552970886 / Valid loss: 7.496840213593982
Training loss: 0.30088385939598083 / Valid loss: 7.53740420568557
Training loss: 0.4630030393600464 / Valid loss: 7.549655773526147
Training loss: 0.3594546616077423 / Valid loss: 7.60859584354219

Epoch: 26
Training loss: 0.4353792667388916 / Valid loss: 7.52673749923706
Training loss: 0.4934999644756317 / Valid loss: 7.494487453642345
Training loss: 0.22679944336414337 / Valid loss: 7.522698173068819
Training loss: 0.4638335704803467 / Valid loss: 7.545256176449004
Training loss: 0.6083855628967285 / Valid loss: 7.567637207394554

Epoch: 27
Training loss: 0.6701663136482239 / Valid loss: 7.4583256131126765
Training loss: 0.5390537977218628 / Valid loss: 7.521209535144624
Training loss: 0.2844235897064209 / Valid loss: 7.462232344491142
Training loss: 0.34438037872314453 / Valid loss: 7.603735006423223
Training loss: 0.33576178550720215 / Valid loss: 7.533988657451811

Epoch: 28
Training loss: 0.2692705988883972 / Valid loss: 7.516566558111282
Training loss: 0.41644617915153503 / Valid loss: 7.481602814084008
Training loss: 0.5690602660179138 / Valid loss: 7.5001711027962825
Training loss: 0.40398871898651123 / Valid loss: 7.484897618066697
Training loss: 0.2919800281524658 / Valid loss: 7.494636122385661

Epoch: 29
Training loss: 0.7705183029174805 / Valid loss: 7.547650596073695
Training loss: 0.34090861678123474 / Valid loss: 7.537130342211042
Training loss: 0.6324901580810547 / Valid loss: 7.507266803014846
Training loss: 0.4092457890510559 / Valid loss: 7.5671137491861975

Epoch: 30
Training loss: 0.3007854223251343 / Valid loss: 7.617790063222249
Training loss: 0.4931265115737915 / Valid loss: 7.489413733709426
Training loss: 0.682086169719696 / Valid loss: 7.560986682346889
Training loss: 0.5913293361663818 / Valid loss: 7.4639285314650765
Training loss: 0.19301658868789673 / Valid loss: 7.526675501323882

Epoch: 31
Training loss: 0.21814697980880737 / Valid loss: 7.511706215994699
Training loss: 0.4779125452041626 / Valid loss: 7.496926148732503
Training loss: 0.20311670005321503 / Valid loss: 7.510593128204346
Training loss: 0.302141010761261 / Valid loss: 7.481096680959066
Training loss: 0.682315468788147 / Valid loss: 7.554557909284319

Epoch: 32
Training loss: 0.2578233480453491 / Valid loss: 7.475116666158041
Training loss: 0.2009304165840149 / Valid loss: 7.506206734975179
Training loss: 0.21460750699043274 / Valid loss: 7.47517891838437
Training loss: 0.21290312707424164 / Valid loss: 7.562351204100109
Training loss: 0.47888535261154175 / Valid loss: 7.508683404468354

Epoch: 33
Training loss: 0.7188746333122253 / Valid loss: 7.533263683319092
Training loss: 0.2708338797092438 / Valid loss: 7.5500054427555625
Training loss: 0.2689417600631714 / Valid loss: 7.5246732076009115
Training loss: 0.2327718585729599 / Valid loss: 7.477434548877534
Training loss: 0.35376250743865967 / Valid loss: 7.482684267134894

Epoch: 34
Training loss: 0.2426251620054245 / Valid loss: 7.536525376637777
Training loss: 0.33782556653022766 / Valid loss: 7.5809346834818525
Training loss: 0.6381131410598755 / Valid loss: 7.50515927814302
Training loss: 0.34093984961509705 / Valid loss: 7.439398997170585
Training loss: 0.24563480913639069 / Valid loss: 7.562099179767427

Epoch: 35
Training loss: 0.3083447217941284 / Valid loss: 7.539411962599981
Training loss: 0.40913450717926025 / Valid loss: 7.5941278412228534
Training loss: 0.2014058232307434 / Valid loss: 7.494923419044131
Training loss: 0.1881386786699295 / Valid loss: 7.460795334407261
Training loss: 0.4894140362739563 / Valid loss: 7.562849746431623

Epoch: 36
Training loss: 0.35134345293045044 / Valid loss: 7.53031218846639
Training loss: 0.38751012086868286 / Valid loss: 7.451153496333531
Training loss: 0.18006449937820435 / Valid loss: 7.479579416910807
Training loss: 0.5778640508651733 / Valid loss: 7.534171199798584
Training loss: 0.2704089879989624 / Valid loss: 7.534466316586449

Epoch: 37
Training loss: 0.3118932545185089 / Valid loss: 7.569976327532814
Training loss: 1.0193328857421875 / Valid loss: 7.5121498244149345
Training loss: 0.2784324884414673 / Valid loss: 7.511622465224493
Training loss: 0.23507395386695862 / Valid loss: 7.472448884873163
Training loss: 0.36432310938835144 / Valid loss: 7.506976331983294

Epoch: 38
Training loss: 0.2542332708835602 / Valid loss: 7.499194208780924
Training loss: 0.20743155479431152 / Valid loss: 7.535943807874407
Training loss: 0.36721593141555786 / Valid loss: 7.517326795487177
Training loss: 0.22970321774482727 / Valid loss: 7.514741134643555
Training loss: 0.37335270643234253 / Valid loss: 7.510649522145589

Epoch: 39
Training loss: 0.2201930284500122 / Valid loss: 7.45075209027245
Training loss: 0.2802746891975403 / Valid loss: 7.549128191811698
Training loss: 0.646377444267273 / Valid loss: 7.53011121749878
Training loss: 0.22829610109329224 / Valid loss: 7.540164543333508

Epoch: 40
Training loss: 0.22092851996421814 / Valid loss: 7.559364464169457
Training loss: 0.36202332377433777 / Valid loss: 7.492301427750361
Training loss: 0.20997080206871033 / Valid loss: 7.4933929511478965
Training loss: 0.4652368426322937 / Valid loss: 7.564382939111619
Training loss: 0.38178539276123047 / Valid loss: 7.567644675572713

Epoch: 41
Training loss: 0.3431508541107178 / Valid loss: 7.552670633225214
Training loss: 0.44848695397377014 / Valid loss: 7.514333686374482
Training loss: 0.2664203345775604 / Valid loss: 7.58241104398455
Training loss: 0.28089404106140137 / Valid loss: 7.510889875321161
Training loss: 0.3267253637313843 / Valid loss: 7.495935680752709

Epoch: 42
Training loss: 0.30824020504951477 / Valid loss: 7.448938644500005
Training loss: 0.20800995826721191 / Valid loss: 7.4434310141063875
Training loss: 0.24819307029247284 / Valid loss: 7.525032184237525
Training loss: 0.166431725025177 / Valid loss: 7.479371379670643
Training loss: 0.32381129264831543 / Valid loss: 7.524115594228109

Epoch: 43
Training loss: 0.2646011710166931 / Valid loss: 7.487165110451834
Training loss: 0.21046221256256104 / Valid loss: 7.483075714111328
Training loss: 0.5153734087944031 / Valid loss: 7.47809770220802
Training loss: 0.19237947463989258 / Valid loss: 7.576376292819068
Training loss: 0.28339749574661255 / Valid loss: 7.538381349472773

Epoch: 44
Training loss: 0.13030140101909637 / Valid loss: 7.538869726090204
Training loss: 0.2841905355453491 / Valid loss: 7.435382479713077
Training loss: 0.17380881309509277 / Valid loss: 7.515160120101202
Training loss: 0.358717679977417 / Valid loss: 7.539830975305467
Training loss: 0.25718533992767334 / Valid loss: 7.481128111339751

Epoch: 45
Training loss: 0.38824498653411865 / Valid loss: 7.511719040643602
Training loss: 0.18131855130195618 / Valid loss: 7.556124573662167
Training loss: 0.3630581796169281 / Valid loss: 7.5481848171779085
Training loss: 0.23455893993377686 / Valid loss: 7.431180132003058
Training loss: 0.2048685997724533 / Valid loss: 7.530764947618757

Epoch: 46
Training loss: 0.3021576404571533 / Valid loss: 7.5454039437430245
Training loss: 0.15013055503368378 / Valid loss: 7.496707139696394
Training loss: 0.2805402874946594 / Valid loss: 7.536015832991827
Training loss: 0.30051863193511963 / Valid loss: 7.502380069096883
Training loss: 0.21436378359794617 / Valid loss: 7.495176955631801

Epoch: 47
Training loss: 0.3935149908065796 / Valid loss: 7.4744386332375665
Training loss: 0.45039576292037964 / Valid loss: 7.527400847843715
Training loss: 0.5103845000267029 / Valid loss: 7.5528636659894675
Training loss: 0.22997063398361206 / Valid loss: 7.509631524767195
Training loss: 0.3508439362049103 / Valid loss: 7.55299335207258

Epoch: 48
Training loss: 0.20871475338935852 / Valid loss: 7.502260793958391
Training loss: 0.22885093092918396 / Valid loss: 7.523973333267938
Training loss: 0.335864782333374 / Valid loss: 7.447497604006813
Training loss: 0.14407075941562653 / Valid loss: 7.398258885883149
Training loss: 0.25793516635894775 / Valid loss: 7.456729439326695

Epoch: 49
Training loss: 0.3481369614601135 / Valid loss: 7.506607963925316
Training loss: 0.18636995553970337 / Valid loss: 7.53591646921067
Training loss: 0.09403170645236969 / Valid loss: 7.427425429934547
Training loss: 0.18704769015312195 / Valid loss: 7.466308568772815

Epoch: 50
Training loss: 0.3560634255409241 / Valid loss: 7.381539503733317
Training loss: 0.29226920008659363 / Valid loss: 7.456511422566005
Training loss: 0.16932746767997742 / Valid loss: 7.4570436205182755
Training loss: 0.1953619420528412 / Valid loss: 7.498839600880941
Training loss: 0.21800591051578522 / Valid loss: 7.447186592647007

Epoch: 51
Training loss: 0.19526223838329315 / Valid loss: 7.477179990495954
Training loss: 0.2180469036102295 / Valid loss: 7.436555049532935
Training loss: 0.2552751898765564 / Valid loss: 7.467118608383905
Training loss: 0.33935344219207764 / Valid loss: 7.412092345101493
Training loss: 0.14224977791309357 / Valid loss: 7.477018996647426

Epoch: 52
Training loss: 0.16083405911922455 / Valid loss: 7.479122502463205
Training loss: 0.2468705177307129 / Valid loss: 7.490876701899937
Training loss: 0.16327227652072906 / Valid loss: 7.418918984276908
Training loss: 0.3164997100830078 / Valid loss: 7.485259605589367
Training loss: 0.11322098970413208 / Valid loss: 7.458241757892427

Epoch: 53
Training loss: 0.3274625539779663 / Valid loss: 7.517706639426095
Training loss: 0.289154589176178 / Valid loss: 7.470742225646973
Training loss: 0.16359661519527435 / Valid loss: 7.377314597084409
Training loss: 0.5255453586578369 / Valid loss: 7.387529575257075
Training loss: 0.21230825781822205 / Valid loss: 7.45446788242885

Epoch: 54
Training loss: 0.29959389567375183 / Valid loss: 7.446563243865967
Training loss: 0.2283858060836792 / Valid loss: 7.493525268917992
Training loss: 0.508916974067688 / Valid loss: 7.444433321271624
Training loss: 0.19583256542682648 / Valid loss: 7.381477791922433
Training loss: 0.24304431676864624 / Valid loss: 7.460923571813674

Epoch: 55
Training loss: 0.11684899032115936 / Valid loss: 7.418221855163575
Training loss: 0.17030799388885498 / Valid loss: 7.435970283689953
Training loss: 0.21958187222480774 / Valid loss: 7.340606412433442
Training loss: 0.19901183247566223 / Valid loss: 7.522749830427624
Training loss: 0.17313668131828308 / Valid loss: 7.519495069412958

Epoch: 56
Training loss: 0.36739951372146606 / Valid loss: 7.444109012967064
Training loss: 0.37930357456207275 / Valid loss: 7.385539627075195
Training loss: 0.14567944407463074 / Valid loss: 7.451777113051642
Training loss: 0.2104180008172989 / Valid loss: 7.400625683012462
Training loss: 0.5416953563690186 / Valid loss: 7.456277633848645

Epoch: 57
Training loss: 0.1856306791305542 / Valid loss: 7.426384785061791
Training loss: 0.3599845767021179 / Valid loss: 7.422021034785679
Training loss: 0.13095033168792725 / Valid loss: 7.448782575698126
Training loss: 0.3618781268596649 / Valid loss: 7.377169899713426
Training loss: 0.38957497477531433 / Valid loss: 7.414367185320173

Epoch: 58
Training loss: 0.21662390232086182 / Valid loss: 7.408923003787086
Training loss: 0.2807323932647705 / Valid loss: 7.393538093566894
Training loss: 0.3158726096153259 / Valid loss: 7.381810238247826
Training loss: 0.18748070299625397 / Valid loss: 7.460416816529774
Training loss: 0.12862807512283325 / Valid loss: 7.478465874989827

Epoch: 59
Training loss: 0.12131789326667786 / Valid loss: 7.382137757255918
Training loss: 0.16159950196743011 / Valid loss: 7.400085194905599
Training loss: 0.35109394788742065 / Valid loss: 7.371128236679803
Training loss: 0.5052812099456787 / Valid loss: 7.432544467562721

Epoch: 60
Training loss: 0.24510124325752258 / Valid loss: 7.381019506000337
Training loss: 0.2981110215187073 / Valid loss: 7.4125657081604
Training loss: 0.2620643675327301 / Valid loss: 7.419445728120349
Training loss: 0.12358130514621735 / Valid loss: 7.390509496416365
Training loss: 0.16593897342681885 / Valid loss: 7.460192348843529

Epoch: 61
Training loss: 0.24961066246032715 / Valid loss: 7.384131681351435
Training loss: 0.1177675724029541 / Valid loss: 7.411319387526739
Training loss: 0.20509716868400574 / Valid loss: 7.409107805433727
Training loss: 0.19075220823287964 / Valid loss: 7.445779568808419
Training loss: 0.18534119427204132 / Valid loss: 7.403227038610549

Epoch: 62
Training loss: 0.256468266248703 / Valid loss: 7.441455118996757
Training loss: 0.14604401588439941 / Valid loss: 7.391569796062651
Training loss: 0.2878354787826538 / Valid loss: 7.379723726000105
Training loss: 0.1682904064655304 / Valid loss: 7.439544582366944
Training loss: 0.24842114746570587 / Valid loss: 7.448676817757743

Epoch: 63
Training loss: 0.42958760261535645 / Valid loss: 7.453282465253557
Training loss: 0.1730075180530548 / Valid loss: 7.413767287844704
Training loss: 0.22189538180828094 / Valid loss: 7.378706863948277
Training loss: 0.20778900384902954 / Valid loss: 7.470349543435233
Training loss: 0.1829734742641449 / Valid loss: 7.4540370759509855

Epoch: 64
Training loss: 0.2176482081413269 / Valid loss: 7.491812735512143
Training loss: 0.12867730855941772 / Valid loss: 7.376991821470715
Training loss: 0.17445401847362518 / Valid loss: 7.383268297286261
Training loss: 0.1578522026538849 / Valid loss: 7.40307681674049
Training loss: 0.1082509309053421 / Valid loss: 7.363457647959391

Epoch: 65
Training loss: 0.17559662461280823 / Valid loss: 7.469439647311256
Training loss: 0.3119211792945862 / Valid loss: 7.398578689211891
Training loss: 0.1682150512933731 / Valid loss: 7.488068380809966
Training loss: 0.3280825912952423 / Valid loss: 7.411201785859608
Training loss: 0.13246464729309082 / Valid loss: 7.467869154612223

Epoch: 66
Training loss: 0.17494773864746094 / Valid loss: 7.4054908093952
Training loss: 0.11377745866775513 / Valid loss: 7.409906387329102
Training loss: 0.38027673959732056 / Valid loss: 7.473130616687593
Training loss: 0.18697351217269897 / Valid loss: 7.438135637555804
Training loss: 0.165076345205307 / Valid loss: 7.462225750514439

Epoch: 67
Training loss: 0.15176984667778015 / Valid loss: 7.450334162939162
Training loss: 0.2897742986679077 / Valid loss: 7.486131309327625
Training loss: 0.08899305760860443 / Valid loss: 7.447209703354608
Training loss: 0.2197543978691101 / Valid loss: 7.395543997628348
Training loss: 0.19432324171066284 / Valid loss: 7.483581720079695

Epoch: 68
Training loss: 0.3174581527709961 / Valid loss: 7.4286142985026045
Training loss: 0.20334510505199432 / Valid loss: 7.381118429274786
Training loss: 0.15905888378620148 / Valid loss: 7.483396650495983
Training loss: 0.26164740324020386 / Valid loss: 7.480173714955648
Training loss: 0.12104330956935883 / Valid loss: 7.414296445392427

Epoch: 69
Training loss: 0.14017102122306824 / Valid loss: 7.361362897782099
Training loss: 0.2481478750705719 / Valid loss: 7.435870238712856
Training loss: 0.23965072631835938 / Valid loss: 7.430696759905134
Training loss: 0.4082147181034088 / Valid loss: 7.398352686564127

Epoch: 70
Training loss: 0.2888385057449341 / Valid loss: 7.416660009111677
Training loss: 0.2645684480667114 / Valid loss: 7.418024217514764
Training loss: 0.23266786336898804 / Valid loss: 7.397164896556309
Training loss: 0.31668758392333984 / Valid loss: 7.326006684984479
Training loss: 0.4563124179840088 / Valid loss: 7.370504778907413

Epoch: 71
Training loss: 0.30794525146484375 / Valid loss: 7.410013948168073
Training loss: 0.1840408891439438 / Valid loss: 7.406471506754557
Training loss: 0.12463517487049103 / Valid loss: 7.411263016292027
Training loss: 0.13340674340724945 / Valid loss: 7.4331060409545895
Training loss: 0.27269068360328674 / Valid loss: 7.471477544875372

Epoch: 72
Training loss: 0.100867360830307 / Valid loss: 7.365812914712088
Training loss: 0.29035651683807373 / Valid loss: 7.3619326409839445
Training loss: 0.1480828821659088 / Valid loss: 7.396306006113688
Training loss: 0.13120798766613007 / Valid loss: 7.361301708221435
Training loss: 0.14364676177501678 / Valid loss: 7.386076563880557

Epoch: 73
Training loss: 0.4553883671760559 / Valid loss: 7.412036691393171
Training loss: 0.12927284836769104 / Valid loss: 7.38042376836141
Training loss: 0.11190742254257202 / Valid loss: 7.3476997602553595
Training loss: 0.12957407534122467 / Valid loss: 7.343370439892723
Training loss: 0.2303372472524643 / Valid loss: 7.411191045670282

Epoch: 74
Training loss: 0.2773301601409912 / Valid loss: 7.377909937359038
Training loss: 0.09712614119052887 / Valid loss: 7.346767743428548
Training loss: 0.09924739599227905 / Valid loss: 7.366466613042922
Training loss: 0.25376343727111816 / Valid loss: 7.399277291979108
Training loss: 0.13418301939964294 / Valid loss: 7.427389785221645

Epoch: 75
Training loss: 0.20907017588615417 / Valid loss: 7.377914592197963
Training loss: 0.5564046502113342 / Valid loss: 7.334964384351458
Training loss: 0.16883793473243713 / Valid loss: 7.390030254636492
Training loss: 0.17719204723834991 / Valid loss: 7.4081552187601725
Training loss: 0.08473885804414749 / Valid loss: 7.439546149117606

Epoch: 76
Training loss: 0.10434295237064362 / Valid loss: 7.3793806530180435
Training loss: 0.18285512924194336 / Valid loss: 7.372047946566627
Training loss: 0.20325028896331787 / Valid loss: 7.365838268824986
Training loss: 0.16194674372673035 / Valid loss: 7.335829834710984
Training loss: 0.19515171647071838 / Valid loss: 7.376978846958705

Epoch: 77
Training loss: 0.22481577098369598 / Valid loss: 7.33301081884475
Training loss: 0.4092223346233368 / Valid loss: 7.41833469300043
Training loss: 0.18581411242485046 / Valid loss: 7.372202682495117
Training loss: 0.13407403230667114 / Valid loss: 7.360198674883161
Training loss: 0.4507560133934021 / Valid loss: 7.305753267379034

Epoch: 78
Training loss: 0.0746144950389862 / Valid loss: 7.416512076059977
Training loss: 0.29534801840782166 / Valid loss: 7.385543954940069
Training loss: 0.1472153663635254 / Valid loss: 7.386092435745966
Training loss: 0.1902821660041809 / Valid loss: 7.406103224981399
Training loss: 0.2767351269721985 / Valid loss: 7.37234651020595

Epoch: 79
Training loss: 0.1544518768787384 / Valid loss: 7.379479728426252
Training loss: 0.1971757411956787 / Valid loss: 7.410930987766811
Training loss: 0.11952336877584457 / Valid loss: 7.387178707122803
Training loss: 0.15470045804977417 / Valid loss: 7.364728673299154
ModuleList(
  (0): Linear(in_features=31191, out_features=248, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=248, out_features=1, bias=True)
)
Loss on test set of optimal model: 6.058201680864607
Training regression with following parameters:
dnn_hidden_units : 
dropout_probs : 0.0, 0.0
learning_rate : 0.001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : Adam
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : TFIDF
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=31191, out_features=1, bias=True)
)

Epoch: 0
Training loss: 20.986988067626953 / Valid loss: 16.471467853727795
Model is saved in epoch 0, overall batch: 0
Training loss: 18.63018035888672 / Valid loss: 15.407264627729143
Model is saved in epoch 0, overall batch: 100
Training loss: 9.775970458984375 / Valid loss: 14.426258850097657
Model is saved in epoch 0, overall batch: 200
Training loss: 14.232864379882812 / Valid loss: 13.518839972359794
Model is saved in epoch 0, overall batch: 300
Training loss: 10.275541305541992 / Valid loss: 12.678959583100818
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 9.813549041748047 / Valid loss: 11.911137335641044
Model is saved in epoch 1, overall batch: 500
Training loss: 8.737800598144531 / Valid loss: 11.236984107607887
Model is saved in epoch 1, overall batch: 600
Training loss: 10.666757583618164 / Valid loss: 10.617521808260964
Model is saved in epoch 1, overall batch: 700
Training loss: 10.168182373046875 / Valid loss: 10.048979196094331
Model is saved in epoch 1, overall batch: 800
Training loss: 13.487499237060547 / Valid loss: 9.520679791768393
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 7.51106071472168 / Valid loss: 9.050390645435877
Model is saved in epoch 2, overall batch: 1000
Training loss: 5.945745944976807 / Valid loss: 8.648081552414666
Model is saved in epoch 2, overall batch: 1100
Training loss: 8.438943862915039 / Valid loss: 8.284702714284261
Model is saved in epoch 2, overall batch: 1200
Training loss: 6.492394924163818 / Valid loss: 7.949681014106387
Model is saved in epoch 2, overall batch: 1300
Training loss: 8.264232635498047 / Valid loss: 7.648545896439325
Model is saved in epoch 2, overall batch: 1400

Epoch: 3
Training loss: 5.461374282836914 / Valid loss: 7.379040933790661
Model is saved in epoch 3, overall batch: 1500
Training loss: 4.330970764160156 / Valid loss: 7.13654230208624
Model is saved in epoch 3, overall batch: 1600
Training loss: 6.036120891571045 / Valid loss: 6.944165985924857
Model is saved in epoch 3, overall batch: 1700
Training loss: 7.556905269622803 / Valid loss: 6.774666450137183
Model is saved in epoch 3, overall batch: 1800
Training loss: 9.208368301391602 / Valid loss: 6.615230208351498
Model is saved in epoch 3, overall batch: 1900

Epoch: 4
Training loss: 8.830127716064453 / Valid loss: 6.485729703449068
Model is saved in epoch 4, overall batch: 2000
Training loss: 7.469746112823486 / Valid loss: 6.355050073351179
Model is saved in epoch 4, overall batch: 2100
Training loss: 7.797349452972412 / Valid loss: 6.256985076268514
Model is saved in epoch 4, overall batch: 2200
Training loss: 7.23930025100708 / Valid loss: 6.165032670611427
Model is saved in epoch 4, overall batch: 2300
Training loss: 4.6738080978393555 / Valid loss: 6.0889358656747
Model is saved in epoch 4, overall batch: 2400

Epoch: 5
Training loss: 3.5148346424102783 / Valid loss: 6.0190873622894285
Model is saved in epoch 5, overall batch: 2500
Training loss: 7.282408714294434 / Valid loss: 5.98071608543396
Model is saved in epoch 5, overall batch: 2600
Training loss: 4.551709175109863 / Valid loss: 5.931868180774507
Model is saved in epoch 5, overall batch: 2700
Training loss: 7.018116474151611 / Valid loss: 5.889771372931344
Model is saved in epoch 5, overall batch: 2800
Training loss: 3.8549957275390625 / Valid loss: 5.8466522307623
Model is saved in epoch 5, overall batch: 2900

Epoch: 6
Training loss: 4.616265296936035 / Valid loss: 5.8137611979529975
Model is saved in epoch 6, overall batch: 3000
Training loss: 5.636221885681152 / Valid loss: 5.8003549462273005
Model is saved in epoch 6, overall batch: 3100
Training loss: 3.526322841644287 / Valid loss: 5.772770541054862
Model is saved in epoch 6, overall batch: 3200
Training loss: 5.155546188354492 / Valid loss: 5.748990079334804
Model is saved in epoch 6, overall batch: 3300
Training loss: 3.940946102142334 / Valid loss: 5.737064599990845
Model is saved in epoch 6, overall batch: 3400

Epoch: 7
Training loss: 4.155340194702148 / Valid loss: 5.720840980893089
Model is saved in epoch 7, overall batch: 3500
Training loss: 6.737896919250488 / Valid loss: 5.7037204651605515
Model is saved in epoch 7, overall batch: 3600
Training loss: 3.382598638534546 / Valid loss: 5.686359469095866
Model is saved in epoch 7, overall batch: 3700
Training loss: 5.368721961975098 / Valid loss: 5.671949731735956
Model is saved in epoch 7, overall batch: 3800
Training loss: 5.057578086853027 / Valid loss: 5.6711028348831904
Model is saved in epoch 7, overall batch: 3900

Epoch: 8
Training loss: 4.709362506866455 / Valid loss: 5.658303771700178
Model is saved in epoch 8, overall batch: 4000
Training loss: 6.755249500274658 / Valid loss: 5.651263250623431
Model is saved in epoch 8, overall batch: 4100
Training loss: 5.235943794250488 / Valid loss: 5.648202575956073
Model is saved in epoch 8, overall batch: 4200
Training loss: 6.896762847900391 / Valid loss: 5.645067664555141
Model is saved in epoch 8, overall batch: 4300
Training loss: 5.341348171234131 / Valid loss: 5.629574787049067
Model is saved in epoch 8, overall batch: 4400

Epoch: 9
Training loss: 6.07421350479126 / Valid loss: 5.625497588657198
Model is saved in epoch 9, overall batch: 4500
Training loss: 5.768555641174316 / Valid loss: 5.620560525712513
Model is saved in epoch 9, overall batch: 4600
Training loss: 5.625482559204102 / Valid loss: 5.6066020965576175
Model is saved in epoch 9, overall batch: 4700
Training loss: 5.50877046585083 / Valid loss: 5.604776262101673
Model is saved in epoch 9, overall batch: 4800

Epoch: 10
Training loss: 5.38389253616333 / Valid loss: 5.60124729020255
Model is saved in epoch 10, overall batch: 4900
Training loss: 6.878102779388428 / Valid loss: 5.592987362543742
Model is saved in epoch 10, overall batch: 5000
Training loss: 6.6444549560546875 / Valid loss: 5.584481430053711
Model is saved in epoch 10, overall batch: 5100
Training loss: 4.63402795791626 / Valid loss: 5.582790465581985
Model is saved in epoch 10, overall batch: 5200
Training loss: 5.699923515319824 / Valid loss: 5.57356477237883
Model is saved in epoch 10, overall batch: 5300

Epoch: 11
Training loss: 5.739457130432129 / Valid loss: 5.569696467263358
Model is saved in epoch 11, overall batch: 5400
Training loss: 5.298558235168457 / Valid loss: 5.562433910369873
Model is saved in epoch 11, overall batch: 5500
Training loss: 6.251924514770508 / Valid loss: 5.565613935107277
Training loss: 5.0719404220581055 / Valid loss: 5.557139371690296
Model is saved in epoch 11, overall batch: 5700
Training loss: 3.952608585357666 / Valid loss: 5.541522911616734
Model is saved in epoch 11, overall batch: 5800

Epoch: 12
Training loss: 6.005978584289551 / Valid loss: 5.5536993208385645
Training loss: 3.7381834983825684 / Valid loss: 5.546840962909517
Training loss: 3.470838785171509 / Valid loss: 5.5433446906861805
Training loss: 6.545736312866211 / Valid loss: 5.538538587661017
Model is saved in epoch 12, overall batch: 6200
Training loss: 3.8931689262390137 / Valid loss: 5.528887083416893
Model is saved in epoch 12, overall batch: 6300

Epoch: 13
Training loss: 3.92470121383667 / Valid loss: 5.53395075343904
Training loss: 3.489238739013672 / Valid loss: 5.5299920649755565
Training loss: 6.522801399230957 / Valid loss: 5.526157131649199
Model is saved in epoch 13, overall batch: 6600
Training loss: 5.315229892730713 / Valid loss: 5.522433037984939
Model is saved in epoch 13, overall batch: 6700
Training loss: 5.406111717224121 / Valid loss: 5.52181879679362
Model is saved in epoch 13, overall batch: 6800

Epoch: 14
Training loss: 5.596658706665039 / Valid loss: 5.517273214885167
Model is saved in epoch 14, overall batch: 6900
Training loss: 3.982999801635742 / Valid loss: 5.506078792753674
Model is saved in epoch 14, overall batch: 7000
Training loss: 5.672061443328857 / Valid loss: 5.512235907145909
Training loss: 6.009856224060059 / Valid loss: 5.512065410614014
Training loss: 4.391214847564697 / Valid loss: 5.508027142570132

Epoch: 15
Training loss: 5.508995532989502 / Valid loss: 5.502175655819121
Model is saved in epoch 15, overall batch: 7400
Training loss: 5.6745219230651855 / Valid loss: 5.491270660218738
Model is saved in epoch 15, overall batch: 7500
Training loss: 3.1222219467163086 / Valid loss: 5.4989682379223055
Training loss: 4.454006195068359 / Valid loss: 5.496225236711048
Training loss: 6.341487884521484 / Valid loss: 5.494764089584351

Epoch: 16
Training loss: 3.4939026832580566 / Valid loss: 5.486854096821376
Model is saved in epoch 16, overall batch: 7900
Training loss: 5.857463836669922 / Valid loss: 5.479247865222749
Model is saved in epoch 16, overall batch: 8000
Training loss: 5.7376909255981445 / Valid loss: 5.48903869447254
Training loss: 4.922816276550293 / Valid loss: 5.479236457461402
Model is saved in epoch 16, overall batch: 8200
Training loss: 5.147218704223633 / Valid loss: 5.486211354391916

Epoch: 17
Training loss: 6.7169084548950195 / Valid loss: 5.482763898940314
Training loss: 4.572077751159668 / Valid loss: 5.474629352206276
Model is saved in epoch 17, overall batch: 8500
Training loss: 4.293863296508789 / Valid loss: 5.479684134892055
Training loss: 3.8922410011291504 / Valid loss: 5.47973282904852
Training loss: 5.4588942527771 / Valid loss: 5.473161218279884
Model is saved in epoch 17, overall batch: 8800

Epoch: 18
Training loss: 3.520796775817871 / Valid loss: 5.477810489563715
Training loss: 4.348184108734131 / Valid loss: 5.470775849478585
Model is saved in epoch 18, overall batch: 9000
Training loss: 4.205758094787598 / Valid loss: 5.472903574080695
Training loss: 4.5511908531188965 / Valid loss: 5.4734054406483965
Training loss: 5.027217864990234 / Valid loss: 5.474196272804623

Epoch: 19
Training loss: 3.8575048446655273 / Valid loss: 5.464369122187296
Model is saved in epoch 19, overall batch: 9400
Training loss: 6.779113292694092 / Valid loss: 5.462612660725911
Model is saved in epoch 19, overall batch: 9500
Training loss: 3.4621453285217285 / Valid loss: 5.467450017020816
Training loss: 6.038926601409912 / Valid loss: 5.461942895253499
Model is saved in epoch 19, overall batch: 9700

Epoch: 20
Training loss: 3.831066608428955 / Valid loss: 5.460612408320109
Model is saved in epoch 20, overall batch: 9800
Training loss: 5.324001312255859 / Valid loss: 5.4684534254528225
Training loss: 4.446750640869141 / Valid loss: 5.46638742855617
Training loss: 4.5989990234375 / Valid loss: 5.459184828258696
Model is saved in epoch 20, overall batch: 10100
Training loss: 4.198691368103027 / Valid loss: 5.460936099007016

Epoch: 21
Training loss: 5.774990081787109 / Valid loss: 5.463640494573684
Training loss: 3.729306697845459 / Valid loss: 5.465460695539202
Training loss: 4.4373064041137695 / Valid loss: 5.463199454262143
Training loss: 5.386929988861084 / Valid loss: 5.463839471907843
Training loss: 3.557811737060547 / Valid loss: 5.461174031666347

Epoch: 22
Training loss: 5.330171585083008 / Valid loss: 5.46182580221267
Training loss: 5.447303295135498 / Valid loss: 5.460245909009661
Training loss: 3.747264862060547 / Valid loss: 5.459955755869547
Training loss: 4.409695625305176 / Valid loss: 5.462120246887207
Training loss: 3.5266315937042236 / Valid loss: 5.459195972624279

Epoch: 23
Training loss: 4.412166595458984 / Valid loss: 5.459629917144776
Training loss: 5.923771381378174 / Valid loss: 5.462530449458531
Training loss: 4.794498443603516 / Valid loss: 5.4594519978477845
Training loss: 4.277701377868652 / Valid loss: 5.4631566865103585
Training loss: 3.39920711517334 / Valid loss: 5.460540678387597

Epoch: 24
Training loss: 3.986401319503784 / Valid loss: 5.461489632016137
Training loss: 4.655772686004639 / Valid loss: 5.4562210241953535
Model is saved in epoch 24, overall batch: 11900
Training loss: 2.764206886291504 / Valid loss: 5.458539497284662
Training loss: 4.550921440124512 / Valid loss: 5.458201120013283
Training loss: 4.368588924407959 / Valid loss: 5.458906963893345

Epoch: 25
Training loss: 4.102358818054199 / Valid loss: 5.454728451229277
Model is saved in epoch 25, overall batch: 12300
Training loss: 3.1712138652801514 / Valid loss: 5.462471909750075
Training loss: 5.878548622131348 / Valid loss: 5.464515390850249
Training loss: 4.762780666351318 / Valid loss: 5.461724079222906
Training loss: 4.97176456451416 / Valid loss: 5.457019946688697

Epoch: 26
Training loss: 3.4158682823181152 / Valid loss: 5.463481980278378
Training loss: 2.5887980461120605 / Valid loss: 5.462875466119676
Training loss: 3.9578447341918945 / Valid loss: 5.46315069652739
Training loss: 4.805314064025879 / Valid loss: 5.465556673776536
Training loss: 3.0926761627197266 / Valid loss: 5.464044427871704

Epoch: 27
Training loss: 4.249815940856934 / Valid loss: 5.465391229447865
Training loss: 3.9139084815979004 / Valid loss: 5.466057271049136
Training loss: 4.237305641174316 / Valid loss: 5.465354111081078
Training loss: 4.648406982421875 / Valid loss: 5.466040681657337
Training loss: 4.868549346923828 / Valid loss: 5.462231129691714

Epoch: 28
Training loss: 3.7042183876037598 / Valid loss: 5.467510445912679
Training loss: 3.237563133239746 / Valid loss: 5.462727092561268
Training loss: 3.533482551574707 / Valid loss: 5.470671199616932
Training loss: 4.426372528076172 / Valid loss: 5.468109223956153
Training loss: 3.2713396549224854 / Valid loss: 5.470784898031326

Epoch: 29
Training loss: 4.34877872467041 / Valid loss: 5.467292658487955
Training loss: 4.953998565673828 / Valid loss: 5.466768242063976
Training loss: 4.69462776184082 / Valid loss: 5.46694800286066
Training loss: 4.653944969177246 / Valid loss: 5.4733062290009995

Epoch: 30
Training loss: 5.436652183532715 / Valid loss: 5.471356276103428
Training loss: 4.259218215942383 / Valid loss: 5.476401240485055
Training loss: 3.3208744525909424 / Valid loss: 5.480070155007499
Training loss: 3.6347432136535645 / Valid loss: 5.479887628555298
Training loss: 3.8807125091552734 / Valid loss: 5.481768864677066

Epoch: 31
Training loss: 4.384098529815674 / Valid loss: 5.4811521371205645
Training loss: 5.077935695648193 / Valid loss: 5.476759143102736
Training loss: 4.34765100479126 / Valid loss: 5.479397217432658
Training loss: 5.206612586975098 / Valid loss: 5.48281569480896
Training loss: 4.906699180603027 / Valid loss: 5.476487009865897

Epoch: 32
Training loss: 2.665677070617676 / Valid loss: 5.483926196325393
Training loss: 4.790565490722656 / Valid loss: 5.485879421234131
Training loss: 4.158268928527832 / Valid loss: 5.485532283782959
Training loss: 4.1446990966796875 / Valid loss: 5.48585102217538
Training loss: 2.8604230880737305 / Valid loss: 5.489724191029866

Epoch: 33
Training loss: 5.027865409851074 / Valid loss: 5.490809102285476
Training loss: 2.909865379333496 / Valid loss: 5.489012529736473
Training loss: 4.623377799987793 / Valid loss: 5.493612559636434
Training loss: 3.740933418273926 / Valid loss: 5.486162889571417
Training loss: 5.635357856750488 / Valid loss: 5.496842082341512

Epoch: 34
Training loss: 3.541306972503662 / Valid loss: 5.495888832637242
Training loss: 3.288703680038452 / Valid loss: 5.4970024335952035
Training loss: 3.410468339920044 / Valid loss: 5.488862846011207
Training loss: 3.601592540740967 / Valid loss: 5.499371957778931
Training loss: 4.07620906829834 / Valid loss: 5.492313414528256

Epoch: 35
Training loss: 3.960672616958618 / Valid loss: 5.496681033997309
Training loss: 4.6308746337890625 / Valid loss: 5.503932653154646
Training loss: 4.73881196975708 / Valid loss: 5.504157652173723
Training loss: 5.873665809631348 / Valid loss: 5.500879251389277
Training loss: 5.6107072830200195 / Valid loss: 5.496418594178699

Epoch: 36
Training loss: 4.059154987335205 / Valid loss: 5.505883625575474
Training loss: 5.345928192138672 / Valid loss: 5.497515855516706
Training loss: 3.2264883518218994 / Valid loss: 5.50652684257144
Training loss: 3.550762414932251 / Valid loss: 5.513733995528448
Training loss: 2.8342270851135254 / Valid loss: 5.512877189545405

Epoch: 37
Training loss: 3.375135898590088 / Valid loss: 5.512912913731166
Training loss: 3.8723583221435547 / Valid loss: 5.515965949921381
Training loss: 3.3152122497558594 / Valid loss: 5.514694118499756
Training loss: 3.689467430114746 / Valid loss: 5.511787911823817
Training loss: 4.012165069580078 / Valid loss: 5.515170079185849

Epoch: 38
Training loss: 3.209845542907715 / Valid loss: 5.516621816725958
Training loss: 3.539217233657837 / Valid loss: 5.520804566428775
Training loss: 4.223217010498047 / Valid loss: 5.520545587085542
Training loss: 3.669124126434326 / Valid loss: 5.523608119147164
Training loss: 4.354582786560059 / Valid loss: 5.525421344666254

Epoch: 39
Training loss: 2.2911105155944824 / Valid loss: 5.525607056844802
Training loss: 3.8304402828216553 / Valid loss: 5.530759738740467
Training loss: 4.818692684173584 / Valid loss: 5.529716348648071
Training loss: 3.9178876876831055 / Valid loss: 5.533752554938907

Epoch: 40
Training loss: 3.978456974029541 / Valid loss: 5.534544156846546
Training loss: 4.728496551513672 / Valid loss: 5.5304929006667365
Training loss: 3.900439977645874 / Valid loss: 5.537602921894618
Training loss: 3.6331162452697754 / Valid loss: 5.535507340658278
Training loss: 3.7179503440856934 / Valid loss: 5.54001342455546

Epoch: 41
Training loss: 4.814150333404541 / Valid loss: 5.540169924781436
Training loss: 4.560025691986084 / Valid loss: 5.543421079998924
Training loss: 3.775669574737549 / Valid loss: 5.544983164469401
Training loss: 3.6620535850524902 / Valid loss: 5.538441312880743
Training loss: 4.669344902038574 / Valid loss: 5.547672348930722

Epoch: 42
Training loss: 2.469287633895874 / Valid loss: 5.5453896227337065
Training loss: 3.0241308212280273 / Valid loss: 5.551875709352039
Training loss: 4.470624923706055 / Valid loss: 5.551000379380726
Training loss: 2.9037301540374756 / Valid loss: 5.550218602589198
Training loss: 3.901705741882324 / Valid loss: 5.550863458996727

Epoch: 43
Training loss: 3.4717960357666016 / Valid loss: 5.5569135870252335
Training loss: 4.086367130279541 / Valid loss: 5.55594273748852
Training loss: 3.6923649311065674 / Valid loss: 5.555255660556612
Training loss: 5.375408172607422 / Valid loss: 5.559746163231986
Training loss: 3.701709508895874 / Valid loss: 5.562414984475999

Epoch: 44
Training loss: 3.844012975692749 / Valid loss: 5.560838740212577
Training loss: 4.345248222351074 / Valid loss: 5.565809738068354
Training loss: 4.170512676239014 / Valid loss: 5.567157300313314
Training loss: 2.494255304336548 / Valid loss: 5.5628767081669395
Training loss: 3.600112199783325 / Valid loss: 5.563715880257742

Epoch: 45
Training loss: 2.990713119506836 / Valid loss: 5.570336900438581
Training loss: 4.788935661315918 / Valid loss: 5.568603681382679
Training loss: 3.435638427734375 / Valid loss: 5.57503141221546
Training loss: 3.8193771839141846 / Valid loss: 5.576100771767752
Training loss: 3.86820125579834 / Valid loss: 5.576730221793765

Epoch: 46
Training loss: 3.7505178451538086 / Valid loss: 5.581610822677613
Training loss: 4.711830139160156 / Valid loss: 5.5803215753464475
Training loss: 4.14688777923584 / Valid loss: 5.582753335861932
Training loss: 3.3808932304382324 / Valid loss: 5.5824354466937836
Training loss: 3.918994903564453 / Valid loss: 5.588506001517886

Epoch: 47
Training loss: 2.948247194290161 / Valid loss: 5.584819632484799
Training loss: 3.5832552909851074 / Valid loss: 5.590942877814883
Training loss: 4.411788463592529 / Valid loss: 5.591764227549235
Training loss: 2.978564500808716 / Valid loss: 5.593418239411854
Training loss: 2.540536880493164 / Valid loss: 5.59769689923241

Epoch: 48
Training loss: 2.6703593730926514 / Valid loss: 5.599001300902594
Training loss: 3.3143041133880615 / Valid loss: 5.601083117439633
Training loss: 4.303369522094727 / Valid loss: 5.601862925574893
Training loss: 4.015885353088379 / Valid loss: 5.600626216615949
Training loss: 3.8116161823272705 / Valid loss: 5.6031389191037135

Epoch: 49
Training loss: 3.86619234085083 / Valid loss: 5.600659540721348
Training loss: 2.5974087715148926 / Valid loss: 5.60615424882798
Training loss: 4.705482006072998 / Valid loss: 5.605756039846511
Training loss: 4.292431831359863 / Valid loss: 5.6103228591737295

Epoch: 50
Training loss: 1.9389556646347046 / Valid loss: 5.608182307652065
Training loss: 4.453980445861816 / Valid loss: 5.606107350758144
Training loss: 3.4444048404693604 / Valid loss: 5.610652691977364
Training loss: 2.870380401611328 / Valid loss: 5.617776934305827
Training loss: 4.090205669403076 / Valid loss: 5.620281040100824

Epoch: 51
Training loss: 4.018610000610352 / Valid loss: 5.623080562409901
Training loss: 4.196046829223633 / Valid loss: 5.616980813798451
Training loss: 4.74177360534668 / Valid loss: 5.624519475301107
Training loss: 3.6547951698303223 / Valid loss: 5.624104869933356
Training loss: 3.8072638511657715 / Valid loss: 5.630973561604818

Epoch: 52
Training loss: 3.4678125381469727 / Valid loss: 5.632199655260359
Training loss: 4.328530788421631 / Valid loss: 5.634467240742275
Training loss: 3.7918238639831543 / Valid loss: 5.632101538067772
Training loss: 3.5288493633270264 / Valid loss: 5.634813742410569
Training loss: 3.218416452407837 / Valid loss: 5.629599069413684

Epoch: 53
Training loss: 3.5090785026550293 / Valid loss: 5.633968189784459
Training loss: 2.2188892364501953 / Valid loss: 5.64056663059053
Training loss: 2.917099952697754 / Valid loss: 5.641831813539778
Training loss: 3.278637409210205 / Valid loss: 5.640833686646961
Training loss: 2.461587429046631 / Valid loss: 5.64711963335673

Epoch: 54
Training loss: 3.4984493255615234 / Valid loss: 5.646967812946865
Training loss: 4.309253692626953 / Valid loss: 5.6454243682679675
Training loss: 3.250375270843506 / Valid loss: 5.65074128196353
Training loss: 3.3894858360290527 / Valid loss: 5.652518399556478
Training loss: 3.318906784057617 / Valid loss: 5.655757300059

Epoch: 55
Training loss: 3.997483015060425 / Valid loss: 5.658541175297328
Training loss: 5.1612067222595215 / Valid loss: 5.659117846261887
Training loss: 3.4862308502197266 / Valid loss: 5.663949233009702
Training loss: 2.4977669715881348 / Valid loss: 5.662772142319453
Training loss: 2.553051710128784 / Valid loss: 5.655481290817261

Epoch: 56
Training loss: 3.3289833068847656 / Valid loss: 5.66890849613008
Training loss: 4.104058265686035 / Valid loss: 5.665941404160999
Training loss: 3.7087020874023438 / Valid loss: 5.667185460953485
Training loss: 2.6171531677246094 / Valid loss: 5.672391039984567
Training loss: 2.7847447395324707 / Valid loss: 5.676356910523914

Epoch: 57
Training loss: 3.355423927307129 / Valid loss: 5.672123656954084
Training loss: 3.0376534461975098 / Valid loss: 5.677576927911668
Training loss: 1.8459136486053467 / Valid loss: 5.681099841708229
Training loss: 3.736178159713745 / Valid loss: 5.680393427894229
Training loss: 3.0573415756225586 / Valid loss: 5.681124289830525

Epoch: 58
Training loss: 4.178513526916504 / Valid loss: 5.6841497875395275
Training loss: 3.020655632019043 / Valid loss: 5.686522826694307
Training loss: 4.397830963134766 / Valid loss: 5.6883445035843625
Training loss: 3.055112838745117 / Valid loss: 5.691753194445655
Training loss: 3.0247552394866943 / Valid loss: 5.686592476708548

Epoch: 59
Training loss: 2.6618781089782715 / Valid loss: 5.6939150401524135
Training loss: 3.7585442066192627 / Valid loss: 5.6996950422014505
Training loss: 2.907092332839966 / Valid loss: 5.694039633160545
Training loss: 2.732210397720337 / Valid loss: 5.700285609563192

Epoch: 60
Training loss: 4.141777038574219 / Valid loss: 5.696721581050328
Training loss: 2.4079108238220215 / Valid loss: 5.706103277206421
Training loss: 2.7134695053100586 / Valid loss: 5.70197483017331
Training loss: 3.739790439605713 / Valid loss: 5.706253489993867
Training loss: 3.580451250076294 / Valid loss: 5.702382371539161

Epoch: 61
Training loss: 3.690708875656128 / Valid loss: 5.71223114104498
Training loss: 3.3837978839874268 / Valid loss: 5.704138601393927
Training loss: 3.5277462005615234 / Valid loss: 5.7143523534139
Training loss: 3.509197473526001 / Valid loss: 5.714927911758423
Training loss: 3.388094663619995 / Valid loss: 5.717169509615217

Epoch: 62
Training loss: 3.1077754497528076 / Valid loss: 5.723692049298967
Training loss: 4.083117485046387 / Valid loss: 5.725460095632644
Training loss: 3.2476978302001953 / Valid loss: 5.726419201351347
Training loss: 3.0186047554016113 / Valid loss: 5.727914267494565
Training loss: 3.8995447158813477 / Valid loss: 5.726917042051043

Epoch: 63
Training loss: 4.098343849182129 / Valid loss: 5.7312102272397
Training loss: 3.445448398590088 / Valid loss: 5.731980970927647
Training loss: 2.7022902965545654 / Valid loss: 5.735570310410999
Training loss: 3.289121150970459 / Valid loss: 5.737180337451753
Training loss: 1.885718822479248 / Valid loss: 5.734482286089943

Epoch: 64
Training loss: 3.1287841796875 / Valid loss: 5.736171522594634
Training loss: 2.651113510131836 / Valid loss: 5.743622584570022
Training loss: 3.550074577331543 / Valid loss: 5.744301419031053
Training loss: 4.017044544219971 / Valid loss: 5.746556924638294
Training loss: 2.913050889968872 / Valid loss: 5.744849239076887

Epoch: 65
Training loss: 3.533936023712158 / Valid loss: 5.746715393520537
Training loss: 6.137874126434326 / Valid loss: 5.753423109508696
Training loss: 3.029001474380493 / Valid loss: 5.750887680053711
Training loss: 3.334174156188965 / Valid loss: 5.750229851404826
Training loss: 4.407320022583008 / Valid loss: 5.760921566826957

Epoch: 66
Training loss: 1.9158892631530762 / Valid loss: 5.761677306038993
Training loss: 2.8313770294189453 / Valid loss: 5.760442652021136
Training loss: 3.4675679206848145 / Valid loss: 5.757900658107939
Training loss: 2.093179702758789 / Valid loss: 5.762772573743548
Training loss: 3.240734815597534 / Valid loss: 5.768254066648938

Epoch: 67
Training loss: 3.413654327392578 / Valid loss: 5.76246382849557
Training loss: 3.4753313064575195 / Valid loss: 5.770776782717023
Training loss: 4.161433219909668 / Valid loss: 5.770627316974458
Training loss: 2.599125623703003 / Valid loss: 5.765208139873686
Training loss: 2.6260626316070557 / Valid loss: 5.77649191674732

Epoch: 68
Training loss: 4.151031494140625 / Valid loss: 5.780100842884608
Training loss: 2.802445888519287 / Valid loss: 5.776599893115816
Training loss: 2.5459022521972656 / Valid loss: 5.782875801268078
Training loss: 4.429739475250244 / Valid loss: 5.786506893521263
Training loss: 3.3202590942382812 / Valid loss: 5.7859147525969

Epoch: 69
Training loss: 3.2762880325317383 / Valid loss: 5.788768320991879
Training loss: 3.1122803688049316 / Valid loss: 5.785433762414115
Training loss: 3.304190158843994 / Valid loss: 5.790765342258272
Training loss: 4.249392509460449 / Valid loss: 5.794539301736014

Epoch: 70
Training loss: 4.878007411956787 / Valid loss: 5.7916629564194455
Training loss: 3.7626829147338867 / Valid loss: 5.790990804490589
Training loss: 2.643735885620117 / Valid loss: 5.798836367470877
Training loss: 3.6023385524749756 / Valid loss: 5.8012874262673515
Training loss: 2.88657808303833 / Valid loss: 5.804955498377482

Epoch: 71
Training loss: 3.0325655937194824 / Valid loss: 5.804740730921427
Training loss: 2.5312955379486084 / Valid loss: 5.802967848096575
Training loss: 2.723543405532837 / Valid loss: 5.805115182059152
Training loss: 2.748403787612915 / Valid loss: 5.805099037715367
Training loss: 2.3979454040527344 / Valid loss: 5.813731718063354

Epoch: 72
Training loss: 2.679192066192627 / Valid loss: 5.810329643885295
Training loss: 2.7999536991119385 / Valid loss: 5.813129683903285
Training loss: 4.325197219848633 / Valid loss: 5.821078377678281
Training loss: 2.7543139457702637 / Valid loss: 5.814128305798485
Training loss: 2.213597536087036 / Valid loss: 5.82210034869966

Epoch: 73
Training loss: 3.535512924194336 / Valid loss: 5.825808672677903
Training loss: 2.465883255004883 / Valid loss: 5.822462801706223
Training loss: 2.7475779056549072 / Valid loss: 5.827595118113926
Training loss: 4.220771312713623 / Valid loss: 5.831382124764579
Training loss: 2.207057237625122 / Valid loss: 5.832929574875605

Epoch: 74
Training loss: 2.2421319484710693 / Valid loss: 5.83697197550819
Training loss: 3.053487777709961 / Valid loss: 5.832024606068929
Training loss: 3.623783588409424 / Valid loss: 5.83503319422404
Training loss: 2.934361457824707 / Valid loss: 5.841305546533494
Training loss: 2.283827066421509 / Valid loss: 5.844550754910424

Epoch: 75
Training loss: 2.982245445251465 / Valid loss: 5.840948250180199
Training loss: 2.2674922943115234 / Valid loss: 5.847033686864943
Training loss: 2.2011313438415527 / Valid loss: 5.849360538664318
Training loss: 3.989914894104004 / Valid loss: 5.853579843611945
Training loss: 3.0736241340637207 / Valid loss: 5.85551659266154

Epoch: 76
Training loss: 2.2871499061584473 / Valid loss: 5.854394247418358
Training loss: 4.258310794830322 / Valid loss: 5.857054154078166
Training loss: 3.158263921737671 / Valid loss: 5.8557012626102996
Training loss: 3.5826613903045654 / Valid loss: 5.8620957692464195
Training loss: 2.9277169704437256 / Valid loss: 5.8507899488721575

Epoch: 77
Training loss: 3.01745867729187 / Valid loss: 5.866433277584258
Training loss: 2.654721975326538 / Valid loss: 5.863965050379435
Training loss: 3.3735239505767822 / Valid loss: 5.866654625393095
Training loss: 3.002575159072876 / Valid loss: 5.870097287495931
Training loss: 5.425280570983887 / Valid loss: 5.86985973176502

Epoch: 78
Training loss: 2.8559749126434326 / Valid loss: 5.876999961762201
Training loss: 3.279106616973877 / Valid loss: 5.88017935979934
Training loss: 3.450700283050537 / Valid loss: 5.875813901992071
Training loss: 2.2854714393615723 / Valid loss: 5.877109945388067
Training loss: 3.29436993598938 / Valid loss: 5.878605390730359

Epoch: 79
Training loss: 3.383833885192871 / Valid loss: 5.882157232647851
Training loss: 2.4011855125427246 / Valid loss: 5.886185580208188
Training loss: 2.3659310340881348 / Valid loss: 5.8894461790720625
Training loss: 2.829115390777588 / Valid loss: 5.891521581013998
ModuleList(
  (0): Linear(in_features=31191, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.361660875592913
Training regression with following parameters:
dnn_hidden_units : 2000, 100, 16
dropout_probs : 0.0, 0.0
learning_rate : 0.0001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : Adam
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : TFIDF
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=31191, out_features=2000, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=2000, out_features=100, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=100, out_features=16, bias=True)
  (9): Dropout(p=0, inplace=False)
  (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (11): LeakyReLU(negative_slope=0.02)
  (12): Linear(in_features=16, out_features=1, bias=True)
)

Epoch: 0
Training loss: 17.8549747467041 / Valid loss: 16.989478783380417
Model is saved in epoch 0, overall batch: 0
Training loss: 18.9604549407959 / Valid loss: 15.762811751592727
Model is saved in epoch 0, overall batch: 100
Training loss: 14.243934631347656 / Valid loss: 14.771505800882975
Model is saved in epoch 0, overall batch: 200
Training loss: 13.741157531738281 / Valid loss: 14.510727628072102
Model is saved in epoch 0, overall batch: 300
Training loss: 15.681009292602539 / Valid loss: 13.818933096386138
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 11.804765701293945 / Valid loss: 13.503786159697032
Model is saved in epoch 1, overall batch: 500
Training loss: 13.750184059143066 / Valid loss: 12.843889495304653
Model is saved in epoch 1, overall batch: 600
Training loss: 9.983104705810547 / Valid loss: 12.513324351537795
Model is saved in epoch 1, overall batch: 700
Training loss: 8.259761810302734 / Valid loss: 11.970251405806769
Model is saved in epoch 1, overall batch: 800
Training loss: 13.36345100402832 / Valid loss: 11.645839890979586
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 7.839372634887695 / Valid loss: 11.188460418156215
Model is saved in epoch 2, overall batch: 1000
Training loss: 5.438817024230957 / Valid loss: 10.850815664018903
Model is saved in epoch 2, overall batch: 1100
Training loss: 8.220318794250488 / Valid loss: 10.44327315830049
Model is saved in epoch 2, overall batch: 1200
Training loss: 3.4135053157806396 / Valid loss: 10.097323217846098
Model is saved in epoch 2, overall batch: 1300
Training loss: 4.968689918518066 / Valid loss: 9.965783055623373
Model is saved in epoch 2, overall batch: 1400

Epoch: 3
Training loss: 5.25254487991333 / Valid loss: 9.761306308564686
Model is saved in epoch 3, overall batch: 1500
Training loss: 4.542266845703125 / Valid loss: 9.606659843808128
Model is saved in epoch 3, overall batch: 1600
Training loss: 3.2191877365112305 / Valid loss: 9.191124171302432
Model is saved in epoch 3, overall batch: 1700
Training loss: 2.6893715858459473 / Valid loss: 9.037983372097923
Model is saved in epoch 3, overall batch: 1800
Training loss: 3.2533884048461914 / Valid loss: 8.503107770284016
Model is saved in epoch 3, overall batch: 1900

Epoch: 4
Training loss: 3.114194869995117 / Valid loss: 8.624888279324486
Training loss: 2.794037342071533 / Valid loss: 8.309217557452975
Model is saved in epoch 4, overall batch: 2100
Training loss: 2.236100673675537 / Valid loss: 8.56189973922003
Training loss: 2.0700531005859375 / Valid loss: 8.097637072063627
Model is saved in epoch 4, overall batch: 2300
Training loss: 2.303368330001831 / Valid loss: 7.930504085904076
Model is saved in epoch 4, overall batch: 2400

Epoch: 5
Training loss: 1.4887430667877197 / Valid loss: 7.874084981282552
Model is saved in epoch 5, overall batch: 2500
Training loss: 1.6395235061645508 / Valid loss: 7.654250360670543
Model is saved in epoch 5, overall batch: 2600
Training loss: 2.4753787517547607 / Valid loss: 7.4716542561848955
Model is saved in epoch 5, overall batch: 2700
Training loss: 2.903928518295288 / Valid loss: 7.601965154920306
Training loss: 1.3593859672546387 / Valid loss: 7.332349877130418
Model is saved in epoch 5, overall batch: 2900

Epoch: 6
Training loss: 1.2435369491577148 / Valid loss: 7.224972649982997
Model is saved in epoch 6, overall batch: 3000
Training loss: 1.0629594326019287 / Valid loss: 7.200286533719018
Model is saved in epoch 6, overall batch: 3100
Training loss: 0.6070163249969482 / Valid loss: 7.12367456299918
Model is saved in epoch 6, overall batch: 3200
Training loss: 0.8960704207420349 / Valid loss: 7.2148067701430545
Training loss: 0.8296201229095459 / Valid loss: 7.184710829598563

Epoch: 7
Training loss: 1.0243456363677979 / Valid loss: 6.9970308031354636
Model is saved in epoch 7, overall batch: 3500
Training loss: 1.323797345161438 / Valid loss: 7.070120816003708
Training loss: 0.37596988677978516 / Valid loss: 6.838238479977562
Model is saved in epoch 7, overall batch: 3700
Training loss: 0.6739439368247986 / Valid loss: 6.894528765905471
Training loss: 1.2239863872528076 / Valid loss: 6.917397549038841

Epoch: 8
Training loss: 0.5739498138427734 / Valid loss: 6.920224557604109
Training loss: 0.9101067781448364 / Valid loss: 6.876267950875419
Training loss: 0.6599305868148804 / Valid loss: 6.770483936582293
Model is saved in epoch 8, overall batch: 4200
Training loss: 0.8790944814682007 / Valid loss: 6.845487590063186
Training loss: 0.47576233744621277 / Valid loss: 6.91627949987139

Epoch: 9
Training loss: 0.33581334352493286 / Valid loss: 6.897675300779797
Training loss: 1.003495693206787 / Valid loss: 6.821571404593332
Training loss: 0.9544498920440674 / Valid loss: 6.771408530644008
Training loss: 0.3690384328365326 / Valid loss: 6.802124409448533

Epoch: 10
Training loss: 0.5431381464004517 / Valid loss: 6.902392123994373
Training loss: 0.45153895020484924 / Valid loss: 6.8260498637244815
Training loss: 0.46570736169815063 / Valid loss: 6.806181975773403
Training loss: 0.7411077618598938 / Valid loss: 6.87525247846331
Training loss: 0.39238643646240234 / Valid loss: 6.88486974352882

Epoch: 11
Training loss: 0.5609350204467773 / Valid loss: 6.815281466075352
Training loss: 0.5107731819152832 / Valid loss: 6.875526600792295
Training loss: 0.2644200325012207 / Valid loss: 6.844042448770432
Training loss: 0.606702983379364 / Valid loss: 6.778639443715414
Training loss: 0.5604170560836792 / Valid loss: 6.934774609974452

Epoch: 12
Training loss: 0.5473272800445557 / Valid loss: 6.803172888074602
Training loss: 0.39758217334747314 / Valid loss: 6.73669995807466
Model is saved in epoch 12, overall batch: 6000
Training loss: 0.3088725805282593 / Valid loss: 6.7955768630618145
Training loss: 0.4500817060470581 / Valid loss: 6.850722044990176
Training loss: 0.3779047727584839 / Valid loss: 6.832348405747187

Epoch: 13
Training loss: 0.5579949021339417 / Valid loss: 6.8155485471089685
Training loss: 0.2153196483850479 / Valid loss: 6.82216705594744
Training loss: 0.3301597833633423 / Valid loss: 6.836717868986584
Training loss: 0.44077762961387634 / Valid loss: 6.928799869900658
Training loss: 0.6700647473335266 / Valid loss: 6.8441530704498295

Epoch: 14
Training loss: 0.5292296409606934 / Valid loss: 6.785062812623524
Training loss: 0.5539875030517578 / Valid loss: 6.746500941685268
Training loss: 0.24252499639987946 / Valid loss: 6.766802706037249
Training loss: 0.3379790186882019 / Valid loss: 6.730667554764521
Model is saved in epoch 14, overall batch: 7200
Training loss: 0.3836494982242584 / Valid loss: 6.84228717031933

Epoch: 15
Training loss: 0.3520006537437439 / Valid loss: 6.792228062947591
Training loss: 0.3449285626411438 / Valid loss: 6.718585718245733
Model is saved in epoch 15, overall batch: 7500
Training loss: 0.2460244596004486 / Valid loss: 6.757302138918922
Training loss: 0.3163890838623047 / Valid loss: 6.797678958801996
Training loss: 0.2651504874229431 / Valid loss: 6.81274816876366

Epoch: 16
Training loss: 0.33195167779922485 / Valid loss: 6.783235858735584
Training loss: 0.7072224020957947 / Valid loss: 6.7611717542012535
Training loss: 0.33475959300994873 / Valid loss: 6.804534128734043
Training loss: 0.39051055908203125 / Valid loss: 6.815451136089506
Training loss: 0.5698040723800659 / Valid loss: 6.785856033506848

Epoch: 17
Training loss: 0.442054808139801 / Valid loss: 6.734289146604992
Training loss: 0.3011819124221802 / Valid loss: 6.765458869934082
Training loss: 0.2919681966304779 / Valid loss: 6.84344208581107
Training loss: 0.2771933376789093 / Valid loss: 6.807620212009975
Training loss: 0.42575299739837646 / Valid loss: 6.7521776063101635

Epoch: 18
Training loss: 0.37893521785736084 / Valid loss: 6.673490883055187
Model is saved in epoch 18, overall batch: 8900
Training loss: 0.343404620885849 / Valid loss: 6.690603238060361
Training loss: 0.3835693597793579 / Valid loss: 6.74746135075887
Training loss: 0.2721300721168518 / Valid loss: 6.8038202694484164
Training loss: 0.21042373776435852 / Valid loss: 6.837271081833612

Epoch: 19
Training loss: 0.2939293086528778 / Valid loss: 6.709373392377581
Training loss: 0.204054594039917 / Valid loss: 6.765358102889288
Training loss: 0.7189841270446777 / Valid loss: 6.8167487871079215
Training loss: 0.22793957591056824 / Valid loss: 6.74536295845395

Epoch: 20
Training loss: 0.27458927035331726 / Valid loss: 6.818800258636474
Training loss: 0.643502950668335 / Valid loss: 6.703916043326968
Training loss: 0.40919923782348633 / Valid loss: 6.860252203260149
Training loss: 0.39447689056396484 / Valid loss: 6.815677613303775
Training loss: 0.3174591660499573 / Valid loss: 6.841670899164109

Epoch: 21
Training loss: 0.70247483253479 / Valid loss: 6.753223936898368
Training loss: 0.42034056782722473 / Valid loss: 6.735323435919625
Training loss: 0.15986913442611694 / Valid loss: 6.7830505961463565
Training loss: 0.17195415496826172 / Valid loss: 6.727358089174543
Training loss: 0.20520547032356262 / Valid loss: 6.752349424362182

Epoch: 22
Training loss: 0.2752501368522644 / Valid loss: 6.821345449629284
Training loss: 0.49725693464279175 / Valid loss: 6.7384551911127
Training loss: 0.6506203413009644 / Valid loss: 6.756122847965785
Training loss: 0.20125806331634521 / Valid loss: 6.84979684920538
Training loss: 0.20270155370235443 / Valid loss: 6.796430587768555

Epoch: 23
Training loss: 0.6763166189193726 / Valid loss: 6.73906325385684
Training loss: 0.39856815338134766 / Valid loss: 6.718262577056885
Training loss: 0.34340327978134155 / Valid loss: 6.811808717818487
Training loss: 0.21485087275505066 / Valid loss: 6.761248506818499
Training loss: 0.342002809047699 / Valid loss: 6.889806552160354

Epoch: 24
Training loss: 0.23928409814834595 / Valid loss: 6.775109811056228
Training loss: 0.18139633536338806 / Valid loss: 6.735822184880575
Training loss: 0.27855145931243896 / Valid loss: 6.775829269772484
Training loss: 0.18065029382705688 / Valid loss: 6.8156948679969425
Training loss: 0.6007393002510071 / Valid loss: 6.805187166304815

Epoch: 25
Training loss: 0.21475335955619812 / Valid loss: 6.8273999304998485
Training loss: 0.27679356932640076 / Valid loss: 6.737676584152949
Training loss: 0.21858522295951843 / Valid loss: 6.737405558994838
Training loss: 0.22296936810016632 / Valid loss: 6.79356575012207
Training loss: 0.2844315767288208 / Valid loss: 6.820682012467158

Epoch: 26
Training loss: 0.23756247758865356 / Valid loss: 6.7038420427413214
Training loss: 0.7757533192634583 / Valid loss: 6.767373087292626
Training loss: 0.21082910895347595 / Valid loss: 6.689236502420335
Training loss: 0.2861737608909607 / Valid loss: 6.753827424276443
Training loss: 0.3284309506416321 / Valid loss: 6.760358390353975

Epoch: 27
Training loss: 0.138717383146286 / Valid loss: 6.750019486745199
Training loss: 0.28578293323516846 / Valid loss: 6.837595894223168
Training loss: 0.5274522304534912 / Valid loss: 6.871369820549375
Training loss: 0.18951624631881714 / Valid loss: 6.774052887871152
Training loss: 0.11294794082641602 / Valid loss: 6.738321147646222

Epoch: 28
Training loss: 0.24426952004432678 / Valid loss: 6.706620000657582
Training loss: 0.26223990321159363 / Valid loss: 6.759342861175537
Training loss: 0.4751245975494385 / Valid loss: 6.759523373558408
Training loss: 0.24936622381210327 / Valid loss: 6.707304162070865
Training loss: 0.23779667913913727 / Valid loss: 6.694358369282313

Epoch: 29
Training loss: 0.14186403155326843 / Valid loss: 6.750195753006708
Training loss: 0.2177591174840927 / Valid loss: 6.782495691662743
Training loss: 0.2107696235179901 / Valid loss: 6.81010008312407
Training loss: 0.3349123001098633 / Valid loss: 6.713498574211484

Epoch: 30
Training loss: 0.2155487984418869 / Valid loss: 6.745994713192895
Training loss: 0.5554934144020081 / Valid loss: 6.704826407205491
Training loss: 0.28896546363830566 / Valid loss: 6.69459121340797
Training loss: 0.2955531179904938 / Valid loss: 6.715953531719389
Training loss: 0.7332888841629028 / Valid loss: 6.737763291313534

Epoch: 31
Training loss: 0.2328016310930252 / Valid loss: 6.719991379692441
Training loss: 0.11600129306316376 / Valid loss: 6.8069935889471145
Training loss: 0.22605513036251068 / Valid loss: 6.7579528445289245
Training loss: 0.10836049914360046 / Valid loss: 6.786216295333135
Training loss: 0.13793343305587769 / Valid loss: 6.76075503939674

Epoch: 32
Training loss: 0.22300365567207336 / Valid loss: 6.725256161462693
Training loss: 0.2218417078256607 / Valid loss: 6.801505751836867
Training loss: 0.16937069594860077 / Valid loss: 6.742709788821992
Training loss: 0.25928357243537903 / Valid loss: 6.72525681086949
Training loss: 0.16320383548736572 / Valid loss: 6.764471483230591

Epoch: 33
Training loss: 0.15947052836418152 / Valid loss: 6.842311568487258
Training loss: 0.19248315691947937 / Valid loss: 6.770128157025292
Training loss: 0.20160116255283356 / Valid loss: 6.680939161209833
Training loss: 0.1611499935388565 / Valid loss: 6.748599274953206
Training loss: 0.1470526158809662 / Valid loss: 6.748466941288539

Epoch: 34
Training loss: 0.1859557181596756 / Valid loss: 6.772602047239031
Training loss: 0.1188066154718399 / Valid loss: 6.741887959979829
Training loss: 0.16587860882282257 / Valid loss: 6.772767019271851
Training loss: 0.17384807765483856 / Valid loss: 6.769509401775542
Training loss: 0.6138131022453308 / Valid loss: 6.71676801953997

Epoch: 35
Training loss: 0.21274614334106445 / Valid loss: 6.706857790265764
Training loss: 0.16994579136371613 / Valid loss: 6.7238447348276775
Training loss: 0.16680774092674255 / Valid loss: 6.765249983469645
Training loss: 0.2880183756351471 / Valid loss: 6.790684409368605
Training loss: 0.21892127394676208 / Valid loss: 6.734586397806804

Epoch: 36
Training loss: 0.2579687833786011 / Valid loss: 6.704917485373361
Training loss: 0.37556058168411255 / Valid loss: 6.791302245003837
Training loss: 0.5738528966903687 / Valid loss: 6.688610058739072
Training loss: 0.46552810072898865 / Valid loss: 6.729285140264602
Training loss: 0.10767881572246552 / Valid loss: 6.675568462553478

Epoch: 37
Training loss: 0.12111412733793259 / Valid loss: 6.675740264710926
Training loss: 0.14752483367919922 / Valid loss: 6.775943124861945
Training loss: 0.24527713656425476 / Valid loss: 6.719796846026466
Training loss: 0.7367719411849976 / Valid loss: 6.7095755781446185
Training loss: 0.4818275570869446 / Valid loss: 6.76403268178304

Epoch: 38
Training loss: 0.15818670392036438 / Valid loss: 6.773845404670352
Training loss: 0.08949186652898788 / Valid loss: 6.7507500625792005
Training loss: 0.27375492453575134 / Valid loss: 6.770172927493141
Training loss: 0.14869996905326843 / Valid loss: 6.74221848533267
Training loss: 0.3657069206237793 / Valid loss: 6.78048970812843

Epoch: 39
Training loss: 0.1467004269361496 / Valid loss: 6.806995189757574
Training loss: 0.3146520256996155 / Valid loss: 6.815779926663353
Training loss: 0.15105512738227844 / Valid loss: 6.6881218456086655
Training loss: 0.18484662473201752 / Valid loss: 6.710921205793109

Epoch: 40
Training loss: 0.24268168210983276 / Valid loss: 6.833500412532262
Training loss: 0.8865512609481812 / Valid loss: 6.839860416594005
Training loss: 0.41935473680496216 / Valid loss: 6.823834582737514
Training loss: 0.33193713426589966 / Valid loss: 6.743218231201172
Training loss: 0.18458688259124756 / Valid loss: 6.868295578729539

Epoch: 41
Training loss: 0.09796421229839325 / Valid loss: 6.8423591863541375
Training loss: 0.18760676681995392 / Valid loss: 6.897700032733735
Training loss: 0.12334878742694855 / Valid loss: 6.732494000026158
Training loss: 0.25222912430763245 / Valid loss: 6.744387281508673
Training loss: 0.6141803860664368 / Valid loss: 6.810506239391509

Epoch: 42
Training loss: 0.0871838927268982 / Valid loss: 6.850833874657041
Training loss: 0.10765432566404343 / Valid loss: 6.855767906279791
Training loss: 0.1666443645954132 / Valid loss: 6.873563303266253
Training loss: 0.14296188950538635 / Valid loss: 6.93103343191601
Training loss: 0.13979478180408478 / Valid loss: 6.818251287369501

Epoch: 43
Training loss: 0.09833917766809464 / Valid loss: 6.912834228788103
Training loss: 0.12582555413246155 / Valid loss: 6.837584786188035
Training loss: 0.17678439617156982 / Valid loss: 6.734565344310942
Training loss: 0.22498297691345215 / Valid loss: 6.83347867784046
Training loss: 0.14048334956169128 / Valid loss: 6.8786247480483285

Epoch: 44
Training loss: 0.1307177096605301 / Valid loss: 6.785913401558286
Training loss: 0.24200734496116638 / Valid loss: 6.850002538590204
Training loss: 0.6108654737472534 / Valid loss: 6.877763135092599
Training loss: 0.2276945859193802 / Valid loss: 6.931619258154006
Training loss: 0.12350982427597046 / Valid loss: 6.89790678024292

Epoch: 45
Training loss: 0.12574756145477295 / Valid loss: 6.922036706833612
Training loss: 0.09312760084867477 / Valid loss: 6.824004027957008
Training loss: 0.22115711867809296 / Valid loss: 6.844513075692313
Training loss: 0.0943773165345192 / Valid loss: 6.914994709832328
Training loss: 0.12617112696170807 / Valid loss: 6.799103082929339

Epoch: 46
Training loss: 0.14519141614437103 / Valid loss: 7.099786002295358
Training loss: 0.09703830629587173 / Valid loss: 6.830905787150065
Training loss: 0.10733605176210403 / Valid loss: 6.831703699202764
Training loss: 0.23952341079711914 / Valid loss: 6.8066092922573995
Training loss: 0.13349032402038574 / Valid loss: 6.975599611373175

Epoch: 47
Training loss: 0.11106947064399719 / Valid loss: 6.826738511948358
Training loss: 0.1834861785173416 / Valid loss: 7.0080832027253654
Training loss: 0.1752929985523224 / Valid loss: 6.832869195938111
Training loss: 0.1063852459192276 / Valid loss: 6.810456437156314
Training loss: 0.21840934455394745 / Valid loss: 6.845311423710414

Epoch: 48
Training loss: 0.532417356967926 / Valid loss: 6.986419255392892
Training loss: 0.44850394129753113 / Valid loss: 6.82317898614066
Training loss: 0.17254194617271423 / Valid loss: 6.880294268471854
Training loss: 0.19412803649902344 / Valid loss: 6.8550992216382705
Training loss: 0.08929486572742462 / Valid loss: 6.961398113341558

Epoch: 49
Training loss: 0.26246148347854614 / Valid loss: 6.877382251194545
Training loss: 0.14045149087905884 / Valid loss: 6.97333037512643
Training loss: 0.24116340279579163 / Valid loss: 6.847129156475975
Training loss: 0.1383802890777588 / Valid loss: 6.91875954809643

Epoch: 50
Training loss: 0.18775472044944763 / Valid loss: 6.854856411616008
Training loss: 0.05393245816230774 / Valid loss: 6.760244471686227
Training loss: 0.09429730474948883 / Valid loss: 7.05201294308617
Training loss: 0.5614858865737915 / Valid loss: 7.032216812315442
Training loss: 0.166789710521698 / Valid loss: 6.940817287990025

Epoch: 51
Training loss: 0.08838969469070435 / Valid loss: 6.9177889687674385
Training loss: 0.3946807384490967 / Valid loss: 6.901929196857271
Training loss: 0.17770138382911682 / Valid loss: 6.979179884138562
Training loss: 0.10598461329936981 / Valid loss: 7.031696769169399
Training loss: 0.08524549752473831 / Valid loss: 6.9035942895071845

Epoch: 52
Training loss: 0.22540171444416046 / Valid loss: 7.035510944184803
Training loss: 0.16373470425605774 / Valid loss: 6.8435194787524996
Training loss: 0.26985692977905273 / Valid loss: 6.797365651811872
Training loss: 0.12655511498451233 / Valid loss: 6.851542515981765
Training loss: 0.14466170966625214 / Valid loss: 6.848220489138648

Epoch: 53
Training loss: 0.0798879861831665 / Valid loss: 6.89837369010562
Training loss: 0.2173880934715271 / Valid loss: 6.932004476728894
Training loss: 0.10887087136507034 / Valid loss: 7.013921190443493
Training loss: 0.1707330346107483 / Valid loss: 7.013428025018602
Training loss: 0.7517258524894714 / Valid loss: 6.823526096343994

Epoch: 54
Training loss: 0.09873397648334503 / Valid loss: 6.85842440241859
Training loss: 0.18456783890724182 / Valid loss: 6.937305713835217
Training loss: 0.06925146281719208 / Valid loss: 6.930875137874058
Training loss: 0.11013475060462952 / Valid loss: 6.961006427946545
Training loss: 0.05895671993494034 / Valid loss: 6.941041896456764

Epoch: 55
Training loss: 0.10644043982028961 / Valid loss: 7.132105059850783
Training loss: 0.05570812523365021 / Valid loss: 6.98681941259475
Training loss: 0.10400187969207764 / Valid loss: 6.8899191402253654
Training loss: 0.07235163450241089 / Valid loss: 6.990779200054351
Training loss: 0.07106949388980865 / Valid loss: 6.983898221878778

Epoch: 56
Training loss: 0.22758229076862335 / Valid loss: 6.903576337723505
Training loss: 0.10633387416601181 / Valid loss: 6.957822786058698
Training loss: 0.09375244379043579 / Valid loss: 6.897053364345005
Training loss: 0.20841558277606964 / Valid loss: 6.9481583686102
Training loss: 0.10436102747917175 / Valid loss: 7.043185937972296

Epoch: 57
Training loss: 0.06919128447771072 / Valid loss: 6.906607795896984
Training loss: 0.12767204642295837 / Valid loss: 6.933333256131127
Training loss: 0.17195865511894226 / Valid loss: 6.937404646192278
Training loss: 0.13192757964134216 / Valid loss: 6.938640060878935
Training loss: 0.28574132919311523 / Valid loss: 6.922419934045701

Epoch: 58
Training loss: 0.08835254609584808 / Valid loss: 6.883179473876953
Training loss: 0.10058391094207764 / Valid loss: 6.979378768375942
Training loss: 0.056422844529151917 / Valid loss: 7.13513248080299
Training loss: 0.11147622764110565 / Valid loss: 7.121637678146362
Training loss: 0.05716065317392349 / Valid loss: 7.046635645911807

Epoch: 59
Training loss: 0.3894351124763489 / Valid loss: 6.847324080694289
Training loss: 0.2457713484764099 / Valid loss: 7.0283326875595815
Training loss: 0.13790163397789001 / Valid loss: 7.01744004431225
Training loss: 0.07203835994005203 / Valid loss: 6.919436118716285

Epoch: 60
Training loss: 0.23871490359306335 / Valid loss: 6.904490747905913
Training loss: 0.0864180475473404 / Valid loss: 6.984951323554629
Training loss: 0.05549604073166847 / Valid loss: 6.901603031158447
Training loss: 0.16755035519599915 / Valid loss: 6.923541693460374
Training loss: 0.09301458299160004 / Valid loss: 7.273300906590053

Epoch: 61
Training loss: 0.13424958288669586 / Valid loss: 7.00738160269601
Training loss: 0.07446512579917908 / Valid loss: 7.056248267491658
Training loss: 0.2886367440223694 / Valid loss: 7.094382626669748
Training loss: 0.26771414279937744 / Valid loss: 7.018891339074997
Training loss: 0.5726991891860962 / Valid loss: 7.073160062517439

Epoch: 62
Training loss: 0.16249503195285797 / Valid loss: 7.051714315868559
Training loss: 0.096653513610363 / Valid loss: 6.964095211029052
Training loss: 0.31129205226898193 / Valid loss: 7.043633624485561
Training loss: 0.08127106726169586 / Valid loss: 6.996306012925648
Training loss: 0.08375158905982971 / Valid loss: 6.817539206005278

Epoch: 63
Training loss: 0.11783933639526367 / Valid loss: 7.134723908560616
Training loss: 0.07288572192192078 / Valid loss: 6.998327218918574
Training loss: 0.40077313780784607 / Valid loss: 7.08628157206944
Training loss: 0.052016276866197586 / Valid loss: 6.936652712594896
Training loss: 0.10090330243110657 / Valid loss: 6.9562779222215925

Epoch: 64
Training loss: 0.09740038216114044 / Valid loss: 7.0330250989823115
Training loss: 0.30107802152633667 / Valid loss: 7.01634977885655
Training loss: 0.10656733810901642 / Valid loss: 7.086569926852271
Training loss: 0.06407548487186432 / Valid loss: 7.003480152856736
Training loss: 0.27979356050491333 / Valid loss: 6.898050285521007

Epoch: 65
Training loss: 0.0862683355808258 / Valid loss: 6.991407694135393
Training loss: 0.08825109153985977 / Valid loss: 7.048659574417841
Training loss: 0.08454278856515884 / Valid loss: 7.008080841246105
Training loss: 0.10744494199752808 / Valid loss: 6.946549302055722
Training loss: 0.1464257538318634 / Valid loss: 7.079771777561732

Epoch: 66
Training loss: 0.10018539428710938 / Valid loss: 6.997560058321271
Training loss: 0.07856592535972595 / Valid loss: 7.10513371967134
Training loss: 0.08805385231971741 / Valid loss: 7.012560204097203
Training loss: 0.0632753074169159 / Valid loss: 6.92860997063773
Training loss: 0.10117952525615692 / Valid loss: 7.026523058755057

Epoch: 67
Training loss: 0.08577249199151993 / Valid loss: 7.098358617510114
Training loss: 0.11530596017837524 / Valid loss: 6.969489251999628
Training loss: 0.07358796894550323 / Valid loss: 7.098583321344285
Training loss: 0.05905601382255554 / Valid loss: 7.08837248030163
Training loss: 0.11405470967292786 / Valid loss: 7.0278523172651015

Epoch: 68
Training loss: 0.2847602963447571 / Valid loss: 7.000750101180303
Training loss: 0.10292629897594452 / Valid loss: 7.015858738762992
Training loss: 0.1751161515712738 / Valid loss: 7.267218394506545
Training loss: 0.07617217302322388 / Valid loss: 7.1915805090041385
Training loss: 0.05265933275222778 / Valid loss: 7.054323677789597

Epoch: 69
Training loss: 0.1110537126660347 / Valid loss: 6.944326355343773
Training loss: 0.2473362386226654 / Valid loss: 7.236773350125268
Training loss: 0.2592082619667053 / Valid loss: 7.127065072740828
Training loss: 0.6848050951957703 / Valid loss: 7.1512556144169395

Epoch: 70
Training loss: 0.06036616116762161 / Valid loss: 7.053172974359422
Training loss: 0.04075025022029877 / Valid loss: 7.07561369850522
Training loss: 0.07233823835849762 / Valid loss: 7.092010225568499
Training loss: 0.08535849303007126 / Valid loss: 7.137091732025146
Training loss: 0.32504284381866455 / Valid loss: 7.218168908073789

Epoch: 71
Training loss: 0.10710638016462326 / Valid loss: 7.137215037572951
Training loss: 0.18046808242797852 / Valid loss: 6.964699050358363
Training loss: 0.07885238528251648 / Valid loss: 7.218156451270694
Training loss: 0.3720303177833557 / Valid loss: 7.077427632468087
Training loss: 0.2260170876979828 / Valid loss: 7.136653350648426

Epoch: 72
Training loss: 0.05617116391658783 / Valid loss: 7.150716872442336
Training loss: 0.053185634315013885 / Valid loss: 7.11407726378668
Training loss: 0.10599721968173981 / Valid loss: 7.012875627336048
Training loss: 0.04282351955771446 / Valid loss: 7.098653130304246
Training loss: 0.11031921207904816 / Valid loss: 7.089369742075602

Epoch: 73
Training loss: 0.07273522764444351 / Valid loss: 7.210893417540051
Training loss: 0.38763439655303955 / Valid loss: 7.120501252583095
Training loss: 0.12027101218700409 / Valid loss: 7.235047390347435
Training loss: 0.08964146673679352 / Valid loss: 7.153362862269083
Training loss: 0.19342058897018433 / Valid loss: 7.148126640773955

Epoch: 74
Training loss: 0.24807089567184448 / Valid loss: 6.986827032906668
Training loss: 0.07989129424095154 / Valid loss: 6.994494855971563
Training loss: 0.1040542870759964 / Valid loss: 7.1238726661318825
Training loss: 0.07722268998622894 / Valid loss: 7.196874918256487
Training loss: 0.2748016119003296 / Valid loss: 7.075822248912993

Epoch: 75
Training loss: 0.16021983325481415 / Valid loss: 7.144443798065185
Training loss: 0.05775073915719986 / Valid loss: 7.146049313318162
Training loss: 0.1346433460712433 / Valid loss: 7.2049647898901075
Training loss: 0.07258260995149612 / Valid loss: 7.177973574683779
Training loss: 0.07012341916561127 / Valid loss: 7.16645454906282

Epoch: 76
Training loss: 0.08442454785108566 / Valid loss: 7.186559777032762
Training loss: 0.05487033724784851 / Valid loss: 7.06132291612171
Training loss: 0.05423210933804512 / Valid loss: 7.1577288445972265
Training loss: 0.08709464967250824 / Valid loss: 7.0567154157729375
Training loss: 0.16755810379981995 / Valid loss: 7.0863244964962915

Epoch: 77
Training loss: 0.03660484030842781 / Valid loss: 7.094052001408168
Training loss: 0.1518356204032898 / Valid loss: 7.050570008868263
Training loss: 0.11137942969799042 / Valid loss: 7.1466208230881465
Training loss: 0.14490467309951782 / Valid loss: 7.106634224028815
Training loss: 0.2388947308063507 / Valid loss: 7.08057655606951

Epoch: 78
Training loss: 0.11090952157974243 / Valid loss: 7.106873489561535
Training loss: 0.10779152810573578 / Valid loss: 7.166087118784587
Training loss: 0.06455573439598083 / Valid loss: 7.194926320938837
Training loss: 0.06320913136005402 / Valid loss: 7.233641992296492
Training loss: 0.06352291256189346 / Valid loss: 7.1874666531880695

Epoch: 79
Training loss: 0.11264802515506744 / Valid loss: 7.2229945228213355
Training loss: 0.07593527436256409 / Valid loss: 7.147082828340077
Training loss: 0.18726882338523865 / Valid loss: 7.0578921545119515
Training loss: 0.13739557564258575 / Valid loss: 7.29256226675851
ModuleList(
  (0): Linear(in_features=31191, out_features=2000, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=2000, out_features=100, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=100, out_features=16, bias=True)
  (9): Dropout(p=0, inplace=False)
  (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (11): LeakyReLU(negative_slope=0.02)
  (12): Linear(in_features=16, out_features=1, bias=True)
)
Loss on test set of optimal model: 6.624967363902501
Training regression with following parameters:
dnn_hidden_units : 300, 32
dropout_probs : 0.0, 0.0
learning_rate : 0.0001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : Adam
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : TFIDF
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=31191, out_features=300, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=300, out_features=32, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=32, out_features=1, bias=True)
)

Epoch: 0
Training loss: 14.313697814941406 / Valid loss: 15.753696487063454
Model is saved in epoch 0, overall batch: 0
Training loss: 14.843012809753418 / Valid loss: 15.198961430504209
Model is saved in epoch 0, overall batch: 100
Training loss: 12.712383270263672 / Valid loss: 13.58493992033459
Model is saved in epoch 0, overall batch: 200
Training loss: 7.54456901550293 / Valid loss: 12.540274093264625
Model is saved in epoch 0, overall batch: 300
Training loss: 8.390302658081055 / Valid loss: 11.754547341664631
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 7.468027114868164 / Valid loss: 11.292772497449603
Model is saved in epoch 1, overall batch: 500
Training loss: 7.5129194259643555 / Valid loss: 10.905619607652937
Model is saved in epoch 1, overall batch: 600
Training loss: 9.747920989990234 / Valid loss: 10.27510727019537
Model is saved in epoch 1, overall batch: 700
Training loss: 6.703456401824951 / Valid loss: 9.654329813094366
Model is saved in epoch 1, overall batch: 800
Training loss: 8.732757568359375 / Valid loss: 9.569907106672014
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 5.537815093994141 / Valid loss: 8.976354181198847
Model is saved in epoch 2, overall batch: 1000
Training loss: 3.0763401985168457 / Valid loss: 8.747594433739073
Model is saved in epoch 2, overall batch: 1100
Training loss: 3.017594337463379 / Valid loss: 8.351310007912772
Model is saved in epoch 2, overall batch: 1200
Training loss: 2.6979565620422363 / Valid loss: 8.000102960495722
Model is saved in epoch 2, overall batch: 1300
Training loss: 4.254835605621338 / Valid loss: 7.81107732682001
Model is saved in epoch 2, overall batch: 1400

Epoch: 3
Training loss: 1.0351741313934326 / Valid loss: 7.278098776226952
Model is saved in epoch 3, overall batch: 1500
Training loss: 3.1401891708374023 / Valid loss: 7.487479109991164
Training loss: 2.6856250762939453 / Valid loss: 7.228772081647601
Model is saved in epoch 3, overall batch: 1700
Training loss: 2.546393394470215 / Valid loss: 7.080998906635103
Model is saved in epoch 3, overall batch: 1800
Training loss: 3.2788634300231934 / Valid loss: 6.996843755812872
Model is saved in epoch 3, overall batch: 1900

Epoch: 4
Training loss: 0.9358392953872681 / Valid loss: 6.847386791592553
Model is saved in epoch 4, overall batch: 2000
Training loss: 1.4807868003845215 / Valid loss: 6.854435625530424
Training loss: 1.246139645576477 / Valid loss: 6.784021718161447
Model is saved in epoch 4, overall batch: 2200
Training loss: 1.7047181129455566 / Valid loss: 6.722559842609224
Model is saved in epoch 4, overall batch: 2300
Training loss: 1.2468078136444092 / Valid loss: 6.743357533500308

Epoch: 5
Training loss: 0.7861952781677246 / Valid loss: 6.652912301108951
Model is saved in epoch 5, overall batch: 2500
Training loss: 1.3788580894470215 / Valid loss: 6.71295067469279
Training loss: 1.2559242248535156 / Valid loss: 6.750842341922579
Training loss: 1.1910043954849243 / Valid loss: 6.725674020676386
Training loss: 1.1267448663711548 / Valid loss: 6.761905029841832

Epoch: 6
Training loss: 0.6802124381065369 / Valid loss: 6.68127848534357
Training loss: 0.84412682056427 / Valid loss: 6.697375520070394
Training loss: 0.734642744064331 / Valid loss: 6.771144471849714
Training loss: 0.7603549957275391 / Valid loss: 6.815760178793044
Training loss: 0.7949017286300659 / Valid loss: 6.714059112185524

Epoch: 7
Training loss: 0.47565892338752747 / Valid loss: 6.742375369299026
Training loss: 0.5359765887260437 / Valid loss: 6.855217910948253
Training loss: 0.8194750547409058 / Valid loss: 6.792947828202021
Training loss: 0.6615052223205566 / Valid loss: 6.878000223068964
Training loss: 0.6660894751548767 / Valid loss: 6.8053489003862655

Epoch: 8
Training loss: 0.4774850010871887 / Valid loss: 6.709632614680699
Training loss: 0.6075410842895508 / Valid loss: 6.824116738637288
Training loss: 0.6927942037582397 / Valid loss: 6.77047917502267
Training loss: 0.29866868257522583 / Valid loss: 6.795749514443534
Training loss: 1.1487510204315186 / Valid loss: 6.7895909173148015

Epoch: 9
Training loss: 0.5340440273284912 / Valid loss: 6.76542702175322
Training loss: 0.5181180238723755 / Valid loss: 6.718706571488154
Training loss: 0.7883564233779907 / Valid loss: 6.776568212963286
Training loss: 1.1910607814788818 / Valid loss: 6.880406136739822

Epoch: 10
Training loss: 0.5802440047264099 / Valid loss: 6.911107676369803
Training loss: 0.49433040618896484 / Valid loss: 6.850507699875605
Training loss: 0.5767273902893066 / Valid loss: 6.848765709286645
Training loss: 0.4102814197540283 / Valid loss: 6.775330854597546
Training loss: 0.34525424242019653 / Valid loss: 6.830074909755162

Epoch: 11
Training loss: 0.5158448219299316 / Valid loss: 6.808866514478411
Training loss: 0.4288245439529419 / Valid loss: 6.787001646132696
Training loss: 0.5912654399871826 / Valid loss: 6.7744750431605745
Training loss: 0.4460943341255188 / Valid loss: 6.930423595791772
Training loss: 0.8701084852218628 / Valid loss: 6.779766144071306

Epoch: 12
Training loss: 0.5356260538101196 / Valid loss: 6.788479491642543
Training loss: 0.34373313188552856 / Valid loss: 6.816744032360258
Training loss: 0.3341811001300812 / Valid loss: 6.947468448820568
Training loss: 0.7505641579627991 / Valid loss: 6.854166653042748
Training loss: 0.5425981283187866 / Valid loss: 6.870962524414063

Epoch: 13
Training loss: 0.919853687286377 / Valid loss: 6.729379406429472
Training loss: 0.3413366675376892 / Valid loss: 6.814873727162679
Training loss: 0.4469653367996216 / Valid loss: 6.789065556299119
Training loss: 0.4784347116947174 / Valid loss: 6.890804354349772
Training loss: 0.45670580863952637 / Valid loss: 6.891915053413028

Epoch: 14
Training loss: 0.2549247741699219 / Valid loss: 6.789233475639707
Training loss: 0.5498886108398438 / Valid loss: 6.78699756349836
Training loss: 0.3895449936389923 / Valid loss: 6.791758705320812
Training loss: 0.42763280868530273 / Valid loss: 6.985291944231306
Training loss: 0.3501206338405609 / Valid loss: 6.84551659311567

Epoch: 15
Training loss: 0.5708348751068115 / Valid loss: 6.7094566345214846
Training loss: 0.23369169235229492 / Valid loss: 6.846040993645078
Training loss: 1.160614252090454 / Valid loss: 6.8173124177115305
Training loss: 0.5568310618400574 / Valid loss: 6.878842022305443
Training loss: 1.336945652961731 / Valid loss: 6.810163447970436

Epoch: 16
Training loss: 0.3346955478191376 / Valid loss: 6.856548091343471
Training loss: 0.6348859071731567 / Valid loss: 6.819860594613211
Training loss: 0.7172620892524719 / Valid loss: 6.894623701913016
Training loss: 0.6916841268539429 / Valid loss: 6.908578361783709
Training loss: 0.3409446179866791 / Valid loss: 6.882897472381591

Epoch: 17
Training loss: 0.2929670512676239 / Valid loss: 6.826634815761021
Training loss: 0.202987939119339 / Valid loss: 6.794696335565476
Training loss: 0.35849833488464355 / Valid loss: 6.8163499196370445
Training loss: 0.6253277659416199 / Valid loss: 6.876091425759451
Training loss: 0.24133768677711487 / Valid loss: 6.921649101802281

Epoch: 18
Training loss: 0.2207256704568863 / Valid loss: 6.766701934451149
Training loss: 0.5001040697097778 / Valid loss: 6.795575341724214
Training loss: 0.29343461990356445 / Valid loss: 6.778574080694289
Training loss: 0.2670270502567291 / Valid loss: 6.894643356686546
Training loss: 0.3846880793571472 / Valid loss: 6.791883595784506

Epoch: 19
Training loss: 0.36628246307373047 / Valid loss: 6.784356183097476
Training loss: 0.3995077311992645 / Valid loss: 6.838403574625651
Training loss: 0.21255606412887573 / Valid loss: 6.868103181748163
Training loss: 0.2618091106414795 / Valid loss: 6.946741705849057

Epoch: 20
Training loss: 0.3474332392215729 / Valid loss: 6.841365836915516
Training loss: 0.3138289451599121 / Valid loss: 6.873812548319498
Training loss: 0.48008957505226135 / Valid loss: 6.879916758764358
Training loss: 0.19026365876197815 / Valid loss: 6.812907377878825
Training loss: 0.3100920617580414 / Valid loss: 6.795332127525693

Epoch: 21
Training loss: 0.14189636707305908 / Valid loss: 6.806473616191319
Training loss: 0.4862443506717682 / Valid loss: 6.737730675651914
Training loss: 0.25240176916122437 / Valid loss: 6.793463221050444
Training loss: 0.20081225037574768 / Valid loss: 6.7995349974859325
Training loss: 0.2317204773426056 / Valid loss: 6.847449125562395

Epoch: 22
Training loss: 0.35564422607421875 / Valid loss: 6.794223690032959
Training loss: 0.15230701863765717 / Valid loss: 6.861483937218075
Training loss: 0.4719240069389343 / Valid loss: 6.817471190861293
Training loss: 0.5883740186691284 / Valid loss: 6.916577502659389
Training loss: 0.2592882513999939 / Valid loss: 6.854958284468878

Epoch: 23
Training loss: 0.1986827254295349 / Valid loss: 6.857266185397194
Training loss: 0.42163771390914917 / Valid loss: 6.87214548928397
Training loss: 0.959857165813446 / Valid loss: 6.774533012935094
Training loss: 0.13871058821678162 / Valid loss: 6.950332823253813
Training loss: 0.2565608322620392 / Valid loss: 6.872097074417841

Epoch: 24
Training loss: 0.32916420698165894 / Valid loss: 6.900554168791998
Training loss: 0.22103314101696014 / Valid loss: 6.77794710340954
Training loss: 0.4730081260204315 / Valid loss: 6.80828979128883
Training loss: 0.204532191157341 / Valid loss: 6.786112176804315
Training loss: 0.4216873347759247 / Valid loss: 6.853757095336914

Epoch: 25
Training loss: 0.41908323764801025 / Valid loss: 6.824651409330822
Training loss: 0.3060964047908783 / Valid loss: 6.8067235787709555
Training loss: 0.32903069257736206 / Valid loss: 6.814995359239124
Training loss: 0.29962989687919617 / Valid loss: 6.808039288293748
Training loss: 0.3225189447402954 / Valid loss: 6.914066487266904

Epoch: 26
Training loss: 0.26686227321624756 / Valid loss: 6.859159637632824
Training loss: 0.26777398586273193 / Valid loss: 6.868744007746378
Training loss: 0.2412346601486206 / Valid loss: 6.829711786905924
Training loss: 0.1644948124885559 / Valid loss: 6.826261885960897
Training loss: 0.3142988681793213 / Valid loss: 6.864504759652274

Epoch: 27
Training loss: 0.23770606517791748 / Valid loss: 6.866000370752244
Training loss: 0.3605474531650543 / Valid loss: 6.902607595352899
Training loss: 0.37771719694137573 / Valid loss: 6.844894238880703
Training loss: 0.20420202612876892 / Valid loss: 6.827095563071115
Training loss: 0.18738910555839539 / Valid loss: 6.752018483479818

Epoch: 28
Training loss: 0.21511459350585938 / Valid loss: 6.813782233283633
Training loss: 0.17459937930107117 / Valid loss: 6.762562156858898
Training loss: 0.40423524379730225 / Valid loss: 6.737609091259184
Training loss: 0.21373511850833893 / Valid loss: 6.818117214384533
Training loss: 0.15509693324565887 / Valid loss: 6.824519761403402

Epoch: 29
Training loss: 0.11955154687166214 / Valid loss: 6.879199886322022
Training loss: 0.20302066206932068 / Valid loss: 6.839168080829439
Training loss: 0.3694685697555542 / Valid loss: 6.821797411782401
Training loss: 0.26014038920402527 / Valid loss: 6.8133487837655204

Epoch: 30
Training loss: 0.49358242750167847 / Valid loss: 6.933948925563267
Training loss: 0.2455330342054367 / Valid loss: 6.747812189374652
Training loss: 0.1639866828918457 / Valid loss: 6.831049832843599
Training loss: 0.2253948152065277 / Valid loss: 6.851490506671724
Training loss: 0.3085760176181793 / Valid loss: 6.850447014399937

Epoch: 31
Training loss: 0.2867448329925537 / Valid loss: 6.917605972290039
Training loss: 0.18103376030921936 / Valid loss: 6.792305301484608
Training loss: 0.21167199313640594 / Valid loss: 6.871933178674607
Training loss: 0.17536482214927673 / Valid loss: 6.754181575775147
Training loss: 0.18958070874214172 / Valid loss: 6.836099883488246

Epoch: 32
Training loss: 0.26624056696891785 / Valid loss: 6.874772307986305
Training loss: 0.1895039677619934 / Valid loss: 6.805401134490967
Training loss: 0.22558808326721191 / Valid loss: 6.743262990315755
Training loss: 0.23573458194732666 / Valid loss: 6.8127100535801475
Training loss: 0.09613310545682907 / Valid loss: 6.783428323836554

Epoch: 33
Training loss: 0.22248247265815735 / Valid loss: 6.828184772673107
Training loss: 0.185958594083786 / Valid loss: 6.745828494571504
Training loss: 0.26854047179222107 / Valid loss: 6.805506629035587
Training loss: 0.14702536165714264 / Valid loss: 6.818772041229975
Training loss: 0.18452392518520355 / Valid loss: 6.790109911419097

Epoch: 34
Training loss: 0.5206811428070068 / Valid loss: 6.755184114547003
Training loss: 0.1464935541152954 / Valid loss: 6.77285430771964
Training loss: 0.18157371878623962 / Valid loss: 6.80527454557873
Training loss: 0.17695540189743042 / Valid loss: 6.808745665777297
Training loss: 0.21783064305782318 / Valid loss: 6.9476253713880265

Epoch: 35
Training loss: 0.20432379841804504 / Valid loss: 6.809744169598534
Training loss: 0.2624642848968506 / Valid loss: 6.805258714585078
Training loss: 0.2237538993358612 / Valid loss: 6.814376626695905
Training loss: 0.10667432844638824 / Valid loss: 6.807266884758359
Training loss: 0.5050758123397827 / Valid loss: 6.869486990429106

Epoch: 36
Training loss: 0.1526976227760315 / Valid loss: 6.812831538064139
Training loss: 0.27794861793518066 / Valid loss: 6.7927031925746375
Training loss: 0.20628014206886292 / Valid loss: 6.879074110303606
Training loss: 0.21822623908519745 / Valid loss: 6.814427900314331
Training loss: 0.25087013840675354 / Valid loss: 6.811988894144694

Epoch: 37
Training loss: 0.1574472337961197 / Valid loss: 6.869239291690644
Training loss: 0.14597828686237335 / Valid loss: 6.743290038335891
Training loss: 0.4632410407066345 / Valid loss: 6.821162725630261
Training loss: 0.2436566948890686 / Valid loss: 6.846349679856074
Training loss: 0.29798638820648193 / Valid loss: 6.9154951277233305

Epoch: 38
Training loss: 0.16338130831718445 / Valid loss: 6.813678573426746
Training loss: 0.15052619576454163 / Valid loss: 6.830858167012533
Training loss: 0.20106768608093262 / Valid loss: 6.786963403792608
Training loss: 0.17200103402137756 / Valid loss: 6.891637625013079
Training loss: 0.09449607878923416 / Valid loss: 6.834856596447173

Epoch: 39
Training loss: 0.15691275894641876 / Valid loss: 6.869220520201184
Training loss: 0.28705739974975586 / Valid loss: 6.801109572819301
Training loss: 0.16413509845733643 / Valid loss: 6.790891897110712
Training loss: 0.14062052965164185 / Valid loss: 6.799091077986217

Epoch: 40
Training loss: 0.16157230734825134 / Valid loss: 6.768572793688093
Training loss: 0.187098428606987 / Valid loss: 6.725073335284279
Training loss: 0.16188502311706543 / Valid loss: 6.764834653763544
Training loss: 0.15788164734840393 / Valid loss: 6.829060145786831
Training loss: 0.1843271404504776 / Valid loss: 6.87599891935076

Epoch: 41
Training loss: 0.46681174635887146 / Valid loss: 6.840251627422514
Training loss: 0.07114660739898682 / Valid loss: 6.779228401184082
Training loss: 0.1329108476638794 / Valid loss: 6.808606926600138
Training loss: 0.18564774096012115 / Valid loss: 6.791052473159064
Training loss: 0.532094419002533 / Valid loss: 6.96283616792588

Epoch: 42
Training loss: 0.14625242352485657 / Valid loss: 6.849146847497849
Training loss: 0.15008307993412018 / Valid loss: 6.815025329589844
Training loss: 0.1880466341972351 / Valid loss: 6.812611806960333
Training loss: 0.16382049024105072 / Valid loss: 6.822935692469279
Training loss: 0.12896671891212463 / Valid loss: 6.803859760647728

Epoch: 43
Training loss: 0.10508005321025848 / Valid loss: 6.801793152945383
Training loss: 0.21147421002388 / Valid loss: 6.731877299717494
Training loss: 0.0960126519203186 / Valid loss: 6.82029052007766
Training loss: 0.23980529606342316 / Valid loss: 6.878417612257458
Training loss: 0.12677478790283203 / Valid loss: 6.8941707474844796

Epoch: 44
Training loss: 0.09322532266378403 / Valid loss: 6.902815232958113
Training loss: 0.17653082311153412 / Valid loss: 6.826381090709141
Training loss: 0.3671721816062927 / Valid loss: 6.84217038835798
Training loss: 0.21263843774795532 / Valid loss: 6.860348306383405
Training loss: 0.10292763262987137 / Valid loss: 6.8515811579568044

Epoch: 45
Training loss: 0.1484142392873764 / Valid loss: 6.795010067167736
Training loss: 0.18036092817783356 / Valid loss: 6.888890077954247
Training loss: 0.11953906714916229 / Valid loss: 6.7700146993001304
Training loss: 0.1040225625038147 / Valid loss: 6.789125805809384
Training loss: 0.11369241774082184 / Valid loss: 6.768809972490583

Epoch: 46
Training loss: 0.33855825662612915 / Valid loss: 6.746380115690686
Training loss: 0.1600959599018097 / Valid loss: 6.81272889091855
Training loss: 0.19294129312038422 / Valid loss: 6.803868929545085
Training loss: 0.1268000602722168 / Valid loss: 6.843598297664097
Training loss: 0.1587907373905182 / Valid loss: 6.830170327141172

Epoch: 47
Training loss: 0.18827712535858154 / Valid loss: 6.772224437622797
Training loss: 0.13405387103557587 / Valid loss: 6.83314935593378
Training loss: 0.11584801971912384 / Valid loss: 6.777153373899914
Training loss: 0.12475484609603882 / Valid loss: 6.864338988349552
Training loss: 0.10446126759052277 / Valid loss: 6.82351637794858

Epoch: 48
Training loss: 0.12500379979610443 / Valid loss: 6.757256905237834
Training loss: 0.09933477640151978 / Valid loss: 6.746480669294085
Training loss: 0.21017295122146606 / Valid loss: 6.8213401113237655
Training loss: 0.11750423908233643 / Valid loss: 6.797937720162528
Training loss: 0.12688598036766052 / Valid loss: 6.850266924358549

Epoch: 49
Training loss: 0.05750458315014839 / Valid loss: 6.815249558857509
Training loss: 0.13665568828582764 / Valid loss: 6.853705224536714
Training loss: 0.0833367258310318 / Valid loss: 6.8405216058095295
Training loss: 0.1574862003326416 / Valid loss: 6.880342029389881

Epoch: 50
Training loss: 0.09269973635673523 / Valid loss: 6.778318373362223
Training loss: 0.2773755192756653 / Valid loss: 6.760318088531494
Training loss: 0.2441130131483078 / Valid loss: 6.732963026137579
Training loss: 0.11251994967460632 / Valid loss: 6.798930803934733
Training loss: 0.1901146024465561 / Valid loss: 6.863955020904541

Epoch: 51
Training loss: 0.13131225109100342 / Valid loss: 6.779146494184221
Training loss: 0.21941247582435608 / Valid loss: 6.7541395278204055
Training loss: 0.17583900690078735 / Valid loss: 6.788127045404344
Training loss: 0.20960602164268494 / Valid loss: 6.753222629002162
Training loss: 0.10921744257211685 / Valid loss: 6.831721921194167

Epoch: 52
Training loss: 0.26063084602355957 / Valid loss: 6.838432134900774
Training loss: 0.10463747382164001 / Valid loss: 6.7960836183457145
Training loss: 0.09557582437992096 / Valid loss: 6.867252477010092
Training loss: 0.1962488740682602 / Valid loss: 6.817642902192615
Training loss: 0.1630321741104126 / Valid loss: 6.870842420487177

Epoch: 53
Training loss: 0.359328955411911 / Valid loss: 6.758999883560907
Training loss: 0.3743928372859955 / Valid loss: 6.750698466528029
Training loss: 0.1751042753458023 / Valid loss: 6.827744143349784
Training loss: 0.1397974193096161 / Valid loss: 6.836380933579944
Training loss: 0.14217114448547363 / Valid loss: 6.8359129360743935

Epoch: 54
Training loss: 0.09337177127599716 / Valid loss: 6.780967208317348
Training loss: 0.3766019344329834 / Valid loss: 6.874198700132824
Training loss: 0.10413377732038498 / Valid loss: 6.852471433367048
Training loss: 0.30950528383255005 / Valid loss: 6.745074896585374
Training loss: 0.24684889614582062 / Valid loss: 6.838629995073591

Epoch: 55
Training loss: 0.22290697693824768 / Valid loss: 6.821985240209671
Training loss: 0.22839629650115967 / Valid loss: 6.740502330235072
Training loss: 0.12322413176298141 / Valid loss: 6.809270922342936
Training loss: 0.14560241997241974 / Valid loss: 6.743810721806118
Training loss: 0.28815650939941406 / Valid loss: 6.704568951470511

Epoch: 56
Training loss: 0.22704508900642395 / Valid loss: 6.7866472766512915
Training loss: 0.11336153745651245 / Valid loss: 6.761102823984055
Training loss: 0.12399875372648239 / Valid loss: 6.785713048208327
Training loss: 0.18494220077991486 / Valid loss: 6.779861886160714
Training loss: 0.33830171823501587 / Valid loss: 6.881042126246861

Epoch: 57
Training loss: 0.1157950758934021 / Valid loss: 6.7824177696591335
Training loss: 0.1132940948009491 / Valid loss: 6.759965210869199
Training loss: 0.19132894277572632 / Valid loss: 6.762456053779239
Training loss: 0.20427873730659485 / Valid loss: 6.799613448551723
Training loss: 0.22031641006469727 / Valid loss: 6.7854519503457205

Epoch: 58
Training loss: 0.13219834864139557 / Valid loss: 6.721163563501268
Training loss: 0.1449308693408966 / Valid loss: 6.743681934901646
Training loss: 0.23764219880104065 / Valid loss: 6.806448591323126
Training loss: 0.06878077983856201 / Valid loss: 6.828149227868943
Training loss: 0.07762004435062408 / Valid loss: 6.802267574128651

Epoch: 59
Training loss: 0.13634563982486725 / Valid loss: 6.745740400041853
Training loss: 0.1180945411324501 / Valid loss: 6.810336301440285
Training loss: 0.16510502994060516 / Valid loss: 6.759327248164586
Training loss: 0.09358102083206177 / Valid loss: 6.795943880081177

Epoch: 60
Training loss: 0.07446084916591644 / Valid loss: 6.802894337972005
Training loss: 0.1075352281332016 / Valid loss: 6.796882447742281
Training loss: 0.09989996999502182 / Valid loss: 6.819233499254499
Training loss: 0.4243893623352051 / Valid loss: 6.795195325215658
Training loss: 0.08756823092699051 / Valid loss: 6.78345403217134

Epoch: 61
Training loss: 0.2387525737285614 / Valid loss: 6.7403885228293285
Training loss: 0.4195561408996582 / Valid loss: 6.745132827758789
Training loss: 0.07680071890354156 / Valid loss: 6.823457447687785
Training loss: 0.12065702676773071 / Valid loss: 6.849786372411819
Training loss: 0.2224266231060028 / Valid loss: 6.785545721508208

Epoch: 62
Training loss: 0.16082286834716797 / Valid loss: 6.764833532060895
Training loss: 0.37969958782196045 / Valid loss: 6.685340890430269
Training loss: 0.0902983546257019 / Valid loss: 6.736180686950684
Training loss: 0.1313479244709015 / Valid loss: 6.730390834808349
Training loss: 0.06227831915020943 / Valid loss: 6.793688492547898

Epoch: 63
Training loss: 0.1234171986579895 / Valid loss: 6.725051750455584
Training loss: 0.12913194298744202 / Valid loss: 6.703868305115472
Training loss: 0.14853790402412415 / Valid loss: 6.7494233721778505
Training loss: 0.09647202491760254 / Valid loss: 6.721630922953287
Training loss: 0.13742291927337646 / Valid loss: 6.796477408636184

Epoch: 64
Training loss: 0.12800896167755127 / Valid loss: 6.771400955745152
Training loss: 0.16509392857551575 / Valid loss: 6.749123041970389
Training loss: 0.10872647166252136 / Valid loss: 6.750935586293538
Training loss: 0.21784283220767975 / Valid loss: 6.729063179379418
Training loss: 0.13937672972679138 / Valid loss: 6.746169864563715

Epoch: 65
Training loss: 0.09910893440246582 / Valid loss: 6.792692597707113
Training loss: 0.13157464563846588 / Valid loss: 6.774339589618501
Training loss: 0.06543497741222382 / Valid loss: 6.718839154924665
Training loss: 0.0671389177441597 / Valid loss: 6.758313996451242
Training loss: 0.14680412411689758 / Valid loss: 6.741068826402937

Epoch: 66
Training loss: 0.12244914472103119 / Valid loss: 6.698860956373669
Training loss: 0.14322315156459808 / Valid loss: 6.729178546723865
Training loss: 0.11880277097225189 / Valid loss: 6.7597158204941525
Training loss: 0.1646929830312729 / Valid loss: 6.772346305847168
Training loss: 0.07979944348335266 / Valid loss: 6.758469168345133

Epoch: 67
Training loss: 0.2829829752445221 / Valid loss: 6.662590873809088
Training loss: 0.27805960178375244 / Valid loss: 6.714839771815709
Training loss: 0.11916424334049225 / Valid loss: 6.696687689281645
Training loss: 0.1861938238143921 / Valid loss: 6.760909475599017
Training loss: 0.10671961307525635 / Valid loss: 6.719815522148496

Epoch: 68
Training loss: 0.22885826230049133 / Valid loss: 6.731128656296503
Training loss: 0.22276905179023743 / Valid loss: 6.741281822749547
Training loss: 0.32298076152801514 / Valid loss: 6.735379446120489
Training loss: 0.08220624178647995 / Valid loss: 6.732847815468197
Training loss: 0.3585040271282196 / Valid loss: 6.735369932083857

Epoch: 69
Training loss: 0.09476516395807266 / Valid loss: 6.678297792162214
Training loss: 0.09353463351726532 / Valid loss: 6.728203369322277
Training loss: 0.07935431599617004 / Valid loss: 6.721263785589309
Training loss: 0.44488751888275146 / Valid loss: 6.754059562228975

Epoch: 70
Training loss: 0.1190289855003357 / Valid loss: 6.7582720847356885
Training loss: 0.13850854337215424 / Valid loss: 6.768338017236619
Training loss: 0.33273810148239136 / Valid loss: 6.727631505330404
Training loss: 0.2169375866651535 / Valid loss: 6.745274793534052
Training loss: 0.07763981819152832 / Valid loss: 6.722483921051025

Epoch: 71
Training loss: 0.06576333940029144 / Valid loss: 6.755733449118478
Training loss: 0.19644327461719513 / Valid loss: 6.735999318531581
Training loss: 0.09762190282344818 / Valid loss: 6.715223680223738
Training loss: 0.08872249722480774 / Valid loss: 6.738504119146437
Training loss: 0.05357883498072624 / Valid loss: 6.752031444367908

Epoch: 72
Training loss: 0.1446358561515808 / Valid loss: 6.765221000853039
Training loss: 0.17245496809482574 / Valid loss: 6.735685498373849
Training loss: 0.2055903971195221 / Valid loss: 6.737142011097499
Training loss: 0.1993948072195053 / Valid loss: 6.7255296116783505
Training loss: 0.16629543900489807 / Valid loss: 6.750156080155145

Epoch: 73
Training loss: 0.1733107566833496 / Valid loss: 6.758975685210455
Training loss: 0.07016505300998688 / Valid loss: 6.7315783682323636
Training loss: 0.12101182341575623 / Valid loss: 6.763509959266299
Training loss: 0.07532911002635956 / Valid loss: 6.708670611608596
Training loss: 0.13202574849128723 / Valid loss: 6.7575099036807105

Epoch: 74
Training loss: 0.20713602006435394 / Valid loss: 6.7148332641238255
Training loss: 0.11949208378791809 / Valid loss: 6.755699096407209
Training loss: 0.1187196895480156 / Valid loss: 6.715070865267799
Training loss: 0.30773448944091797 / Valid loss: 6.782609117598761
Training loss: 0.31680893898010254 / Valid loss: 6.766374610719227

Epoch: 75
Training loss: 0.08270741254091263 / Valid loss: 6.662778107325236
Training loss: 0.24187326431274414 / Valid loss: 6.725795523325602
Training loss: 0.2198406308889389 / Valid loss: 6.709950349444434
Training loss: 0.08276951313018799 / Valid loss: 6.725714994612194
Training loss: 0.10243958234786987 / Valid loss: 6.7655975432623

Epoch: 76
Training loss: 0.059924401342868805 / Valid loss: 6.703158619290306
Training loss: 0.4823998808860779 / Valid loss: 6.745151519775391
Training loss: 0.6762640476226807 / Valid loss: 6.698070158277239
Training loss: 0.0655275508761406 / Valid loss: 6.802614157540457
Training loss: 0.17439785599708557 / Valid loss: 6.738619132268997

Epoch: 77
Training loss: 0.15366831421852112 / Valid loss: 6.70755705833435
Training loss: 0.3894149363040924 / Valid loss: 6.7385110083080475
Training loss: 0.08514192700386047 / Valid loss: 6.710795534224737
Training loss: 0.20280177891254425 / Valid loss: 6.721714514777774
Training loss: 0.08785340934991837 / Valid loss: 6.745105638958159

Epoch: 78
Training loss: 0.14469438791275024 / Valid loss: 6.715918468293689
Training loss: 0.2795259952545166 / Valid loss: 6.734909087135678
Training loss: 0.10359217971563339 / Valid loss: 6.770283553713844
Training loss: 0.1627163589000702 / Valid loss: 6.71175058228629
Training loss: 0.2584766745567322 / Valid loss: 6.725042770022438

Epoch: 79
Training loss: 0.12272964417934418 / Valid loss: 6.747553527922857
Training loss: 0.13716131448745728 / Valid loss: 6.7387351898919965
Training loss: 0.0714186429977417 / Valid loss: 6.715031235558646
Training loss: 0.24541613459587097 / Valid loss: 6.704548313504174
ModuleList(
  (0): Linear(in_features=31191, out_features=300, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=300, out_features=32, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=32, out_features=1, bias=True)
)
Loss on test set of optimal model: 6.5720638661157516
Training regression with following parameters:
dnn_hidden_units : 248
dropout_probs : 0.0, 0.0
learning_rate : 0.0001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : Adam
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : TFIDF
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=31191, out_features=248, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=248, out_features=1, bias=True)
)

Epoch: 0
Training loss: 15.220863342285156 / Valid loss: 16.43889894031343
Model is saved in epoch 0, overall batch: 0
Training loss: 11.010725021362305 / Valid loss: 12.136854262579055
Model is saved in epoch 0, overall batch: 100
Training loss: 8.312519073486328 / Valid loss: 8.353009378342401
Model is saved in epoch 0, overall batch: 200
Training loss: 5.576720714569092 / Valid loss: 6.936966671262469
Model is saved in epoch 0, overall batch: 300
Training loss: 6.93902063369751 / Valid loss: 6.341448842911493
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 4.22274923324585 / Valid loss: 6.054472991398403
Model is saved in epoch 1, overall batch: 500
Training loss: 3.307562828063965 / Valid loss: 6.093241350991385
Training loss: 2.688591241836548 / Valid loss: 6.184382445471627
Training loss: 4.3806257247924805 / Valid loss: 6.255521887824649
Training loss: 4.116939544677734 / Valid loss: 6.284444234484718

Epoch: 2
Training loss: 1.685755729675293 / Valid loss: 6.288634895143055
Training loss: 2.2900938987731934 / Valid loss: 6.423663591203235
Training loss: 2.166539192199707 / Valid loss: 6.4515859899066745
Training loss: 2.069154977798462 / Valid loss: 6.514133371625628
Training loss: 2.034419298171997 / Valid loss: 6.5277907689412435

Epoch: 3
Training loss: 1.5604474544525146 / Valid loss: 6.612724202019828
Training loss: 1.8657437562942505 / Valid loss: 6.71597413562593
Training loss: 1.95290207862854 / Valid loss: 6.682222012111119
Training loss: 1.4603689908981323 / Valid loss: 6.678148719242641
Training loss: 2.54310941696167 / Valid loss: 6.682394018627348

Epoch: 4
Training loss: 1.3245253562927246 / Valid loss: 6.743814963386172
Training loss: 1.1290065050125122 / Valid loss: 6.782487524123419
Training loss: 1.4995176792144775 / Valid loss: 6.802688539595831
Training loss: 2.012632369995117 / Valid loss: 6.842526317778088
Training loss: 1.284424066543579 / Valid loss: 6.87516607329959

Epoch: 5
Training loss: 0.9802114963531494 / Valid loss: 6.823968914576939
Training loss: 1.753232479095459 / Valid loss: 6.8382567746298655
Training loss: 0.8567119836807251 / Valid loss: 6.865124902271089
Training loss: 1.9267489910125732 / Valid loss: 6.835303361075265
Training loss: 1.9004170894622803 / Valid loss: 6.860692264920189

Epoch: 6
Training loss: 1.047821283340454 / Valid loss: 6.876826290857224
Training loss: 1.488762617111206 / Valid loss: 6.860671856289819
Training loss: 1.6646640300750732 / Valid loss: 6.8857053211757115
Training loss: 1.0729615688323975 / Valid loss: 6.8943580082484655
Training loss: 2.4375357627868652 / Valid loss: 6.9643440927777975

Epoch: 7
Training loss: 1.3937321901321411 / Valid loss: 6.964436308542887
Training loss: 0.8741785287857056 / Valid loss: 6.962203146162487
Training loss: 1.0502454042434692 / Valid loss: 6.922637773695446
Training loss: 1.020350456237793 / Valid loss: 6.934606338682629
Training loss: 1.1639456748962402 / Valid loss: 7.001792762393043

Epoch: 8
Training loss: 0.8620957732200623 / Valid loss: 6.929139657247634
Training loss: 1.0681827068328857 / Valid loss: 6.95725231624785
Training loss: 1.189394235610962 / Valid loss: 7.0570085321153915
Training loss: 0.7450203895568848 / Valid loss: 7.094849123273577
Training loss: 0.9157299399375916 / Valid loss: 7.084551157270159

Epoch: 9
Training loss: 0.7911748886108398 / Valid loss: 7.027384108588809
Training loss: 0.9922532439231873 / Valid loss: 6.937702324276879
Training loss: 0.877464234828949 / Valid loss: 7.002670460655576
Training loss: 0.6232957243919373 / Valid loss: 7.023536718459356

Epoch: 10
Training loss: 0.5907033681869507 / Valid loss: 7.034772859300886
Training loss: 0.8060780167579651 / Valid loss: 7.0562429609752835
Training loss: 0.5145354270935059 / Valid loss: 7.069271673474993
Training loss: 1.2520129680633545 / Valid loss: 7.026525953837804
Training loss: 1.0947365760803223 / Valid loss: 7.13703396660941

Epoch: 11
Training loss: 0.5585460662841797 / Valid loss: 7.102332569303966
Training loss: 0.6277426481246948 / Valid loss: 7.0142974876222155
Training loss: 0.7668939232826233 / Valid loss: 7.139676598140172
Training loss: 0.9671870470046997 / Valid loss: 7.2437482379731675
Training loss: 0.8539898991584778 / Valid loss: 7.188925579616002

Epoch: 12
Training loss: 0.6566191911697388 / Valid loss: 7.204005077907017
Training loss: 0.4326581358909607 / Valid loss: 7.159751587822324
Training loss: 1.179897427558899 / Valid loss: 7.146103363945371
Training loss: 0.7157042026519775 / Valid loss: 7.073645671208699
Training loss: 0.6124178171157837 / Valid loss: 7.103249627067929

Epoch: 13
Training loss: 0.7674095630645752 / Valid loss: 7.069810553959438
Training loss: 0.5332539081573486 / Valid loss: 7.089443283989316
Training loss: 0.5923007726669312 / Valid loss: 7.076223941076369
Training loss: 0.46528324484825134 / Valid loss: 7.16174685160319
Training loss: 0.8815881609916687 / Valid loss: 7.067097155253093

Epoch: 14
Training loss: 0.7154781818389893 / Valid loss: 7.095803256261917
Training loss: 0.5875641107559204 / Valid loss: 7.063563905443464
Training loss: 0.4630761444568634 / Valid loss: 7.0647342500232515
Training loss: 0.4945969879627228 / Valid loss: 7.106763421921503
Training loss: 0.6335958242416382 / Valid loss: 7.1230066208612355

Epoch: 15
Training loss: 0.6444014310836792 / Valid loss: 7.170005466824486
Training loss: 0.6619549989700317 / Valid loss: 7.159081390925816
Training loss: 0.8930954337120056 / Valid loss: 7.154626796359108
Training loss: 0.85792475938797 / Valid loss: 7.1142310028984435
Training loss: 0.3975512683391571 / Valid loss: 7.159545053754534

Epoch: 16
Training loss: 0.7336669564247131 / Valid loss: 7.145486232212612
Training loss: 0.4641796946525574 / Valid loss: 7.078643866947719
Training loss: 0.44675225019454956 / Valid loss: 7.065433547610328
Training loss: 0.7043405771255493 / Valid loss: 7.176013628641765
Training loss: 0.9182149171829224 / Valid loss: 7.041791343688965

Epoch: 17
Training loss: 0.4471115171909332 / Valid loss: 7.079055563608805
Training loss: 0.3570058047771454 / Valid loss: 7.117388634454636
Training loss: 0.5481861233711243 / Valid loss: 7.097369807107108
Training loss: 0.4013429582118988 / Valid loss: 7.110388083685012
Training loss: 0.6108609437942505 / Valid loss: 7.110741424560547

Epoch: 18
Training loss: 0.8557604551315308 / Valid loss: 7.079570652189709
Training loss: 0.9366413354873657 / Valid loss: 7.07907817023141
Training loss: 0.8217254281044006 / Valid loss: 7.120234530312675
Training loss: 0.43516111373901367 / Valid loss: 7.151746245792934
Training loss: 0.6407977938652039 / Valid loss: 7.201108210427421

Epoch: 19
Training loss: 0.778720498085022 / Valid loss: 7.080169187273298
Training loss: 0.5393562316894531 / Valid loss: 7.076718543824695
Training loss: 0.7087148427963257 / Valid loss: 7.111634417942592
Training loss: 0.5702794194221497 / Valid loss: 7.101467786516462

Epoch: 20
Training loss: 0.3731014132499695 / Valid loss: 7.16519505182902
Training loss: 0.6948340535163879 / Valid loss: 7.0201416537875225
Training loss: 0.30771175026893616 / Valid loss: 7.068975126175653
Training loss: 0.5479652285575867 / Valid loss: 7.129569589524042
Training loss: 0.4792598485946655 / Valid loss: 7.049782053629557

Epoch: 21
Training loss: 0.17904892563819885 / Valid loss: 7.144348909741356
Training loss: 0.48197507858276367 / Valid loss: 7.089768931979225
Training loss: 0.6363959312438965 / Valid loss: 7.042125043414888
Training loss: 0.48837414383888245 / Valid loss: 7.131077443985712
Training loss: 0.48628175258636475 / Valid loss: 7.1404013951619465

Epoch: 22
Training loss: 0.40938469767570496 / Valid loss: 7.1121663547697525
Training loss: 0.2545161247253418 / Valid loss: 7.144327754066104
Training loss: 0.6882036924362183 / Valid loss: 7.09191370010376
Training loss: 0.4939751923084259 / Valid loss: 7.1419182277861095
Training loss: 0.28418537974357605 / Valid loss: 7.045908877963112

Epoch: 23
Training loss: 0.37706416845321655 / Valid loss: 7.051175458090646
Training loss: 0.3789159655570984 / Valid loss: 7.083803671882266
Training loss: 0.46872764825820923 / Valid loss: 7.025963765098935
Training loss: 0.862682580947876 / Valid loss: 7.085049992515927
Training loss: 0.48877209424972534 / Valid loss: 7.099100103832426

Epoch: 24
Training loss: 0.3509310781955719 / Valid loss: 7.067668578738258
Training loss: 0.561310887336731 / Valid loss: 7.088577175140381
Training loss: 0.7400058507919312 / Valid loss: 7.078513059161958
Training loss: 0.5029176473617554 / Valid loss: 7.147199703398205
Training loss: 0.340705931186676 / Valid loss: 7.117360069638207

Epoch: 25
Training loss: 0.5662655234336853 / Valid loss: 7.072266431081863
Training loss: 0.5900287628173828 / Valid loss: 7.07653507959275
Training loss: 0.3347401022911072 / Valid loss: 7.104861659095401
Training loss: 0.3967958390712738 / Valid loss: 7.064677960532052
Training loss: 0.37938374280929565 / Valid loss: 7.049376855577742

Epoch: 26
Training loss: 0.396867960691452 / Valid loss: 7.04867825735183
Training loss: 0.39075055718421936 / Valid loss: 6.990539668855213
Training loss: 0.34383922815322876 / Valid loss: 7.049469893319266
Training loss: 0.42446470260620117 / Valid loss: 7.070613804317656
Training loss: 0.5729614496231079 / Valid loss: 7.04766366141183

Epoch: 27
Training loss: 0.6845331192016602 / Valid loss: 7.012137376694453
Training loss: 0.6675896644592285 / Valid loss: 6.997539202372233
Training loss: 0.27437567710876465 / Valid loss: 7.025667063395182
Training loss: 0.2925542891025543 / Valid loss: 7.10383715856643
Training loss: 0.33306729793548584 / Valid loss: 7.094251918792724

Epoch: 28
Training loss: 0.2840394675731659 / Valid loss: 7.044048270725068
Training loss: 0.43845871090888977 / Valid loss: 7.088881138392857
Training loss: 0.5152723789215088 / Valid loss: 7.041694028036935
Training loss: 0.3260875344276428 / Valid loss: 7.061306817190988
Training loss: 0.28037145733833313 / Valid loss: 7.092274420601981

Epoch: 29
Training loss: 0.788262128829956 / Valid loss: 7.079811918167841
Training loss: 0.24343901872634888 / Valid loss: 7.101370202927362
Training loss: 0.44496044516563416 / Valid loss: 7.010643477666946
Training loss: 0.40854793787002563 / Valid loss: 7.054571056365967

Epoch: 30
Training loss: 0.3794634938240051 / Valid loss: 7.1077138083321705
Training loss: 0.5003958344459534 / Valid loss: 7.008455644335066
Training loss: 0.5343549251556396 / Valid loss: 7.012238466171992
Training loss: 0.5936756134033203 / Valid loss: 7.010988735017323
Training loss: 0.2212054580450058 / Valid loss: 7.00769544328962

Epoch: 31
Training loss: 0.2620561718940735 / Valid loss: 7.012795988718668
Training loss: 0.4561142921447754 / Valid loss: 7.013898917606899
Training loss: 0.3807978928089142 / Valid loss: 7.086037311099824
Training loss: 0.4204857051372528 / Valid loss: 7.010263272694179
Training loss: 0.6750738620758057 / Valid loss: 7.058216483252389

Epoch: 32
Training loss: 0.1812475621700287 / Valid loss: 7.026829492478144
Training loss: 0.2207207977771759 / Valid loss: 7.037157848903111
Training loss: 0.28058120608329773 / Valid loss: 6.989345255352202
Training loss: 0.2040015310049057 / Valid loss: 7.132482560475667
Training loss: 0.4374743103981018 / Valid loss: 7.080489626384916

Epoch: 33
Training loss: 0.6396987438201904 / Valid loss: 7.023339889163062
Training loss: 0.3338611423969269 / Valid loss: 7.050342850458055
Training loss: 0.27859586477279663 / Valid loss: 7.0945637339637395
Training loss: 0.17618171870708466 / Valid loss: 7.026346751621792
Training loss: 0.36097070574760437 / Valid loss: 7.0755668594723655

Epoch: 34
Training loss: 0.20651331543922424 / Valid loss: 7.034980474199568
Training loss: 0.29477259516716003 / Valid loss: 7.058251292364938
Training loss: 0.49960994720458984 / Valid loss: 7.05553750764756
Training loss: 0.35413411259651184 / Valid loss: 6.996748529161725
Training loss: 0.19278869032859802 / Valid loss: 7.078712131863549

Epoch: 35
Training loss: 0.4168831706047058 / Valid loss: 7.064978313446045
Training loss: 0.3366396725177765 / Valid loss: 7.055232286453247
Training loss: 0.25345128774642944 / Valid loss: 6.984307420821417
Training loss: 0.26596546173095703 / Valid loss: 7.01649508249192
Training loss: 0.389209121465683 / Valid loss: 7.099722231002081

Epoch: 36
Training loss: 0.32646968960762024 / Valid loss: 7.04905195917402
Training loss: 0.2592369019985199 / Valid loss: 7.0226911998930435
Training loss: 0.18870854377746582 / Valid loss: 7.028390044257755
Training loss: 0.34274089336395264 / Valid loss: 7.085550916762579
Training loss: 0.236776202917099 / Valid loss: 7.068241112572807

Epoch: 37
Training loss: 0.28310078382492065 / Valid loss: 7.041920475732713
Training loss: 0.9691177606582642 / Valid loss: 7.007404761087327
Training loss: 0.25092998147010803 / Valid loss: 7.028324613117037
Training loss: 0.3354108929634094 / Valid loss: 6.984066059475853
Training loss: 0.30190712213516235 / Valid loss: 6.989691436858404

Epoch: 38
Training loss: 0.25419148802757263 / Valid loss: 6.983464009421212
Training loss: 0.2177290916442871 / Valid loss: 7.000724547249931
Training loss: 0.42470794916152954 / Valid loss: 7.069397490365165
Training loss: 0.22574634850025177 / Valid loss: 7.056407694589524
Training loss: 0.392309308052063 / Valid loss: 7.045142759595598

Epoch: 39
Training loss: 0.21129339933395386 / Valid loss: 6.970331855047316
Training loss: 0.2097775638103485 / Valid loss: 7.072067396981375
Training loss: 0.4827858805656433 / Valid loss: 6.980125023069836
Training loss: 0.27364131808280945 / Valid loss: 7.0419281959533695

Epoch: 40
Training loss: 0.18970352411270142 / Valid loss: 7.0396696544828865
Training loss: 0.28082701563835144 / Valid loss: 6.936172072092692
Training loss: 0.19222430884838104 / Valid loss: 6.996555169423421
Training loss: 0.4628674387931824 / Valid loss: 7.014765989212763
Training loss: 0.27568912506103516 / Valid loss: 7.005126975831532

Epoch: 41
Training loss: 0.21568940579891205 / Valid loss: 7.0154203414917
Training loss: 0.5458751916885376 / Valid loss: 7.004100091116769
Training loss: 0.2338676154613495 / Valid loss: 7.038597347622826
Training loss: 0.2526339888572693 / Valid loss: 7.037362761724562
Training loss: 0.4076066315174103 / Valid loss: 7.008481497991653

Epoch: 42
Training loss: 0.19328343868255615 / Valid loss: 6.972723947252546
Training loss: 0.2377922534942627 / Valid loss: 6.998024259294782
Training loss: 0.26365065574645996 / Valid loss: 7.003694016592843
Training loss: 0.170308917760849 / Valid loss: 7.015108440035865
Training loss: 0.3048640191555023 / Valid loss: 7.0591803051176525

Epoch: 43
Training loss: 0.20651957392692566 / Valid loss: 7.012581639062791
Training loss: 0.26088640093803406 / Valid loss: 6.996357450031099
Training loss: 0.4067656993865967 / Valid loss: 6.977461360749745
Training loss: 0.22457684576511383 / Valid loss: 7.028489180973598
Training loss: 0.3787115514278412 / Valid loss: 7.034475648970831

Epoch: 44
Training loss: 0.19267526268959045 / Valid loss: 7.069866016932896
Training loss: 0.3495062589645386 / Valid loss: 6.928344751539685
Training loss: 0.21717441082000732 / Valid loss: 6.991908704666864
Training loss: 0.18554966151714325 / Valid loss: 6.981099968864804
Training loss: 0.21843701601028442 / Valid loss: 7.023723929268973

Epoch: 45
Training loss: 0.2746037244796753 / Valid loss: 6.9844882238478885
Training loss: 0.21325859427452087 / Valid loss: 7.008851564498174
Training loss: 0.4155537188053131 / Valid loss: 7.031738540104457
Training loss: 0.18510296940803528 / Valid loss: 6.9348687716892785
Training loss: 0.19994010031223297 / Valid loss: 6.9934763386136005

Epoch: 46
Training loss: 0.31122303009033203 / Valid loss: 7.00809847059704
Training loss: 0.17221790552139282 / Valid loss: 7.011106677282424
Training loss: 0.2434583604335785 / Valid loss: 7.002209522610619
Training loss: 0.2097741663455963 / Valid loss: 6.958481329963321
Training loss: 0.20065084099769592 / Valid loss: 6.990789315814063

Epoch: 47
Training loss: 0.38261979818344116 / Valid loss: 6.938560860497611
Training loss: 0.24978503584861755 / Valid loss: 6.958371707371303
Training loss: 0.4114833176136017 / Valid loss: 6.9949721926734565
Training loss: 0.28183022141456604 / Valid loss: 6.9814325786772224
Training loss: 0.29768723249435425 / Valid loss: 7.01023706254505

Epoch: 48
Training loss: 0.2052825689315796 / Valid loss: 6.959778356552124
Training loss: 0.3491452932357788 / Valid loss: 7.01623606908889
Training loss: 0.31857824325561523 / Valid loss: 6.952193637121291
Training loss: 0.17282649874687195 / Valid loss: 6.903872698829288
Training loss: 0.23836371302604675 / Valid loss: 6.9598869346437

Epoch: 49
Training loss: 0.3021617531776428 / Valid loss: 6.97047792162214
Training loss: 0.1585441678762436 / Valid loss: 6.981635052817208
Training loss: 0.20877747237682343 / Valid loss: 6.917365564618792
Training loss: 0.22712507843971252 / Valid loss: 6.954799082165673

Epoch: 50
Training loss: 0.28348642587661743 / Valid loss: 6.919574587685721
Training loss: 0.3055289387702942 / Valid loss: 6.926980945042201
Training loss: 0.1653982549905777 / Valid loss: 6.922295720236642
Training loss: 0.21175256371498108 / Valid loss: 6.9539451167697
Training loss: 0.22902336716651917 / Valid loss: 6.953044128417969

Epoch: 51
Training loss: 0.21223825216293335 / Valid loss: 6.9856319291251046
Training loss: 0.22148749232292175 / Valid loss: 6.896815554300944
Training loss: 0.22868523001670837 / Valid loss: 6.966587053026472
Training loss: 0.2575172781944275 / Valid loss: 6.9231080691019695
Training loss: 0.16760659217834473 / Valid loss: 6.967822940008981

Epoch: 52
Training loss: 0.13672930002212524 / Valid loss: 6.948732837041219
Training loss: 0.22696378827095032 / Valid loss: 6.924655787150065
Training loss: 0.23964472115039825 / Valid loss: 6.925349003928048
Training loss: 0.3658052086830139 / Valid loss: 6.893768287840343
Training loss: 0.1656704843044281 / Valid loss: 6.958290027436756

Epoch: 53
Training loss: 0.41281306743621826 / Valid loss: 6.971356376012166
Training loss: 0.2994181215763092 / Valid loss: 6.94250597726731
Training loss: 0.165065735578537 / Valid loss: 6.902623757861909
Training loss: 0.43507009744644165 / Valid loss: 6.939838722773961
Training loss: 0.2347736358642578 / Valid loss: 6.9997552871704105

Epoch: 54
Training loss: 0.31218409538269043 / Valid loss: 6.954022720881871
Training loss: 0.1195000633597374 / Valid loss: 6.98393296741304
Training loss: 0.3492892384529114 / Valid loss: 6.914869603656587
Training loss: 0.21805347502231598 / Valid loss: 6.873148475374494
Training loss: 0.1690002828836441 / Valid loss: 6.902417964027041

Epoch: 55
Training loss: 0.12278085201978683 / Valid loss: 6.911874920981271
Training loss: 0.14568756520748138 / Valid loss: 6.949962684086391
Training loss: 0.24020648002624512 / Valid loss: 6.893591449374244
Training loss: 0.1266845464706421 / Valid loss: 6.9509796051752
Training loss: 0.46088510751724243 / Valid loss: 6.990718886965797

Epoch: 56
Training loss: 0.519972562789917 / Valid loss: 6.9118619055975055
Training loss: 0.2660242021083832 / Valid loss: 6.902068760281518
Training loss: 0.21864983439445496 / Valid loss: 6.947186086291358
Training loss: 0.29994168877601624 / Valid loss: 6.917279388791039
Training loss: 0.5793516635894775 / Valid loss: 6.924501101175944

Epoch: 57
Training loss: 0.1738593876361847 / Valid loss: 6.874306045259748
Training loss: 0.3174903094768524 / Valid loss: 6.91903798466637
Training loss: 0.20961926877498627 / Valid loss: 6.899197015308198
Training loss: 0.3566073477268219 / Valid loss: 6.865473315829322
Training loss: 0.35657742619514465 / Valid loss: 6.934317425319127

Epoch: 58
Training loss: 0.20930781960487366 / Valid loss: 6.905824867884318
Training loss: 0.3487170338630676 / Valid loss: 6.8982465358007525
Training loss: 0.454716295003891 / Valid loss: 6.886820243653797
Training loss: 0.2050117552280426 / Valid loss: 6.9566534087771466
Training loss: 0.1639319360256195 / Valid loss: 6.974353731246222

Epoch: 59
Training loss: 0.16435909271240234 / Valid loss: 6.862187503633045
Training loss: 0.1449425220489502 / Valid loss: 6.889647797175816
Training loss: 0.24930131435394287 / Valid loss: 6.884277947743734
Training loss: 0.4918822646141052 / Valid loss: 6.92672518321446

Epoch: 60
Training loss: 0.36195167899131775 / Valid loss: 6.8777735187893825
Training loss: 0.21565087139606476 / Valid loss: 6.848827925182524
Training loss: 0.24846582114696503 / Valid loss: 6.850160003843762
Training loss: 0.12673720717430115 / Valid loss: 6.9140124457223076
Training loss: 0.20703567564487457 / Valid loss: 6.900399167197091

Epoch: 61
Training loss: 0.3018922805786133 / Valid loss: 6.891392680576869
Training loss: 0.15913578867912292 / Valid loss: 6.912923177083333
Training loss: 0.23464414477348328 / Valid loss: 6.897018929890224
Training loss: 0.1783100962638855 / Valid loss: 6.896624624161493
Training loss: 0.16979512572288513 / Valid loss: 6.90636727469308

Epoch: 62
Training loss: 0.16531437635421753 / Valid loss: 6.917834118434361
Training loss: 0.12513718008995056 / Valid loss: 6.876594475337437
Training loss: 0.23828813433647156 / Valid loss: 6.917481676737467
Training loss: 0.16944582760334015 / Valid loss: 6.927624439057849
Training loss: 0.2892343997955322 / Valid loss: 6.910470126924061

Epoch: 63
Training loss: 0.32561787962913513 / Valid loss: 6.907133670080276
Training loss: 0.10933966934680939 / Valid loss: 6.933445639837355
Training loss: 0.1309880018234253 / Valid loss: 6.8724498975844615
Training loss: 0.18532055616378784 / Valid loss: 6.90274444534665
Training loss: 0.20318159461021423 / Valid loss: 6.906406030200777

Epoch: 64
Training loss: 0.27464717626571655 / Valid loss: 6.940505652200608
Training loss: 0.08750375360250473 / Valid loss: 6.881343437376477
Training loss: 0.14959801733493805 / Valid loss: 6.87588302067348
Training loss: 0.1745254099369049 / Valid loss: 6.892733430862426
Training loss: 0.1311781108379364 / Valid loss: 6.839960752214704

Epoch: 65
Training loss: 0.12541618943214417 / Valid loss: 6.920618093581426
Training loss: 0.22430837154388428 / Valid loss: 6.8744341714041575
Training loss: 0.21172979474067688 / Valid loss: 6.914971256256104
Training loss: 0.33554384112358093 / Valid loss: 6.851822008405413
Training loss: 0.10193933546543121 / Valid loss: 6.8849580810183575

Epoch: 66
Training loss: 0.18624122440814972 / Valid loss: 6.877422698338827
Training loss: 0.17764705419540405 / Valid loss: 6.893794668288458
Training loss: 0.423049658536911 / Valid loss: 6.923048727852958
Training loss: 0.18238916993141174 / Valid loss: 6.922284312475295
Training loss: 0.15722337365150452 / Valid loss: 6.881086826324463

Epoch: 67
Training loss: 0.13160327076911926 / Valid loss: 6.850106950033279
Training loss: 0.24475304782390594 / Valid loss: 6.8941545486450195
Training loss: 0.15949489176273346 / Valid loss: 6.929376647585914
Training loss: 0.23879459500312805 / Valid loss: 6.905198235738845
Training loss: 0.11888967454433441 / Valid loss: 6.91365190914699

Epoch: 68
Training loss: 0.32339218258857727 / Valid loss: 6.87851436478751
Training loss: 0.15114976465702057 / Valid loss: 6.825373463403611
Training loss: 0.2013911008834839 / Valid loss: 6.880389674504598
Training loss: 0.12771406769752502 / Valid loss: 6.937005592527844
Training loss: 0.21028485894203186 / Valid loss: 6.911410881224133

Epoch: 69
Training loss: 0.24308538436889648 / Valid loss: 6.874102583385649
Training loss: 0.16996772587299347 / Valid loss: 6.8766184988475985
Training loss: 0.17170101404190063 / Valid loss: 6.927020254589262
Training loss: 0.3151009976863861 / Valid loss: 6.871671803792318

Epoch: 70
Training loss: 0.20629537105560303 / Valid loss: 6.894552730378651
Training loss: 0.5045564770698547 / Valid loss: 6.873184099651518
Training loss: 0.34670132398605347 / Valid loss: 6.8440816175369985
Training loss: 0.1688862442970276 / Valid loss: 6.834525408063616
Training loss: 0.5272544622421265 / Valid loss: 6.8667458784012565

Epoch: 71
Training loss: 0.242954820394516 / Valid loss: 6.894505605243501
Training loss: 0.2375284731388092 / Valid loss: 6.842455596015567
Training loss: 0.13655763864517212 / Valid loss: 6.847799641745431
Training loss: 0.11826406419277191 / Valid loss: 6.8613980157034735
Training loss: 0.21043626964092255 / Valid loss: 6.899507622491746

Epoch: 72
Training loss: 0.12925148010253906 / Valid loss: 6.879399849119641
Training loss: 0.31204909086227417 / Valid loss: 6.865337085723877
Training loss: 0.2360721081495285 / Valid loss: 6.870556354522705
Training loss: 0.14538881182670593 / Valid loss: 6.836613282703218
Training loss: 0.18635272979736328 / Valid loss: 6.852428518022809

Epoch: 73
Training loss: 0.5297369956970215 / Valid loss: 6.870925094967797
Training loss: 0.13152313232421875 / Valid loss: 6.868832447415307
Training loss: 0.19651223719120026 / Valid loss: 6.8523880141122
Training loss: 0.1954096257686615 / Valid loss: 6.827948495319911
Training loss: 0.15226076543331146 / Valid loss: 6.871870554061163

Epoch: 74
Training loss: 0.3322327733039856 / Valid loss: 6.871175116584414
Training loss: 0.1304571032524109 / Valid loss: 6.842508956364223
Training loss: 0.15149587392807007 / Valid loss: 6.864929862249465
Training loss: 0.22517132759094238 / Valid loss: 6.826172778719948
Training loss: 0.1973690241575241 / Valid loss: 6.904317728678385

Epoch: 75
Training loss: 0.21942207217216492 / Valid loss: 6.881027080899194
Training loss: 0.5425713062286377 / Valid loss: 6.837202717009045
Training loss: 0.19995462894439697 / Valid loss: 6.841618308566866
Training loss: 0.17088720202445984 / Valid loss: 6.92528076171875
Training loss: 0.14928743243217468 / Valid loss: 6.891203878039406

Epoch: 76
Training loss: 0.1099383533000946 / Valid loss: 6.809781508218674
Training loss: 0.2808625102043152 / Valid loss: 6.85618729137239
Training loss: 0.0980120301246643 / Valid loss: 6.82984888667152
Training loss: 0.11492887884378433 / Valid loss: 6.8671423457917715
Training loss: 0.2058429718017578 / Valid loss: 6.870664492107573

Epoch: 77
Training loss: 0.19537541270256042 / Valid loss: 6.828969696589879
Training loss: 0.39371389150619507 / Valid loss: 6.893922905694871
Training loss: 0.299365758895874 / Valid loss: 6.874913837796166
Training loss: 0.12944665551185608 / Valid loss: 6.809036422911144
Training loss: 0.4558436870574951 / Valid loss: 6.782972503843761

Epoch: 78
Training loss: 0.17166170477867126 / Valid loss: 6.872733025323777
Training loss: 0.33221322298049927 / Valid loss: 6.888719513302758
Training loss: 0.17985698580741882 / Valid loss: 6.85054836727324
Training loss: 0.1644512414932251 / Valid loss: 6.860617104030791
Training loss: 0.2904464602470398 / Valid loss: 6.852325911748977

Epoch: 79
Training loss: 0.11512184888124466 / Valid loss: 6.846293478920346
Training loss: 0.12785720825195312 / Valid loss: 6.899875858851842
Training loss: 0.07519523799419403 / Valid loss: 6.804656975609916
Training loss: 0.15359525382518768 / Valid loss: 6.842061251685733
ModuleList(
  (0): Linear(in_features=31191, out_features=248, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=248, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.846810458955311
Training regression with following parameters:
dnn_hidden_units : 
dropout_probs : 0.0, 0.0
learning_rate : 0.0001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : Adam
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : TFIDF
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=31191, out_features=1, bias=True)
)

Epoch: 0
Training loss: 20.986988067626953 / Valid loss: 16.48066234588623
Model is saved in epoch 0, overall batch: 0
Training loss: 19.682048797607422 / Valid loss: 16.37194080352783
Model is saved in epoch 0, overall batch: 100
Training loss: 11.277936935424805 / Valid loss: 16.270790345328194
Model is saved in epoch 0, overall batch: 200
Training loss: 17.17060089111328 / Valid loss: 16.158159146990094
Model is saved in epoch 0, overall batch: 300
Training loss: 13.421060562133789 / Valid loss: 16.04465164002918
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 13.482011795043945 / Valid loss: 15.918952969142369
Model is saved in epoch 1, overall batch: 500
Training loss: 12.709381103515625 / Valid loss: 15.825508480980282
Model is saved in epoch 1, overall batch: 600
Training loss: 15.81386947631836 / Valid loss: 15.729942212785993
Model is saved in epoch 1, overall batch: 700
Training loss: 16.324106216430664 / Valid loss: 15.625586237226214
Model is saved in epoch 1, overall batch: 800
Training loss: 20.26406478881836 / Valid loss: 15.500804764883858
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 13.794792175292969 / Valid loss: 15.392302703857421
Model is saved in epoch 2, overall batch: 1000
Training loss: 11.086048126220703 / Valid loss: 15.314764358883812
Model is saved in epoch 2, overall batch: 1100
Training loss: 15.955490112304688 / Valid loss: 15.208577719188872
Model is saved in epoch 2, overall batch: 1200
Training loss: 12.489133834838867 / Valid loss: 15.111477406819661
Model is saved in epoch 2, overall batch: 1300
Training loss: 16.036945343017578 / Valid loss: 15.00173830304827
Model is saved in epoch 2, overall batch: 1400

Epoch: 3
Training loss: 12.296623229980469 / Valid loss: 14.889990234375
Model is saved in epoch 3, overall batch: 1500
Training loss: 10.433905601501465 / Valid loss: 14.789945511590867
Model is saved in epoch 3, overall batch: 1600
Training loss: 11.790611267089844 / Valid loss: 14.703085063752674
Model is saved in epoch 3, overall batch: 1700
Training loss: 15.266878128051758 / Valid loss: 14.622550274076916
Model is saved in epoch 3, overall batch: 1800
Training loss: 19.18914222717285 / Valid loss: 14.523673284621466
Model is saved in epoch 3, overall batch: 1900

Epoch: 4
Training loss: 19.98931884765625 / Valid loss: 14.428661201113746
Model is saved in epoch 4, overall batch: 2000
Training loss: 17.70398712158203 / Valid loss: 14.321386673336937
Model is saved in epoch 4, overall batch: 2100
Training loss: 17.032913208007812 / Valid loss: 14.23578216916039
Model is saved in epoch 4, overall batch: 2200
Training loss: 16.628955841064453 / Valid loss: 14.136079533894856
Model is saved in epoch 4, overall batch: 2300
Training loss: 8.939642906188965 / Valid loss: 14.029433023361932
Model is saved in epoch 4, overall batch: 2400

Epoch: 5
Training loss: 8.300857543945312 / Valid loss: 13.927495683942523
Model is saved in epoch 5, overall batch: 2500
Training loss: 17.888978958129883 / Valid loss: 13.863056092035203
Model is saved in epoch 5, overall batch: 2600
Training loss: 11.465845108032227 / Valid loss: 13.779152992793492
Model is saved in epoch 5, overall batch: 2700
Training loss: 15.246354103088379 / Valid loss: 13.688334732963925
Model is saved in epoch 5, overall batch: 2800
Training loss: 9.759997367858887 / Valid loss: 13.58138785589309
Model is saved in epoch 5, overall batch: 2900

Epoch: 6
Training loss: 10.536222457885742 / Valid loss: 13.494659396580287
Model is saved in epoch 6, overall batch: 3000
Training loss: 15.552804946899414 / Valid loss: 13.420817724863689
Model is saved in epoch 6, overall batch: 3100
Training loss: 10.575103759765625 / Valid loss: 13.32546554747082
Model is saved in epoch 6, overall batch: 3200
Training loss: 12.887259483337402 / Valid loss: 13.232887976510185
Model is saved in epoch 6, overall batch: 3300
Training loss: 7.42832088470459 / Valid loss: 13.15969780967349
Model is saved in epoch 6, overall batch: 3400

Epoch: 7
Training loss: 12.315414428710938 / Valid loss: 13.067579119546073
Model is saved in epoch 7, overall batch: 3500
Training loss: 14.849267959594727 / Valid loss: 12.9857957976205
Model is saved in epoch 7, overall batch: 3600
Training loss: 10.279006958007812 / Valid loss: 12.89237067812965
Model is saved in epoch 7, overall batch: 3700
Training loss: 12.9608736038208 / Valid loss: 12.794570750281924
Model is saved in epoch 7, overall batch: 3800
Training loss: 12.382295608520508 / Valid loss: 12.730896059672038
Model is saved in epoch 7, overall batch: 3900

Epoch: 8
Training loss: 12.953064918518066 / Valid loss: 12.630402428763253
Model is saved in epoch 8, overall batch: 4000
Training loss: 14.429489135742188 / Valid loss: 12.546014281681606
Model is saved in epoch 8, overall batch: 4100
Training loss: 12.974165916442871 / Valid loss: 12.485242471240817
Model is saved in epoch 8, overall batch: 4200
Training loss: 17.060237884521484 / Valid loss: 12.405861618405297
Model is saved in epoch 8, overall batch: 4300
Training loss: 13.49267864227295 / Valid loss: 12.329460566384451
Model is saved in epoch 8, overall batch: 4400

Epoch: 9
Training loss: 12.661523818969727 / Valid loss: 12.237885257175991
Model is saved in epoch 9, overall batch: 4500
Training loss: 12.848800659179688 / Valid loss: 12.165480186825707
Model is saved in epoch 9, overall batch: 4600
Training loss: 14.488607406616211 / Valid loss: 12.07058756692069
Model is saved in epoch 9, overall batch: 4700
Training loss: 12.78664779663086 / Valid loss: 12.006422742207844
Model is saved in epoch 9, overall batch: 4800

Epoch: 10
Training loss: 11.318477630615234 / Valid loss: 11.934741347176688
Model is saved in epoch 10, overall batch: 4900
Training loss: 14.250657081604004 / Valid loss: 11.849716894967216
Model is saved in epoch 10, overall batch: 5000
Training loss: 15.35003662109375 / Valid loss: 11.760051768166678
Model is saved in epoch 10, overall batch: 5100
Training loss: 10.402201652526855 / Valid loss: 11.700620596749442
Model is saved in epoch 10, overall batch: 5200
Training loss: 9.59667682647705 / Valid loss: 11.61595755985805
Model is saved in epoch 10, overall batch: 5300

Epoch: 11
Training loss: 13.91616153717041 / Valid loss: 11.545271264939082
Model is saved in epoch 11, overall batch: 5400
Training loss: 12.028694152832031 / Valid loss: 11.46419475646246
Model is saved in epoch 11, overall batch: 5500
Training loss: 15.863500595092773 / Valid loss: 11.411583691551572
Model is saved in epoch 11, overall batch: 5600
Training loss: 9.365795135498047 / Valid loss: 11.331166875930059
Model is saved in epoch 11, overall batch: 5700
Training loss: 8.788071632385254 / Valid loss: 11.235160514286585
Model is saved in epoch 11, overall batch: 5800

Epoch: 12
Training loss: 12.931285858154297 / Valid loss: 11.192734627496629
Model is saved in epoch 12, overall batch: 5900
Training loss: 9.14463996887207 / Valid loss: 11.12009361357916
Model is saved in epoch 12, overall batch: 6000
Training loss: 7.943866729736328 / Valid loss: 11.053012747991653
Model is saved in epoch 12, overall batch: 6100
Training loss: 12.71893310546875 / Valid loss: 10.97653767267863
Model is saved in epoch 12, overall batch: 6200
Training loss: 9.803539276123047 / Valid loss: 10.89538856688
Model is saved in epoch 12, overall batch: 6300

Epoch: 13
Training loss: 8.23149299621582 / Valid loss: 10.841041483197893
Model is saved in epoch 13, overall batch: 6400
Training loss: 5.316556930541992 / Valid loss: 10.773876285552978
Model is saved in epoch 13, overall batch: 6500
Training loss: 16.398771286010742 / Valid loss: 10.705930637177968
Model is saved in epoch 13, overall batch: 6600
Training loss: 10.863359451293945 / Valid loss: 10.639790235246931
Model is saved in epoch 13, overall batch: 6700
Training loss: 11.081249237060547 / Valid loss: 10.573303590502057
Model is saved in epoch 13, overall batch: 6800

Epoch: 14
Training loss: 12.457226753234863 / Valid loss: 10.506310031527565
Model is saved in epoch 14, overall batch: 6900
Training loss: 8.325041770935059 / Valid loss: 10.430002916426886
Model is saved in epoch 14, overall batch: 7000
Training loss: 11.232620239257812 / Valid loss: 10.378535370599655
Model is saved in epoch 14, overall batch: 7100
Training loss: 12.521027565002441 / Valid loss: 10.31368628456479
Model is saved in epoch 14, overall batch: 7200
Training loss: 9.738624572753906 / Valid loss: 10.248642335619245
Model is saved in epoch 14, overall batch: 7300

Epoch: 15
Training loss: 9.12507152557373 / Valid loss: 10.172648025694347
Model is saved in epoch 15, overall batch: 7400
Training loss: 11.46051025390625 / Valid loss: 10.112477733975364
Model is saved in epoch 15, overall batch: 7500
Training loss: 7.849015712738037 / Valid loss: 10.056317565554664
Model is saved in epoch 15, overall batch: 7600
Training loss: 8.746415138244629 / Valid loss: 10.000544697897775
Model is saved in epoch 15, overall batch: 7700
Training loss: 12.457427978515625 / Valid loss: 9.938714967455184
Model is saved in epoch 15, overall batch: 7800

Epoch: 16
Training loss: 8.21353530883789 / Valid loss: 9.863726779392787
Model is saved in epoch 16, overall batch: 7900
Training loss: 13.074492454528809 / Valid loss: 9.802010926746187
Model is saved in epoch 16, overall batch: 8000
Training loss: 9.916379928588867 / Valid loss: 9.757700198037284
Model is saved in epoch 16, overall batch: 8100
Training loss: 10.219854354858398 / Valid loss: 9.684298056647892
Model is saved in epoch 16, overall batch: 8200
Training loss: 11.502340316772461 / Valid loss: 9.640258166903541
Model is saved in epoch 16, overall batch: 8300

Epoch: 17
Training loss: 14.204569816589355 / Valid loss: 9.581542455582392
Model is saved in epoch 17, overall batch: 8400
Training loss: 10.009955406188965 / Valid loss: 9.51403964360555
Model is saved in epoch 17, overall batch: 8500
Training loss: 7.5635786056518555 / Valid loss: 9.470443525768461
Model is saved in epoch 17, overall batch: 8600
Training loss: 7.332355499267578 / Valid loss: 9.41474609375
Model is saved in epoch 17, overall batch: 8700
Training loss: 10.604107856750488 / Valid loss: 9.344839105151948
Model is saved in epoch 17, overall batch: 8800

Epoch: 18
Training loss: 7.74551248550415 / Valid loss: 9.304518254597982
Model is saved in epoch 18, overall batch: 8900
Training loss: 8.721367835998535 / Valid loss: 9.24378812880743
Model is saved in epoch 18, overall batch: 9000
Training loss: 8.48185920715332 / Valid loss: 9.194694832393102
Model is saved in epoch 18, overall batch: 9100
Training loss: 9.893543243408203 / Valid loss: 9.139756279899961
Model is saved in epoch 18, overall batch: 9200
Training loss: 10.01772689819336 / Valid loss: 9.08765535808745
Model is saved in epoch 18, overall batch: 9300

Epoch: 19
Training loss: 7.984832286834717 / Valid loss: 9.021559020451138
Model is saved in epoch 19, overall batch: 9400
Training loss: 13.705082893371582 / Valid loss: 8.97275292078654
Model is saved in epoch 19, overall batch: 9500
Training loss: 7.8443145751953125 / Valid loss: 8.927644161950974
Model is saved in epoch 19, overall batch: 9600
Training loss: 9.692012786865234 / Valid loss: 8.867765644618443
Model is saved in epoch 19, overall batch: 9700

Epoch: 20
Training loss: 8.243289947509766 / Valid loss: 8.817563833509173
Model is saved in epoch 20, overall batch: 9800
Training loss: 7.973526954650879 / Valid loss: 8.776530567804972
Model is saved in epoch 20, overall batch: 9900
Training loss: 7.908421993255615 / Valid loss: 8.727069859277634
Model is saved in epoch 20, overall batch: 10000
Training loss: 8.625310897827148 / Valid loss: 8.665111042204357
Model is saved in epoch 20, overall batch: 10100
Training loss: 7.779120922088623 / Valid loss: 8.62550997052874
Model is saved in epoch 20, overall batch: 10200

Epoch: 21
Training loss: 10.446858406066895 / Valid loss: 8.578724761236282
Model is saved in epoch 21, overall batch: 10300
Training loss: 7.084285259246826 / Valid loss: 8.534106838135493
Model is saved in epoch 21, overall batch: 10400
Training loss: 8.033493041992188 / Valid loss: 8.487863436199369
Model is saved in epoch 21, overall batch: 10500
Training loss: 10.207932472229004 / Valid loss: 8.44068979535784
Model is saved in epoch 21, overall batch: 10600
Training loss: 6.014873504638672 / Valid loss: 8.397699660346621
Model is saved in epoch 21, overall batch: 10700

Epoch: 22
Training loss: 9.762716293334961 / Valid loss: 8.34499880472819
Model is saved in epoch 22, overall batch: 10800
Training loss: 10.322514533996582 / Valid loss: 8.306488509405227
Model is saved in epoch 22, overall batch: 10900
Training loss: 7.075475692749023 / Valid loss: 8.258304155440557
Model is saved in epoch 22, overall batch: 11000
Training loss: 8.624849319458008 / Valid loss: 8.220180802118211
Model is saved in epoch 22, overall batch: 11100
Training loss: 7.0339179039001465 / Valid loss: 8.166706067039852
Model is saved in epoch 22, overall batch: 11200

Epoch: 23
Training loss: 6.749889373779297 / Valid loss: 8.132677409762428
Model is saved in epoch 23, overall batch: 11300
Training loss: 9.434531211853027 / Valid loss: 8.089775189899264
Model is saved in epoch 23, overall batch: 11400
Training loss: 9.242650985717773 / Valid loss: 8.047398857843309
Model is saved in epoch 23, overall batch: 11500
Training loss: 9.20905876159668 / Valid loss: 8.007768108731224
Model is saved in epoch 23, overall batch: 11600
Training loss: 7.030669212341309 / Valid loss: 7.962444042024158
Model is saved in epoch 23, overall batch: 11700

Epoch: 24
Training loss: 6.561295986175537 / Valid loss: 7.921996470860073
Model is saved in epoch 24, overall batch: 11800
Training loss: 9.040871620178223 / Valid loss: 7.872059672219413
Model is saved in epoch 24, overall batch: 11900
Training loss: 5.018951416015625 / Valid loss: 7.844508071172805
Model is saved in epoch 24, overall batch: 12000
Training loss: 7.180352210998535 / Valid loss: 7.799436373937698
Model is saved in epoch 24, overall batch: 12100
Training loss: 7.522808074951172 / Valid loss: 7.76118221282959
Model is saved in epoch 24, overall batch: 12200

Epoch: 25
Training loss: 7.213128089904785 / Valid loss: 7.716519859858922
Model is saved in epoch 25, overall batch: 12300
Training loss: 5.065730094909668 / Valid loss: 7.692800982793172
Model is saved in epoch 25, overall batch: 12400
Training loss: 9.215853691101074 / Valid loss: 7.6548626945132305
Model is saved in epoch 25, overall batch: 12500
Training loss: 7.34841251373291 / Valid loss: 7.619838383084252
Model is saved in epoch 25, overall batch: 12600
Training loss: 7.990118980407715 / Valid loss: 7.573426494144258
Model is saved in epoch 25, overall batch: 12700

Epoch: 26
Training loss: 4.871264457702637 / Valid loss: 7.5420619510468985
Model is saved in epoch 26, overall batch: 12800
Training loss: 5.153250217437744 / Valid loss: 7.50938822882516
Model is saved in epoch 26, overall batch: 12900
Training loss: 6.817732810974121 / Valid loss: 7.477307678404308
Model is saved in epoch 26, overall batch: 13000
Training loss: 6.640079021453857 / Valid loss: 7.4408416748046875
Model is saved in epoch 26, overall batch: 13100
Training loss: 5.4359917640686035 / Valid loss: 7.403074010213216
Model is saved in epoch 26, overall batch: 13200

Epoch: 27
Training loss: 6.719500541687012 / Valid loss: 7.373971684773763
Model is saved in epoch 27, overall batch: 13300
Training loss: 7.678191184997559 / Valid loss: 7.339787469591413
Model is saved in epoch 27, overall batch: 13400
Training loss: 5.690126419067383 / Valid loss: 7.308266948518299
Model is saved in epoch 27, overall batch: 13500
Training loss: 9.939260482788086 / Valid loss: 7.275042838142031
Model is saved in epoch 27, overall batch: 13600
Training loss: 7.206747055053711 / Valid loss: 7.235150080635434
Model is saved in epoch 27, overall batch: 13700

Epoch: 28
Training loss: 6.5599846839904785 / Valid loss: 7.209531379881359
Model is saved in epoch 28, overall batch: 13800
Training loss: 5.544612407684326 / Valid loss: 7.170056638263521
Model is saved in epoch 28, overall batch: 13900
Training loss: 5.580269813537598 / Valid loss: 7.149353769847325
Model is saved in epoch 28, overall batch: 14000
Training loss: 7.545458793640137 / Valid loss: 7.1128284431639175
Model is saved in epoch 28, overall batch: 14100
Training loss: 6.597137451171875 / Valid loss: 7.091689468565441
Model is saved in epoch 28, overall batch: 14200

Epoch: 29
Training loss: 7.114513397216797 / Valid loss: 7.056382515316918
Model is saved in epoch 29, overall batch: 14300
Training loss: 7.104617118835449 / Valid loss: 7.023388862609863
Model is saved in epoch 29, overall batch: 14400
Training loss: 7.799118995666504 / Valid loss: 7.000736050378709
Model is saved in epoch 29, overall batch: 14500
Training loss: 7.6495361328125 / Valid loss: 6.972735500335693
Model is saved in epoch 29, overall batch: 14600

Epoch: 30
Training loss: 7.701648235321045 / Valid loss: 6.94017999058678
Model is saved in epoch 30, overall batch: 14700
Training loss: 6.902754306793213 / Valid loss: 6.920930757976714
Model is saved in epoch 30, overall batch: 14800
Training loss: 6.556793212890625 / Valid loss: 6.896700607027326
Model is saved in epoch 30, overall batch: 14900
Training loss: 5.587644577026367 / Valid loss: 6.868607836677914
Model is saved in epoch 30, overall batch: 15000
Training loss: 7.208433151245117 / Valid loss: 6.844891702561151
Model is saved in epoch 30, overall batch: 15100

Epoch: 31
Training loss: 7.565220832824707 / Valid loss: 6.818242786044166
Model is saved in epoch 31, overall batch: 15200
Training loss: 7.458193302154541 / Valid loss: 6.7858726592290965
Model is saved in epoch 31, overall batch: 15300
Training loss: 6.709178924560547 / Valid loss: 6.764234797159831
Model is saved in epoch 31, overall batch: 15400
Training loss: 8.398345947265625 / Valid loss: 6.744727473031907
Model is saved in epoch 31, overall batch: 15500
Training loss: 8.66853141784668 / Valid loss: 6.712681720370338
Model is saved in epoch 31, overall batch: 15600

Epoch: 32
Training loss: 5.211962699890137 / Valid loss: 6.693080847603934
Model is saved in epoch 32, overall batch: 15700
Training loss: 7.3792009353637695 / Valid loss: 6.673259167444138
Model is saved in epoch 32, overall batch: 15800
Training loss: 6.8103556632995605 / Valid loss: 6.64864908400036
Model is saved in epoch 32, overall batch: 15900
Training loss: 6.148314476013184 / Valid loss: 6.625681829452515
Model is saved in epoch 32, overall batch: 16000
Training loss: 3.468625545501709 / Valid loss: 6.606570098513648
Model is saved in epoch 32, overall batch: 16100

Epoch: 33
Training loss: 8.989485740661621 / Valid loss: 6.583173817679995
Model is saved in epoch 33, overall batch: 16200
Training loss: 3.968885898590088 / Valid loss: 6.560458421707153
Model is saved in epoch 33, overall batch: 16300
Training loss: 7.75716495513916 / Valid loss: 6.543986172903152
Model is saved in epoch 33, overall batch: 16400
Training loss: 5.627066135406494 / Valid loss: 6.514040481476557
Model is saved in epoch 33, overall batch: 16500
Training loss: 8.754674911499023 / Valid loss: 6.503159048443749
Model is saved in epoch 33, overall batch: 16600

Epoch: 34
Training loss: 6.3698649406433105 / Valid loss: 6.481677650270008
Model is saved in epoch 34, overall batch: 16700
Training loss: 5.686793327331543 / Valid loss: 6.461179492587135
Model is saved in epoch 34, overall batch: 16800
Training loss: 5.849918365478516 / Valid loss: 6.436648498262678
Model is saved in epoch 34, overall batch: 16900
Training loss: 5.365469932556152 / Valid loss: 6.4259866510118755
Model is saved in epoch 34, overall batch: 17000
Training loss: 6.180820465087891 / Valid loss: 6.3955019723801385
Model is saved in epoch 34, overall batch: 17100

Epoch: 35
Training loss: 6.420785903930664 / Valid loss: 6.383819089617048
Model is saved in epoch 35, overall batch: 17200
Training loss: 6.0384321212768555 / Valid loss: 6.371484820048014
Model is saved in epoch 35, overall batch: 17300
Training loss: 5.9723286628723145 / Valid loss: 6.355618608565558
Model is saved in epoch 35, overall batch: 17400
Training loss: 8.753804206848145 / Valid loss: 6.32885768981207
Model is saved in epoch 35, overall batch: 17500
Training loss: 9.091300964355469 / Valid loss: 6.304590620313372
Model is saved in epoch 35, overall batch: 17600

Epoch: 36
Training loss: 5.635075569152832 / Valid loss: 6.302248750414167
Model is saved in epoch 36, overall batch: 17700
Training loss: 8.582216262817383 / Valid loss: 6.271927947089786
Model is saved in epoch 36, overall batch: 17800
Training loss: 4.723543643951416 / Valid loss: 6.265770008450462
Model is saved in epoch 36, overall batch: 17900
Training loss: 5.019966125488281 / Valid loss: 6.256271764210292
Model is saved in epoch 36, overall batch: 18000
Training loss: 5.156325817108154 / Valid loss: 6.241504837217785
Model is saved in epoch 36, overall batch: 18100

Epoch: 37
Training loss: 4.257423400878906 / Valid loss: 6.223622683116368
Model is saved in epoch 37, overall batch: 18200
Training loss: 6.48952579498291 / Valid loss: 6.213091046469552
Model is saved in epoch 37, overall batch: 18300
Training loss: 5.173551559448242 / Valid loss: 6.192239604677472
Model is saved in epoch 37, overall batch: 18400
Training loss: 5.929388999938965 / Valid loss: 6.173491711843582
Model is saved in epoch 37, overall batch: 18500
Training loss: 5.362987518310547 / Valid loss: 6.163554432278588
Model is saved in epoch 37, overall batch: 18600

Epoch: 38
Training loss: 4.333440780639648 / Valid loss: 6.150973619733538
Model is saved in epoch 38, overall batch: 18700
Training loss: 6.75394344329834 / Valid loss: 6.143286798113868
Model is saved in epoch 38, overall batch: 18800
Training loss: 6.75734281539917 / Valid loss: 6.126579550334386
Model is saved in epoch 38, overall batch: 18900
Training loss: 5.579655170440674 / Valid loss: 6.118428305217198
Model is saved in epoch 38, overall batch: 19000
Training loss: 7.495403289794922 / Valid loss: 6.104158097221738
Model is saved in epoch 38, overall batch: 19100

Epoch: 39
Training loss: 4.2290778160095215 / Valid loss: 6.093478754588536
Model is saved in epoch 39, overall batch: 19200
Training loss: 6.333347797393799 / Valid loss: 6.083985576175508
Model is saved in epoch 39, overall batch: 19300
Training loss: 7.369989395141602 / Valid loss: 6.0706811496189665
Model is saved in epoch 39, overall batch: 19400
Training loss: 6.377228736877441 / Valid loss: 6.06127055258978
Model is saved in epoch 39, overall batch: 19500

Epoch: 40
Training loss: 5.803625583648682 / Valid loss: 6.047926961807978
Model is saved in epoch 40, overall batch: 19600
Training loss: 6.695918083190918 / Valid loss: 6.034293835503714
Model is saved in epoch 40, overall batch: 19700
Training loss: 5.271652698516846 / Valid loss: 6.028855464571998
Model is saved in epoch 40, overall batch: 19800
Training loss: 4.873356342315674 / Valid loss: 6.01488455136617
Model is saved in epoch 40, overall batch: 19900
Training loss: 5.155724048614502 / Valid loss: 6.008696222305298
Model is saved in epoch 40, overall batch: 20000

Epoch: 41
Training loss: 7.775659561157227 / Valid loss: 5.996420953387306
Model is saved in epoch 41, overall batch: 20100
Training loss: 7.168051242828369 / Valid loss: 5.991711559749785
Model is saved in epoch 41, overall batch: 20200
Training loss: 5.645244121551514 / Valid loss: 5.982778249468122
Model is saved in epoch 41, overall batch: 20300
Training loss: 5.390275001525879 / Valid loss: 5.961741333916073
Model is saved in epoch 41, overall batch: 20400
Training loss: 5.99405574798584 / Valid loss: 5.963021950494675

Epoch: 42
Training loss: 4.528724670410156 / Valid loss: 5.950669685999553
Model is saved in epoch 42, overall batch: 20600
Training loss: 4.9997968673706055 / Valid loss: 5.947133211862473
Model is saved in epoch 42, overall batch: 20700
Training loss: 5.3975629806518555 / Valid loss: 5.938574936276391
Model is saved in epoch 42, overall batch: 20800
Training loss: 4.785845756530762 / Valid loss: 5.927835634776524
Model is saved in epoch 42, overall batch: 20900
Training loss: 5.702527046203613 / Valid loss: 5.918546840122768
Model is saved in epoch 42, overall batch: 21000

Epoch: 43
Training loss: 5.4373321533203125 / Valid loss: 5.918210111345563
Model is saved in epoch 43, overall batch: 21100
Training loss: 6.240683555603027 / Valid loss: 5.90749066897801
Model is saved in epoch 43, overall batch: 21200
Training loss: 5.770668983459473 / Valid loss: 5.8967225506192165
Model is saved in epoch 43, overall batch: 21300
Training loss: 7.3799028396606445 / Valid loss: 5.895143433979579
Model is saved in epoch 43, overall batch: 21400
Training loss: 5.521450042724609 / Valid loss: 5.8894422826312836
Model is saved in epoch 43, overall batch: 21500

Epoch: 44
Training loss: 5.722561836242676 / Valid loss: 5.878433672587077
Model is saved in epoch 44, overall batch: 21600
Training loss: 7.097311019897461 / Valid loss: 5.876551376070295
Model is saved in epoch 44, overall batch: 21700
Training loss: 6.486145973205566 / Valid loss: 5.870007689793905
Model is saved in epoch 44, overall batch: 21800
Training loss: 4.957681655883789 / Valid loss: 5.856867134003412
Model is saved in epoch 44, overall batch: 21900
Training loss: 5.93634033203125 / Valid loss: 5.85107295853751
Model is saved in epoch 44, overall batch: 22000

Epoch: 45
Training loss: 4.467526435852051 / Valid loss: 5.852007470812116
Training loss: 7.644455432891846 / Valid loss: 5.843350562595186
Model is saved in epoch 45, overall batch: 22200
Training loss: 6.194436550140381 / Valid loss: 5.84300248055231
Model is saved in epoch 45, overall batch: 22300
Training loss: 5.987737655639648 / Valid loss: 5.8378580297742575
Model is saved in epoch 45, overall batch: 22400
Training loss: 5.6540021896362305 / Valid loss: 5.834283172516596
Model is saved in epoch 45, overall batch: 22500

Epoch: 46
Training loss: 5.237789630889893 / Valid loss: 5.831532339822679
Model is saved in epoch 46, overall batch: 22600
Training loss: 7.538846015930176 / Valid loss: 5.822729657945179
Model is saved in epoch 46, overall batch: 22700
Training loss: 6.328474044799805 / Valid loss: 5.8161087172372
Model is saved in epoch 46, overall batch: 22800
Training loss: 5.285771369934082 / Valid loss: 5.814855723153977
Model is saved in epoch 46, overall batch: 22900
Training loss: 5.43994140625 / Valid loss: 5.8134520076570055
Model is saved in epoch 46, overall batch: 23000

Epoch: 47
Training loss: 4.580597877502441 / Valid loss: 5.804686646234422
Model is saved in epoch 47, overall batch: 23100
Training loss: 6.141639709472656 / Valid loss: 5.805763265064784
Training loss: 7.01570987701416 / Valid loss: 5.79776927175976
Model is saved in epoch 47, overall batch: 23300
Training loss: 3.885998249053955 / Valid loss: 5.794749457495553
Model is saved in epoch 47, overall batch: 23400
Training loss: 3.6696553230285645 / Valid loss: 5.796809693745204

Epoch: 48
Training loss: 4.701953887939453 / Valid loss: 5.792827989941552
Model is saved in epoch 48, overall batch: 23600
Training loss: 4.608548164367676 / Valid loss: 5.7899745645977205
Model is saved in epoch 48, overall batch: 23700
Training loss: 6.936526298522949 / Valid loss: 5.784499599820092
Model is saved in epoch 48, overall batch: 23800
Training loss: 5.336643695831299 / Valid loss: 5.776852925618489
Model is saved in epoch 48, overall batch: 23900
Training loss: 5.818894386291504 / Valid loss: 5.777889644531976

Epoch: 49
Training loss: 4.753944396972656 / Valid loss: 5.769032712209793
Model is saved in epoch 49, overall batch: 24100
Training loss: 4.053979873657227 / Valid loss: 5.773669174739292
Training loss: 7.311246871948242 / Valid loss: 5.762256408873059
Model is saved in epoch 49, overall batch: 24300
Training loss: 6.369017601013184 / Valid loss: 5.7647200788770405

Epoch: 50
Training loss: 2.9169979095458984 / Valid loss: 5.760670239584787
Model is saved in epoch 50, overall batch: 24500
Training loss: 6.3555145263671875 / Valid loss: 5.753842612675258
Model is saved in epoch 50, overall batch: 24600
Training loss: 5.202606201171875 / Valid loss: 5.7502174536387125
Model is saved in epoch 50, overall batch: 24700
Training loss: 4.4505462646484375 / Valid loss: 5.756580227897281
Training loss: 6.142806053161621 / Valid loss: 5.757525173823039

Epoch: 51
Training loss: 5.050544738769531 / Valid loss: 5.75445397240775
Training loss: 5.387276649475098 / Valid loss: 5.744666213080997
Model is saved in epoch 51, overall batch: 25100
Training loss: 6.7472429275512695 / Valid loss: 5.7485784212748205
Training loss: 5.92277717590332 / Valid loss: 5.743291959308443
Model is saved in epoch 51, overall batch: 25300
Training loss: 5.751809120178223 / Valid loss: 5.746450848806472

Epoch: 52
Training loss: 5.130088806152344 / Valid loss: 5.7450516973223005
Training loss: 6.819611549377441 / Valid loss: 5.74382343746367
Training loss: 6.578333854675293 / Valid loss: 5.739600422268822
Model is saved in epoch 52, overall batch: 25700
Training loss: 6.322884559631348 / Valid loss: 5.739628026598976
Training loss: 4.76620626449585 / Valid loss: 5.723173286801293
Model is saved in epoch 52, overall batch: 25900

Epoch: 53
Training loss: 5.394003868103027 / Valid loss: 5.726662588119507
Training loss: 3.7206411361694336 / Valid loss: 5.733340578987485
Training loss: 4.855290412902832 / Valid loss: 5.731851956957862
Training loss: 5.504040241241455 / Valid loss: 5.7246973582676475
Training loss: 4.145469665527344 / Valid loss: 5.729844511122931

Epoch: 54
Training loss: 4.522854804992676 / Valid loss: 5.722767664137341
Model is saved in epoch 54, overall batch: 26500
Training loss: 6.466938018798828 / Valid loss: 5.721192546117873
Model is saved in epoch 54, overall batch: 26600
Training loss: 5.650846481323242 / Valid loss: 5.719268381027948
Model is saved in epoch 54, overall batch: 26700
Training loss: 5.609864234924316 / Valid loss: 5.721486427670434
Training loss: 4.266074180603027 / Valid loss: 5.720000789279029

Epoch: 55
Training loss: 5.879146575927734 / Valid loss: 5.720980469385783
Training loss: 7.80426025390625 / Valid loss: 5.719170381909325
Model is saved in epoch 55, overall batch: 27100
Training loss: 5.753293991088867 / Valid loss: 5.717676466987246
Model is saved in epoch 55, overall batch: 27200
Training loss: 4.356982231140137 / Valid loss: 5.716536403837658
Model is saved in epoch 55, overall batch: 27300
Training loss: 3.991332769393921 / Valid loss: 5.70393994422186
Model is saved in epoch 55, overall batch: 27400

Epoch: 56
Training loss: 5.028393745422363 / Valid loss: 5.714859590076265
Training loss: 6.1928839683532715 / Valid loss: 5.7070315633501325
Training loss: 5.546547889709473 / Valid loss: 5.709025049209595
Training loss: 5.03002405166626 / Valid loss: 5.707761526107788
Training loss: 4.836821556091309 / Valid loss: 5.70907120023455

Epoch: 57
Training loss: 5.670679092407227 / Valid loss: 5.703468254634312
Model is saved in epoch 57, overall batch: 28000
Training loss: 4.450545310974121 / Valid loss: 5.704269116265433
Training loss: 2.9706015586853027 / Valid loss: 5.704175202051799
Training loss: 5.226532936096191 / Valid loss: 5.702358125504993
Model is saved in epoch 57, overall batch: 28300
Training loss: 5.4384541511535645 / Valid loss: 5.698579388573056
Model is saved in epoch 57, overall batch: 28400

Epoch: 58
Training loss: 5.775944709777832 / Valid loss: 5.69988162404015
Training loss: 4.242907524108887 / Valid loss: 5.699809215182349
Training loss: 7.432225227355957 / Valid loss: 5.697808379218692
Model is saved in epoch 58, overall batch: 28700
Training loss: 5.014969825744629 / Valid loss: 5.698128743398757
Training loss: 5.001935005187988 / Valid loss: 5.692543731416975
Model is saved in epoch 58, overall batch: 28900

Epoch: 59
Training loss: 4.168295860290527 / Valid loss: 5.69580895333063
Training loss: 6.668811798095703 / Valid loss: 5.696497858138311
Training loss: 5.791794776916504 / Valid loss: 5.687084604444958
Model is saved in epoch 59, overall batch: 29200
Training loss: 4.2424211502075195 / Valid loss: 5.691874885559082

Epoch: 60
Training loss: 5.717854976654053 / Valid loss: 5.684493323734828
Model is saved in epoch 60, overall batch: 29400
Training loss: 4.99418830871582 / Valid loss: 5.691031369708833
Training loss: 3.888432502746582 / Valid loss: 5.685899182728359
Training loss: 5.376650810241699 / Valid loss: 5.685938210714431
Training loss: 5.577582836151123 / Valid loss: 5.683239450908842
Model is saved in epoch 60, overall batch: 29800

Epoch: 61
Training loss: 5.8616251945495605 / Valid loss: 5.685828776586623
Training loss: 5.118300437927246 / Valid loss: 5.674983662650699
Model is saved in epoch 61, overall batch: 30000
Training loss: 5.4434309005737305 / Valid loss: 5.683968146642049
Training loss: 5.67513370513916 / Valid loss: 5.6792853923071
Training loss: 4.501978397369385 / Valid loss: 5.67912795430138

Epoch: 62
Training loss: 3.8764917850494385 / Valid loss: 5.682981107348487
Training loss: 5.983235836029053 / Valid loss: 5.681698776426769
Training loss: 5.940973281860352 / Valid loss: 5.680098338354202
Training loss: 4.952910900115967 / Valid loss: 5.679454231262207
Training loss: 5.422904014587402 / Valid loss: 5.672836265109834
Model is saved in epoch 62, overall batch: 30800

Epoch: 63
Training loss: 6.537377834320068 / Valid loss: 5.675304941903978
Training loss: 5.356103420257568 / Valid loss: 5.675217778342111
Training loss: 5.069410800933838 / Valid loss: 5.676867625826881
Training loss: 5.460731029510498 / Valid loss: 5.6723285629635765
Model is saved in epoch 63, overall batch: 31200
Training loss: 4.417551040649414 / Valid loss: 5.668804829461234
Model is saved in epoch 63, overall batch: 31300

Epoch: 64
Training loss: 5.313470840454102 / Valid loss: 5.665866122926984
Model is saved in epoch 64, overall batch: 31400
Training loss: 4.5661797523498535 / Valid loss: 5.671034311112903
Training loss: 5.408322334289551 / Valid loss: 5.668865060806274
Training loss: 6.516327857971191 / Valid loss: 5.6699748016539075
Training loss: 5.605186462402344 / Valid loss: 5.665279642740885
Model is saved in epoch 64, overall batch: 31800

Epoch: 65
Training loss: 6.153847694396973 / Valid loss: 5.6608941418784005
Model is saved in epoch 65, overall batch: 31900
Training loss: 8.147008895874023 / Valid loss: 5.667904426938011
Training loss: 5.521518707275391 / Valid loss: 5.663261170614334
Training loss: 5.339005470275879 / Valid loss: 5.658512353897095
Model is saved in epoch 65, overall batch: 32200
Training loss: 6.599666118621826 / Valid loss: 5.665227274667649

Epoch: 66
Training loss: 3.5026865005493164 / Valid loss: 5.664421315420242
Training loss: 3.54500675201416 / Valid loss: 5.6618379184177945
Training loss: 5.256572246551514 / Valid loss: 5.658062680562337
Model is saved in epoch 66, overall batch: 32600
Training loss: 3.465834379196167 / Valid loss: 5.656825456165132
Model is saved in epoch 66, overall batch: 32700
Training loss: 3.8543357849121094 / Valid loss: 5.659791099457514

Epoch: 67
Training loss: 4.672262668609619 / Valid loss: 5.652746211914789
Model is saved in epoch 67, overall batch: 32900
Training loss: 6.049521446228027 / Valid loss: 5.655487242199126
Training loss: 6.820846080780029 / Valid loss: 5.653046194712321
Training loss: 4.326782703399658 / Valid loss: 5.646715811320713
Model is saved in epoch 67, overall batch: 33200
Training loss: 3.952695369720459 / Valid loss: 5.656236862000965

Epoch: 68
Training loss: 5.49180793762207 / Valid loss: 5.655469451631818
Training loss: 5.206277370452881 / Valid loss: 5.649506014869327
Training loss: 4.276354789733887 / Valid loss: 5.6544350828443255
Training loss: 7.669520378112793 / Valid loss: 5.6541811488923575
Training loss: 5.383461952209473 / Valid loss: 5.649945538384574

Epoch: 69
Training loss: 6.186971664428711 / Valid loss: 5.650990794953846
Training loss: 5.122649669647217 / Valid loss: 5.644987807955061
Model is saved in epoch 69, overall batch: 34000
Training loss: 5.991163730621338 / Valid loss: 5.648839968726748
Training loss: 6.183654308319092 / Valid loss: 5.648598970685686

Epoch: 70
Training loss: 7.399242401123047 / Valid loss: 5.643376495724633
Model is saved in epoch 70, overall batch: 34300
Training loss: 5.760087013244629 / Valid loss: 5.639754449753534
Model is saved in epoch 70, overall batch: 34400
Training loss: 5.8133392333984375 / Valid loss: 5.643773328690302
Training loss: 5.600527763366699 / Valid loss: 5.644496054876418
Training loss: 5.094790458679199 / Valid loss: 5.645151651473272

Epoch: 71
Training loss: 6.274688243865967 / Valid loss: 5.641267887751261
Training loss: 4.988303184509277 / Valid loss: 5.6388470082055955
Model is saved in epoch 71, overall batch: 34900
Training loss: 4.969576358795166 / Valid loss: 5.63886448542277
Training loss: 5.022750377655029 / Valid loss: 5.635328304199946
Model is saved in epoch 71, overall batch: 35100
Training loss: 4.31379508972168 / Valid loss: 5.640188596362159

Epoch: 72
Training loss: 4.481810569763184 / Valid loss: 5.633028182529268
Model is saved in epoch 72, overall batch: 35300
Training loss: 4.858323097229004 / Valid loss: 5.63402583485558
Training loss: 7.94981575012207 / Valid loss: 5.638481178737822
Training loss: 4.683403015136719 / Valid loss: 5.630694110052926
Model is saved in epoch 72, overall batch: 35600
Training loss: 4.136646270751953 / Valid loss: 5.6346698715573265

Epoch: 73
Training loss: 5.942680358886719 / Valid loss: 5.635072344825382
Training loss: 3.77103328704834 / Valid loss: 5.6297140893482025
Model is saved in epoch 73, overall batch: 35900
Training loss: 5.154266834259033 / Valid loss: 5.632968309947422
Training loss: 7.081118583679199 / Valid loss: 5.633132696151733
Training loss: 4.05415153503418 / Valid loss: 5.633721349352882

Epoch: 74
Training loss: 3.930102586746216 / Valid loss: 5.633940617243449
Training loss: 5.161819934844971 / Valid loss: 5.62842051869347
Model is saved in epoch 74, overall batch: 36400
Training loss: 5.474938869476318 / Valid loss: 5.62806746392023
Model is saved in epoch 74, overall batch: 36500
Training loss: 5.715826988220215 / Valid loss: 5.630903423400152
Training loss: 4.243630886077881 / Valid loss: 5.629295392263503

Epoch: 75
Training loss: 4.639866352081299 / Valid loss: 5.622450973874047
Model is saved in epoch 75, overall batch: 36800
Training loss: 4.45982551574707 / Valid loss: 5.62859529313587
Training loss: 4.205801963806152 / Valid loss: 5.6282371907007125
Training loss: 8.345954895019531 / Valid loss: 5.6276969228472025
Training loss: 4.764924049377441 / Valid loss: 5.626222381137667

Epoch: 76
Training loss: 5.241910934448242 / Valid loss: 5.62322663352603
Training loss: 7.0504045486450195 / Valid loss: 5.623027504058111
Training loss: 5.855197906494141 / Valid loss: 5.622139017922538
Model is saved in epoch 76, overall batch: 37500
Training loss: 5.513286113739014 / Valid loss: 5.6240034171513145
Training loss: 4.855635643005371 / Valid loss: 5.615770183290754
Model is saved in epoch 76, overall batch: 37700

Epoch: 77
Training loss: 6.247070789337158 / Valid loss: 5.621978421438308
Training loss: 4.93449592590332 / Valid loss: 5.614637463433402
Model is saved in epoch 77, overall batch: 37900
Training loss: 5.680752754211426 / Valid loss: 5.611062474477858
Model is saved in epoch 77, overall batch: 38000
Training loss: 5.042914390563965 / Valid loss: 5.6168676944006055
Training loss: 7.321018218994141 / Valid loss: 5.616129657200404

Epoch: 78
Training loss: 5.8524017333984375 / Valid loss: 5.6176365375518795
Training loss: 5.541521072387695 / Valid loss: 5.618693124680292
Training loss: 6.0119218826293945 / Valid loss: 5.6117455028352285
Training loss: 3.883645534515381 / Valid loss: 5.613967650277274
Training loss: 5.071498870849609 / Valid loss: 5.610042022523426
Model is saved in epoch 78, overall batch: 38700

Epoch: 79
Training loss: 5.402289390563965 / Valid loss: 5.613137858254569
Training loss: 4.254778861999512 / Valid loss: 5.6114368143535795
Training loss: 3.59920597076416 / Valid loss: 5.613035124824161
Training loss: 4.095914363861084 / Valid loss: 5.612387850171044
ModuleList(
  (0): Linear(in_features=31191, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.487976326261248
Training regression with following parameters:
dnn_hidden_units : 2000, 100, 16
dropout_probs : 0.0, 0.0
learning_rate : 0.001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : SGD
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : Bert
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=5376, out_features=2000, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=2000, out_features=100, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=100, out_features=16, bias=True)
  (9): Dropout(p=0, inplace=False)
  (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (11): LeakyReLU(negative_slope=0.02)
  (12): Linear(in_features=16, out_features=1, bias=True)
)

Epoch: 0
Training loss: 15.765700340270996 / Valid loss: 15.266402771359399
Model is saved in epoch 0, overall batch: 0
Training loss: 5.042430877685547 / Valid loss: 7.500886340368361
Model is saved in epoch 0, overall batch: 100
Training loss: 4.23737907409668 / Valid loss: 5.921776885078067
Model is saved in epoch 0, overall batch: 200
Training loss: 6.29364538192749 / Valid loss: 5.682949795041766
Model is saved in epoch 0, overall batch: 300
Training loss: 5.842200756072998 / Valid loss: 5.548471437181745
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 4.756719589233398 / Valid loss: 5.553807235899425
Training loss: 4.298105239868164 / Valid loss: 5.569606599353609
Training loss: 5.326928615570068 / Valid loss: 5.642630109332857
Training loss: 5.017754554748535 / Valid loss: 5.6339343093690415
Training loss: 3.9678406715393066 / Valid loss: 5.5637674763089136

Epoch: 2
Training loss: 4.209566593170166 / Valid loss: 5.612356049673898
Training loss: 4.178608417510986 / Valid loss: 5.750446242377872
Training loss: 3.3077023029327393 / Valid loss: 5.74691725685483
Training loss: 4.88202428817749 / Valid loss: 5.984495680672782
Training loss: 4.264095306396484 / Valid loss: 5.786848156792777

Epoch: 3
Training loss: 2.5928397178649902 / Valid loss: 5.875179701759702
Training loss: 2.498826503753662 / Valid loss: 6.106087437130156
Training loss: 4.6850714683532715 / Valid loss: 5.97977549235026
Training loss: 2.186169385910034 / Valid loss: 6.105248587472098
Training loss: 3.4255576133728027 / Valid loss: 6.111393374488467

Epoch: 4
Training loss: 2.261228322982788 / Valid loss: 6.212632283710298
Training loss: 2.7856407165527344 / Valid loss: 6.367695467812674
Training loss: 2.8565831184387207 / Valid loss: 6.320631045386905
Training loss: 2.643772602081299 / Valid loss: 6.169245856148856
Training loss: 2.3476099967956543 / Valid loss: 6.288671822774978

Epoch: 5
Training loss: 2.6007585525512695 / Valid loss: 6.993596685500372
Training loss: 1.937721848487854 / Valid loss: 6.489501063028971
Training loss: 2.0332107543945312 / Valid loss: 6.682902040935698
Training loss: 2.2377610206604004 / Valid loss: 6.4714922450837635
Training loss: 2.2933297157287598 / Valid loss: 6.610230096181234

Epoch: 6
Training loss: 2.3704824447631836 / Valid loss: 6.5890911692664735
Training loss: 1.2237951755523682 / Valid loss: 6.530026122501918
Training loss: 2.6668028831481934 / Valid loss: 6.618755563100179
Training loss: 1.8128156661987305 / Valid loss: 6.598240836461385
Training loss: 1.754177212715149 / Valid loss: 6.67875330334618

Epoch: 7
Training loss: 1.6314806938171387 / Valid loss: 6.549886939639137
Training loss: 1.7161669731140137 / Valid loss: 6.626883702051072
Training loss: 1.825516939163208 / Valid loss: 6.685345942633493
Training loss: 1.6144566535949707 / Valid loss: 6.730530461810884
Training loss: 1.254022240638733 / Valid loss: 6.626742994217645

Epoch: 8
Training loss: 0.8628376722335815 / Valid loss: 6.59803987003508
Training loss: 0.840111494064331 / Valid loss: 6.550634683881487
Training loss: 1.0600968599319458 / Valid loss: 6.688631010055542
Training loss: 1.804614543914795 / Valid loss: 6.621865404219855
Training loss: 1.3723456859588623 / Valid loss: 6.63860752923148

Epoch: 9
Training loss: 0.6908299922943115 / Valid loss: 6.583039256504604
Training loss: 0.7573602795600891 / Valid loss: 6.690453978947231
Training loss: 1.4202158451080322 / Valid loss: 6.676934541974749
Training loss: 1.119789958000183 / Valid loss: 6.6478013401939755

Epoch: 10
Training loss: 0.9327704906463623 / Valid loss: 6.61181899252392
Training loss: 0.7600219249725342 / Valid loss: 6.525962102980841
Training loss: 0.5637192726135254 / Valid loss: 6.57061973299299
Training loss: 1.3438125848770142 / Valid loss: 6.6073793547494075
Training loss: 0.7735837697982788 / Valid loss: 6.65690032641093

Epoch: 11
Training loss: 0.5911161303520203 / Valid loss: 6.639800630296979
Training loss: 0.9196419715881348 / Valid loss: 6.714557536443075
Training loss: 0.7024827003479004 / Valid loss: 6.790416422344389
Training loss: 0.6993299722671509 / Valid loss: 6.754666791643415
Training loss: 0.7075324058532715 / Valid loss: 6.7032001586187455

Epoch: 12
Training loss: 0.39375412464141846 / Valid loss: 6.579132511502221
Training loss: 0.5301622748374939 / Valid loss: 6.604428423018683
Training loss: 0.6285430192947388 / Valid loss: 6.513908277239119
Training loss: 0.6034932732582092 / Valid loss: 6.645499206724621
Training loss: 0.6196821331977844 / Valid loss: 6.61227723757426

Epoch: 13
Training loss: 0.37680479884147644 / Valid loss: 6.681903859547206
Training loss: 0.526980996131897 / Valid loss: 6.640049271356492
Training loss: 0.4539257884025574 / Valid loss: 6.595271096910749
Training loss: 0.5621163845062256 / Valid loss: 6.582649800890968
Training loss: 0.4460565745830536 / Valid loss: 6.5734669299352735

Epoch: 14
Training loss: 0.5914333462715149 / Valid loss: 6.621801598866781
Training loss: 0.49070507287979126 / Valid loss: 6.560744562603179
Training loss: 0.5259989500045776 / Valid loss: 6.555673088346209
Training loss: 0.25948449969291687 / Valid loss: 6.586678527650379
Training loss: 0.6754760146141052 / Valid loss: 6.649354369299752

Epoch: 15
Training loss: 0.46882298588752747 / Valid loss: 6.6811547869727725
Training loss: 0.6348530054092407 / Valid loss: 6.670148454393659
Training loss: 0.46523556113243103 / Valid loss: 6.6584804807390485
Training loss: 0.45887142419815063 / Valid loss: 6.60891052427746
Training loss: 0.48496049642562866 / Valid loss: 6.634208256857736

Epoch: 16
Training loss: 0.3049743175506592 / Valid loss: 6.565555495307559
Training loss: 0.45435047149658203 / Valid loss: 6.612872582390195
Training loss: 0.36655542254447937 / Valid loss: 6.5486997104826425
Training loss: 0.3891465663909912 / Valid loss: 6.6117689904712496
Training loss: 0.39975547790527344 / Valid loss: 6.563732653572446

Epoch: 17
Training loss: 0.7990560531616211 / Valid loss: 6.569073933646792
Training loss: 0.7692824602127075 / Valid loss: 6.557745831353324
Training loss: 0.6669824123382568 / Valid loss: 6.614656439281645
Training loss: 0.27177250385284424 / Valid loss: 6.601601418994722
Training loss: 0.3779035210609436 / Valid loss: 6.620827372868856

Epoch: 18
Training loss: 0.4896887242794037 / Valid loss: 6.604000136965797
Training loss: 0.42007529735565186 / Valid loss: 6.5563198248545325
Training loss: 0.420172780752182 / Valid loss: 6.566674936385382
Training loss: 0.45496243238449097 / Valid loss: 6.598615662256877
Training loss: 0.6350970268249512 / Valid loss: 6.5631274904523575

Epoch: 19
Training loss: 0.5448774099349976 / Valid loss: 6.654344436100551
Training loss: 0.8887042999267578 / Valid loss: 6.577063755762009
Training loss: 0.4142709970474243 / Valid loss: 6.5773750532241095
Training loss: 0.2850325107574463 / Valid loss: 6.547097835086641

Epoch: 20
Training loss: 0.32555830478668213 / Valid loss: 6.4868345578511555
Training loss: 0.6206218004226685 / Valid loss: 6.558145187014625
Training loss: 0.21500426530838013 / Valid loss: 6.539990411485944
Training loss: 0.3254860043525696 / Valid loss: 6.58965566725958
Training loss: 0.7169045209884644 / Valid loss: 6.543543238866897

Epoch: 21
Training loss: 0.3072414696216583 / Valid loss: 6.5334583850133985
Training loss: 0.4154866337776184 / Valid loss: 6.569000938960484
Training loss: 0.32305556535720825 / Valid loss: 6.564593673887707
Training loss: 0.27794021368026733 / Valid loss: 6.5852838834126795
Training loss: 0.3463420569896698 / Valid loss: 6.5662931692032585

Epoch: 22
Training loss: 0.3098863363265991 / Valid loss: 6.557641692388625
Training loss: 0.253909707069397 / Valid loss: 6.467937930425008
Training loss: 0.38885200023651123 / Valid loss: 6.539727826345534
Training loss: 1.0445916652679443 / Valid loss: 6.594146610441662
Training loss: 0.4033229351043701 / Valid loss: 6.584196276891799

Epoch: 23
Training loss: 0.24921837449073792 / Valid loss: 6.556321732203165
Training loss: 0.7468335032463074 / Valid loss: 6.482907140822638
Training loss: 0.2993065118789673 / Valid loss: 6.507833896364485
Training loss: 0.20183780789375305 / Valid loss: 6.515956374577113
Training loss: 0.436636745929718 / Valid loss: 6.586847171329317

Epoch: 24
Training loss: 0.558465301990509 / Valid loss: 6.580224627540225
Training loss: 0.396455854177475 / Valid loss: 6.5163773445856
Training loss: 0.25740212202072144 / Valid loss: 6.585533464522589
Training loss: 0.5150564908981323 / Valid loss: 6.575876276833671
Training loss: 0.8670803904533386 / Valid loss: 6.589196180161975

Epoch: 25
Training loss: 0.6435341238975525 / Valid loss: 6.579582589013236
Training loss: 0.29623180627822876 / Valid loss: 6.517912360600063
Training loss: 0.41823065280914307 / Valid loss: 6.528584094274612
Training loss: 0.2676159739494324 / Valid loss: 6.514958645048596
Training loss: 0.24382954835891724 / Valid loss: 6.54841746148609

Epoch: 26
Training loss: 0.3725477457046509 / Valid loss: 6.54251918338594
Training loss: 0.504570484161377 / Valid loss: 6.555820183526902
Training loss: 0.20895236730575562 / Valid loss: 6.497135160082863
Training loss: 0.2649601101875305 / Valid loss: 6.582287747519357
Training loss: 0.3682362735271454 / Valid loss: 6.565891969771612

Epoch: 27
Training loss: 0.26271557807922363 / Valid loss: 6.516990770612444
Training loss: 0.39834481477737427 / Valid loss: 6.5540310064951575
Training loss: 0.39193862676620483 / Valid loss: 6.584957041059222
Training loss: 0.36901986598968506 / Valid loss: 6.53929474467323
Training loss: 0.3372167944908142 / Valid loss: 6.527570056915283

Epoch: 28
Training loss: 0.2596457004547119 / Valid loss: 6.523834460122245
Training loss: 0.4018998146057129 / Valid loss: 6.519163869676136
Training loss: 0.5498902201652527 / Valid loss: 6.553589929853167
Training loss: 0.3178008794784546 / Valid loss: 6.489233925229027
Training loss: 0.29510974884033203 / Valid loss: 6.527069623129709

Epoch: 29
Training loss: 0.3009474575519562 / Valid loss: 6.478154214223226
Training loss: 0.2926444709300995 / Valid loss: 6.515493987855457
Training loss: 0.12174738943576813 / Valid loss: 6.493541413261777
Training loss: 0.20460005104541779 / Valid loss: 6.508174405779157

Epoch: 30
Training loss: 0.22724877297878265 / Valid loss: 6.498072901226226
Training loss: 0.2598232626914978 / Valid loss: 6.4871627081008185
Training loss: 0.25000786781311035 / Valid loss: 6.531401722771781
Training loss: 0.315096914768219 / Valid loss: 6.53367938768296
Training loss: 0.30825871229171753 / Valid loss: 6.511435715357463

Epoch: 31
Training loss: 0.2798534631729126 / Valid loss: 6.433579987571353
Training loss: 0.263679563999176 / Valid loss: 6.473984209696452
Training loss: 0.24449357390403748 / Valid loss: 6.47363756497701
Training loss: 0.282825767993927 / Valid loss: 6.511305145990281
Training loss: 0.18286991119384766 / Valid loss: 6.539030633653913

Epoch: 32
Training loss: 0.3272579312324524 / Valid loss: 6.530714384714762
Training loss: 0.31074586510658264 / Valid loss: 6.512446162814186
Training loss: 0.20961004495620728 / Valid loss: 6.572762714113508
Training loss: 0.1993136703968048 / Valid loss: 6.476679697490874
Training loss: 0.32529497146606445 / Valid loss: 6.516221082778204

Epoch: 33
Training loss: 0.2471737265586853 / Valid loss: 6.4616634573255265
Training loss: 0.3477966785430908 / Valid loss: 6.5341354188464935
Training loss: 0.20642465353012085 / Valid loss: 6.461787173861549
Training loss: 0.1547841727733612 / Valid loss: 6.487263852074033
Training loss: 0.28536760807037354 / Valid loss: 6.497025898524693

Epoch: 34
Training loss: 0.5804500579833984 / Valid loss: 6.44485284941537
Training loss: 0.25263845920562744 / Valid loss: 6.464764149983724
Training loss: 0.22393028438091278 / Valid loss: 6.53330568586077
Training loss: 0.21801960468292236 / Valid loss: 6.5301706541152225
Training loss: 0.19783607125282288 / Valid loss: 6.4900689147767565

Epoch: 35
Training loss: 0.7059658765792847 / Valid loss: 6.470491100492931
Training loss: 0.2884620428085327 / Valid loss: 6.443025284721738
Training loss: 0.36435389518737793 / Valid loss: 6.5528745923723495
Training loss: 0.16806453466415405 / Valid loss: 6.506603879020328
Training loss: 0.19943425059318542 / Valid loss: 6.555985153289068

Epoch: 36
Training loss: 0.24202662706375122 / Valid loss: 6.500633044469924
Training loss: 0.4951649308204651 / Valid loss: 6.4992023468017575
Training loss: 0.16354691982269287 / Valid loss: 6.4916447730291456
Training loss: 0.21823997795581818 / Valid loss: 6.5242975779942105
Training loss: 0.17191584408283234 / Valid loss: 6.5625038237798785

Epoch: 37
Training loss: 0.33796337246894836 / Valid loss: 6.470151140576317
Training loss: 0.18709143996238708 / Valid loss: 6.49595235869998
Training loss: 0.38278505206108093 / Valid loss: 6.496720563797724
Training loss: 0.6351658701896667 / Valid loss: 6.4828751791091195
Training loss: 0.36936014890670776 / Valid loss: 6.478620590482439

Epoch: 38
Training loss: 0.2900775074958801 / Valid loss: 6.45573145094372
Training loss: 0.230264350771904 / Valid loss: 6.47436508224124
Training loss: 0.24393035471439362 / Valid loss: 6.47273131779262
Training loss: 0.15568336844444275 / Valid loss: 6.479994260697138
Training loss: 0.24576780200004578 / Valid loss: 6.552403949555897

Epoch: 39
Training loss: 0.251237154006958 / Valid loss: 6.4952503749302455
Training loss: 0.17403073608875275 / Valid loss: 6.496827915736607
Training loss: 0.2253260612487793 / Valid loss: 6.455013774690174
Training loss: 0.20019690692424774 / Valid loss: 6.4839876243046355

Epoch: 40
Training loss: 0.16414153575897217 / Valid loss: 6.460242518924532
Training loss: 0.2303619533777237 / Valid loss: 6.440657617932274
Training loss: 0.20619961619377136 / Valid loss: 6.480282454263596
Training loss: 0.16448424756526947 / Valid loss: 6.504538027445475
Training loss: 0.1437200903892517 / Valid loss: 6.515617847442627

Epoch: 41
Training loss: 0.24530014395713806 / Valid loss: 6.4566205092838835
Training loss: 0.18025606870651245 / Valid loss: 6.438510840279715
Training loss: 0.21488246321678162 / Valid loss: 6.477592291150774
Training loss: 1.118802547454834 / Valid loss: 6.51607027053833
Training loss: 0.36013415455818176 / Valid loss: 6.461066686539423

Epoch: 42
Training loss: 0.1628488004207611 / Valid loss: 6.482588704427084
Training loss: 0.21322810649871826 / Valid loss: 6.496055566696894
Training loss: 0.2698012888431549 / Valid loss: 6.478043660663423
Training loss: 0.15830481052398682 / Valid loss: 6.460016657057262
Training loss: 0.16900739073753357 / Valid loss: 6.473711034229823

Epoch: 43
Training loss: 0.2869962453842163 / Valid loss: 6.469106692359561
Training loss: 0.20188933610916138 / Valid loss: 6.471167432694208
Training loss: 0.19407644867897034 / Valid loss: 6.468402635483515
Training loss: 0.4035569131374359 / Valid loss: 6.463747374216715
Training loss: 0.2676756978034973 / Valid loss: 6.464208478019351

Epoch: 44
Training loss: 0.18687205016613007 / Valid loss: 6.500656000773112
Training loss: 0.20516744256019592 / Valid loss: 6.479520874931699
Training loss: 0.2585129141807556 / Valid loss: 6.424930656523932
Training loss: 0.14302077889442444 / Valid loss: 6.410916791643415
Training loss: 0.2980179190635681 / Valid loss: 6.495898680459885

Epoch: 45
Training loss: 0.1693333089351654 / Valid loss: 6.431118411109561
Training loss: 0.33454546332359314 / Valid loss: 6.4309495835077195
Training loss: 0.4446280300617218 / Valid loss: 6.528272699174427
Training loss: 0.1860540360212326 / Valid loss: 6.471066608883086
Training loss: 0.21815894544124603 / Valid loss: 6.441833641415551

Epoch: 46
Training loss: 0.11010241508483887 / Valid loss: 6.437472425188337
Training loss: 0.2536678910255432 / Valid loss: 6.432887061436971
Training loss: 0.3705959618091583 / Valid loss: 6.459955705915179
Training loss: 0.0996260792016983 / Valid loss: 6.419195000330607
Training loss: 0.5902842283248901 / Valid loss: 6.45604582741147

Epoch: 47
Training loss: 0.10716493427753448 / Valid loss: 6.431344718024844
Training loss: 0.2454679310321808 / Valid loss: 6.490338034856887
Training loss: 0.38025957345962524 / Valid loss: 6.433895399456932
Training loss: 0.1942223310470581 / Valid loss: 6.43385599454244
Training loss: 0.18325155973434448 / Valid loss: 6.469023073287238

Epoch: 48
Training loss: 0.19283102452754974 / Valid loss: 6.492764039266677
Training loss: 0.3023659586906433 / Valid loss: 6.4602781068711055
Training loss: 0.21869555115699768 / Valid loss: 6.4754110563369025
Training loss: 0.16282393038272858 / Valid loss: 6.468641662597657
Training loss: 0.29198482632637024 / Valid loss: 6.444720488502866

Epoch: 49
Training loss: 0.3586122989654541 / Valid loss: 6.472088747932798
Training loss: 0.1698007583618164 / Valid loss: 6.4460055532909575
Training loss: 0.18436697125434875 / Valid loss: 6.462417080288842
Training loss: 0.22286131978034973 / Valid loss: 6.460023625691732

Epoch: 50
Training loss: 0.28334712982177734 / Valid loss: 6.455861414046515
Training loss: 0.22202980518341064 / Valid loss: 6.466064723332723
Training loss: 0.1678978055715561 / Valid loss: 6.423628350666591
Training loss: 0.2686591148376465 / Valid loss: 6.464798720677694
Training loss: 0.3956199586391449 / Valid loss: 6.458104767118182

Epoch: 51
Training loss: 0.1519360989332199 / Valid loss: 6.434102671486991
Training loss: 0.320894330739975 / Valid loss: 6.464236248107183
Training loss: 0.2191004902124405 / Valid loss: 6.411193995248704
Training loss: 0.19268375635147095 / Valid loss: 6.490602066403343
Training loss: 0.25765207409858704 / Valid loss: 6.3968986284165155

Epoch: 52
Training loss: 0.13751880824565887 / Valid loss: 6.4520240465799965
Training loss: 0.10310176014900208 / Valid loss: 6.431108031954084
Training loss: 0.15264007449150085 / Valid loss: 6.462610063098726
Training loss: 0.16902166604995728 / Valid loss: 6.407850683303106
Training loss: 0.3515225052833557 / Valid loss: 6.465167772202265

Epoch: 53
Training loss: 0.15263475477695465 / Valid loss: 6.409921319144113
Training loss: 0.3299385905265808 / Valid loss: 6.413794022514707
Training loss: 0.15401817858219147 / Valid loss: 6.424110623768398
Training loss: 0.4960412085056305 / Valid loss: 6.403119609469459
Training loss: 0.2546340823173523 / Valid loss: 6.444769677661714

Epoch: 54
Training loss: 0.28801462054252625 / Valid loss: 6.441448125385103
Training loss: 0.3182638883590698 / Valid loss: 6.454235426584879
Training loss: 0.1724241077899933 / Valid loss: 6.451311810811361
Training loss: 0.1500752866268158 / Valid loss: 6.4452796640850245
Training loss: 0.30608364939689636 / Valid loss: 6.425220589410691

Epoch: 55
Training loss: 0.5271943211555481 / Valid loss: 6.430661909920829
Training loss: 0.3344670534133911 / Valid loss: 6.409948033378238
Training loss: 0.4309447407722473 / Valid loss: 6.425917738959903
Training loss: 0.17575542628765106 / Valid loss: 6.459461850211734
Training loss: 0.2597511410713196 / Valid loss: 6.455588522411528

Epoch: 56
Training loss: 0.4460563659667969 / Valid loss: 6.442088445027669
Training loss: 0.15093007683753967 / Valid loss: 6.417564260391962
Training loss: 0.1513858437538147 / Valid loss: 6.392606412796747
Training loss: 0.17092105746269226 / Valid loss: 6.390770603361584
Training loss: 0.28505939245224 / Valid loss: 6.415219079880488

Epoch: 57
Training loss: 0.6073035001754761 / Valid loss: 6.4241612411680675
Training loss: 0.33692610263824463 / Valid loss: 6.426250471387591
Training loss: 0.28244641423225403 / Valid loss: 6.4169469106765025
Training loss: 0.5004138946533203 / Valid loss: 6.426950341179257
Training loss: 0.42479297518730164 / Valid loss: 6.446034488223848

Epoch: 58
Training loss: 0.17794150114059448 / Valid loss: 6.378240648905436
Training loss: 0.29364705085754395 / Valid loss: 6.422733429500035
Training loss: 0.11600545048713684 / Valid loss: 6.402946712857201
Training loss: 0.38747161626815796 / Valid loss: 6.410565873554774
Training loss: 0.14547303318977356 / Valid loss: 6.40334753763108

Epoch: 59
Training loss: 0.26980704069137573 / Valid loss: 6.415687987917946
Training loss: 0.3091619312763214 / Valid loss: 6.368788648786999
Training loss: 0.21759623289108276 / Valid loss: 6.425389405659267
Training loss: 0.2503666579723358 / Valid loss: 6.426740648632958

Epoch: 60
Training loss: 0.20996791124343872 / Valid loss: 6.448155321393695
Training loss: 0.5508055686950684 / Valid loss: 6.446132053647722
Training loss: 0.13736677169799805 / Valid loss: 6.415488663173857
Training loss: 0.24522598087787628 / Valid loss: 6.399518555686587
Training loss: 0.13587158918380737 / Valid loss: 6.404240944271996

Epoch: 61
Training loss: 0.3713666498661041 / Valid loss: 6.385814301172892
Training loss: 0.11027577519416809 / Valid loss: 6.395043316341582
Training loss: 0.4406837522983551 / Valid loss: 6.40865889957973
Training loss: 0.28984612226486206 / Valid loss: 6.417125408990042
Training loss: 0.1411258578300476 / Valid loss: 6.373506868453253

Epoch: 62
Training loss: 0.07512064278125763 / Valid loss: 6.405236148834229
Training loss: 0.12571504712104797 / Valid loss: 6.397777125948951
Training loss: 0.13357582688331604 / Valid loss: 6.406822263626825
Training loss: 0.23017603158950806 / Valid loss: 6.426078919001988
Training loss: 0.18108639121055603 / Valid loss: 6.408461993081229

Epoch: 63
Training loss: 0.2676023244857788 / Valid loss: 6.390839422316779
Training loss: 0.17496246099472046 / Valid loss: 6.384416816348121
Training loss: 0.13901154696941376 / Valid loss: 6.4285507474626815
Training loss: 0.2826370894908905 / Valid loss: 6.3926447459629605
Training loss: 0.1755586564540863 / Valid loss: 6.37895987374442

Epoch: 64
Training loss: 0.20380598306655884 / Valid loss: 6.377519598461332
Training loss: 0.13412022590637207 / Valid loss: 6.413230593999227
Training loss: 0.26380765438079834 / Valid loss: 6.400458780924479
Training loss: 0.15620093047618866 / Valid loss: 6.41102762903486
Training loss: 0.14484095573425293 / Valid loss: 6.437744172414144

Epoch: 65
Training loss: 0.18184953927993774 / Valid loss: 6.3863902773175925
Training loss: 0.307429701089859 / Valid loss: 6.3836912927173435
Training loss: 0.21065860986709595 / Valid loss: 6.3919322922116235
Training loss: 0.1430898904800415 / Valid loss: 6.38922286487761
Training loss: 0.9966495037078857 / Valid loss: 6.376174602054414

Epoch: 66
Training loss: 0.12379288673400879 / Valid loss: 6.3762088457743324
Training loss: 0.1314248889684677 / Valid loss: 6.363207939692906
Training loss: 0.49382320046424866 / Valid loss: 6.429370017278762
Training loss: 0.1896178126335144 / Valid loss: 6.44899540855771
Training loss: 0.3517659902572632 / Valid loss: 6.366899417695545

Epoch: 67
Training loss: 0.19452032446861267 / Valid loss: 6.413976224263509
Training loss: 0.08782894909381866 / Valid loss: 6.427938965388707
Training loss: 0.11512821912765503 / Valid loss: 6.401551896049863
Training loss: 0.6412409543991089 / Valid loss: 6.3999561446053645
Training loss: 0.22524496912956238 / Valid loss: 6.426959628150577

Epoch: 68
Training loss: 0.19396336376667023 / Valid loss: 6.367981415703183
Training loss: 0.24474012851715088 / Valid loss: 6.366862099511283
Training loss: 0.143762469291687 / Valid loss: 6.363574822743733
Training loss: 0.14347538352012634 / Valid loss: 6.414360616320655
Training loss: 0.2169269174337387 / Valid loss: 6.3804668471926735

Epoch: 69
Training loss: 0.2902604341506958 / Valid loss: 6.38683039574396
Training loss: 0.2057105004787445 / Valid loss: 6.380639266967774
Training loss: 0.2580888569355011 / Valid loss: 6.415684677305675
Training loss: 0.30055636167526245 / Valid loss: 6.369109069733392

Epoch: 70
Training loss: 0.15171724557876587 / Valid loss: 6.4016354969569615
Training loss: 0.48688817024230957 / Valid loss: 6.35352532523019
Training loss: 0.18163177371025085 / Valid loss: 6.377068301609584
Training loss: 0.19107021391391754 / Valid loss: 6.37387562025161
Training loss: 0.2170679122209549 / Valid loss: 6.343246403194609

Epoch: 71
Training loss: 0.27173054218292236 / Valid loss: 6.371781467256092
Training loss: 0.3603571355342865 / Valid loss: 6.351015281677246
Training loss: 0.1392894685268402 / Valid loss: 6.364069100788662
Training loss: 0.12592406570911407 / Valid loss: 6.35192776180449
Training loss: 0.1536390483379364 / Valid loss: 6.365172068277995

Epoch: 72
Training loss: 0.1500091850757599 / Valid loss: 6.365414723895845
Training loss: 0.36779162287712097 / Valid loss: 6.361125233059838
Training loss: 0.16407105326652527 / Valid loss: 6.351516230901082
Training loss: 0.14547589421272278 / Valid loss: 6.4005286693573
Training loss: 0.4628208875656128 / Valid loss: 6.349948120117188

Epoch: 73
Training loss: 0.3234761357307434 / Valid loss: 6.372968008404686
Training loss: 0.4039190709590912 / Valid loss: 6.3426520574660525
Training loss: 0.1986491084098816 / Valid loss: 6.3450053010668075
Training loss: 0.12525975704193115 / Valid loss: 6.358750141234625
Training loss: 0.1173602044582367 / Valid loss: 6.3613428797040665

Epoch: 74
Training loss: 0.13991358876228333 / Valid loss: 6.37265632947286
Training loss: 0.19992807507514954 / Valid loss: 6.366491317749023
Training loss: 0.33867907524108887 / Valid loss: 6.313078455697923
Training loss: 0.37945556640625 / Valid loss: 6.38682583173116
Training loss: 0.17365118861198425 / Valid loss: 6.391597713742938

Epoch: 75
Training loss: 0.16219261288642883 / Valid loss: 6.334480199359712
Training loss: 0.26773208379745483 / Valid loss: 6.356841763995942
Training loss: 0.4660983681678772 / Valid loss: 6.334250143596104
Training loss: 0.1330040991306305 / Valid loss: 6.308213826588222
Training loss: 0.24956099689006805 / Valid loss: 6.318492067427862

Epoch: 76
Training loss: 0.3140931725502014 / Valid loss: 6.3049195425851
Training loss: 0.48272955417633057 / Valid loss: 6.359162780216762
Training loss: 0.1641683131456375 / Valid loss: 6.3095206396920345
Training loss: 0.24776586890220642 / Valid loss: 6.360502120426723
Training loss: 0.19081729650497437 / Valid loss: 6.337754572005499

Epoch: 77
Training loss: 0.17644508183002472 / Valid loss: 6.357056837990171
Training loss: 0.23343130946159363 / Valid loss: 6.332255408877418
Training loss: 0.3262977600097656 / Valid loss: 6.363460677010672
Training loss: 0.31189480423927307 / Valid loss: 6.365561403547015
Training loss: 0.4388204514980316 / Valid loss: 6.367628008978707

Epoch: 78
Training loss: 0.20859310030937195 / Valid loss: 6.352250707717169
Training loss: 0.1349269449710846 / Valid loss: 6.363267035711379
Training loss: 0.12820421159267426 / Valid loss: 6.349946242287046
Training loss: 0.15040694177150726 / Valid loss: 6.3553952126275925
Training loss: 0.36882147192955017 / Valid loss: 6.373518496467954

Epoch: 79
Training loss: 0.0935317873954773 / Valid loss: 6.344944374901908
Training loss: 0.3093976378440857 / Valid loss: 6.366897476287115
Training loss: 0.07659834623336792 / Valid loss: 6.360671440760295
Training loss: 0.10881249606609344 / Valid loss: 6.360940138498942
ModuleList(
  (0): Linear(in_features=5376, out_features=2000, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=2000, out_features=100, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=100, out_features=16, bias=True)
  (9): Dropout(p=0, inplace=False)
  (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (11): LeakyReLU(negative_slope=0.02)
  (12): Linear(in_features=16, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.381952912466867
Training regression with following parameters:
dnn_hidden_units : 300, 32
dropout_probs : 0.0, 0.0
learning_rate : 0.001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : SGD
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : Bert
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=5376, out_features=300, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=300, out_features=32, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=32, out_features=1, bias=True)
)

Epoch: 0
Training loss: 13.485506057739258 / Valid loss: 16.577342787243072
Model is saved in epoch 0, overall batch: 0
Training loss: 3.4570741653442383 / Valid loss: 6.530275013333275
Model is saved in epoch 0, overall batch: 100
Training loss: 4.844887733459473 / Valid loss: 5.776760314759754
Model is saved in epoch 0, overall batch: 200
Training loss: 5.132018566131592 / Valid loss: 5.72529575030009
Model is saved in epoch 0, overall batch: 300
Training loss: 4.305407524108887 / Valid loss: 5.633358435403733
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 5.884970664978027 / Valid loss: 5.566636818931216
Model is saved in epoch 1, overall batch: 500
Training loss: 5.1891303062438965 / Valid loss: 5.602497368767148
Training loss: 3.8000714778900146 / Valid loss: 5.707312974475679
Training loss: 4.112241744995117 / Valid loss: 5.657078302474249
Training loss: 5.247347354888916 / Valid loss: 5.5525198187146865
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 5.111993789672852 / Valid loss: 5.595766122000558
Training loss: 3.9510116577148438 / Valid loss: 5.692064555486043
Training loss: 3.8972678184509277 / Valid loss: 5.667489344733102
Training loss: 5.479437828063965 / Valid loss: 5.915282499222529
Training loss: 5.177994728088379 / Valid loss: 5.575221906389509

Epoch: 3
Training loss: 4.20750617980957 / Valid loss: 5.896482197443644
Training loss: 3.4518933296203613 / Valid loss: 5.716273580278669
Training loss: 4.298651218414307 / Valid loss: 5.912095598947435
Training loss: 4.46403694152832 / Valid loss: 5.741578815096901
Training loss: 4.143260955810547 / Valid loss: 6.06236081804548

Epoch: 4
Training loss: 2.6088037490844727 / Valid loss: 5.830150197801136
Training loss: 3.865724802017212 / Valid loss: 5.851315382548741
Training loss: 3.7868330478668213 / Valid loss: 5.917695302054995
Training loss: 3.905289888381958 / Valid loss: 5.934809950419835
Training loss: 4.568512916564941 / Valid loss: 5.88766549428304

Epoch: 5
Training loss: 3.5554354190826416 / Valid loss: 5.917294075375511
Training loss: 3.8144683837890625 / Valid loss: 5.989838205065046
Training loss: 3.678898334503174 / Valid loss: 6.031517623719715
Training loss: 2.5668509006500244 / Valid loss: 5.980013252439953
Training loss: 4.721310615539551 / Valid loss: 6.088733409699939

Epoch: 6
Training loss: 2.87192440032959 / Valid loss: 6.058384257271176
Training loss: 1.8016934394836426 / Valid loss: 6.220289938790458
Training loss: 2.665989398956299 / Valid loss: 6.188613348915464
Training loss: 3.1001064777374268 / Valid loss: 6.203480577468872
Training loss: 2.820021629333496 / Valid loss: 6.087038507915678

Epoch: 7
Training loss: 2.6387758255004883 / Valid loss: 6.357588972364153
Training loss: 2.1998581886291504 / Valid loss: 6.406004174550374
Training loss: 2.270864486694336 / Valid loss: 7.398605414799282
Training loss: 2.562973976135254 / Valid loss: 6.724879460107712
Training loss: 2.236323833465576 / Valid loss: 6.488356029419672

Epoch: 8
Training loss: 1.8100686073303223 / Valid loss: 6.445573756808327
Training loss: 2.258617401123047 / Valid loss: 6.673467567988804
Training loss: 2.0214877128601074 / Valid loss: 6.5934448877970375
Training loss: 2.462266445159912 / Valid loss: 7.267830934978667
Training loss: 2.563457489013672 / Valid loss: 6.461018587294079

Epoch: 9
Training loss: 1.3175965547561646 / Valid loss: 6.435939078103928
Training loss: 2.1292898654937744 / Valid loss: 6.956590173358009
Training loss: 2.799058675765991 / Valid loss: 6.646304534730457
Training loss: 2.6456470489501953 / Valid loss: 6.550208405085972

Epoch: 10
Training loss: 1.6224770545959473 / Valid loss: 6.492935030800956
Training loss: 1.6329761743545532 / Valid loss: 7.0931503886268255
Training loss: 1.8883934020996094 / Valid loss: 6.659072778338477
Training loss: 1.784714937210083 / Valid loss: 7.168391180038452
Training loss: 1.790762186050415 / Valid loss: 6.7750151929401214

Epoch: 11
Training loss: 1.8431358337402344 / Valid loss: 6.7256905124301
Training loss: 1.9447927474975586 / Valid loss: 6.632198683420817
Training loss: 1.2166545391082764 / Valid loss: 6.877502968197777
Training loss: 2.1264216899871826 / Valid loss: 6.832256121862502
Training loss: 1.7260408401489258 / Valid loss: 7.26327375230335

Epoch: 12
Training loss: 1.176666021347046 / Valid loss: 6.885088312058222
Training loss: 1.3779499530792236 / Valid loss: 6.728337637583414
Training loss: 1.2002198696136475 / Valid loss: 7.039281427292597
Training loss: 1.5668423175811768 / Valid loss: 6.752382596333821
Training loss: 1.8814347982406616 / Valid loss: 6.692215367725917

Epoch: 13
Training loss: 1.2199516296386719 / Valid loss: 6.742926795142037
Training loss: 1.1335384845733643 / Valid loss: 6.7964219502040315
Training loss: 1.2104263305664062 / Valid loss: 6.768533261617025
Training loss: 1.1344892978668213 / Valid loss: 7.009672246660505
Training loss: 1.4516105651855469 / Valid loss: 6.804419231414795

Epoch: 14
Training loss: 1.2707455158233643 / Valid loss: 7.212129987989154
Training loss: 0.8627619743347168 / Valid loss: 6.828333209809803
Training loss: 0.9298070073127747 / Valid loss: 6.801197917120797
Training loss: 0.8657584190368652 / Valid loss: 6.816377607981364
Training loss: 1.3180333375930786 / Valid loss: 7.471163345518566

Epoch: 15
Training loss: 1.0745412111282349 / Valid loss: 6.762745925358364
Training loss: 1.3267104625701904 / Valid loss: 7.1384644644601005
Training loss: 1.034844994544983 / Valid loss: 6.7811291195097425
Training loss: 1.0370997190475464 / Valid loss: 7.182143370310466
Training loss: 1.357581377029419 / Valid loss: 6.920540973118373

Epoch: 16
Training loss: 1.7190804481506348 / Valid loss: 6.917948164258685
Training loss: 0.6100587248802185 / Valid loss: 6.892762883504232
Training loss: 1.2082757949829102 / Valid loss: 6.944518870399111
Training loss: 0.7216235995292664 / Valid loss: 6.867903309776669
Training loss: 0.8370188474655151 / Valid loss: 6.878616778055827

Epoch: 17
Training loss: 0.752098560333252 / Valid loss: 6.857291975475493
Training loss: 1.2123687267303467 / Valid loss: 7.2286987667992
Training loss: 0.6045585870742798 / Valid loss: 7.475333486284528
Training loss: 1.0052251815795898 / Valid loss: 6.851885977245512
Training loss: 1.1565428972244263 / Valid loss: 6.808535008203416

Epoch: 18
Training loss: 0.7613834142684937 / Valid loss: 6.852655269986108
Training loss: 1.292846441268921 / Valid loss: 6.96835067385719
Training loss: 0.7163707613945007 / Valid loss: 6.87259638877142
Training loss: 0.839563250541687 / Valid loss: 6.833955060868036
Training loss: 0.8825705051422119 / Valid loss: 6.9994033995128815

Epoch: 19
Training loss: 0.7163336277008057 / Valid loss: 6.899087905883789
Training loss: 1.2209455966949463 / Valid loss: 6.7125652880895705
Training loss: 1.3012529611587524 / Valid loss: 6.962290300641741
Training loss: 0.3375643491744995 / Valid loss: 6.789933545248849

Epoch: 20
Training loss: 0.45929422974586487 / Valid loss: 6.865611712137858
Training loss: 0.4780704379081726 / Valid loss: 6.831105046045213
Training loss: 0.5596227049827576 / Valid loss: 6.9172822271074565
Training loss: 0.6627935171127319 / Valid loss: 6.8773961339678085
Training loss: 0.8231115341186523 / Valid loss: 7.212409920919509

Epoch: 21
Training loss: 0.7881560921669006 / Valid loss: 7.091179970332554
Training loss: 0.7351148128509521 / Valid loss: 6.877445731844221
Training loss: 0.8956986665725708 / Valid loss: 6.910907259441557
Training loss: 1.0391745567321777 / Valid loss: 7.406857672191801
Training loss: 0.9281609058380127 / Valid loss: 6.821814820879982

Epoch: 22
Training loss: 0.5004188418388367 / Valid loss: 6.764326735905239
Training loss: 0.9319153428077698 / Valid loss: 7.078857340131488
Training loss: 0.7585253119468689 / Valid loss: 6.8439528783162435
Training loss: 0.5953716039657593 / Valid loss: 7.252071648552304
Training loss: 0.6517243385314941 / Valid loss: 6.888495951607114

Epoch: 23
Training loss: 0.5677701830863953 / Valid loss: 6.847617673873901
Training loss: 0.6247624158859253 / Valid loss: 6.9428961435953775
Training loss: 0.8995022773742676 / Valid loss: 6.984660312107631
Training loss: 0.6495487689971924 / Valid loss: 7.082498754773821
Training loss: 0.5745131969451904 / Valid loss: 6.89308998017084

Epoch: 24
Training loss: 0.45167461037635803 / Valid loss: 6.830669748215448
Training loss: 0.917344868183136 / Valid loss: 6.984068993159703
Training loss: 0.4396199584007263 / Valid loss: 6.822426755087716
Training loss: 0.6662071347236633 / Valid loss: 6.7646410896664575
Training loss: 0.4931257963180542 / Valid loss: 7.136090051560175

Epoch: 25
Training loss: 0.6583238840103149 / Valid loss: 6.851349653516497
Training loss: 0.7597413659095764 / Valid loss: 6.956604507991246
Training loss: 0.6999838352203369 / Valid loss: 6.866417803083148
Training loss: 0.572652280330658 / Valid loss: 6.835244351341611
Training loss: 0.45869213342666626 / Valid loss: 6.908564867292132

Epoch: 26
Training loss: 0.3454555571079254 / Valid loss: 6.812876719520205
Training loss: 0.4125431180000305 / Valid loss: 6.986858819779895
Training loss: 0.5950696468353271 / Valid loss: 6.912083970932733
Training loss: 0.5943369269371033 / Valid loss: 6.872687671298072
Training loss: 0.716728687286377 / Valid loss: 6.928625186284383

Epoch: 27
Training loss: 0.5915087461471558 / Valid loss: 6.940908777146112
Training loss: 0.36498063802719116 / Valid loss: 6.8118483861287435
Training loss: 0.7431935667991638 / Valid loss: 6.9018452371869765
Training loss: 0.5283437967300415 / Valid loss: 6.969739346277146
Training loss: 0.4297175407409668 / Valid loss: 6.806534744444347

Epoch: 28
Training loss: 0.33937326073646545 / Valid loss: 6.83280538604373
Training loss: 0.3737083077430725 / Valid loss: 6.854984494618007
Training loss: 0.26269668340682983 / Valid loss: 6.967533100219
Training loss: 0.4124552011489868 / Valid loss: 6.9173486664181665
Training loss: 0.4830261170864105 / Valid loss: 6.859507358641851

Epoch: 29
Training loss: 0.34671393036842346 / Valid loss: 6.869463141759237
Training loss: 0.286737322807312 / Valid loss: 6.795862652006603
Training loss: 0.49604904651641846 / Valid loss: 6.87221466700236
Training loss: 0.6726782321929932 / Valid loss: 6.998738997323173

Epoch: 30
Training loss: 0.4162137508392334 / Valid loss: 6.851128405616397
Training loss: 0.6545424461364746 / Valid loss: 6.968309615907215
Training loss: 0.40414363145828247 / Valid loss: 6.897067642211914
Training loss: 0.34227877855300903 / Valid loss: 6.861683141617548
Training loss: 0.7106068134307861 / Valid loss: 6.9125278927031015

Epoch: 31
Training loss: 0.44585347175598145 / Valid loss: 6.91486941746303
Training loss: 1.203381061553955 / Valid loss: 6.839730544317336
Training loss: 0.3731040060520172 / Valid loss: 6.945900031498501
Training loss: 0.506367564201355 / Valid loss: 6.840452503022694
Training loss: 0.49862658977508545 / Valid loss: 6.893275837671189

Epoch: 32
Training loss: 0.3162592649459839 / Valid loss: 6.8682549294971285
Training loss: 0.7038939595222473 / Valid loss: 6.879982662200928
Training loss: 0.4051509201526642 / Valid loss: 6.799691985902332
Training loss: 0.3026164472103119 / Valid loss: 6.879541224525088
Training loss: 0.4407041668891907 / Valid loss: 6.844918178376697

Epoch: 33
Training loss: 0.2967285215854645 / Valid loss: 7.205709534599667
Training loss: 0.4596618711948395 / Valid loss: 7.021758792513893
Training loss: 0.5868988037109375 / Valid loss: 6.865783984320505
Training loss: 0.4256957173347473 / Valid loss: 6.881491661071777
Training loss: 0.4544009566307068 / Valid loss: 7.244366804758708

Epoch: 34
Training loss: 0.8901783227920532 / Valid loss: 7.051511387597947
Training loss: 0.33228033781051636 / Valid loss: 6.781505866277786
Training loss: 0.28158384561538696 / Valid loss: 6.913215192159017
Training loss: 0.4508061408996582 / Valid loss: 6.810369936625163
Training loss: 0.6336835026741028 / Valid loss: 6.896123282114664

Epoch: 35
Training loss: 0.4027222990989685 / Valid loss: 6.9023961839221775
Training loss: 0.276203989982605 / Valid loss: 6.857167966025216
Training loss: 0.47990211844444275 / Valid loss: 6.918976438613165
Training loss: 0.19990865886211395 / Valid loss: 6.863313804353987
Training loss: 0.25360673666000366 / Valid loss: 6.863024806976318

Epoch: 36
Training loss: 0.3287600874900818 / Valid loss: 6.81584381375994
Training loss: 0.33990025520324707 / Valid loss: 6.82461028780256
Training loss: 0.5760876536369324 / Valid loss: 7.333871096656436
Training loss: 0.6256959438323975 / Valid loss: 6.988913245428176
Training loss: 0.3855710029602051 / Valid loss: 6.858831460135324

Epoch: 37
Training loss: 0.27400994300842285 / Valid loss: 6.823809669131324
Training loss: 0.23926402628421783 / Valid loss: 6.861449836549305
Training loss: 0.40206068754196167 / Valid loss: 6.789379019964309
Training loss: 0.3797105848789215 / Valid loss: 7.14957917985462
Training loss: 0.42887791991233826 / Valid loss: 6.799765305292039

Epoch: 38
Training loss: 0.36443787813186646 / Valid loss: 6.8943546158926825
Training loss: 0.30907538533210754 / Valid loss: 6.8422865958440875
Training loss: 0.3774983584880829 / Valid loss: 6.80353649684361
Training loss: 0.40939417481422424 / Valid loss: 6.848960806074596
Training loss: 0.6456255912780762 / Valid loss: 7.088196036929176

Epoch: 39
Training loss: 0.3082059919834137 / Valid loss: 6.823976916358585
Training loss: 0.38445335626602173 / Valid loss: 6.80925840650286
Training loss: 0.34243080019950867 / Valid loss: 6.774687004089356
Training loss: 0.2808007001876831 / Valid loss: 6.809128983815511

Epoch: 40
Training loss: 0.2540445327758789 / Valid loss: 6.822380374726795
Training loss: 0.25889313220977783 / Valid loss: 6.816827170054117
Training loss: 0.43507784605026245 / Valid loss: 6.939946796780541
Training loss: 0.3171404004096985 / Valid loss: 7.0184466225760325
Training loss: 0.29008615016937256 / Valid loss: 6.782937556221372

Epoch: 41
Training loss: 0.3691224455833435 / Valid loss: 6.824496096656436
Training loss: 0.25223684310913086 / Valid loss: 6.849828047979446
Training loss: 0.24246101081371307 / Valid loss: 6.793924506505331
Training loss: 0.5449906587600708 / Valid loss: 6.833999470302037
Training loss: 0.40516170859336853 / Valid loss: 6.8496817725045345

Epoch: 42
Training loss: 0.5013837218284607 / Valid loss: 6.804998220716204
Training loss: 0.2854146659374237 / Valid loss: 6.806082366761707
Training loss: 0.29787716269493103 / Valid loss: 6.773450515383765
Training loss: 0.47264599800109863 / Valid loss: 6.812897491455078
Training loss: 0.28912273049354553 / Valid loss: 6.865201234817505

Epoch: 43
Training loss: 0.35210877656936646 / Valid loss: 6.863998760495867
Training loss: 0.6684643030166626 / Valid loss: 6.824514720553443
Training loss: 0.48262453079223633 / Valid loss: 6.793299116407122
Training loss: 0.4612841010093689 / Valid loss: 6.782626233782087
Training loss: 0.23458164930343628 / Valid loss: 6.84851069904509

Epoch: 44
Training loss: 0.45514753460884094 / Valid loss: 6.779814334142776
Training loss: 0.1652388870716095 / Valid loss: 6.802751831781297
Training loss: 0.278476357460022 / Valid loss: 6.832399445488339
Training loss: 0.34359490871429443 / Valid loss: 6.786294819059826
Training loss: 0.30877935886383057 / Valid loss: 7.037484877450126

Epoch: 45
Training loss: 0.20487087965011597 / Valid loss: 6.842046542394729
Training loss: 0.7092756628990173 / Valid loss: 6.848445724305653
Training loss: 0.2024819552898407 / Valid loss: 6.780355353582473
Training loss: 0.5111775994300842 / Valid loss: 6.77539139248076
Training loss: 0.2572581171989441 / Valid loss: 6.820330301920573

Epoch: 46
Training loss: 0.5342199802398682 / Valid loss: 6.825904909769694
Training loss: 0.27790558338165283 / Valid loss: 6.757217672892979
Training loss: 0.34743332862854004 / Valid loss: 6.883573970340547
Training loss: 0.3753563165664673 / Valid loss: 6.774286706107003
Training loss: 0.5325287580490112 / Valid loss: 6.847932579403832

Epoch: 47
Training loss: 0.3754684329032898 / Valid loss: 6.840835017249698
Training loss: 0.24334102869033813 / Valid loss: 6.788365354992094
Training loss: 0.24519690871238708 / Valid loss: 6.744423791340419
Training loss: 0.304393470287323 / Valid loss: 6.763397262209938
Training loss: 0.29258090257644653 / Valid loss: 6.78583075205485

Epoch: 48
Training loss: 0.2340536117553711 / Valid loss: 6.76690768741426
Training loss: 0.28640031814575195 / Valid loss: 6.8116228421529135
Training loss: 0.264728307723999 / Valid loss: 6.824964141845703
Training loss: 0.5960477590560913 / Valid loss: 6.838293865748814
Training loss: 0.2284301221370697 / Valid loss: 6.745575341724214

Epoch: 49
Training loss: 0.1980821192264557 / Valid loss: 6.825425284249442
Training loss: 0.33413952589035034 / Valid loss: 6.802088489986601
Training loss: 0.36267679929733276 / Valid loss: 6.867968009767078
Training loss: 0.4051835536956787 / Valid loss: 6.744223113287063

Epoch: 50
Training loss: 0.6295350790023804 / Valid loss: 6.843454796927316
Training loss: 0.1498502492904663 / Valid loss: 6.8529545625050865
Training loss: 0.22585484385490417 / Valid loss: 6.780762963067918
Training loss: 0.22355592250823975 / Valid loss: 6.835238824571882
Training loss: 0.399588942527771 / Valid loss: 6.821658086776734

Epoch: 51
Training loss: 0.2686787247657776 / Valid loss: 6.788905852181571
Training loss: 0.2095508873462677 / Valid loss: 6.781059256054106
Training loss: 0.27118492126464844 / Valid loss: 6.895508802504766
Training loss: 0.5703043341636658 / Valid loss: 6.887876433417911
Training loss: 0.25784969329833984 / Valid loss: 6.834739401226952

Epoch: 52
Training loss: 0.39237210154533386 / Valid loss: 6.773396344411941
Training loss: 0.3678821623325348 / Valid loss: 6.8471559660775325
Training loss: 0.27089905738830566 / Valid loss: 6.85750002861023
Training loss: 0.3194272518157959 / Valid loss: 6.801558757963635
Training loss: 0.2215990126132965 / Valid loss: 6.794281991322835

Epoch: 53
Training loss: 0.2541002631187439 / Valid loss: 6.839925214222499
Training loss: 0.3433820903301239 / Valid loss: 6.786899030776251
Training loss: 0.42929723858833313 / Valid loss: 6.79124234971546
Training loss: 0.2740210294723511 / Valid loss: 6.826604211898077
Training loss: 0.29305678606033325 / Valid loss: 6.8031075545719695

Epoch: 54
Training loss: 0.27709493041038513 / Valid loss: 6.772081811087472
Training loss: 0.2938686013221741 / Valid loss: 6.877081725710914
Training loss: 0.30403804779052734 / Valid loss: 6.886251349676223
Training loss: 0.1952340006828308 / Valid loss: 6.791381454467773
Training loss: 0.19933629035949707 / Valid loss: 6.852973935717628

Epoch: 55
Training loss: 0.2739367187023163 / Valid loss: 6.74303826831636
Training loss: 0.35246554017066956 / Valid loss: 6.836227090018136
Training loss: 0.510836124420166 / Valid loss: 6.8135110355558846
Training loss: 0.30848294496536255 / Valid loss: 6.765733083089192
Training loss: 0.33717653155326843 / Valid loss: 6.8318634078616185

Epoch: 56
Training loss: 0.2512352168560028 / Valid loss: 6.773753611246745
Training loss: 0.3885825276374817 / Valid loss: 6.782387229374477
Training loss: 0.4098738431930542 / Valid loss: 6.763984780084519
Training loss: 0.6591814160346985 / Valid loss: 6.766606471652076
Training loss: 0.27622073888778687 / Valid loss: 6.809577694393339

Epoch: 57
Training loss: 0.3182424306869507 / Valid loss: 6.818795989808582
Training loss: 0.406358003616333 / Valid loss: 6.8093205769856775
Training loss: 0.3839922547340393 / Valid loss: 6.811577783312116
Training loss: 0.2111622542142868 / Valid loss: 6.74698790595645
Training loss: 0.29711639881134033 / Valid loss: 6.832635320935931

Epoch: 58
Training loss: 0.38396668434143066 / Valid loss: 6.837733936309815
Training loss: 0.2641172409057617 / Valid loss: 6.902911422366188
Training loss: 0.3427106440067291 / Valid loss: 6.798402513776507
Training loss: 0.44210612773895264 / Valid loss: 6.772655861718314
Training loss: 0.2010623961687088 / Valid loss: 6.783663795107887

Epoch: 59
Training loss: 0.20434369146823883 / Valid loss: 6.7988826933361235
Training loss: 0.28206419944763184 / Valid loss: 6.776427225839524
Training loss: 0.30525463819503784 / Valid loss: 6.764584673018683
Training loss: 0.42802393436431885 / Valid loss: 6.768765526726132

Epoch: 60
Training loss: 0.410860538482666 / Valid loss: 6.756829824901763
Training loss: 0.33089661598205566 / Valid loss: 6.747382109505789
Training loss: 0.3340752124786377 / Valid loss: 6.740649355025519
Training loss: 0.2144266664981842 / Valid loss: 6.782057653154646
Training loss: 0.3997235894203186 / Valid loss: 6.831509914852324

Epoch: 61
Training loss: 0.196322500705719 / Valid loss: 6.765134493509929
Training loss: 0.27254605293273926 / Valid loss: 6.850789601462228
Training loss: 0.2643607258796692 / Valid loss: 6.750758250554402
Training loss: 0.23267784714698792 / Valid loss: 6.742791166759672
Training loss: 0.2739800810813904 / Valid loss: 6.7725354739597865

Epoch: 62
Training loss: 0.27046385407447815 / Valid loss: 6.787410795120966
Training loss: 0.20932361483573914 / Valid loss: 6.738061768668039
Training loss: 0.18614116311073303 / Valid loss: 6.73845937819708
Training loss: 0.25516360998153687 / Valid loss: 6.677121609733218
Training loss: 0.5920919179916382 / Valid loss: 6.740099675314767

Epoch: 63
Training loss: 0.4961109161376953 / Valid loss: 6.8423640818822955
Training loss: 0.26938968896865845 / Valid loss: 6.771845826648531
Training loss: 0.17903964221477509 / Valid loss: 6.8014602797372
Training loss: 0.27120816707611084 / Valid loss: 6.744919649759928
Training loss: 0.26830044388771057 / Valid loss: 6.723481232779367

Epoch: 64
Training loss: 0.2330828160047531 / Valid loss: 6.84465453738258
Training loss: 0.2527996301651001 / Valid loss: 6.737191756566365
Training loss: 0.2598552107810974 / Valid loss: 6.693252990359352
Training loss: 0.5949990749359131 / Valid loss: 6.857938655217489
Training loss: 0.4682732820510864 / Valid loss: 6.730885950724284

Epoch: 65
Training loss: 0.7895015478134155 / Valid loss: 6.775057063783918
Training loss: 0.8441762924194336 / Valid loss: 6.853095127287365
Training loss: 0.1963118016719818 / Valid loss: 6.703488172803606
Training loss: 0.48360931873321533 / Valid loss: 6.755483027866909
Training loss: 0.1529003083705902 / Valid loss: 6.823268563406808

Epoch: 66
Training loss: 0.18516704440116882 / Valid loss: 6.743623084113711
Training loss: 0.1970767378807068 / Valid loss: 6.77973834900629
Training loss: 0.30430206656455994 / Valid loss: 6.771327745346796
Training loss: 0.22531700134277344 / Valid loss: 6.799580878303164
Training loss: 0.29818233847618103 / Valid loss: 6.768349963142758

Epoch: 67
Training loss: 0.20804835855960846 / Valid loss: 6.749194483529954
Training loss: 0.36725345253944397 / Valid loss: 6.756166744232178
Training loss: 0.7180564403533936 / Valid loss: 6.754337771733602
Training loss: 0.5060389637947083 / Valid loss: 6.777647658756801
Training loss: 0.4465923011302948 / Valid loss: 6.761226104554676

Epoch: 68
Training loss: 0.22188520431518555 / Valid loss: 6.743005988711403
Training loss: 0.42895281314849854 / Valid loss: 6.8047635350908555
Training loss: 0.4004930257797241 / Valid loss: 6.792923961366926
Training loss: 0.1623292714357376 / Valid loss: 6.746030185336158
Training loss: 0.21719390153884888 / Valid loss: 6.725353227342878

Epoch: 69
Training loss: 0.23188354074954987 / Valid loss: 6.778948293413435
Training loss: 0.29794687032699585 / Valid loss: 6.70600817089989
Training loss: 0.2368851602077484 / Valid loss: 6.7383074260893325
Training loss: 0.2791026532649994 / Valid loss: 6.746834378015428

Epoch: 70
Training loss: 0.3232101798057556 / Valid loss: 6.725097524552118
Training loss: 0.2712368071079254 / Valid loss: 6.706375657944452
Training loss: 0.2678160071372986 / Valid loss: 6.739890389215379
Training loss: 0.17634110152721405 / Valid loss: 6.780197722571237
Training loss: 0.4968556761741638 / Valid loss: 6.765674522944859

Epoch: 71
Training loss: 0.1987067461013794 / Valid loss: 6.760185704912458
Training loss: 0.25057530403137207 / Valid loss: 6.769595064435687
Training loss: 0.2763547897338867 / Valid loss: 6.765354556129092
Training loss: 0.294171005487442 / Valid loss: 6.703408277602422
Training loss: 0.35021084547042847 / Valid loss: 6.74340497198559

Epoch: 72
Training loss: 0.4156190752983093 / Valid loss: 6.722485451471238
Training loss: 0.3778257966041565 / Valid loss: 6.787533576147897
Training loss: 0.17911159992218018 / Valid loss: 6.6800423440479095
Training loss: 0.289224773645401 / Valid loss: 6.76214971996489
Training loss: 0.17227619886398315 / Valid loss: 6.852358429772513

Epoch: 73
Training loss: 0.5686764121055603 / Valid loss: 6.718997841789609
Training loss: 0.2187536656856537 / Valid loss: 6.808343692052932
Training loss: 0.2018645703792572 / Valid loss: 6.741706671033587
Training loss: 0.21322903037071228 / Valid loss: 6.721482717423212
Training loss: 0.29890623688697815 / Valid loss: 6.795516554514567

Epoch: 74
Training loss: 0.29905641078948975 / Valid loss: 6.887888417925153
Training loss: 0.18963265419006348 / Valid loss: 6.7495816003708615
Training loss: 0.5075234770774841 / Valid loss: 6.711737941560291
Training loss: 0.2301051765680313 / Valid loss: 6.743754604884557
Training loss: 0.26039838790893555 / Valid loss: 6.715830494108654

Epoch: 75
Training loss: 0.27326613664627075 / Valid loss: 6.731472038087391
Training loss: 0.26965662837028503 / Valid loss: 6.724297173817953
Training loss: 0.1516609489917755 / Valid loss: 6.7303664525349935
Training loss: 0.23275722563266754 / Valid loss: 6.748108686719622
Training loss: 0.17196126282215118 / Valid loss: 6.736229655856178

Epoch: 76
Training loss: 0.1388411521911621 / Valid loss: 6.76078309785752
Training loss: 0.2008332461118698 / Valid loss: 6.833154896327428
Training loss: 0.20559385418891907 / Valid loss: 6.686438297090076
Training loss: 0.21655505895614624 / Valid loss: 6.794442712692987
Training loss: 0.22688642144203186 / Valid loss: 6.748138341449556

Epoch: 77
Training loss: 0.18353334069252014 / Valid loss: 6.705806727636428
Training loss: 0.44017481803894043 / Valid loss: 6.700549652462914
Training loss: 0.4038894772529602 / Valid loss: 6.738928390684582
Training loss: 0.2886130213737488 / Valid loss: 6.741568202064151
Training loss: 0.2936944365501404 / Valid loss: 6.716601458049956

Epoch: 78
Training loss: 0.24125589430332184 / Valid loss: 6.738854771568661
Training loss: 0.6029118299484253 / Valid loss: 6.726688857305618
Training loss: 0.5111819505691528 / Valid loss: 6.767527968542916
Training loss: 0.36554577946662903 / Valid loss: 6.750232424054827
Training loss: 0.21798375248908997 / Valid loss: 6.707362333933513

Epoch: 79
Training loss: 0.17890504002571106 / Valid loss: 6.714539150964646
Training loss: 0.5236692428588867 / Valid loss: 6.774152192615327
Training loss: 0.22128793597221375 / Valid loss: 6.736054084414527
Training loss: 0.4582979381084442 / Valid loss: 6.754451946985154
ModuleList(
  (0): Linear(in_features=5376, out_features=300, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=300, out_features=32, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=32, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.456649437404814
Training regression with following parameters:
dnn_hidden_units : 248
dropout_probs : 0.0, 0.0
learning_rate : 0.001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : SGD
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : Bert
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=5376, out_features=248, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=248, out_features=1, bias=True)
)

Epoch: 0
Training loss: 20.62260627746582 / Valid loss: 15.821076865423294
Model is saved in epoch 0, overall batch: 0
Training loss: 6.312438488006592 / Valid loss: 5.782402011326381
Model is saved in epoch 0, overall batch: 100
Training loss: 6.626265525817871 / Valid loss: 5.648898072469802
Model is saved in epoch 0, overall batch: 200
Training loss: 5.999965667724609 / Valid loss: 5.561895890462966
Model is saved in epoch 0, overall batch: 300
Training loss: 8.334207534790039 / Valid loss: 5.654933245976766

Epoch: 1
Training loss: 5.244283199310303 / Valid loss: 5.5207379522777735
Model is saved in epoch 1, overall batch: 500
Training loss: 5.461071491241455 / Valid loss: 5.537272419248309
Training loss: 7.309114456176758 / Valid loss: 5.678013149897257
Training loss: 5.803442001342773 / Valid loss: 5.587360309419178
Training loss: 5.411737442016602 / Valid loss: 5.5323139145260765

Epoch: 2
Training loss: 4.822872638702393 / Valid loss: 5.5481255372365315
Training loss: 4.553755760192871 / Valid loss: 5.557839439028785
Training loss: 5.0963897705078125 / Valid loss: 5.595197818392799
Training loss: 5.403703212738037 / Valid loss: 5.525537722451347
Training loss: 5.436009407043457 / Valid loss: 5.5749356542314805

Epoch: 3
Training loss: 3.486049175262451 / Valid loss: 5.572971319016956
Training loss: 4.630762100219727 / Valid loss: 5.5767019022078745
Training loss: 3.9973928928375244 / Valid loss: 5.655842749277751
Training loss: 4.906824111938477 / Valid loss: 5.889032793045044
Training loss: 4.649782180786133 / Valid loss: 5.592046848932902

Epoch: 4
Training loss: 3.3244166374206543 / Valid loss: 5.830181137720744
Training loss: 4.0159101486206055 / Valid loss: 5.651510890324911
Training loss: 3.8812828063964844 / Valid loss: 5.937579842976161
Training loss: 4.830534934997559 / Valid loss: 5.643080879393078
Training loss: 6.1269001960754395 / Valid loss: 5.781846918378558

Epoch: 5
Training loss: 3.6648192405700684 / Valid loss: 5.7482916968209405
Training loss: 3.3266990184783936 / Valid loss: 5.882529313223703
Training loss: 5.620205402374268 / Valid loss: 5.7094084194728305
Training loss: 4.914240837097168 / Valid loss: 5.789184275127592
Training loss: 6.35711669921875 / Valid loss: 6.270100180308024

Epoch: 6
Training loss: 3.645369529724121 / Valid loss: 5.879225120090303
Training loss: 2.953738212585449 / Valid loss: 5.943836882000878
Training loss: 3.931783676147461 / Valid loss: 5.917436100187755
Training loss: 3.622002363204956 / Valid loss: 5.902938413619995
Training loss: 2.798304796218872 / Valid loss: 5.894418432599022

Epoch: 7
Training loss: 2.320878505706787 / Valid loss: 5.918871970403762
Training loss: 3.0377392768859863 / Valid loss: 5.980479269935971
Training loss: 3.617147922515869 / Valid loss: 6.126538190387544
Training loss: 4.319531440734863 / Valid loss: 5.912345754532587
Training loss: 3.8508827686309814 / Valid loss: 6.351355257488432

Epoch: 8
Training loss: 3.076977491378784 / Valid loss: 6.022086393265497
Training loss: 3.0622143745422363 / Valid loss: 6.3435213679359075
Training loss: 4.180960178375244 / Valid loss: 6.006243662607102
Training loss: 3.341827630996704 / Valid loss: 6.064748278118315
Training loss: 3.111532211303711 / Valid loss: 6.848010771615165

Epoch: 9
Training loss: 3.1600849628448486 / Valid loss: 6.1069217273167204
Training loss: 3.25532865524292 / Valid loss: 6.224871147246588
Training loss: 3.521022319793701 / Valid loss: 6.4632301421392535
Training loss: 2.1903724670410156 / Valid loss: 7.069436259496779

Epoch: 10
Training loss: 2.719900608062744 / Valid loss: 6.134010169619605
Training loss: 3.373067855834961 / Valid loss: 6.351782678422474
Training loss: 2.8975272178649902 / Valid loss: 6.2298657462710425
Training loss: 3.1403613090515137 / Valid loss: 6.178451824188232
Training loss: 3.001293420791626 / Valid loss: 6.432161299387614

Epoch: 11
Training loss: 3.0253567695617676 / Valid loss: 6.282483296167283
Training loss: 2.8200957775115967 / Valid loss: 6.195561431703114
Training loss: 2.7768054008483887 / Valid loss: 6.4379486538115005
Training loss: 2.7201359272003174 / Valid loss: 6.158489215941656
Training loss: 2.620471954345703 / Valid loss: 6.407860905783517

Epoch: 12
Training loss: 2.8014986515045166 / Valid loss: 7.080790151868547
Training loss: 2.336186408996582 / Valid loss: 6.7314493905930295
Training loss: 3.2585458755493164 / Valid loss: 6.449056661696661
Training loss: 2.6679506301879883 / Valid loss: 7.324375193459647
Training loss: 1.8373174667358398 / Valid loss: 6.676259735652379

Epoch: 13
Training loss: 1.9504060745239258 / Valid loss: 6.487425234204247
Training loss: 2.126605749130249 / Valid loss: 6.4027812321980795
Training loss: 1.6486432552337646 / Valid loss: 6.591701693761916
Training loss: 1.8099974393844604 / Valid loss: 6.768780345008487
Training loss: 2.268421173095703 / Valid loss: 6.5504781450544085

Epoch: 14
Training loss: 1.6912081241607666 / Valid loss: 6.6034802754720054
Training loss: 2.398416757583618 / Valid loss: 6.584603241511753
Training loss: 4.172308921813965 / Valid loss: 7.601777558099656
Training loss: 2.4657371044158936 / Valid loss: 6.716397962116059
Training loss: 2.6717379093170166 / Valid loss: 6.542923836481004

Epoch: 15
Training loss: 1.5136778354644775 / Valid loss: 7.112515413193476
Training loss: 2.703660488128662 / Valid loss: 6.570807150432041
Training loss: 2.40661358833313 / Valid loss: 6.7601741018749415
Training loss: 2.3519058227539062 / Valid loss: 6.601628968829201
Training loss: 2.0764241218566895 / Valid loss: 6.735687024252755

Epoch: 16
Training loss: 2.7509775161743164 / Valid loss: 6.65966256459554
Training loss: 1.93463933467865 / Valid loss: 6.828725590024676
Training loss: 1.3701145648956299 / Valid loss: 6.686442384265718
Training loss: 2.2532691955566406 / Valid loss: 6.675660242353167
Training loss: 2.2510194778442383 / Valid loss: 7.822255234491258

Epoch: 17
Training loss: 1.9451680183410645 / Valid loss: 6.646299239567348
Training loss: 1.7607523202896118 / Valid loss: 6.724984146299816
Training loss: 1.5927481651306152 / Valid loss: 7.046758231662569
Training loss: 3.6873903274536133 / Valid loss: 6.807383019583566
Training loss: 1.653456211090088 / Valid loss: 6.947065453302293

Epoch: 18
Training loss: 2.5527515411376953 / Valid loss: 7.228678685142881
Training loss: 1.4423255920410156 / Valid loss: 8.694548516046433
Training loss: 2.3361072540283203 / Valid loss: 8.179304740542458
Training loss: 1.7511323690414429 / Valid loss: 7.235463346753802
Training loss: 1.7928860187530518 / Valid loss: 6.790559201013474

Epoch: 19
Training loss: 1.2379469871520996 / Valid loss: 7.175202501387823
Training loss: 1.890880823135376 / Valid loss: 7.303953938257127
Training loss: 1.7326329946517944 / Valid loss: 7.304204641069685
Training loss: 1.251649260520935 / Valid loss: 7.8710838862827845

Epoch: 20
Training loss: 2.158975124359131 / Valid loss: 7.161475395020984
Training loss: 1.4121849536895752 / Valid loss: 6.779689044044131
Training loss: 1.400665283203125 / Valid loss: 7.563430854252407
Training loss: 1.27761971950531 / Valid loss: 7.924210330418178
Training loss: 1.31663978099823 / Valid loss: 9.345052482968285

Epoch: 21
Training loss: 1.0083339214324951 / Valid loss: 7.273468639737084
Training loss: 1.620606780052185 / Valid loss: 6.977515175229027
Training loss: 1.5522946119308472 / Valid loss: 7.655810778481619
Training loss: 2.152210235595703 / Valid loss: 7.658027471814837
Training loss: 1.626043677330017 / Valid loss: 7.413818313961937

Epoch: 22
Training loss: 1.1321399211883545 / Valid loss: 6.9571509906223845
Training loss: 1.2778651714324951 / Valid loss: 7.425983824048724
Training loss: 1.9657901525497437 / Valid loss: 7.52528167452131
Training loss: 1.4729115962982178 / Valid loss: 7.606688790094285
Training loss: 1.1462655067443848 / Valid loss: 6.891003231775193

Epoch: 23
Training loss: 0.7695568799972534 / Valid loss: 6.7873677730560305
Training loss: 1.6960642337799072 / Valid loss: 9.775730160304478
Training loss: 1.6201090812683105 / Valid loss: 6.899731436229888
Training loss: 1.0499831438064575 / Valid loss: 7.60558530716669
Training loss: 1.2725582122802734 / Valid loss: 6.927141389392671

Epoch: 24
Training loss: 0.9235942959785461 / Valid loss: 7.263785244169689
Training loss: 1.4577627182006836 / Valid loss: 7.833597196851458
Training loss: 1.2676076889038086 / Valid loss: 6.996071034386045
Training loss: 0.931744396686554 / Valid loss: 7.527961526598249
Training loss: 1.2709816694259644 / Valid loss: 6.951789887746175

Epoch: 25
Training loss: 0.8715004324913025 / Valid loss: 6.983160364060175
Training loss: 0.9061920642852783 / Valid loss: 7.042179357437861
Training loss: 1.3260633945465088 / Valid loss: 7.073294680459159
Training loss: 1.2035713195800781 / Valid loss: 7.153155844552177
Training loss: 1.1284788846969604 / Valid loss: 6.976862103598458

Epoch: 26
Training loss: 0.565925121307373 / Valid loss: 6.959483818780808
Training loss: 1.0841190814971924 / Valid loss: 7.117844168345133
Training loss: 0.7412866353988647 / Valid loss: 7.248322327931722
Training loss: 0.8270851373672485 / Valid loss: 7.827180549076625
Training loss: 0.8841052651405334 / Valid loss: 7.3820248876299175

Epoch: 27
Training loss: 1.1943004131317139 / Valid loss: 6.976496998469035
Training loss: 0.9046428203582764 / Valid loss: 7.032549481164842
Training loss: 1.2672779560089111 / Valid loss: 12.832330939883278
Training loss: 1.0461781024932861 / Valid loss: 6.938991469428653
Training loss: 1.6026496887207031 / Valid loss: 7.022827738807315

Epoch: 28
Training loss: 0.6578078269958496 / Valid loss: 7.52043848945981
Training loss: 1.5707437992095947 / Valid loss: 12.310394704909552
Training loss: 0.7806028723716736 / Valid loss: 7.259953884851365
Training loss: 1.5970242023468018 / Valid loss: 8.663047200157528
Training loss: 1.291646957397461 / Valid loss: 7.058036695207869

Epoch: 29
Training loss: 0.6785643100738525 / Valid loss: 7.063009330204555
Training loss: 0.998985767364502 / Valid loss: 10.35784786769322
Training loss: 1.0889352560043335 / Valid loss: 7.0853437968662805
Training loss: 0.8913177251815796 / Valid loss: 6.986072077069964

Epoch: 30
Training loss: 0.5871413946151733 / Valid loss: 7.235504781632196
Training loss: 0.7231724262237549 / Valid loss: 7.019511141095843
Training loss: 0.6910883784294128 / Valid loss: 7.088810566493443
Training loss: 0.8817110061645508 / Valid loss: 7.367452457972935
Training loss: 0.7224568128585815 / Valid loss: 7.075583580562046

Epoch: 31
Training loss: 0.7816085815429688 / Valid loss: 7.564044293903169
Training loss: 0.9432468414306641 / Valid loss: 7.723707283110846
Training loss: 0.8293903470039368 / Valid loss: 7.192809529531569
Training loss: 0.7992712259292603 / Valid loss: 7.151208269028436
Training loss: 0.7845082879066467 / Valid loss: 7.270709923335484

Epoch: 32
Training loss: 0.5720974206924438 / Valid loss: 7.577519112541562
Training loss: 0.44194406270980835 / Valid loss: 7.04359023684547
Training loss: 1.0357846021652222 / Valid loss: 7.398456537155878
Training loss: 0.5651695132255554 / Valid loss: 7.123799428485689
Training loss: 0.9525454044342041 / Valid loss: 7.092059203556606

Epoch: 33
Training loss: 0.7870014905929565 / Valid loss: 8.142335460299538
Training loss: 1.0066142082214355 / Valid loss: 7.608128833770752
Training loss: 0.7811516523361206 / Valid loss: 7.20413864680699
Training loss: 0.9908014535903931 / Valid loss: 7.487918072655088
Training loss: 1.0367634296417236 / Valid loss: 8.047446986607143

Epoch: 34
Training loss: 0.5266765356063843 / Valid loss: 7.444060702550979
Training loss: 1.180842638015747 / Valid loss: 8.290840907323927
Training loss: 0.4769260883331299 / Valid loss: 7.021278299604144
Training loss: 0.7135266065597534 / Valid loss: 7.164872737157912
Training loss: 0.5368931293487549 / Valid loss: 7.11102382569086

Epoch: 35
Training loss: 0.7694202065467834 / Valid loss: 8.698550110771542
Training loss: 0.6952452063560486 / Valid loss: 7.212755235036214
Training loss: 1.1983537673950195 / Valid loss: 7.8438841819763185
Training loss: 0.7231157422065735 / Valid loss: 7.88514164515904
Training loss: 1.3573447465896606 / Valid loss: 9.16420685450236

Epoch: 36
Training loss: 0.6967319250106812 / Valid loss: 7.096651703970773
Training loss: 0.8207906484603882 / Valid loss: 7.356746448789324
Training loss: 0.5043139457702637 / Valid loss: 7.232939270564488
Training loss: 0.7085784673690796 / Valid loss: 7.837363070533389
Training loss: 0.8565972447395325 / Valid loss: 7.333512015569777

Epoch: 37
Training loss: 1.248915433883667 / Valid loss: 8.128690619695755
Training loss: 0.5872550010681152 / Valid loss: 7.867724550338019
Training loss: 0.6185203790664673 / Valid loss: 7.298463430858794
Training loss: 0.38984963297843933 / Valid loss: 7.115603106362479
Training loss: 0.8182886838912964 / Valid loss: 7.572126606532506

Epoch: 38
Training loss: 0.4790794849395752 / Valid loss: 7.352297973632813
Training loss: 0.6044061183929443 / Valid loss: 7.3300574711390905
Training loss: 0.5140707492828369 / Valid loss: 7.319137387048631
Training loss: 0.9603894352912903 / Valid loss: 7.286004475184849
Training loss: 1.1746454238891602 / Valid loss: 9.81565389179048

Epoch: 39
Training loss: 0.527906060218811 / Valid loss: 7.531298564729236
Training loss: 0.7206075191497803 / Valid loss: 7.785276403881254
Training loss: 0.5597670078277588 / Valid loss: 7.477237151917957
Training loss: 0.4318363666534424 / Valid loss: 8.000659815470378

Epoch: 40
Training loss: 0.43210622668266296 / Valid loss: 7.159402134304955
Training loss: 0.560921311378479 / Valid loss: 7.200255734579904
Training loss: 0.5131359696388245 / Valid loss: 7.477752413068499
Training loss: 0.6347547769546509 / Valid loss: 7.7040837787446526
Training loss: 0.5991976261138916 / Valid loss: 7.281584267389206

Epoch: 41
Training loss: 0.5448082685470581 / Valid loss: 7.528254549843925
Training loss: 0.35777467489242554 / Valid loss: 7.496493144262405
Training loss: 0.7508818507194519 / Valid loss: 7.405935646238781
Training loss: 0.5939278602600098 / Valid loss: 7.336964807056245
Training loss: 1.1381756067276 / Valid loss: 8.284356044587636

Epoch: 42
Training loss: 0.6879156827926636 / Valid loss: 7.613783518473308
Training loss: 0.6032792329788208 / Valid loss: 7.184174633026123
Training loss: 0.5717681646347046 / Valid loss: 7.227603222074963
Training loss: 1.032655954360962 / Valid loss: 8.124815082550048
Training loss: 0.5197587013244629 / Valid loss: 7.248090471540179

Epoch: 43
Training loss: 0.509456992149353 / Valid loss: 7.631041245233445
Training loss: 0.46906352043151855 / Valid loss: 7.1391090983436225
Training loss: 0.6706218719482422 / Valid loss: 7.717282481420607
Training loss: 0.5298594832420349 / Valid loss: 7.404906113942464
Training loss: 0.3701806664466858 / Valid loss: 7.622350801740374

Epoch: 44
Training loss: 0.6167009472846985 / Valid loss: 7.55052680060977
Training loss: 0.4337422847747803 / Valid loss: 7.673064785911923
Training loss: 0.6111456751823425 / Valid loss: 8.930984937577021
Training loss: 0.4130980372428894 / Valid loss: 7.154562872932071
Training loss: 0.4655488431453705 / Valid loss: 7.261870093572707

Epoch: 45
Training loss: 0.44411200284957886 / Valid loss: 7.412175859723773
Training loss: 0.5282151103019714 / Valid loss: 7.133074083782378
Training loss: 0.37763941287994385 / Valid loss: 7.15631065822783
Training loss: 0.5962949991226196 / Valid loss: 8.047651118323916
Training loss: 0.23897771537303925 / Valid loss: 7.132068629491897

Epoch: 46
Training loss: 0.4683545231819153 / Valid loss: 7.840953182038807
Training loss: 0.4312049150466919 / Valid loss: 7.725620138077509
Training loss: 0.4694696068763733 / Valid loss: 7.389789626711891
Training loss: 0.4210676848888397 / Valid loss: 7.188404006049747
Training loss: 0.5126180052757263 / Valid loss: 7.201879633040655

Epoch: 47
Training loss: 0.3886250853538513 / Valid loss: 7.322903991880871
Training loss: 0.4160422682762146 / Valid loss: 7.122021541141328
Training loss: 0.6395459175109863 / Valid loss: 7.197230098361061
Training loss: 0.3690994381904602 / Valid loss: 7.918411091395787
Training loss: 0.3602365553379059 / Valid loss: 7.4475076947893415

Epoch: 48
Training loss: 0.6152610182762146 / Valid loss: 7.278537827446347
Training loss: 0.35828304290771484 / Valid loss: 7.2270294870649066
Training loss: 0.4826466739177704 / Valid loss: 7.414450472877139
Training loss: 0.5504187345504761 / Valid loss: 7.2622903574080695
Training loss: 0.5122232437133789 / Valid loss: 7.363067372639974

Epoch: 49
Training loss: 0.5961971282958984 / Valid loss: 8.473667126610165
Training loss: 0.5196599960327148 / Valid loss: 7.745248272305443
Training loss: 0.5339346528053284 / Valid loss: 7.609709017617362
Training loss: 0.48272567987442017 / Valid loss: 7.229865473792667

Epoch: 50
Training loss: 0.47244858741760254 / Valid loss: 7.225041235060919
Training loss: 0.4082154631614685 / Valid loss: 7.274577547255016
Training loss: 0.5031441450119019 / Valid loss: 7.342532929920015
Training loss: 0.5533815622329712 / Valid loss: 7.294003872644334
Training loss: 0.4022366404533386 / Valid loss: 7.1677668639591765

Epoch: 51
Training loss: 0.7830044031143188 / Valid loss: 7.8340454464867
Training loss: 0.5181688070297241 / Valid loss: 7.244844084694272
Training loss: 0.6823526620864868 / Valid loss: 7.410847432272774
Training loss: 0.4152390956878662 / Valid loss: 7.295555078415644
Training loss: 0.4376499652862549 / Valid loss: 7.216448143550328

Epoch: 52
Training loss: 0.2714395523071289 / Valid loss: 7.244098840441023
Training loss: 0.49389275908470154 / Valid loss: 7.265991347176688
Training loss: 0.4793314039707184 / Valid loss: 7.593214757101876
Training loss: 0.7984294295310974 / Valid loss: 7.269077101207915
Training loss: 0.4114433825016022 / Valid loss: 7.954146217164539

Epoch: 53
Training loss: 0.5073558688163757 / Valid loss: 7.571480719248454
Training loss: 0.3267993628978729 / Valid loss: 7.2819341341654455
Training loss: 0.7235515117645264 / Valid loss: 7.405701641809372
Training loss: 0.41175541281700134 / Valid loss: 7.282475950604393
Training loss: 0.4819018244743347 / Valid loss: 7.491364901406424

Epoch: 54
Training loss: 0.30732461810112 / Valid loss: 7.9203418913341705
Training loss: 0.3226988911628723 / Valid loss: 7.247798056829543
Training loss: 0.3683014512062073 / Valid loss: 7.291162686120896
Training loss: 0.5242809057235718 / Valid loss: 7.205890274047851
Training loss: 0.5624621510505676 / Valid loss: 7.3340415863763715

Epoch: 55
Training loss: 0.3542720079421997 / Valid loss: 7.30296292532058
Training loss: 0.39394083619117737 / Valid loss: 7.254289054870606
Training loss: 0.4811682105064392 / Valid loss: 7.2014861561003185
Training loss: 0.6718205213546753 / Valid loss: 7.180204809279669
Training loss: 0.2973936200141907 / Valid loss: 7.241559296562558

Epoch: 56
Training loss: 0.4874998927116394 / Valid loss: 7.228392158235822
Training loss: 0.5376642942428589 / Valid loss: 7.243460948126657
Training loss: 0.5906956195831299 / Valid loss: 8.127772149585542
Training loss: 0.3934117555618286 / Valid loss: 7.57913750239781
Training loss: 0.4824164807796478 / Valid loss: 7.486756411052886

Epoch: 57
Training loss: 0.2724219560623169 / Valid loss: 7.198471636999221
Training loss: 0.4082205295562744 / Valid loss: 7.267860062917074
Training loss: 0.3638661503791809 / Valid loss: 7.26251045408703
Training loss: 0.5061250329017639 / Valid loss: 7.283489949362618
Training loss: 0.38947024941444397 / Valid loss: 7.3999164672124955

Epoch: 58
Training loss: 0.3007410168647766 / Valid loss: 7.220042623792376
Training loss: 0.2228247970342636 / Valid loss: 7.2372623080299014
Training loss: 0.6279114484786987 / Valid loss: 7.577763711838495
Training loss: 0.36672747135162354 / Valid loss: 7.606192784082322
Training loss: 0.6153466701507568 / Valid loss: 7.587790066855295

Epoch: 59
Training loss: 0.24889594316482544 / Valid loss: 7.222536268688383
Training loss: 0.2894681692123413 / Valid loss: 7.192299470447359
Training loss: 0.3944787383079529 / Valid loss: 7.251861658550444
Training loss: 0.27472954988479614 / Valid loss: 7.22474699928647

Epoch: 60
Training loss: 0.5563288927078247 / Valid loss: 7.311895363671439
Training loss: 0.30555492639541626 / Valid loss: 7.308354654766265
Training loss: 0.3083878755569458 / Valid loss: 7.562421262831915
Training loss: 0.6222342252731323 / Valid loss: 7.238445781526112
Training loss: 0.31751540303230286 / Valid loss: 7.257216235569545

Epoch: 61
Training loss: 0.4368875026702881 / Valid loss: 7.289949022020612
Training loss: 0.5112060904502869 / Valid loss: 7.213898726872036
Training loss: 0.4648282825946808 / Valid loss: 7.463070964813232
Training loss: 0.3468126356601715 / Valid loss: 7.196576631636846
Training loss: 0.2689444124698639 / Valid loss: 7.187462452479771

Epoch: 62
Training loss: 0.3893289566040039 / Valid loss: 7.277636873154413
Training loss: 0.2812305986881256 / Valid loss: 7.244815998985654
Training loss: 0.29132363200187683 / Valid loss: 7.34105555670602
Training loss: 0.4349079728126526 / Valid loss: 7.175719719841367
Training loss: 0.4742533564567566 / Valid loss: 7.793012532733735

Epoch: 63
Training loss: 0.3344404995441437 / Valid loss: 7.485470758165632
Training loss: 0.3145318031311035 / Valid loss: 7.269847597394671
Training loss: 0.2608967125415802 / Valid loss: 7.279785633087158
Training loss: 0.23489153385162354 / Valid loss: 7.2221337409246535
Training loss: 0.2701333165168762 / Valid loss: 7.211680920918782

Epoch: 64
Training loss: 0.5590292811393738 / Valid loss: 7.7469612348647345
Training loss: 0.5330010056495667 / Valid loss: 7.3122128441220235
Training loss: 0.24001702666282654 / Valid loss: 7.29078261965797
Training loss: 0.3872091770172119 / Valid loss: 7.226454648517427
Training loss: 0.7732561826705933 / Valid loss: 7.906595838637579

Epoch: 65
Training loss: 0.2954031229019165 / Valid loss: 7.201210130964006
Training loss: 0.2506505846977234 / Valid loss: 7.2274060067676364
Training loss: 0.4679373800754547 / Valid loss: 7.3276401792253765
Training loss: 0.40985172986984253 / Valid loss: 7.228288977486747
Training loss: 0.4808773398399353 / Valid loss: 7.45952228818621

Epoch: 66
Training loss: 0.23806656897068024 / Valid loss: 7.238569364093599
Training loss: 0.3471931219100952 / Valid loss: 7.362487352462042
Training loss: 0.5221861004829407 / Valid loss: 8.245369684128534
Training loss: 0.33757084608078003 / Valid loss: 7.941686148870559
Training loss: 0.23793739080429077 / Valid loss: 7.217057559603736

Epoch: 67
Training loss: 0.3789363503456116 / Valid loss: 7.207877236320859
Training loss: 0.30151891708374023 / Valid loss: 7.31505928947812
Training loss: 0.38034266233444214 / Valid loss: 7.743768837338402
Training loss: 0.2936694622039795 / Valid loss: 7.243506417955671
Training loss: 0.5888515710830688 / Valid loss: 7.371954940614247

Epoch: 68
Training loss: 0.26469242572784424 / Valid loss: 7.3667943409511025
Training loss: 0.30162033438682556 / Valid loss: 7.323333013625372
Training loss: 0.2277545928955078 / Valid loss: 7.296429506937662
Training loss: 0.3552773892879486 / Valid loss: 7.335300027756464
Training loss: 0.32532817125320435 / Valid loss: 7.3113815897987005

Epoch: 69
Training loss: 0.30886995792388916 / Valid loss: 7.5976777757917136
Training loss: 0.22735677659511566 / Valid loss: 7.377676659538633
Training loss: 0.38045787811279297 / Valid loss: 8.133025441850934
Training loss: 0.43488991260528564 / Valid loss: 7.968884481702532

Epoch: 70
Training loss: 0.2969725728034973 / Valid loss: 7.423791676475888
Training loss: 0.1643100380897522 / Valid loss: 7.17656298591977
Training loss: 0.49361899495124817 / Valid loss: 7.561388011205764
Training loss: 0.45551416277885437 / Valid loss: 7.443735526856922
Training loss: 0.6155499219894409 / Valid loss: 7.542508420490083

Epoch: 71
Training loss: 0.274899423122406 / Valid loss: 7.4006407056536
Training loss: 0.5460876822471619 / Valid loss: 7.199116611480713
Training loss: 0.30612462759017944 / Valid loss: 7.233295061474755
Training loss: 0.42562979459762573 / Valid loss: 7.740529410044352
Training loss: 0.3501700162887573 / Valid loss: 7.450445838201613

Epoch: 72
Training loss: 0.4347415864467621 / Valid loss: 7.342548352196103
Training loss: 0.25266599655151367 / Valid loss: 7.235036827269054
Training loss: 0.26313334703445435 / Valid loss: 7.227935741061256
Training loss: 0.4941661059856415 / Valid loss: 7.542013250078473
Training loss: 0.27773481607437134 / Valid loss: 7.3847141947065085

Epoch: 73
Training loss: 0.3144568204879761 / Valid loss: 7.347217037564232
Training loss: 0.5498901009559631 / Valid loss: 8.277870032900855
Training loss: 0.24571102857589722 / Valid loss: 7.269307626996722
Training loss: 0.376190721988678 / Valid loss: 7.377109550294422
Training loss: 0.3293265998363495 / Valid loss: 7.271978691646031

Epoch: 74
Training loss: 0.49355706572532654 / Valid loss: 7.404563404264904
Training loss: 0.2623109817504883 / Valid loss: 7.690822324298677
Training loss: 0.3728242516517639 / Valid loss: 7.3395069894336515
Training loss: 0.20800939202308655 / Valid loss: 7.246410433451334
Training loss: 0.3620191514492035 / Valid loss: 7.4378071240016395

Epoch: 75
Training loss: 0.539117157459259 / Valid loss: 7.3083649816967196
Training loss: 0.2808090150356293 / Valid loss: 7.214666066850935
Training loss: 0.21295732259750366 / Valid loss: 7.348626745314825
Training loss: 0.2996176481246948 / Valid loss: 7.239096271424066
Training loss: 0.308510422706604 / Valid loss: 7.458705302647182

Epoch: 76
Training loss: 0.2988719344139099 / Valid loss: 7.237681411561512
Training loss: 0.3204355537891388 / Valid loss: 7.184747105553036
Training loss: 0.424765944480896 / Valid loss: 7.478474194662912
Training loss: 0.22340311110019684 / Valid loss: 7.170738170260475
Training loss: 0.27613842487335205 / Valid loss: 7.251460202534994

Epoch: 77
Training loss: 0.3223189413547516 / Valid loss: 7.250800264449347
Training loss: 0.3040657043457031 / Valid loss: 7.332145286741711
Training loss: 0.297647088766098 / Valid loss: 7.1893715585981095
Training loss: 0.328890860080719 / Valid loss: 7.250525874183292
Training loss: 0.22148428857326508 / Valid loss: 7.216483624776204

Epoch: 78
Training loss: 0.34672194719314575 / Valid loss: 7.419606299627395
Training loss: 0.2255343794822693 / Valid loss: 7.259066790626163
Training loss: 0.2300950586795807 / Valid loss: 7.2124580905551
Training loss: 0.4174755811691284 / Valid loss: 7.216965816134498
Training loss: 0.2802690267562866 / Valid loss: 7.180953770592099

Epoch: 79
Training loss: 0.3772117495536804 / Valid loss: 7.2216144561767575
Training loss: 0.2057357132434845 / Valid loss: 7.2033212343851725
Training loss: 0.26127415895462036 / Valid loss: 7.370211737496512
Training loss: 0.3602254390716553 / Valid loss: 7.425491678147089
ModuleList(
  (0): Linear(in_features=5376, out_features=248, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=248, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.385041824976603
Training regression with following parameters:
dnn_hidden_units : 
dropout_probs : 0.0, 0.0
learning_rate : 0.001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : SGD
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : Bert
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=5376, out_features=1, bias=True)
)

Epoch: 0
Training loss: 19.044994354248047 / Valid loss: 11.605803235371907
Model is saved in epoch 0, overall batch: 0
Training loss: 6.233587265014648 / Valid loss: 5.6877159527369905
Model is saved in epoch 0, overall batch: 100
Training loss: 8.956886291503906 / Valid loss: 6.622720209757487
Training loss: 6.104818344116211 / Valid loss: 5.5687253974732895
Model is saved in epoch 0, overall batch: 300
Training loss: 5.278043746948242 / Valid loss: 7.2043254261925105

Epoch: 1
Training loss: 6.830215930938721 / Valid loss: 5.590337753295898
Training loss: 6.109194755554199 / Valid loss: 6.903700687771752
Training loss: 7.234245777130127 / Valid loss: 5.82455054918925
Training loss: 4.501651763916016 / Valid loss: 5.536232619058518
Model is saved in epoch 1, overall batch: 800
Training loss: 4.593646049499512 / Valid loss: 5.567711214792161

Epoch: 2
Training loss: 5.865692138671875 / Valid loss: 5.658770677021572
Training loss: 4.678683280944824 / Valid loss: 5.758566286450341
Training loss: 5.74685525894165 / Valid loss: 5.608671220143636
Training loss: 3.720409631729126 / Valid loss: 5.516275882720947
Model is saved in epoch 2, overall batch: 1300
Training loss: 4.305973052978516 / Valid loss: 5.584481568563552

Epoch: 3
Training loss: 6.397364616394043 / Valid loss: 7.340221745627267
Training loss: 3.5680248737335205 / Valid loss: 5.522664431163243
Training loss: 7.928363800048828 / Valid loss: 5.6984667936960856
Training loss: 4.823384761810303 / Valid loss: 5.579473150344122
Training loss: 6.852466106414795 / Valid loss: 5.866765460513887

Epoch: 4
Training loss: 6.533152103424072 / Valid loss: 5.8073187283107215
Training loss: 5.8464202880859375 / Valid loss: 6.906640818005516
Training loss: 8.197744369506836 / Valid loss: 6.6357269332522435
Training loss: 4.234875202178955 / Valid loss: 5.558915267671858
Training loss: 6.440201759338379 / Valid loss: 5.8595650718325665

Epoch: 5
Training loss: 8.43641471862793 / Valid loss: 6.7196505274091445
Training loss: 4.9477996826171875 / Valid loss: 6.170750904083252
Training loss: 5.98702335357666 / Valid loss: 6.21905092284793
Training loss: 6.48671817779541 / Valid loss: 6.58290175256275
Training loss: 6.5802388191223145 / Valid loss: 6.555798825763521

Epoch: 6
Training loss: 5.147722244262695 / Valid loss: 5.786156191144671
Training loss: 5.493581771850586 / Valid loss: 5.59947992960612
Training loss: 5.899710655212402 / Valid loss: 6.493518298012869
Training loss: 4.31746768951416 / Valid loss: 5.642876550129482
Training loss: 7.172349452972412 / Valid loss: 5.7266990752447215

Epoch: 7
Training loss: 5.477851867675781 / Valid loss: 6.393417921520415
Training loss: 4.094450950622559 / Valid loss: 5.570412215732393
Training loss: 6.077883720397949 / Valid loss: 5.5666077636537095
Training loss: 5.927037715911865 / Valid loss: 5.662841665177118
Training loss: 5.029651641845703 / Valid loss: 5.547769526072911

Epoch: 8
Training loss: 5.203245162963867 / Valid loss: 5.651392848151071
Training loss: 4.287456035614014 / Valid loss: 5.856799416314988
Training loss: 4.227967262268066 / Valid loss: 5.927859131495158
Training loss: 5.034282684326172 / Valid loss: 5.5950026671091715
Training loss: 2.7079224586486816 / Valid loss: 5.573429670787993

Epoch: 9
Training loss: 3.8609728813171387 / Valid loss: 5.623851596741449
Training loss: 5.114484786987305 / Valid loss: 5.532989917482649
Training loss: 6.079976558685303 / Valid loss: 7.0948711803981235
Training loss: 6.05258846282959 / Valid loss: 5.587150682721819

Epoch: 10
Training loss: 3.675558090209961 / Valid loss: 5.826813525245303
Training loss: 4.768142223358154 / Valid loss: 5.652700907843453
Training loss: 5.309962272644043 / Valid loss: 5.741624539239066
Training loss: 5.626169204711914 / Valid loss: 5.659780000504993
Training loss: 4.5319504737854 / Valid loss: 5.56618481363569

Epoch: 11
Training loss: 5.256104469299316 / Valid loss: 5.5605287302108035
Training loss: 5.382481575012207 / Valid loss: 5.631904988061814
Training loss: 4.7153730392456055 / Valid loss: 6.05427519934518
Training loss: 8.08288288116455 / Valid loss: 5.966754967825754
Training loss: 5.055109977722168 / Valid loss: 5.608443544024513

Epoch: 12
Training loss: 5.645113945007324 / Valid loss: 5.90388555980864
Training loss: 6.477214813232422 / Valid loss: 5.725001425970168
Training loss: 3.318206310272217 / Valid loss: 5.566337483269828
Training loss: 7.468264102935791 / Valid loss: 6.632022199176607
Training loss: 4.171628952026367 / Valid loss: 5.678161332720802

Epoch: 13
Training loss: 4.677181243896484 / Valid loss: 5.572214401335943
Training loss: 4.708996772766113 / Valid loss: 6.083573809124174
Training loss: 5.760586261749268 / Valid loss: 6.1308925901140485
Training loss: 5.77506685256958 / Valid loss: 5.923007181712559
Training loss: 5.067523002624512 / Valid loss: 5.6042783737182615

Epoch: 14
Training loss: 6.0380635261535645 / Valid loss: 5.607392034076509
Training loss: 5.212264060974121 / Valid loss: 6.096261206127348
Training loss: 6.4772491455078125 / Valid loss: 6.143990484873454
Training loss: 3.5006978511810303 / Valid loss: 5.600411451430547
Training loss: 5.698729991912842 / Valid loss: 6.181932235899426

Epoch: 15
Training loss: 7.542665481567383 / Valid loss: 6.313969761984689
Training loss: 5.362405776977539 / Valid loss: 5.7362406617119195
Training loss: 4.465013027191162 / Valid loss: 5.784387922286987
Training loss: 5.467430114746094 / Valid loss: 6.099666926974342
Training loss: 5.061066627502441 / Valid loss: 5.7661211286272325

Epoch: 16
Training loss: 4.883539199829102 / Valid loss: 5.6205765133812315
Training loss: 3.9475603103637695 / Valid loss: 5.789505617959159
Training loss: 5.191761016845703 / Valid loss: 5.673306617282686
Training loss: 6.204493999481201 / Valid loss: 5.9248096466064455
Training loss: 4.815020561218262 / Valid loss: 5.733182294028146

Epoch: 17
Training loss: 7.310279369354248 / Valid loss: 6.609887649899437
Training loss: 5.048857688903809 / Valid loss: 5.626484453110468
Training loss: 4.90383243560791 / Valid loss: 6.623116177604312
Training loss: 4.7015838623046875 / Valid loss: 5.904196123849778
Training loss: 6.708926200866699 / Valid loss: 6.206314436594645

Epoch: 18
Training loss: 5.302820205688477 / Valid loss: 5.72102515129816
Training loss: 4.712104320526123 / Valid loss: 5.919375896453857
Training loss: 6.733667373657227 / Valid loss: 6.007576486042567
Training loss: 4.087976455688477 / Valid loss: 5.879420257750011
Training loss: 5.991967678070068 / Valid loss: 6.400280096417382

Epoch: 19
Training loss: 4.020490646362305 / Valid loss: 5.600616902396792
Training loss: 4.263517379760742 / Valid loss: 5.692392515000843
Training loss: 4.7462568283081055 / Valid loss: 5.913887180600848
Training loss: 4.60718297958374 / Valid loss: 5.654750885282244

Epoch: 20
Training loss: 4.818239688873291 / Valid loss: 5.706610906691778
Training loss: 4.9601030349731445 / Valid loss: 5.605382760365804
Training loss: 3.135228157043457 / Valid loss: 5.804007089705694
Training loss: 3.841580390930176 / Valid loss: 5.826805353164673
Training loss: 5.641953468322754 / Valid loss: 6.198301051911853

Epoch: 21
Training loss: 4.688629150390625 / Valid loss: 5.63499421846299
Training loss: 6.4580230712890625 / Valid loss: 5.681576002211798
Training loss: 5.643385887145996 / Valid loss: 5.591377017611549
Training loss: 7.5972442626953125 / Valid loss: 6.19975110008603
Training loss: 6.441099166870117 / Valid loss: 5.616251718430292

Epoch: 22
Training loss: 5.397235870361328 / Valid loss: 5.595166785376413
Training loss: 4.263177871704102 / Valid loss: 5.987125478472028
Training loss: 6.3736467361450195 / Valid loss: 6.479333080564227
Training loss: 5.637017250061035 / Valid loss: 5.754922167460124
Training loss: 4.293376922607422 / Valid loss: 5.596246262959071

Epoch: 23
Training loss: 4.202808380126953 / Valid loss: 5.914879303886777
Training loss: 6.216846466064453 / Valid loss: 5.6223649955931165
Training loss: 6.93431282043457 / Valid loss: 6.794202845437186
Training loss: 4.8869309425354 / Valid loss: 6.304131862095424
Training loss: 7.144604682922363 / Valid loss: 5.854468620391119

Epoch: 24
Training loss: 6.222475051879883 / Valid loss: 5.614241781688872
Training loss: 5.109199523925781 / Valid loss: 5.656102700460525
Training loss: 5.8730149269104 / Valid loss: 5.903124868302118
Training loss: 7.265566825866699 / Valid loss: 5.6949914387294225
Training loss: 3.1198339462280273 / Valid loss: 5.939079068955921

Epoch: 25
Training loss: 3.6499381065368652 / Valid loss: 5.619322079703921
Training loss: 4.7351765632629395 / Valid loss: 6.090116950443813
Training loss: 3.295076608657837 / Valid loss: 5.808775048028855
Training loss: 7.251196384429932 / Valid loss: 5.765037874948411
Training loss: 3.5082905292510986 / Valid loss: 5.692767622357323

Epoch: 26
Training loss: 5.520445823669434 / Valid loss: 5.857924931389945
Training loss: 5.945540428161621 / Valid loss: 5.627878990627471
Training loss: 6.008176326751709 / Valid loss: 6.013500481560117
Training loss: 5.612238883972168 / Valid loss: 5.593208387919835
Training loss: 5.895040035247803 / Valid loss: 6.169143642698016

Epoch: 27
Training loss: 7.878345966339111 / Valid loss: 5.771604533422561
Training loss: 3.800182342529297 / Valid loss: 5.797807579948788
Training loss: 5.039762496948242 / Valid loss: 5.588474457604544
Training loss: 6.272525787353516 / Valid loss: 5.904419835408529
Training loss: 5.91379976272583 / Valid loss: 5.6839205923534575

Epoch: 28
Training loss: 4.336751937866211 / Valid loss: 5.643369438534691
Training loss: 3.8723649978637695 / Valid loss: 5.758279589244298
Training loss: 4.889076232910156 / Valid loss: 5.794171710241408
Training loss: 4.564959526062012 / Valid loss: 5.774090460368565
Training loss: 4.856571197509766 / Valid loss: 5.805958573023478

Epoch: 29
Training loss: 6.126382827758789 / Valid loss: 6.325887512025379
Training loss: 4.7741546630859375 / Valid loss: 5.800983978453137
Training loss: 6.333512306213379 / Valid loss: 5.763782973516555
Training loss: 6.408913612365723 / Valid loss: 5.638013950983683

Epoch: 30
Training loss: 5.8819966316223145 / Valid loss: 5.751700078873407
Training loss: 5.228111743927002 / Valid loss: 5.68864936601548
Training loss: 4.56832218170166 / Valid loss: 5.907743874050322
Training loss: 5.918269157409668 / Valid loss: 6.506429962884813
Training loss: 4.50120735168457 / Valid loss: 5.704903781981695

Epoch: 31
Training loss: 5.2229509353637695 / Valid loss: 5.665068335760207
Training loss: 5.248996734619141 / Valid loss: 5.636965451921736
Training loss: 4.419496536254883 / Valid loss: 5.633541804268247
Training loss: 4.910571575164795 / Valid loss: 5.673246712911697
Training loss: 6.287589073181152 / Valid loss: 5.718127641223726

Epoch: 32
Training loss: 5.862462043762207 / Valid loss: 5.653569246473767
Training loss: 5.908127784729004 / Valid loss: 5.88056366784232
Training loss: 4.933133125305176 / Valid loss: 5.738030442737398
Training loss: 4.100588321685791 / Valid loss: 5.66922185080392
Training loss: 7.525920867919922 / Valid loss: 5.622197230656941

Epoch: 33
Training loss: 3.8701677322387695 / Valid loss: 5.625374798547654
Training loss: 6.629280090332031 / Valid loss: 5.795474486123948
Training loss: 7.193123817443848 / Valid loss: 7.377545502072289
Training loss: 5.5168538093566895 / Valid loss: 5.660670028414045
Training loss: 6.612575531005859 / Valid loss: 5.750549479893276

Epoch: 34
Training loss: 5.894913673400879 / Valid loss: 6.1731927258627755
Training loss: 6.4904656410217285 / Valid loss: 6.001151616232736
Training loss: 6.136376857757568 / Valid loss: 7.050502940586635
Training loss: 5.878281593322754 / Valid loss: 6.182113938104539
Training loss: 3.811739444732666 / Valid loss: 5.971574365525019

Epoch: 35
Training loss: 5.4219970703125 / Valid loss: 5.714378711155483
Training loss: 4.389300346374512 / Valid loss: 5.740226282392229
Training loss: 5.78460693359375 / Valid loss: 5.766556694394066
Training loss: 4.696505546569824 / Valid loss: 5.64801504271371
Training loss: 4.478883743286133 / Valid loss: 5.642313652946836

Epoch: 36
Training loss: 3.875303268432617 / Valid loss: 6.733918417067755
Training loss: 6.571816444396973 / Valid loss: 5.6376824401673815
Training loss: 3.894845962524414 / Valid loss: 6.0234915551685155
Training loss: 6.470118522644043 / Valid loss: 6.454912065324329
Training loss: 4.92977237701416 / Valid loss: 6.425132578895205

Epoch: 37
Training loss: 5.505114555358887 / Valid loss: 6.179086814607893
Training loss: 3.8298258781433105 / Valid loss: 5.665137288683937
Training loss: 4.687688827514648 / Valid loss: 5.906090295882452
Training loss: 6.1500563621521 / Valid loss: 5.815752740133377
Training loss: 5.639581680297852 / Valid loss: 5.6493039948599675

Epoch: 38
Training loss: 5.3923139572143555 / Valid loss: 5.681745828901018
Training loss: 6.763485908508301 / Valid loss: 6.500005926404681
Training loss: 5.479387283325195 / Valid loss: 5.659573441460019
Training loss: 4.815489292144775 / Valid loss: 5.799389237449283
Training loss: 5.212503433227539 / Valid loss: 6.276879608063471

Epoch: 39
Training loss: 4.415060043334961 / Valid loss: 5.833248504002889
Training loss: 5.258335113525391 / Valid loss: 6.557717904590425
Training loss: 6.478341579437256 / Valid loss: 6.194249139513288
Training loss: 4.929792404174805 / Valid loss: 5.757008704685029

Epoch: 40
Training loss: 4.054076194763184 / Valid loss: 5.671984811056228
Training loss: 5.891111850738525 / Valid loss: 6.001905409495036
Training loss: 3.927546501159668 / Valid loss: 5.661502492995489
Training loss: 5.357043266296387 / Valid loss: 5.904327783130464
Training loss: 5.673117160797119 / Valid loss: 7.459960197267078

Epoch: 41
Training loss: 4.618231296539307 / Valid loss: 6.082292497725714
Training loss: 5.829824447631836 / Valid loss: 6.477197603952317
Training loss: 4.235082149505615 / Valid loss: 5.650320791062855
Training loss: 6.575473785400391 / Valid loss: 5.713962738854544
Training loss: 4.047456741333008 / Valid loss: 5.755526728857131

Epoch: 42
Training loss: 3.2946014404296875 / Valid loss: 5.686618114653088
Training loss: 4.407805919647217 / Valid loss: 5.65289774622236
Training loss: 5.934802055358887 / Valid loss: 5.694701714742751
Training loss: 4.270878791809082 / Valid loss: 5.687556403023856
Training loss: 3.5100529193878174 / Valid loss: 5.792053102311634

Epoch: 43
Training loss: 5.348223686218262 / Valid loss: 5.786017744881766
Training loss: 4.669022083282471 / Valid loss: 5.6666961193084715
Training loss: 5.533875465393066 / Valid loss: 5.93410085950579
Training loss: 5.736018657684326 / Valid loss: 6.2189582824707035
Training loss: 5.764945030212402 / Valid loss: 5.76647888365246

Epoch: 44
Training loss: 4.851474761962891 / Valid loss: 5.6924091270991735
Training loss: 4.591353893280029 / Valid loss: 5.691949755804879
Training loss: 5.594213008880615 / Valid loss: 5.766161237444196
Training loss: 6.2146196365356445 / Valid loss: 5.675543019885109
Training loss: 5.782008171081543 / Valid loss: 5.773788393111456

Epoch: 45
Training loss: 4.7150983810424805 / Valid loss: 6.111649819782802
Training loss: 4.963120937347412 / Valid loss: 6.170562871297201
Training loss: 3.4852325916290283 / Valid loss: 5.734935917173114
Training loss: 5.615776538848877 / Valid loss: 5.729991120383853
Training loss: 5.555149078369141 / Valid loss: 6.66835443405878

Epoch: 46
Training loss: 6.371488571166992 / Valid loss: 6.3428817521958125
Training loss: 7.156218528747559 / Valid loss: 7.46488230569022
Training loss: 4.868258476257324 / Valid loss: 5.806841405232747
Training loss: 5.129620552062988 / Valid loss: 5.874716163816906
Training loss: 4.789304256439209 / Valid loss: 5.7674910340990335

Epoch: 47
Training loss: 2.7958970069885254 / Valid loss: 5.895924177623931
Training loss: 3.938777446746826 / Valid loss: 5.728676194236392
Training loss: 5.029048919677734 / Valid loss: 5.761300963447208
Training loss: 6.19975471496582 / Valid loss: 5.935399545942034
Training loss: 5.659267425537109 / Valid loss: 5.755924903778803

Epoch: 48
Training loss: 4.744508743286133 / Valid loss: 5.666742054621379
Training loss: 4.987205982208252 / Valid loss: 6.383929252624512
Training loss: 4.037599086761475 / Valid loss: 5.68674167905535
Training loss: 5.3892693519592285 / Valid loss: 6.156610057467506
Training loss: 4.443065643310547 / Valid loss: 5.684120080584571

Epoch: 49
Training loss: 6.350976943969727 / Valid loss: 5.8701706250508625
Training loss: 5.075145721435547 / Valid loss: 5.746337797528222
Training loss: 4.656845569610596 / Valid loss: 5.7056197189149405
Training loss: 4.716065883636475 / Valid loss: 6.012952461696806

Epoch: 50
Training loss: 4.610006332397461 / Valid loss: 5.742596253894624
Training loss: 3.0900673866271973 / Valid loss: 5.770894615990775
Training loss: 4.233882904052734 / Valid loss: 5.90454801377796
Training loss: 5.123194694519043 / Valid loss: 5.686993869145711
Training loss: 7.130707740783691 / Valid loss: 6.125097218013945

Epoch: 51
Training loss: 4.658613204956055 / Valid loss: 5.772259805316017
Training loss: 3.1340131759643555 / Valid loss: 5.728032386870611
Training loss: 7.016305923461914 / Valid loss: 5.980583965210688
Training loss: 4.101378440856934 / Valid loss: 6.660947933651152
Training loss: 5.115567207336426 / Valid loss: 5.867234239124117

Epoch: 52
Training loss: 5.510245323181152 / Valid loss: 6.405882431211926
Training loss: 4.929419040679932 / Valid loss: 5.724816703796387
Training loss: 4.493052005767822 / Valid loss: 5.807447964804513
Training loss: 5.275816440582275 / Valid loss: 6.728379612877255
Training loss: 5.310881614685059 / Valid loss: 5.774311814989362

Epoch: 53
Training loss: 4.9197773933410645 / Valid loss: 5.777420450392223
Training loss: 4.877292633056641 / Valid loss: 5.922510542188372
Training loss: 12.598642349243164 / Valid loss: 10.568297976539249
Training loss: 5.2896013259887695 / Valid loss: 5.917039176395961
Training loss: 5.878080368041992 / Valid loss: 5.710448787325904

Epoch: 54
Training loss: 4.567004680633545 / Valid loss: 5.95639283316476
Training loss: 4.181604385375977 / Valid loss: 5.7540969508034845
Training loss: 4.239507675170898 / Valid loss: 5.775805893398466
Training loss: 4.649639129638672 / Valid loss: 5.7527472700391495
Training loss: 4.321338176727295 / Valid loss: 5.698266976220268

Epoch: 55
Training loss: 4.791440963745117 / Valid loss: 5.850544148399717
Training loss: 4.745848655700684 / Valid loss: 6.0931449844723655
Training loss: 5.327483177185059 / Valid loss: 6.495486927032471
Training loss: 5.023461818695068 / Valid loss: 6.055172600064959
Training loss: 4.0397443771362305 / Valid loss: 5.707320086161295

Epoch: 56
Training loss: 5.298213005065918 / Valid loss: 7.050295457385835
Training loss: 4.874715328216553 / Valid loss: 5.700337194261097
Training loss: 3.1966214179992676 / Valid loss: 6.156282658804031
Training loss: 6.892688274383545 / Valid loss: 5.749652590070452
Training loss: 4.750631809234619 / Valid loss: 5.718152879533314

Epoch: 57
Training loss: 4.2851738929748535 / Valid loss: 5.7066715058826265
Training loss: 3.973116159439087 / Valid loss: 5.787909314745948
Training loss: 4.917503833770752 / Valid loss: 5.806319298063006
Training loss: 4.670291900634766 / Valid loss: 5.738032350086031
Training loss: 4.885261535644531 / Valid loss: 5.677657779057821

Epoch: 58
Training loss: 3.7182586193084717 / Valid loss: 5.733432517732893
Training loss: 4.767333984375 / Valid loss: 5.774907841001238
Training loss: 3.4356906414031982 / Valid loss: 5.713641856965564
Training loss: 5.389076232910156 / Valid loss: 5.717265467416673
Training loss: 5.4836297035217285 / Valid loss: 5.928695088341122

Epoch: 59
Training loss: 3.7220497131347656 / Valid loss: 6.511193241391863
Training loss: 4.526828289031982 / Valid loss: 5.763289603732881
Training loss: 3.9285523891448975 / Valid loss: 5.728544814246042
Training loss: 2.226707935333252 / Valid loss: 5.686875048137846

Epoch: 60
Training loss: 6.094586372375488 / Valid loss: 6.334253738040016
Training loss: 3.8493099212646484 / Valid loss: 6.297736708323161
Training loss: 5.576166152954102 / Valid loss: 6.289089393615723
Training loss: 5.705822944641113 / Valid loss: 5.864377005894979
Training loss: 4.864530563354492 / Valid loss: 5.682677936553955

Epoch: 61
Training loss: 4.981034278869629 / Valid loss: 5.7455638385954355
Training loss: 4.1701154708862305 / Valid loss: 5.906918369020734
Training loss: 5.968598365783691 / Valid loss: 6.006957281203497
Training loss: 5.119598388671875 / Valid loss: 5.7148296288081575
Training loss: 5.684532165527344 / Valid loss: 5.711033591769991

Epoch: 62
Training loss: 4.463017463684082 / Valid loss: 5.828109582265218
Training loss: 3.600074052810669 / Valid loss: 5.925149120603289
Training loss: 4.564453125 / Valid loss: 5.754842326754615
Training loss: 5.594109058380127 / Valid loss: 6.590832042694092
Training loss: 7.047939777374268 / Valid loss: 5.75376752444676

Epoch: 63
Training loss: 4.091423988342285 / Valid loss: 5.9167747384025935
Training loss: 5.923980712890625 / Valid loss: 5.742091185706002
Training loss: 5.122800350189209 / Valid loss: 5.750309662591843
Training loss: 5.159043312072754 / Valid loss: 5.709760577338082
Training loss: 4.419541358947754 / Valid loss: 6.611298111506871

Epoch: 64
Training loss: 4.199769973754883 / Valid loss: 5.921432903834751
Training loss: 5.47296142578125 / Valid loss: 5.75194301151094
Training loss: 4.969578742980957 / Valid loss: 5.748637226649693
Training loss: 4.194592475891113 / Valid loss: 5.736455724352882
Training loss: 4.501229763031006 / Valid loss: 5.765234275091262

Epoch: 65
Training loss: 3.785122871398926 / Valid loss: 5.761845059621901
Training loss: 7.2161664962768555 / Valid loss: 6.262061060042608
Training loss: 5.756412506103516 / Valid loss: 6.137237444378081
Training loss: 5.01798152923584 / Valid loss: 5.8017749423072456
Training loss: 5.147647857666016 / Valid loss: 5.73892769359407

Epoch: 66
Training loss: 4.068634986877441 / Valid loss: 5.723188711348034
Training loss: 5.358376502990723 / Valid loss: 5.865591042382377
Training loss: 4.122390270233154 / Valid loss: 6.320376023792085
Training loss: 6.741630554199219 / Valid loss: 5.857688470113845
Training loss: 4.602914810180664 / Valid loss: 6.93164896283831

Epoch: 67
Training loss: 5.435881614685059 / Valid loss: 6.792879463377453
Training loss: 6.148253440856934 / Valid loss: 5.761768565859113
Training loss: 5.059746742248535 / Valid loss: 5.8891415051051546
Training loss: 6.12984561920166 / Valid loss: 5.720875690096901
Training loss: 4.68535041809082 / Valid loss: 6.04592885744004

Epoch: 68
Training loss: 5.15541934967041 / Valid loss: 5.80949433190482
Training loss: 5.591158390045166 / Valid loss: 5.83782027335394
Training loss: 4.678759574890137 / Valid loss: 5.810167142323086
Training loss: 4.485735893249512 / Valid loss: 5.8007559526534305
Training loss: 6.079888343811035 / Valid loss: 7.206347202119373

Epoch: 69
Training loss: 6.0480570793151855 / Valid loss: 6.317708971386864
Training loss: 3.6329188346862793 / Valid loss: 5.763781406765893
Training loss: 4.711826324462891 / Valid loss: 5.927973713193621
Training loss: 5.2249884605407715 / Valid loss: 5.712642799104963

Epoch: 70
Training loss: 5.023542404174805 / Valid loss: 5.785966929935274
Training loss: 5.701106071472168 / Valid loss: 6.069269171215239
Training loss: 4.922286033630371 / Valid loss: 5.786768565859114
Training loss: 5.649513244628906 / Valid loss: 5.700861043021792
Training loss: 5.139307022094727 / Valid loss: 5.750880895342146

Epoch: 71
Training loss: 5.111471652984619 / Valid loss: 5.7593518802097865
Training loss: 3.458005905151367 / Valid loss: 5.902078174409413
Training loss: 5.064974784851074 / Valid loss: 5.754792903718494
Training loss: 6.7940497398376465 / Valid loss: 5.815218859627134
Training loss: 6.809335708618164 / Valid loss: 5.916238292058309

Epoch: 72
Training loss: 4.1871867179870605 / Valid loss: 6.017292467753093
Training loss: 6.361083984375 / Valid loss: 6.237359891619001
Training loss: 3.897535800933838 / Valid loss: 5.85555978502546
Training loss: 6.054357528686523 / Valid loss: 5.845198910576957
Training loss: 5.317418098449707 / Valid loss: 5.739059271131243

Epoch: 73
Training loss: 4.625738143920898 / Valid loss: 7.2062854494367325
Training loss: 5.279277801513672 / Valid loss: 5.750667106537592
Training loss: 5.125402927398682 / Valid loss: 6.081134923299154
Training loss: 8.02235221862793 / Valid loss: 7.11054478145781
Training loss: 5.098570346832275 / Valid loss: 5.737540933064052

Epoch: 74
Training loss: 4.78944206237793 / Valid loss: 5.813416110901605
Training loss: 4.845145225524902 / Valid loss: 6.068921357109433
Training loss: 3.862109661102295 / Valid loss: 5.775385048275902
Training loss: 5.305248260498047 / Valid loss: 6.199691540854317
Training loss: 6.928717613220215 / Valid loss: 6.170993264516195

Epoch: 75
Training loss: 4.316182613372803 / Valid loss: 5.730935314723424
Training loss: 4.395938396453857 / Valid loss: 5.877264095488049
Training loss: 4.133999824523926 / Valid loss: 5.991073930831183
Training loss: 4.571759223937988 / Valid loss: 5.8744937056586854
Training loss: 4.215391635894775 / Valid loss: 5.7621665273393905

Epoch: 76
Training loss: 3.34188175201416 / Valid loss: 5.77360821678525
Training loss: 3.5553786754608154 / Valid loss: 6.916304004760016
Training loss: 5.147883415222168 / Valid loss: 5.907278022311982
Training loss: 4.869265556335449 / Valid loss: 5.849413451694307
Training loss: 4.0195770263671875 / Valid loss: 7.126146221160889

Epoch: 77
Training loss: 5.020943641662598 / Valid loss: 6.376245916457403
Training loss: 4.580240249633789 / Valid loss: 6.413973152069818
Training loss: 6.691824913024902 / Valid loss: 5.8064771743047805
Training loss: 5.189922332763672 / Valid loss: 6.225557136535644
Training loss: 4.898501396179199 / Valid loss: 6.698093148640224

Epoch: 78
Training loss: 3.561506748199463 / Valid loss: 5.76529746736799
Training loss: 6.389960289001465 / Valid loss: 6.108360413142613
Training loss: 3.727728843688965 / Valid loss: 6.007229394004458
Training loss: 6.028920650482178 / Valid loss: 6.120677319027129
Training loss: 6.8559112548828125 / Valid loss: 6.664475345611573

Epoch: 79
Training loss: 4.373857498168945 / Valid loss: 5.804291718346732
Training loss: 4.237455368041992 / Valid loss: 5.772765702293032
Training loss: 3.572892665863037 / Valid loss: 5.760055641900926
Training loss: 7.228179931640625 / Valid loss: 6.161578400929769
ModuleList(
  (0): Linear(in_features=5376, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.361213756742932
Training regression with following parameters:
dnn_hidden_units : 2000, 100, 16
dropout_probs : 0.0, 0.0
learning_rate : 0.0001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : SGD
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : Bert
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=5376, out_features=2000, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=2000, out_features=100, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=100, out_features=16, bias=True)
  (9): Dropout(p=0, inplace=False)
  (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (11): LeakyReLU(negative_slope=0.02)
  (12): Linear(in_features=16, out_features=1, bias=True)
)

Epoch: 0
Training loss: 15.765700340270996 / Valid loss: 15.326356043134417
Model is saved in epoch 0, overall batch: 0
Training loss: 9.031549453735352 / Valid loss: 12.925361442565919
Model is saved in epoch 0, overall batch: 100
Training loss: 9.649495124816895 / Valid loss: 11.93502668199085
Model is saved in epoch 0, overall batch: 200
Training loss: 14.655001640319824 / Valid loss: 11.029834052494595
Model is saved in epoch 0, overall batch: 300
Training loss: 10.413329124450684 / Valid loss: 10.265079829806373
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 8.910350799560547 / Valid loss: 9.613765380496071
Model is saved in epoch 1, overall batch: 500
Training loss: 7.872617721557617 / Valid loss: 8.97424146107265
Model is saved in epoch 1, overall batch: 600
Training loss: 7.332974433898926 / Valid loss: 8.527550057002477
Model is saved in epoch 1, overall batch: 700
Training loss: 7.229619026184082 / Valid loss: 8.04958698181879
Model is saved in epoch 1, overall batch: 800
Training loss: 5.423467636108398 / Valid loss: 7.773928292592367
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 7.810892105102539 / Valid loss: 7.546292895362491
Model is saved in epoch 2, overall batch: 1000
Training loss: 7.799148082733154 / Valid loss: 7.289633210500082
Model is saved in epoch 2, overall batch: 1100
Training loss: 7.037626266479492 / Valid loss: 7.038455272856213
Model is saved in epoch 2, overall batch: 1200
Training loss: 8.314278602600098 / Valid loss: 6.658316196714129
Model is saved in epoch 2, overall batch: 1300
Training loss: 4.37082576751709 / Valid loss: 6.479670063654582
Model is saved in epoch 2, overall batch: 1400

Epoch: 3
Training loss: 4.279825687408447 / Valid loss: 6.456323323931013
Model is saved in epoch 3, overall batch: 1500
Training loss: 3.787858724594116 / Valid loss: 6.2811033793858115
Model is saved in epoch 3, overall batch: 1600
Training loss: 6.567384719848633 / Valid loss: 6.132880061013358
Model is saved in epoch 3, overall batch: 1700
Training loss: 3.074599266052246 / Valid loss: 6.027197063536871
Model is saved in epoch 3, overall batch: 1800
Training loss: 5.374438285827637 / Valid loss: 5.917620524905977
Model is saved in epoch 3, overall batch: 1900

Epoch: 4
Training loss: 5.37590217590332 / Valid loss: 6.066183928080967
Training loss: 3.7718729972839355 / Valid loss: 6.084708586193266
Training loss: 4.1693549156188965 / Valid loss: 5.980021408626011
Training loss: 4.449491500854492 / Valid loss: 5.9436943780808225
Training loss: 3.1457338333129883 / Valid loss: 5.8985951628003805
Model is saved in epoch 4, overall batch: 2400

Epoch: 5
Training loss: 6.034307479858398 / Valid loss: 5.8190965062096005
Model is saved in epoch 5, overall batch: 2500
Training loss: 4.65392541885376 / Valid loss: 5.883803662799654
Training loss: 3.245314359664917 / Valid loss: 5.882777790796189
Training loss: 3.8647522926330566 / Valid loss: 5.8596199580601285
Training loss: 3.6135709285736084 / Valid loss: 5.8016817705971855
Model is saved in epoch 5, overall batch: 2900

Epoch: 6
Training loss: 5.956195831298828 / Valid loss: 5.851204438436599
Training loss: 3.4913218021392822 / Valid loss: 5.922347840808687
Training loss: 3.9809350967407227 / Valid loss: 5.927971462976365
Training loss: 3.54435396194458 / Valid loss: 5.909689396903628
Training loss: 4.117196559906006 / Valid loss: 6.0334273542676655

Epoch: 7
Training loss: 3.502049446105957 / Valid loss: 5.933380254109701
Training loss: 3.139695644378662 / Valid loss: 5.993251664297921
Training loss: 2.697209358215332 / Valid loss: 5.977835546221052
Training loss: 4.136932373046875 / Valid loss: 6.063802925745646
Training loss: 3.038693428039551 / Valid loss: 6.007130838575817

Epoch: 8
Training loss: 2.8324384689331055 / Valid loss: 6.0750229494912285
Training loss: 1.8436771631240845 / Valid loss: 6.078082086926415
Training loss: 3.234579086303711 / Valid loss: 6.108758088520595
Training loss: 4.641075134277344 / Valid loss: 6.153123925981068
Training loss: 2.8398232460021973 / Valid loss: 6.134172952742803

Epoch: 9
Training loss: 1.5098446607589722 / Valid loss: 6.158533652623494
Training loss: 2.5671896934509277 / Valid loss: 6.18920902070545
Training loss: 3.6185734272003174 / Valid loss: 6.201976576305571
Training loss: 2.732630968093872 / Valid loss: 6.195091059094383

Epoch: 10
Training loss: 1.832048773765564 / Valid loss: 6.237085744312831
Training loss: 2.661381244659424 / Valid loss: 6.234330043338594
Training loss: 1.560402512550354 / Valid loss: 6.398729760306222
Training loss: 2.305189609527588 / Valid loss: 6.391875509988694
Training loss: 2.492584705352783 / Valid loss: 6.298088019234793

Epoch: 11
Training loss: 1.2297296524047852 / Valid loss: 6.3910364877609975
Training loss: 1.4975640773773193 / Valid loss: 6.3959820860908145
Training loss: 2.548607349395752 / Valid loss: 6.465189738500686
Training loss: 1.4185914993286133 / Valid loss: 6.6187856447129025
Training loss: 2.128636360168457 / Valid loss: 6.666912732805525

Epoch: 12
Training loss: 1.1633267402648926 / Valid loss: 6.452874792189825
Training loss: 1.2297829389572144 / Valid loss: 6.56710113797869
Training loss: 1.5909547805786133 / Valid loss: 6.575278670447213
Training loss: 1.3911828994750977 / Valid loss: 6.523057824089413
Training loss: 1.3432307243347168 / Valid loss: 6.534570619038173

Epoch: 13
Training loss: 0.9551684260368347 / Valid loss: 6.706716859908331
Training loss: 0.8917296528816223 / Valid loss: 6.6589717774164106
Training loss: 1.1735572814941406 / Valid loss: 6.546581147965931
Training loss: 1.4201452732086182 / Valid loss: 6.681150949568975
Training loss: 1.3012744188308716 / Valid loss: 6.600960706529163

Epoch: 14
Training loss: 1.0165108442306519 / Valid loss: 6.741644266673497
Training loss: 1.0852172374725342 / Valid loss: 6.643154287338257
Training loss: 1.4932785034179688 / Valid loss: 6.633780184246245
Training loss: 1.1285059452056885 / Valid loss: 6.6558440480913434
Training loss: 1.6491352319717407 / Valid loss: 6.664465704418364

Epoch: 15
Training loss: 1.0540403127670288 / Valid loss: 6.7938585939861476
Training loss: 1.0658385753631592 / Valid loss: 6.817523004895165
Training loss: 1.0568095445632935 / Valid loss: 6.705037425813221
Training loss: 1.0983721017837524 / Valid loss: 6.749984929675148
Training loss: 1.1242650747299194 / Valid loss: 6.689923824582781

Epoch: 16
Training loss: 0.5892389416694641 / Valid loss: 6.810284650893438
Training loss: 0.7803249359130859 / Valid loss: 7.188371404012044
Training loss: 1.1032828092575073 / Valid loss: 6.764204202379499
Training loss: 1.0612361431121826 / Valid loss: 6.95405265490214
Training loss: 1.173661708831787 / Valid loss: 6.885861097063337

Epoch: 17
Training loss: 1.0085021257400513 / Valid loss: 6.822495294752575
Training loss: 0.9435634613037109 / Valid loss: 6.956481792813256
Training loss: 0.9202849864959717 / Valid loss: 6.930529340108236
Training loss: 0.666002094745636 / Valid loss: 6.919105189187186
Training loss: 1.0445382595062256 / Valid loss: 6.757153756277901

Epoch: 18
Training loss: 0.6763856410980225 / Valid loss: 6.79201413109189
Training loss: 0.8552510738372803 / Valid loss: 6.800828341075352
Training loss: 0.8908299207687378 / Valid loss: 6.922042628696986
Training loss: 0.9965186715126038 / Valid loss: 7.065425046284994
Training loss: 0.863675594329834 / Valid loss: 6.810019663402012

Epoch: 19
Training loss: 0.8063485026359558 / Valid loss: 6.918242499941871
Training loss: 1.2864010334014893 / Valid loss: 6.813279499326433
Training loss: 0.6465586423873901 / Valid loss: 6.807423300970168
Training loss: 0.6824859380722046 / Valid loss: 6.840832583109537

Epoch: 20
Training loss: 0.40538251399993896 / Valid loss: 6.810974334535144
Training loss: 1.036321997642517 / Valid loss: 6.8397407032194595
Training loss: 0.4680996537208557 / Valid loss: 6.826008274441674
Training loss: 0.6702053546905518 / Valid loss: 6.848900013878232
Training loss: 1.099815845489502 / Valid loss: 6.829094416754586

Epoch: 21
Training loss: 0.5849310159683228 / Valid loss: 6.897969468434652
Training loss: 0.7242369651794434 / Valid loss: 6.8522044408889045
Training loss: 0.6205954551696777 / Valid loss: 6.849351374308268
Training loss: 0.492944598197937 / Valid loss: 6.910346090225946
Training loss: 0.671619176864624 / Valid loss: 6.842398089454288

Epoch: 22
Training loss: 0.7165206670761108 / Valid loss: 6.86344078154791
Training loss: 0.554999589920044 / Valid loss: 6.95038419905163
Training loss: 0.4596119523048401 / Valid loss: 6.781331836609613
Training loss: 1.3692537546157837 / Valid loss: 6.841743144534883
Training loss: 0.7559306621551514 / Valid loss: 6.840181078229632

Epoch: 23
Training loss: 0.7283676862716675 / Valid loss: 6.892171362468175
Training loss: 0.7919235229492188 / Valid loss: 6.783128611246744
Training loss: 0.8206788897514343 / Valid loss: 6.887018896284557
Training loss: 0.5897453427314758 / Valid loss: 6.852277633122036
Training loss: 1.0101314783096313 / Valid loss: 6.9078188987005325

Epoch: 24
Training loss: 0.8423129320144653 / Valid loss: 6.823648264294579
Training loss: 0.6432785987854004 / Valid loss: 6.800510660807292
Training loss: 0.5377112030982971 / Valid loss: 6.923416818891253
Training loss: 0.9146564602851868 / Valid loss: 6.848580855414981
Training loss: 1.0273497104644775 / Valid loss: 6.892161977858771

Epoch: 25
Training loss: 1.0057035684585571 / Valid loss: 6.882301693870907
Training loss: 0.3921237587928772 / Valid loss: 6.856995741526286
Training loss: 0.8008273839950562 / Valid loss: 6.7691147622608
Training loss: 0.3524518609046936 / Valid loss: 6.795892313548497
Training loss: 0.5134373903274536 / Valid loss: 6.9135886056082585

Epoch: 26
Training loss: 0.5141182541847229 / Valid loss: 6.811796706063407
Training loss: 0.5204722881317139 / Valid loss: 6.847500975926717
Training loss: 0.3656955361366272 / Valid loss: 6.839329501560756
Training loss: 0.43640822172164917 / Valid loss: 6.982221017565046
Training loss: 0.4070833921432495 / Valid loss: 6.97004113424392

Epoch: 27
Training loss: 0.3686547875404358 / Valid loss: 6.825541260128929
Training loss: 0.47597256302833557 / Valid loss: 6.963418935594104
Training loss: 0.6055011749267578 / Valid loss: 6.956779216584705
Training loss: 0.4820709824562073 / Valid loss: 6.935784280867804
Training loss: 0.6080188751220703 / Valid loss: 6.914210024334135

Epoch: 28
Training loss: 0.4018572270870209 / Valid loss: 6.922458239964077
Training loss: 0.37014228105545044 / Valid loss: 6.837387693495978
Training loss: 0.7190433144569397 / Valid loss: 6.880425839197068
Training loss: 0.57194584608078 / Valid loss: 6.869017782665434
Training loss: 0.4527132511138916 / Valid loss: 6.875129699707031

Epoch: 29
Training loss: 0.6052722930908203 / Valid loss: 6.821631667727516
Training loss: 0.46156978607177734 / Valid loss: 6.808241335550944
Training loss: 0.31890395283699036 / Valid loss: 6.8673095703125
Training loss: 0.4430583119392395 / Valid loss: 6.832905601319813

Epoch: 30
Training loss: 0.4817635715007782 / Valid loss: 6.803235054016113
Training loss: 0.4514594078063965 / Valid loss: 6.817978398005168
Training loss: 0.3631715178489685 / Valid loss: 6.807428577968053
Training loss: 0.5134695768356323 / Valid loss: 6.876563944135394
Training loss: 0.4263817369937897 / Valid loss: 6.7823568571181525

Epoch: 31
Training loss: 0.5117906332015991 / Valid loss: 6.86391129266648
Training loss: 0.4331490993499756 / Valid loss: 6.831766886938186
Training loss: 0.4823755621910095 / Valid loss: 6.872081515902565
Training loss: 0.33831608295440674 / Valid loss: 6.8909860020592095
Training loss: 0.43682053685188293 / Valid loss: 6.999074477241153

Epoch: 32
Training loss: 0.5587068796157837 / Valid loss: 6.849571125847953
Training loss: 0.4467211365699768 / Valid loss: 6.856874209358579
Training loss: 0.4933033585548401 / Valid loss: 6.851555061340332
Training loss: 0.41836023330688477 / Valid loss: 6.806804557073684
Training loss: 0.5701733231544495 / Valid loss: 6.752812017713274

Epoch: 33
Training loss: 0.48938149213790894 / Valid loss: 6.830871200561523
Training loss: 0.5299113392829895 / Valid loss: 6.78384948912121
Training loss: 0.3791443407535553 / Valid loss: 6.854760578700474
Training loss: 0.3959607183933258 / Valid loss: 6.874238688605172
Training loss: 0.5073026418685913 / Valid loss: 6.915350973038446

Epoch: 34
Training loss: 0.84784996509552 / Valid loss: 6.810558641524542
Training loss: 0.3780098557472229 / Valid loss: 6.870923362459455
Training loss: 0.5260709524154663 / Valid loss: 6.858384286789667
Training loss: 0.3105500042438507 / Valid loss: 6.847722543988909
Training loss: 0.37165871262550354 / Valid loss: 6.790072752180554

Epoch: 35
Training loss: 0.8120191097259521 / Valid loss: 6.947482231685093
Training loss: 0.40832674503326416 / Valid loss: 6.791333491461618
Training loss: 0.2575708031654358 / Valid loss: 6.839314024788993
Training loss: 0.32510441541671753 / Valid loss: 6.917860930306571
Training loss: 0.3456174433231354 / Valid loss: 6.814979321616036

Epoch: 36
Training loss: 0.36534979939460754 / Valid loss: 6.851553079060146
Training loss: 0.7617155909538269 / Valid loss: 6.811295768192836
Training loss: 0.31516551971435547 / Valid loss: 6.866854703994024
Training loss: 0.33060356974601746 / Valid loss: 6.8456908725556875
Training loss: 0.41588684916496277 / Valid loss: 6.8495058332170755

Epoch: 37
Training loss: 0.42353859543800354 / Valid loss: 6.873068968454997
Training loss: 0.3280651867389679 / Valid loss: 6.7587628818693615
Training loss: 0.4312743842601776 / Valid loss: 6.870133681524368
Training loss: 0.7213282585144043 / Valid loss: 6.8087525526682535
Training loss: 0.48998257517814636 / Valid loss: 6.8538070451645625

Epoch: 38
Training loss: 0.3917848765850067 / Valid loss: 6.765246945335751
Training loss: 0.357817679643631 / Valid loss: 6.76726332846142
Training loss: 0.41595977544784546 / Valid loss: 6.762485940115792
Training loss: 0.3384285271167755 / Valid loss: 6.8026490415845595
Training loss: 0.32240891456604004 / Valid loss: 6.9024126370747885

Epoch: 39
Training loss: 0.5113993287086487 / Valid loss: 6.83139526049296
Training loss: 0.3025866746902466 / Valid loss: 6.79451983315604
Training loss: 0.3561829924583435 / Valid loss: 6.755090431939988
Training loss: 0.45146700739860535 / Valid loss: 6.957076218014672

Epoch: 40
Training loss: 0.36804628372192383 / Valid loss: 6.874037115914481
Training loss: 0.38985177874565125 / Valid loss: 6.743153272356306
Training loss: 0.26375043392181396 / Valid loss: 6.882572759900774
Training loss: 0.31998610496520996 / Valid loss: 6.782429118383498
Training loss: 0.3033495545387268 / Valid loss: 6.772621184303647

Epoch: 41
Training loss: 0.2733774185180664 / Valid loss: 6.866429837544759
Training loss: 0.25624948740005493 / Valid loss: 6.7811607837677
Training loss: 0.2962963581085205 / Valid loss: 6.848663548060826
Training loss: 1.2327595949172974 / Valid loss: 6.76028528213501
Training loss: 0.4783816933631897 / Valid loss: 6.814179098038446

Epoch: 42
Training loss: 0.39118099212646484 / Valid loss: 6.759415899004255
Training loss: 0.3444925844669342 / Valid loss: 6.80299927847726
Training loss: 0.3744836449623108 / Valid loss: 6.756099392118908
Training loss: 0.32826337218284607 / Valid loss: 6.747801853361584
Training loss: 0.37627869844436646 / Valid loss: 6.76649592263358

Epoch: 43
Training loss: 0.3811500370502472 / Valid loss: 6.794272372836159
Training loss: 0.32206419110298157 / Valid loss: 6.8181998207455585
Training loss: 0.2588002681732178 / Valid loss: 6.7701265902746295
Training loss: 0.5416268110275269 / Valid loss: 6.752507813771566
Training loss: 0.29299452900886536 / Valid loss: 6.75570479120527

Epoch: 44
Training loss: 0.23972025513648987 / Valid loss: 6.765600036439442
Training loss: 0.3293181359767914 / Valid loss: 6.805912362961542
Training loss: 0.3223400413990021 / Valid loss: 6.786621938432966
Training loss: 0.3097377419471741 / Valid loss: 6.794602176121303
Training loss: 0.43824344873428345 / Valid loss: 6.807029651460193

Epoch: 45
Training loss: 0.2801916003227234 / Valid loss: 6.743092972891671
Training loss: 0.4561864137649536 / Valid loss: 6.796846952892485
Training loss: 0.522200882434845 / Valid loss: 6.771978337424142
Training loss: 0.3911826014518738 / Valid loss: 6.707783487864903
Training loss: 0.38306760787963867 / Valid loss: 6.825072869800386

Epoch: 46
Training loss: 0.30472809076309204 / Valid loss: 6.757801737104144
Training loss: 0.32752498984336853 / Valid loss: 6.805779695510864
Training loss: 0.4997628927230835 / Valid loss: 6.775128409976051
Training loss: 0.3409487307071686 / Valid loss: 6.736865511394682
Training loss: 0.6677675247192383 / Valid loss: 6.694364036832537

Epoch: 47
Training loss: 0.19558504223823547 / Valid loss: 6.702166289374942
Training loss: 0.3180335760116577 / Valid loss: 6.729248537336077
Training loss: 0.48342302441596985 / Valid loss: 6.785060024261474
Training loss: 0.3862532377243042 / Valid loss: 6.806991767883301
Training loss: 0.2732636332511902 / Valid loss: 6.76103454771496

Epoch: 48
Training loss: 0.24597975611686707 / Valid loss: 6.728623362949916
Training loss: 0.4236012101173401 / Valid loss: 6.843870162963867
Training loss: 0.37488868832588196 / Valid loss: 6.704499503544398
Training loss: 0.2817808985710144 / Valid loss: 6.730080336616153
Training loss: 0.44567030668258667 / Valid loss: 6.786397407168434

Epoch: 49
Training loss: 0.4393573999404907 / Valid loss: 6.731303719111851
Training loss: 0.25647956132888794 / Valid loss: 6.797152814410982
Training loss: 0.20093435049057007 / Valid loss: 6.73744230497451
Training loss: 0.2900494635105133 / Valid loss: 6.7258472170148575

Epoch: 50
Training loss: 0.46962541341781616 / Valid loss: 6.699434284936814
Training loss: 0.3220330476760864 / Valid loss: 6.674120330810547
Training loss: 0.29386743903160095 / Valid loss: 6.711546103159587
Training loss: 0.29852235317230225 / Valid loss: 6.708015450977144
Training loss: 0.5148974657058716 / Valid loss: 6.816843416577294

Epoch: 51
Training loss: 0.23548740148544312 / Valid loss: 6.736036421003796
Training loss: 0.4178692698478699 / Valid loss: 6.767370832534064
Training loss: 0.28324565291404724 / Valid loss: 6.730896827152797
Training loss: 0.25252464413642883 / Valid loss: 6.707066404251825
Training loss: 0.35402363538742065 / Valid loss: 6.711458492279053

Epoch: 52
Training loss: 0.25875067710876465 / Valid loss: 6.724168273380824
Training loss: 0.2623487710952759 / Valid loss: 6.756116574151175
Training loss: 0.2128627449274063 / Valid loss: 6.717803519112723
Training loss: 0.1926773190498352 / Valid loss: 6.704392324175154
Training loss: 0.36973828077316284 / Valid loss: 6.713899035680861

Epoch: 53
Training loss: 0.24603763222694397 / Valid loss: 6.763773277827672
Training loss: 0.4876273274421692 / Valid loss: 6.707433228265671
Training loss: 0.2852274179458618 / Valid loss: 6.747799033210391
Training loss: 0.6705142855644226 / Valid loss: 6.7391944567362465
Training loss: 0.4465499520301819 / Valid loss: 6.76401474362328

Epoch: 54
Training loss: 0.5303177833557129 / Valid loss: 6.687629495348249
Training loss: 0.3286805748939514 / Valid loss: 6.794836509795416
Training loss: 0.3106897175312042 / Valid loss: 6.75164741334461
Training loss: 0.2318662703037262 / Valid loss: 6.7098256270090735
Training loss: 0.3557831346988678 / Valid loss: 6.758794512067523

Epoch: 55
Training loss: 0.5168576240539551 / Valid loss: 6.705766225996472
Training loss: 0.4875376224517822 / Valid loss: 6.759159515017555
Training loss: 0.5993860960006714 / Valid loss: 6.781763281141009
Training loss: 0.27772843837738037 / Valid loss: 6.810182339804513
Training loss: 0.3392465114593506 / Valid loss: 6.739926226933798

Epoch: 56
Training loss: 0.6266573071479797 / Valid loss: 6.710631915501186
Training loss: 0.1744554191827774 / Valid loss: 6.765591453370594
Training loss: 0.3134199380874634 / Valid loss: 6.69522210984003
Training loss: 0.31472039222717285 / Valid loss: 6.670461872645787
Training loss: 0.5152013897895813 / Valid loss: 6.690105004537673

Epoch: 57
Training loss: 0.7524474859237671 / Valid loss: 6.766784797395979
Training loss: 0.3706541359424591 / Valid loss: 6.710080396561396
Training loss: 0.35724395513534546 / Valid loss: 6.749285752432687
Training loss: 0.6074902415275574 / Valid loss: 6.689384891873314
Training loss: 0.44736865162849426 / Valid loss: 6.72520558493478

Epoch: 58
Training loss: 0.3819587826728821 / Valid loss: 6.689128784906297
Training loss: 0.4916685223579407 / Valid loss: 6.735916532788958
Training loss: 0.3611557185649872 / Valid loss: 6.711106672741118
Training loss: 0.534123420715332 / Valid loss: 6.67636771656218
Training loss: 0.22396443784236908 / Valid loss: 6.724246406555176

Epoch: 59
Training loss: 0.2273387461900711 / Valid loss: 6.680069655463809
Training loss: 0.42568856477737427 / Valid loss: 6.669782334282285
Training loss: 0.3666840195655823 / Valid loss: 6.721442597252982
Training loss: 0.4067525565624237 / Valid loss: 6.671936652773902

Epoch: 60
Training loss: 0.34881871938705444 / Valid loss: 6.710927477337065
Training loss: 0.6154779195785522 / Valid loss: 6.726460093543643
Training loss: 0.23126104474067688 / Valid loss: 6.669532276335216
Training loss: 0.3360059857368469 / Valid loss: 6.721975612640381
Training loss: 0.39391452074050903 / Valid loss: 6.6899144717625205

Epoch: 61
Training loss: 0.44558197259902954 / Valid loss: 6.7684749989282516
Training loss: 0.20760712027549744 / Valid loss: 6.768717820303781
Training loss: 0.550693929195404 / Valid loss: 6.6894766716730025
Training loss: 0.41413360834121704 / Valid loss: 6.741762708482288
Training loss: 0.3054914176464081 / Valid loss: 6.715096432822091

Epoch: 62
Training loss: 0.15472835302352905 / Valid loss: 6.666775571732294
Training loss: 0.27374690771102905 / Valid loss: 6.676443340664818
Training loss: 0.1859350949525833 / Valid loss: 6.6890191532316665
Training loss: 0.36541715264320374 / Valid loss: 6.7309935161045615
Training loss: 0.4565538763999939 / Valid loss: 6.716866742996943

Epoch: 63
Training loss: 0.3241569399833679 / Valid loss: 6.617739561625889
Training loss: 0.2074940949678421 / Valid loss: 6.634667342049735
Training loss: 0.2874569594860077 / Valid loss: 6.625707553681873
Training loss: 0.4158697724342346 / Valid loss: 6.709875547318232
Training loss: 0.2488686442375183 / Valid loss: 6.7120491209484285

Epoch: 64
Training loss: 0.20841088891029358 / Valid loss: 6.670325551714216
Training loss: 0.17572864890098572 / Valid loss: 6.69535178002857
Training loss: 0.5030312538146973 / Valid loss: 6.683894500278291
Training loss: 0.2802730202674866 / Valid loss: 6.668777388618106
Training loss: 0.29570499062538147 / Valid loss: 6.65590085756211

Epoch: 65
Training loss: 0.21561826765537262 / Valid loss: 6.657608425049554
Training loss: 0.4194198250770569 / Valid loss: 6.685143191473824
Training loss: 0.19582059979438782 / Valid loss: 6.695774296351842
Training loss: 0.26846858859062195 / Valid loss: 6.663293915703183
Training loss: 1.200953483581543 / Valid loss: 6.636239810216995

Epoch: 66
Training loss: 0.20386239886283875 / Valid loss: 6.635817682175409
Training loss: 0.2242625504732132 / Valid loss: 6.6748885200137185
Training loss: 0.6934322118759155 / Valid loss: 6.612638042086647
Training loss: 0.2251012921333313 / Valid loss: 6.662507272901989
Training loss: 0.48607316613197327 / Valid loss: 6.653824186325073

Epoch: 67
Training loss: 0.28059470653533936 / Valid loss: 6.696042982737223
Training loss: 0.1762937605381012 / Valid loss: 6.748717868895758
Training loss: 0.23315705358982086 / Valid loss: 6.679172847384498
Training loss: 0.9508079886436462 / Valid loss: 6.686927713666644
Training loss: 0.2847082018852234 / Valid loss: 6.6408798830849785

Epoch: 68
Training loss: 0.2023329734802246 / Valid loss: 6.638641952332996
Training loss: 0.32127800583839417 / Valid loss: 6.684152616773333
Training loss: 0.22909942269325256 / Valid loss: 6.686097304026286
Training loss: 0.25614750385284424 / Valid loss: 6.698540562675113
Training loss: 0.2671150267124176 / Valid loss: 6.679765060969761

Epoch: 69
Training loss: 0.41309303045272827 / Valid loss: 6.706050623030889
Training loss: 0.2782416343688965 / Valid loss: 6.664101877666655
Training loss: 0.3861317038536072 / Valid loss: 6.688184724535261
Training loss: 0.31186074018478394 / Valid loss: 6.675781572432745

Epoch: 70
Training loss: 0.2071351408958435 / Valid loss: 6.688096720831735
Training loss: 0.5145910978317261 / Valid loss: 6.686439979644049
Training loss: 0.35519811511039734 / Valid loss: 6.624032397497268
Training loss: 0.3331165909767151 / Valid loss: 6.6752090204329715
Training loss: 0.4087202548980713 / Valid loss: 6.661813890366327

Epoch: 71
Training loss: 0.3515656292438507 / Valid loss: 6.696151760646275
Training loss: 0.5540785789489746 / Valid loss: 6.669122055598668
Training loss: 0.2891699969768524 / Valid loss: 6.689207860401699
Training loss: 0.23078607022762299 / Valid loss: 6.65930077234904
Training loss: 0.2650478482246399 / Valid loss: 6.637486718949818

Epoch: 72
Training loss: 0.22568164765834808 / Valid loss: 6.663834410622006
Training loss: 0.5306540727615356 / Valid loss: 6.627140587852114
Training loss: 0.2193690687417984 / Valid loss: 6.640688666843233
Training loss: 0.34747231006622314 / Valid loss: 6.651382991245815
Training loss: 0.5703251361846924 / Valid loss: 6.67217553229559

Epoch: 73
Training loss: 0.44613921642303467 / Valid loss: 6.643679614294143
Training loss: 0.42118895053863525 / Valid loss: 6.644640227726527
Training loss: 0.2059280276298523 / Valid loss: 6.678271491186959
Training loss: 0.2047095000743866 / Valid loss: 6.634040482838949
Training loss: 0.26169097423553467 / Valid loss: 6.679233503341675

Epoch: 74
Training loss: 0.21150918304920197 / Valid loss: 6.645373253595261
Training loss: 0.2562561631202698 / Valid loss: 6.603808500653222
Training loss: 0.4858044683933258 / Valid loss: 6.637781792595273
Training loss: 0.43979257345199585 / Valid loss: 6.656432694480532
Training loss: 0.2181214690208435 / Valid loss: 6.632199003582909

Epoch: 75
Training loss: 0.27400001883506775 / Valid loss: 6.663445495423817
Training loss: 0.3727610111236572 / Valid loss: 6.663954471406482
Training loss: 0.5653051733970642 / Valid loss: 6.638429282960438
Training loss: 0.20947265625 / Valid loss: 6.633637993676322
Training loss: 0.40302059054374695 / Valid loss: 6.609807087126232

Epoch: 76
Training loss: 0.319435179233551 / Valid loss: 6.619022117342268
Training loss: 0.468672513961792 / Valid loss: 6.669357222602481
Training loss: 0.17770695686340332 / Valid loss: 6.673665396372477
Training loss: 0.33879488706588745 / Valid loss: 6.613214574541364
Training loss: 0.27779558300971985 / Valid loss: 6.71521782875061

Epoch: 77
Training loss: 0.2996503710746765 / Valid loss: 6.683221017746698
Training loss: 0.35909560322761536 / Valid loss: 6.705450166974749
Training loss: 0.3195039629936218 / Valid loss: 6.642677543276832
Training loss: 0.41818860173225403 / Valid loss: 6.663578564780099
Training loss: 0.44790446758270264 / Valid loss: 6.616634650457473

Epoch: 78
Training loss: 0.36747539043426514 / Valid loss: 6.666807201930455
Training loss: 0.18169009685516357 / Valid loss: 6.6603870119367325
Training loss: 0.15213361382484436 / Valid loss: 6.6445341973077685
Training loss: 0.3188200891017914 / Valid loss: 6.673798642839704
Training loss: 0.49758583307266235 / Valid loss: 6.664251005081903

Epoch: 79
Training loss: 0.2632230520248413 / Valid loss: 6.633800034295945
Training loss: 0.34705644845962524 / Valid loss: 6.6278168405805316
Training loss: 0.1976604163646698 / Valid loss: 6.662951056162516
Training loss: 0.19321796298027039 / Valid loss: 6.697877266293481
ModuleList(
  (0): Linear(in_features=5376, out_features=2000, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=2000, out_features=100, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=100, out_features=16, bias=True)
  (9): Dropout(p=0, inplace=False)
  (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (11): LeakyReLU(negative_slope=0.02)
  (12): Linear(in_features=16, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.645615534555344
Training regression with following parameters:
dnn_hidden_units : 300, 32
dropout_probs : 0.0, 0.0
learning_rate : 0.0001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : SGD
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : Bert
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=5376, out_features=300, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=300, out_features=32, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=32, out_features=1, bias=True)
)

Epoch: 0
Training loss: 13.485506057739258 / Valid loss: 16.65686526525588
Model is saved in epoch 0, overall batch: 0
Training loss: 8.353205680847168 / Valid loss: 13.521798624311174
Model is saved in epoch 0, overall batch: 100
Training loss: 9.878501892089844 / Valid loss: 11.759728340875535
Model is saved in epoch 0, overall batch: 200
Training loss: 8.94137954711914 / Valid loss: 10.662508110772995
Model is saved in epoch 0, overall batch: 300
Training loss: 7.284103870391846 / Valid loss: 9.390273657299224
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 10.038227081298828 / Valid loss: 8.6975235303243
Model is saved in epoch 1, overall batch: 500
Training loss: 7.003228187561035 / Valid loss: 8.028719107309977
Model is saved in epoch 1, overall batch: 600
Training loss: 5.50408411026001 / Valid loss: 7.721278290521531
Model is saved in epoch 1, overall batch: 700
Training loss: 4.810075283050537 / Valid loss: 7.310529688426427
Model is saved in epoch 1, overall batch: 800
Training loss: 7.264642238616943 / Valid loss: 6.510662315005348
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 5.978977203369141 / Valid loss: 6.450229251952399
Model is saved in epoch 2, overall batch: 1000
Training loss: 5.520969390869141 / Valid loss: 6.250886642365229
Model is saved in epoch 2, overall batch: 1100
Training loss: 5.182527542114258 / Valid loss: 6.037901083628337
Model is saved in epoch 2, overall batch: 1200
Training loss: 6.5769758224487305 / Valid loss: 6.223790320895967
Training loss: 5.607414722442627 / Valid loss: 5.8855375494275775
Model is saved in epoch 2, overall batch: 1400

Epoch: 3
Training loss: 4.964859485626221 / Valid loss: 5.842487902868362
Model is saved in epoch 3, overall batch: 1500
Training loss: 4.32572078704834 / Valid loss: 5.7728999228704545
Model is saved in epoch 3, overall batch: 1600
Training loss: 6.642495155334473 / Valid loss: 5.807491749808902
Training loss: 5.040497303009033 / Valid loss: 5.72698795681908
Model is saved in epoch 3, overall batch: 1800
Training loss: 4.986632823944092 / Valid loss: 5.871810997100104

Epoch: 4
Training loss: 3.0767107009887695 / Valid loss: 5.708779026213146
Model is saved in epoch 4, overall batch: 2000
Training loss: 4.436709880828857 / Valid loss: 5.7278491973876955
Training loss: 4.455597877502441 / Valid loss: 5.7002104532150994
Model is saved in epoch 4, overall batch: 2200
Training loss: 5.7150774002075195 / Valid loss: 5.651837548755464
Model is saved in epoch 4, overall batch: 2300
Training loss: 5.348583698272705 / Valid loss: 5.647511498133341
Model is saved in epoch 4, overall batch: 2400

Epoch: 5
Training loss: 5.756872177124023 / Valid loss: 5.642830601192656
Model is saved in epoch 5, overall batch: 2500
Training loss: 5.546241760253906 / Valid loss: 5.66232902208964
Training loss: 4.737227916717529 / Valid loss: 5.674365799767631
Training loss: 3.1277337074279785 / Valid loss: 5.669475580397107
Training loss: 5.894631862640381 / Valid loss: 5.663637163525536

Epoch: 6
Training loss: 4.596457481384277 / Valid loss: 5.6173127673921135
Model is saved in epoch 6, overall batch: 3000
Training loss: 2.6523051261901855 / Valid loss: 5.65349889709836
Training loss: 4.984997749328613 / Valid loss: 5.6713565190633135
Training loss: 3.9716835021972656 / Valid loss: 5.639438958395095
Training loss: 4.596701622009277 / Valid loss: 5.643691081092471

Epoch: 7
Training loss: 4.185222625732422 / Valid loss: 5.691637854349046
Training loss: 3.424835681915283 / Valid loss: 5.647243397576468
Training loss: 3.2519397735595703 / Valid loss: 5.69198731240772
Training loss: 5.034510612487793 / Valid loss: 5.671269428162348
Training loss: 3.414945363998413 / Valid loss: 5.699990901492891

Epoch: 8
Training loss: 3.4447197914123535 / Valid loss: 5.69239448365711
Training loss: 3.854642629623413 / Valid loss: 5.7410568986620225
Training loss: 3.331362247467041 / Valid loss: 5.732310102099464
Training loss: 4.362034797668457 / Valid loss: 5.726867348807199
Training loss: 4.993036270141602 / Valid loss: 5.706485827763875

Epoch: 9
Training loss: 2.586872100830078 / Valid loss: 5.720364257267543
Training loss: 4.44199275970459 / Valid loss: 5.7706506751832505
Training loss: 4.526033401489258 / Valid loss: 5.725092429206485
Training loss: 3.9691691398620605 / Valid loss: 5.755699171338763

Epoch: 10
Training loss: 3.5760233402252197 / Valid loss: 5.749398222423735
Training loss: 2.579925537109375 / Valid loss: 5.875948824201312
Training loss: 3.984163999557495 / Valid loss: 5.825910754430861
Training loss: 3.3292977809906006 / Valid loss: 5.797548997969854
Training loss: 4.5648193359375 / Valid loss: 5.832621547154018

Epoch: 11
Training loss: 3.8599345684051514 / Valid loss: 5.79313554082598
Training loss: 4.02146053314209 / Valid loss: 5.866930189586821
Training loss: 3.8362345695495605 / Valid loss: 5.879468513670422
Training loss: 3.6321663856506348 / Valid loss: 5.821375058946155
Training loss: 3.412081718444824 / Valid loss: 5.884131111417498

Epoch: 12
Training loss: 2.9512975215911865 / Valid loss: 5.84042340687343
Training loss: 4.117049694061279 / Valid loss: 5.87895462853568
Training loss: 3.4439003467559814 / Valid loss: 5.9965362526121595
Training loss: 3.089524269104004 / Valid loss: 5.9381985846019925
Training loss: 4.246267318725586 / Valid loss: 5.860563316799346

Epoch: 13
Training loss: 2.8052940368652344 / Valid loss: 5.870312316077096
Training loss: 3.571504592895508 / Valid loss: 5.856103815351214
Training loss: 2.1911802291870117 / Valid loss: 5.915453415825254
Training loss: 2.8195762634277344 / Valid loss: 5.922555010659354
Training loss: 3.802422523498535 / Valid loss: 5.891080197833833

Epoch: 14
Training loss: 2.9747562408447266 / Valid loss: 6.021978114900135
Training loss: 2.6204116344451904 / Valid loss: 5.961826111021496
Training loss: 2.182865619659424 / Valid loss: 5.938886092957996
Training loss: 2.9145400524139404 / Valid loss: 5.961219313031151
Training loss: 3.4904520511627197 / Valid loss: 6.100813052767799

Epoch: 15
Training loss: 2.9508118629455566 / Valid loss: 6.0236552102225165
Training loss: 3.2023191452026367 / Valid loss: 6.0836275259653725
Training loss: 2.3326539993286133 / Valid loss: 5.9511540935153056
Training loss: 2.9784626960754395 / Valid loss: 6.066595869972592
Training loss: 2.7173678874969482 / Valid loss: 6.282965900784447

Epoch: 16
Training loss: 3.688462495803833 / Valid loss: 6.079001499357678
Training loss: 2.3898093700408936 / Valid loss: 6.143254697890509
Training loss: 3.362879753112793 / Valid loss: 6.108857173011416
Training loss: 2.760833740234375 / Valid loss: 6.097749108359928
Training loss: 2.6331684589385986 / Valid loss: 6.14865266936166

Epoch: 17
Training loss: 2.2222723960876465 / Valid loss: 6.12653394880749
Training loss: 2.5854673385620117 / Valid loss: 6.106607112430391
Training loss: 2.506639242172241 / Valid loss: 6.116756187166486
Training loss: 2.6066365242004395 / Valid loss: 6.205545650209699
Training loss: 2.5980377197265625 / Valid loss: 6.1271946907043455

Epoch: 18
Training loss: 1.8954410552978516 / Valid loss: 6.135683402561006
Training loss: 3.0427050590515137 / Valid loss: 6.441155769711449
Training loss: 2.2443931102752686 / Valid loss: 6.28295712243943
Training loss: 2.4863104820251465 / Valid loss: 6.234489272889637
Training loss: 2.6563732624053955 / Valid loss: 6.144725009373256

Epoch: 19
Training loss: 2.7764713764190674 / Valid loss: 6.449720046633765
Training loss: 2.08288836479187 / Valid loss: 6.802956994374593
Training loss: 2.139772415161133 / Valid loss: 6.3264600345066615
Training loss: 1.405703067779541 / Valid loss: 6.28228584471203

Epoch: 20
Training loss: 1.3874616622924805 / Valid loss: 6.347855944860549
Training loss: 1.5261539220809937 / Valid loss: 6.460552524384998
Training loss: 1.8891382217407227 / Valid loss: 6.369381300608317
Training loss: 2.465214967727661 / Valid loss: 6.532475907461984
Training loss: 1.8322231769561768 / Valid loss: 6.343320297059559

Epoch: 21
Training loss: 1.7291579246520996 / Valid loss: 6.312827398663475
Training loss: 1.4778952598571777 / Valid loss: 6.329848716372536
Training loss: 2.075546979904175 / Valid loss: 6.3541476476760135
Training loss: 1.9983172416687012 / Valid loss: 6.529545068740845
Training loss: 2.0440828800201416 / Valid loss: 6.398956712086996

Epoch: 22
Training loss: 1.2081115245819092 / Valid loss: 6.475120424088978
Training loss: 1.6865599155426025 / Valid loss: 6.5642771175929475
Training loss: 2.368455410003662 / Valid loss: 6.998839037758963
Training loss: 1.5687150955200195 / Valid loss: 6.422386062712897
Training loss: 1.3970706462860107 / Valid loss: 6.480036812736874

Epoch: 23
Training loss: 1.6374409198760986 / Valid loss: 6.527257115500314
Training loss: 1.8463696241378784 / Valid loss: 6.472088831946963
Training loss: 2.17460560798645 / Valid loss: 6.716503422600883
Training loss: 2.0419583320617676 / Valid loss: 6.553533367883592
Training loss: 1.3195946216583252 / Valid loss: 6.509785320645287

Epoch: 24
Training loss: 0.9632573127746582 / Valid loss: 6.786494414011638
Training loss: 2.161050796508789 / Valid loss: 6.576518758138021
Training loss: 0.9973966479301453 / Valid loss: 6.6802029745919365
Training loss: 1.7548105716705322 / Valid loss: 6.5076683884575255
Training loss: 1.4880642890930176 / Valid loss: 6.5951555025009885

Epoch: 25
Training loss: 1.164557933807373 / Valid loss: 6.613419237590971
Training loss: 1.8219079971313477 / Valid loss: 6.587387743450346
Training loss: 1.480905294418335 / Valid loss: 6.683131626674107
Training loss: 1.542391300201416 / Valid loss: 6.7504057203020364
Training loss: 1.3713080883026123 / Valid loss: 6.637079559053693

Epoch: 26
Training loss: 1.5010294914245605 / Valid loss: 6.838565304165795
Training loss: 1.6990028619766235 / Valid loss: 6.833563389096941
Training loss: 1.647304892539978 / Valid loss: 6.986454813820975
Training loss: 1.8020609617233276 / Valid loss: 6.636682051704043
Training loss: 1.589633584022522 / Valid loss: 6.654491392771403

Epoch: 27
Training loss: 1.3943285942077637 / Valid loss: 6.6356805892217725
Training loss: 0.995750904083252 / Valid loss: 6.731440448760987
Training loss: 1.5247769355773926 / Valid loss: 6.692764822642008
Training loss: 1.3581902980804443 / Valid loss: 7.26837861651466
Training loss: 1.0418033599853516 / Valid loss: 6.676517332167853

Epoch: 28
Training loss: 0.6629917621612549 / Valid loss: 6.693877565293085
Training loss: 1.379703402519226 / Valid loss: 6.8592827547164195
Training loss: 1.0912469625473022 / Valid loss: 6.863615176791236
Training loss: 1.1063610315322876 / Valid loss: 6.844954290844146
Training loss: 1.3837019205093384 / Valid loss: 6.963094420660109

Epoch: 29
Training loss: 1.0201003551483154 / Valid loss: 6.746186515263148
Training loss: 0.9874293804168701 / Valid loss: 6.866666525886172
Training loss: 0.9811508655548096 / Valid loss: 6.77959026382083
Training loss: 1.6192638874053955 / Valid loss: 7.102864097413563

Epoch: 30
Training loss: 0.9306873083114624 / Valid loss: 7.120335669744582
Training loss: 1.5959800481796265 / Valid loss: 7.055652282351539
Training loss: 0.8025593757629395 / Valid loss: 6.8105706737155005
Training loss: 1.075927972793579 / Valid loss: 7.172974023364839
Training loss: 1.733196496963501 / Valid loss: 7.14609203338623

Epoch: 31
Training loss: 0.8117022514343262 / Valid loss: 8.074024095989408
Training loss: 1.7545924186706543 / Valid loss: 6.967454705919538
Training loss: 1.2076795101165771 / Valid loss: 6.857500764301845
Training loss: 1.1912091970443726 / Valid loss: 6.8442380837031775
Training loss: 1.2517788410186768 / Valid loss: 7.073267600649879

Epoch: 32
Training loss: 0.6158621311187744 / Valid loss: 6.9288228988647464
Training loss: 1.4258272647857666 / Valid loss: 7.293109544118246
Training loss: 0.9333984851837158 / Valid loss: 6.938070814950126
Training loss: 0.6497617363929749 / Valid loss: 7.0537382489158995
Training loss: 0.8921734094619751 / Valid loss: 6.9075604393368675

Epoch: 33
Training loss: 0.9078625440597534 / Valid loss: 7.163627174922398
Training loss: 0.9280069470405579 / Valid loss: 7.11833811260405
Training loss: 1.1662657260894775 / Valid loss: 6.917031921659198
Training loss: 1.370581865310669 / Valid loss: 7.290657220567976
Training loss: 0.7273364067077637 / Valid loss: 7.170710808890206

Epoch: 34
Training loss: 1.3582934141159058 / Valid loss: 7.0295683293115525
Training loss: 0.9722646474838257 / Valid loss: 6.873892861320859
Training loss: 0.7352050542831421 / Valid loss: 6.954585983639672
Training loss: 0.9213889241218567 / Valid loss: 7.026775373731341
Training loss: 1.1259057521820068 / Valid loss: 7.190350319090344

Epoch: 35
Training loss: 0.9235047101974487 / Valid loss: 7.870264371236165
Training loss: 0.9232757091522217 / Valid loss: 7.0828199976966495
Training loss: 1.0799190998077393 / Valid loss: 7.096007596878779
Training loss: 0.5745688080787659 / Valid loss: 7.138947055453346
Training loss: 0.8419153094291687 / Valid loss: 7.365202526819139

Epoch: 36
Training loss: 0.6563662886619568 / Valid loss: 6.938310913812547
Training loss: 0.9207398891448975 / Valid loss: 7.059687805175781
Training loss: 0.9757116436958313 / Valid loss: 7.512586266653878
Training loss: 1.231321096420288 / Valid loss: 6.981192225501651
Training loss: 0.7989597320556641 / Valid loss: 7.086079057057699

Epoch: 37
Training loss: 0.544928789138794 / Valid loss: 7.206286364509946
Training loss: 0.5447613596916199 / Valid loss: 7.212695671263195
Training loss: 0.7931307554244995 / Valid loss: 6.993155974433535
Training loss: 0.7320933938026428 / Valid loss: 7.181392247336252
Training loss: 1.1800637245178223 / Valid loss: 7.499863029661633

Epoch: 38
Training loss: 0.707287073135376 / Valid loss: 7.313116881960914
Training loss: 0.5276812314987183 / Valid loss: 7.112008816855294
Training loss: 0.7552834749221802 / Valid loss: 7.541641480582101
Training loss: 0.7265993356704712 / Valid loss: 7.0216155733381
Training loss: 1.1091328859329224 / Valid loss: 7.112737728300549

Epoch: 39
Training loss: 0.835628092288971 / Valid loss: 7.197056298028855
Training loss: 0.638336718082428 / Valid loss: 7.311685353233701
Training loss: 0.8097957968711853 / Valid loss: 7.097062101818266
Training loss: 0.6675061583518982 / Valid loss: 7.103133969079881

Epoch: 40
Training loss: 0.5679277181625366 / Valid loss: 7.07649727775937
Training loss: 0.4503835141658783 / Valid loss: 7.168875231061663
Training loss: 0.836927592754364 / Valid loss: 7.218388798123314
Training loss: 0.41670653223991394 / Valid loss: 7.141042373293922
Training loss: 0.4665340781211853 / Valid loss: 7.20211976369222

Epoch: 41
Training loss: 0.778715968132019 / Valid loss: 7.745113872346424
Training loss: 0.47550100088119507 / Valid loss: 7.122212553024292
Training loss: 0.6255239248275757 / Valid loss: 7.171908560253325
Training loss: 0.8047041893005371 / Valid loss: 7.167555014292399
Training loss: 0.5594807863235474 / Valid loss: 7.421640350705101

Epoch: 42
Training loss: 0.9363167881965637 / Valid loss: 7.153348641168503
Training loss: 0.4152439832687378 / Valid loss: 7.143696943918864
Training loss: 0.4587075412273407 / Valid loss: 7.292699044091361
Training loss: 0.7369362711906433 / Valid loss: 7.213079538799468
Training loss: 0.5552021265029907 / Valid loss: 7.336374941326323

Epoch: 43
Training loss: 0.4688132107257843 / Valid loss: 7.213870707012358
Training loss: 0.9329792261123657 / Valid loss: 7.212048058282761
Training loss: 0.8559157252311707 / Valid loss: 7.027223936716715
Training loss: 1.0321364402770996 / Valid loss: 7.1820057641892205
Training loss: 0.5796685218811035 / Valid loss: 7.314299960363479

Epoch: 44
Training loss: 0.6890779733657837 / Valid loss: 7.398573988959903
Training loss: 0.5104454159736633 / Valid loss: 7.325634688422793
Training loss: 0.4504673480987549 / Valid loss: 7.140320121674311
Training loss: 0.4542989134788513 / Valid loss: 7.131885594413394
Training loss: 0.6306449770927429 / Valid loss: 7.3045825640360516

Epoch: 45
Training loss: 0.5097880363464355 / Valid loss: 7.16045154389881
Training loss: 0.8868545889854431 / Valid loss: 7.151425870259603
Training loss: 0.3107004165649414 / Valid loss: 7.145532780601865
Training loss: 0.8646021485328674 / Valid loss: 7.148854042234875
Training loss: 0.5743454694747925 / Valid loss: 7.113458224705288

Epoch: 46
Training loss: 1.4844868183135986 / Valid loss: 7.730842163449242
Training loss: 0.5319056510925293 / Valid loss: 7.187153652736119
Training loss: 0.6238306164741516 / Valid loss: 7.222552908034552
Training loss: 0.5763000249862671 / Valid loss: 7.345535818735758
Training loss: 1.0264003276824951 / Valid loss: 7.459705439068022

Epoch: 47
Training loss: 0.700688898563385 / Valid loss: 7.229549494243804
Training loss: 0.46388426423072815 / Valid loss: 7.22678861618042
Training loss: 0.38886570930480957 / Valid loss: 7.197088818323045
Training loss: 0.49404454231262207 / Valid loss: 7.203221825190953
Training loss: 0.6049854755401611 / Valid loss: 7.257221221923828

Epoch: 48
Training loss: 0.44844937324523926 / Valid loss: 7.376722240447998
Training loss: 0.48462581634521484 / Valid loss: 7.22709466843378
Training loss: 0.486883282661438 / Valid loss: 7.133872277396065
Training loss: 1.0335445404052734 / Valid loss: 7.2585704712640675
Training loss: 1.035405158996582 / Valid loss: 7.24125828061785

Epoch: 49
Training loss: 0.4102819859981537 / Valid loss: 7.099325002942766
Training loss: 0.5312927961349487 / Valid loss: 7.2434902781531925
Training loss: 0.5178179740905762 / Valid loss: 7.239430654616583
Training loss: 0.6674890518188477 / Valid loss: 7.193948836553664

Epoch: 50
Training loss: 0.655849277973175 / Valid loss: 7.404098651522681
Training loss: 0.39730656147003174 / Valid loss: 7.396046363739741
Training loss: 0.5550585389137268 / Valid loss: 7.404127066476004
Training loss: 0.4255214035511017 / Valid loss: 7.223256406329927
Training loss: 0.5735509395599365 / Valid loss: 7.339184279668899

Epoch: 51
Training loss: 0.396328330039978 / Valid loss: 7.193425101325626
Training loss: 0.3627109229564667 / Valid loss: 7.271930576506115
Training loss: 0.3570318818092346 / Valid loss: 7.419812652042934
Training loss: 0.46630576252937317 / Valid loss: 7.201318804423014
Training loss: 0.41449302434921265 / Valid loss: 7.127533285958426

Epoch: 52
Training loss: 0.5098362565040588 / Valid loss: 7.183498829887027
Training loss: 0.5670045614242554 / Valid loss: 7.1753317151750835
Training loss: 0.5469739437103271 / Valid loss: 7.320106933230446
Training loss: 0.777762234210968 / Valid loss: 7.192063638142177
Training loss: 0.4081178903579712 / Valid loss: 7.136449632190523

Epoch: 53
Training loss: 0.4359613358974457 / Valid loss: 7.411311126890636
Training loss: 0.6760150194168091 / Valid loss: 7.220258957999093
Training loss: 0.5539911985397339 / Valid loss: 7.2479627654666
Training loss: 0.451671302318573 / Valid loss: 7.340843418666295
Training loss: 0.6124120950698853 / Valid loss: 7.168149285089402

Epoch: 54
Training loss: 0.5324425101280212 / Valid loss: 7.120746751058669
Training loss: 0.5628736019134521 / Valid loss: 7.342231373559861
Training loss: 0.41565924882888794 / Valid loss: 7.2555630502246675
Training loss: 0.36248576641082764 / Valid loss: 7.304964492434547
Training loss: 0.4172646999359131 / Valid loss: 7.29530611038208

Epoch: 55
Training loss: 0.4268144965171814 / Valid loss: 7.216436944689069
Training loss: 0.7453279495239258 / Valid loss: 7.507946990785145
Training loss: 0.6070394515991211 / Valid loss: 7.255918557303293
Training loss: 0.44326066970825195 / Valid loss: 7.177557545616513
Training loss: 0.5570393800735474 / Valid loss: 7.224488812401181

Epoch: 56
Training loss: 0.32396432757377625 / Valid loss: 7.179266670772008
Training loss: 0.690322995185852 / Valid loss: 7.31411839893886
Training loss: 0.7682938575744629 / Valid loss: 7.1632740066165015
Training loss: 0.5935851335525513 / Valid loss: 7.749359457833426
Training loss: 0.31330394744873047 / Valid loss: 7.21822398957752

Epoch: 57
Training loss: 0.5831236839294434 / Valid loss: 7.228710437956311
Training loss: 0.6603431105613708 / Valid loss: 7.329332070123582
Training loss: 0.4646352529525757 / Valid loss: 7.226652753920782
Training loss: 0.4380362033843994 / Valid loss: 7.109053162166051
Training loss: 0.5203269720077515 / Valid loss: 7.365804822104318

Epoch: 58
Training loss: 0.49253201484680176 / Valid loss: 7.248952018646967
Training loss: 0.3753055930137634 / Valid loss: 7.34649570555914
Training loss: 0.49474799633026123 / Valid loss: 7.3486738159542995
Training loss: 0.4723641276359558 / Valid loss: 7.302532809121268
Training loss: 0.3412826657295227 / Valid loss: 7.229173814682733

Epoch: 59
Training loss: 0.397320419549942 / Valid loss: 7.772772511981782
Training loss: 0.539291262626648 / Valid loss: 7.210553114754813
Training loss: 0.3092149794101715 / Valid loss: 7.232146104176839
Training loss: 0.615314245223999 / Valid loss: 7.198801213219053

Epoch: 60
Training loss: 0.4752061665058136 / Valid loss: 7.236976687113444
Training loss: 0.48369067907333374 / Valid loss: 7.163430377415248
Training loss: 0.47955089807510376 / Valid loss: 7.404694993155343
Training loss: 0.5136860013008118 / Valid loss: 7.165613760266985
Training loss: 0.663061261177063 / Valid loss: 7.2874635855356855

Epoch: 61
Training loss: 0.33269116282463074 / Valid loss: 7.214531408037458
Training loss: 0.4038369059562683 / Valid loss: 7.47897515978132
Training loss: 0.5223003625869751 / Valid loss: 7.174090587525141
Training loss: 0.5277438759803772 / Valid loss: 7.149217169625419
Training loss: 0.255845308303833 / Valid loss: 7.169799318767729

Epoch: 62
Training loss: 0.33354735374450684 / Valid loss: 7.472092832837786
Training loss: 0.40193265676498413 / Valid loss: 7.640915988740467
Training loss: 0.42322781682014465 / Valid loss: 7.1805734543573285
Training loss: 0.37132707238197327 / Valid loss: 7.137715544019427
Training loss: 0.8202080726623535 / Valid loss: 7.613465577080136

Epoch: 63
Training loss: 0.5614098906517029 / Valid loss: 7.28074693225679
Training loss: 0.28298836946487427 / Valid loss: 7.232256121862502
Training loss: 0.2594730854034424 / Valid loss: 7.388455790565128
Training loss: 0.4553847312927246 / Valid loss: 7.272846726008824
Training loss: 0.39825645089149475 / Valid loss: 7.395835712977818

Epoch: 64
Training loss: 0.3788943588733673 / Valid loss: 7.361874416896275
Training loss: 0.40706712007522583 / Valid loss: 7.204178673880441
Training loss: 0.43757328391075134 / Valid loss: 7.207491170792353
Training loss: 0.8256121277809143 / Valid loss: 7.207130849929083
Training loss: 0.6461206674575806 / Valid loss: 7.24599643434797

Epoch: 65
Training loss: 1.013168215751648 / Valid loss: 7.174901671636672
Training loss: 1.1203721761703491 / Valid loss: 7.169782920110793
Training loss: 0.25761428475379944 / Valid loss: 7.239043272109258
Training loss: 0.6642298698425293 / Valid loss: 7.592367017836798
Training loss: 0.33986395597457886 / Valid loss: 7.169904222942534

Epoch: 66
Training loss: 0.4330098032951355 / Valid loss: 7.347686912899926
Training loss: 0.30276307463645935 / Valid loss: 7.16196201415289
Training loss: 0.3958272337913513 / Valid loss: 7.328487605140323
Training loss: 0.41068896651268005 / Valid loss: 7.236127199445452
Training loss: 0.37068435549736023 / Valid loss: 7.37662749063401

Epoch: 67
Training loss: 0.3108088970184326 / Valid loss: 7.2527197678883875
Training loss: 0.35923948884010315 / Valid loss: 7.387099388667515
Training loss: 0.8406725525856018 / Valid loss: 7.289218502952939
Training loss: 0.6446253657341003 / Valid loss: 7.296507038388934
Training loss: 0.496057391166687 / Valid loss: 7.405712186722528

Epoch: 68
Training loss: 0.30754104256629944 / Valid loss: 7.226669647580102
Training loss: 0.686754584312439 / Valid loss: 7.31321781703404
Training loss: 0.5148905515670776 / Valid loss: 7.236498387654622
Training loss: 0.4139038026332855 / Valid loss: 7.248628134954544
Training loss: 0.3672786056995392 / Valid loss: 7.34861099152338

Epoch: 69
Training loss: 0.41753578186035156 / Valid loss: 7.203237252008347
Training loss: 0.2426169216632843 / Valid loss: 7.314026083265032
Training loss: 0.39720475673675537 / Valid loss: 7.196630291711717
Training loss: 0.3609195351600647 / Valid loss: 7.202561705453055

Epoch: 70
Training loss: 0.3771182596683502 / Valid loss: 7.233497061048236
Training loss: 0.3965105414390564 / Valid loss: 7.191929090590704
Training loss: 0.39420175552368164 / Valid loss: 7.620951298304966
Training loss: 0.3317681849002838 / Valid loss: 7.239657283964611
Training loss: 0.6142701506614685 / Valid loss: 7.3705069405691965

Epoch: 71
Training loss: 0.3760524392127991 / Valid loss: 7.303921763102213
Training loss: 0.30354759097099304 / Valid loss: 7.379582695733934
Training loss: 0.38156092166900635 / Valid loss: 7.206929933457148
Training loss: 0.3394452929496765 / Valid loss: 7.244684541793097
Training loss: 0.32823652029037476 / Valid loss: 7.20911747160412

Epoch: 72
Training loss: 0.5953978300094604 / Valid loss: 7.2263417879740395
Training loss: 0.4539209008216858 / Valid loss: 7.232245013827369
Training loss: 0.2543729543685913 / Valid loss: 7.116292099725633
Training loss: 0.4616694450378418 / Valid loss: 7.1916741870698475
Training loss: 0.2800072431564331 / Valid loss: 7.48411804380871

Epoch: 73
Training loss: 0.7199380993843079 / Valid loss: 7.28800766808646
Training loss: 0.33581647276878357 / Valid loss: 7.412859771365211
Training loss: 0.3874611258506775 / Valid loss: 7.306776391892206
Training loss: 0.35164037346839905 / Valid loss: 7.172890742619832
Training loss: 0.33768129348754883 / Valid loss: 7.21256522224063

Epoch: 74
Training loss: 0.5156568884849548 / Valid loss: 7.618030239286877
Training loss: 0.2693519592285156 / Valid loss: 7.3047336532956075
Training loss: 0.6995607614517212 / Valid loss: 7.21340381985619
Training loss: 0.2991449236869812 / Valid loss: 7.179142216273717
Training loss: 0.4521183371543884 / Valid loss: 7.103614362080892

Epoch: 75
Training loss: 0.4197004437446594 / Valid loss: 7.196364802405948
Training loss: 0.49070975184440613 / Valid loss: 7.195450492132277
Training loss: 0.1922636330127716 / Valid loss: 7.381273664746966
Training loss: 0.3177264630794525 / Valid loss: 7.106188835416521
Training loss: 0.2973695993423462 / Valid loss: 7.257337901705787

Epoch: 76
Training loss: 0.33577364683151245 / Valid loss: 7.284320268176851
Training loss: 0.2740378975868225 / Valid loss: 7.350874303636097
Training loss: 0.30488157272338867 / Valid loss: 7.135417524973551
Training loss: 0.27368974685668945 / Valid loss: 7.249813447679792
Training loss: 0.3363969922065735 / Valid loss: 7.17802274340675

Epoch: 77
Training loss: 0.28276965022087097 / Valid loss: 7.266218566894532
Training loss: 0.44901344180107117 / Valid loss: 7.240250542050316
Training loss: 0.4806956648826599 / Valid loss: 7.202144472939628
Training loss: 0.3210061192512512 / Valid loss: 7.218148622058687
Training loss: 0.41328954696655273 / Valid loss: 7.422068355196998

Epoch: 78
Training loss: 0.21770857274532318 / Valid loss: 7.1310225214277
Training loss: 0.581318199634552 / Valid loss: 7.1421238218035015
Training loss: 0.6554352045059204 / Valid loss: 7.441735944293794
Training loss: 0.6129366159439087 / Valid loss: 7.191486971718924
Training loss: 0.4009004831314087 / Valid loss: 7.295323449089413

Epoch: 79
Training loss: 0.24375148117542267 / Valid loss: 7.342482117244176
Training loss: 0.6144287586212158 / Valid loss: 7.23642182577224
Training loss: 0.31217479705810547 / Valid loss: 7.15431855065482
Training loss: 0.5859256982803345 / Valid loss: 7.178431951432001
ModuleList(
  (0): Linear(in_features=5376, out_features=300, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=300, out_features=32, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=32, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.492673873901367
Training regression with following parameters:
dnn_hidden_units : 248
dropout_probs : 0.0, 0.0
learning_rate : 0.0001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : SGD
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : Bert
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=5376, out_features=248, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=248, out_features=1, bias=True)
)

Epoch: 0
Training loss: 20.62260627746582 / Valid loss: 16.374367114475795
Model is saved in epoch 0, overall batch: 0
Training loss: 9.723286628723145 / Valid loss: 8.03689811797369
Model is saved in epoch 0, overall batch: 100
Training loss: 7.480327129364014 / Valid loss: 6.270145116533552
Model is saved in epoch 0, overall batch: 200
Training loss: 6.113794803619385 / Valid loss: 5.767492276146299
Model is saved in epoch 0, overall batch: 300
Training loss: 8.645269393920898 / Valid loss: 5.683840640385946
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 5.7855329513549805 / Valid loss: 5.636974350611369
Model is saved in epoch 1, overall batch: 500
Training loss: 5.952703475952148 / Valid loss: 5.620285365695045
Model is saved in epoch 1, overall batch: 600
Training loss: 7.779379844665527 / Valid loss: 5.607268519628615
Model is saved in epoch 1, overall batch: 700
Training loss: 5.61826229095459 / Valid loss: 5.591315775825864
Model is saved in epoch 1, overall batch: 800
Training loss: 5.868439674377441 / Valid loss: 5.5809512751443044
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 5.585034370422363 / Valid loss: 5.568961988176619
Model is saved in epoch 2, overall batch: 1000
Training loss: 5.186855792999268 / Valid loss: 5.56346074058896
Model is saved in epoch 2, overall batch: 1100
Training loss: 5.649401664733887 / Valid loss: 5.552265010561261
Model is saved in epoch 2, overall batch: 1200
Training loss: 6.644792556762695 / Valid loss: 5.551360021318708
Model is saved in epoch 2, overall batch: 1300
Training loss: 5.73404598236084 / Valid loss: 5.551116521017892
Model is saved in epoch 2, overall batch: 1400

Epoch: 3
Training loss: 4.002068519592285 / Valid loss: 5.543919526963007
Model is saved in epoch 3, overall batch: 1500
Training loss: 5.211565971374512 / Valid loss: 5.530445948101225
Model is saved in epoch 3, overall batch: 1600
Training loss: 4.413474082946777 / Valid loss: 5.5389294419969834
Training loss: 5.650099277496338 / Valid loss: 5.534274639402117
Training loss: 4.929032325744629 / Valid loss: 5.520228640238444
Model is saved in epoch 3, overall batch: 1900

Epoch: 4
Training loss: 3.663520097732544 / Valid loss: 5.525265702747164
Training loss: 4.548025131225586 / Valid loss: 5.503819140933809
Model is saved in epoch 4, overall batch: 2100
Training loss: 4.473043441772461 / Valid loss: 5.504852301733834
Training loss: 5.676331043243408 / Valid loss: 5.504366359256562
Training loss: 7.401066303253174 / Valid loss: 5.5190348693302695

Epoch: 5
Training loss: 4.693532466888428 / Valid loss: 5.516100965227399
Training loss: 4.425579071044922 / Valid loss: 5.505906166349138
Training loss: 6.140329360961914 / Valid loss: 5.507202395938692
Training loss: 6.074995994567871 / Valid loss: 5.505961988085792
Training loss: 8.119731903076172 / Valid loss: 5.552161357516334

Epoch: 6
Training loss: 4.920608043670654 / Valid loss: 5.4966453120822
Model is saved in epoch 6, overall batch: 3000
Training loss: 3.5722315311431885 / Valid loss: 5.499852854864938
Training loss: 5.343437671661377 / Valid loss: 5.503778316861108
Training loss: 4.2412567138671875 / Valid loss: 5.506594853174119
Training loss: 3.6292004585266113 / Valid loss: 5.508016241164435

Epoch: 7
Training loss: 3.034107208251953 / Valid loss: 5.492367213112967
Model is saved in epoch 7, overall batch: 3500
Training loss: 4.586381912231445 / Valid loss: 5.499123493830363
Training loss: 4.650707721710205 / Valid loss: 5.510363678705125
Training loss: 5.466540336608887 / Valid loss: 5.497427647454398
Training loss: 5.5551300048828125 / Valid loss: 5.492298257918585
Model is saved in epoch 7, overall batch: 3900

Epoch: 8
Training loss: 4.886886119842529 / Valid loss: 5.474659220377604
Model is saved in epoch 8, overall batch: 4000
Training loss: 4.101755619049072 / Valid loss: 5.49233805565607
Training loss: 6.47113037109375 / Valid loss: 5.503897562481108
Training loss: 5.396266937255859 / Valid loss: 5.508086136409214
Training loss: 4.64796257019043 / Valid loss: 5.505141226450602

Epoch: 9
Training loss: 4.131557941436768 / Valid loss: 5.504770914713542
Training loss: 4.4432172775268555 / Valid loss: 5.503911220459711
Training loss: 4.806093215942383 / Valid loss: 5.502504818780082
Training loss: 3.09077787399292 / Valid loss: 5.526000349862235

Epoch: 10
Training loss: 3.6631410121917725 / Valid loss: 5.479949353990101
Training loss: 4.112114906311035 / Valid loss: 5.509141531444731
Training loss: 4.880876064300537 / Valid loss: 5.4891913050696965
Training loss: 4.935422897338867 / Valid loss: 5.4816707951681956
Training loss: 4.868746280670166 / Valid loss: 5.496526232219877

Epoch: 11
Training loss: 5.796143531799316 / Valid loss: 5.490044389452253
Training loss: 4.455735683441162 / Valid loss: 5.489797442299979
Training loss: 4.99518346786499 / Valid loss: 5.50384598232451
Training loss: 4.147449493408203 / Valid loss: 5.487559879393805
Training loss: 4.281708240509033 / Valid loss: 5.502151564189366

Epoch: 12
Training loss: 6.217983245849609 / Valid loss: 5.480363432566325
Training loss: 4.277544975280762 / Valid loss: 5.503284899393718
Training loss: 5.311287879943848 / Valid loss: 5.5023855845133465
Training loss: 4.662668228149414 / Valid loss: 5.4882111140659875
Training loss: 4.268229007720947 / Valid loss: 5.495553059805007

Epoch: 13
Training loss: 4.589259147644043 / Valid loss: 5.500099588575817
Training loss: 4.708662986755371 / Valid loss: 5.517121866771153
Training loss: 5.091606616973877 / Valid loss: 5.527061525980631
Training loss: 3.2598397731781006 / Valid loss: 5.498584615616571
Training loss: 4.63021183013916 / Valid loss: 5.505291664032709

Epoch: 14
Training loss: 4.8848066329956055 / Valid loss: 5.512971237727574
Training loss: 3.3257455825805664 / Valid loss: 5.500072043282645
Training loss: 5.672566890716553 / Valid loss: 5.4990129538944785
Training loss: 4.858784198760986 / Valid loss: 5.500127120245071
Training loss: 4.002681255340576 / Valid loss: 5.510383708136422

Epoch: 15
Training loss: 3.3913888931274414 / Valid loss: 5.49686845824832
Training loss: 5.701915740966797 / Valid loss: 5.509979325249081
Training loss: 4.671329498291016 / Valid loss: 5.500605694452921
Training loss: 4.647863864898682 / Valid loss: 5.508078250430879
Training loss: 3.8420639038085938 / Valid loss: 5.495794729959397

Epoch: 16
Training loss: 5.851274490356445 / Valid loss: 5.518983300526937
Training loss: 4.4100141525268555 / Valid loss: 5.518141233353388
Training loss: 3.2053446769714355 / Valid loss: 5.5425974573407855
Training loss: 5.162504196166992 / Valid loss: 5.508488487062
Training loss: 4.365017414093018 / Valid loss: 5.526884128933861

Epoch: 17
Training loss: 4.261116981506348 / Valid loss: 5.52179615838187
Training loss: 4.306163787841797 / Valid loss: 5.510702339808146
Training loss: 2.8198914527893066 / Valid loss: 5.506832947049822
Training loss: 6.722352504730225 / Valid loss: 5.542065100442795
Training loss: 3.9405417442321777 / Valid loss: 5.5194371223449705

Epoch: 18
Training loss: 4.212460041046143 / Valid loss: 5.535814968744914
Training loss: 3.9081106185913086 / Valid loss: 5.5212704386029925
Training loss: 4.497907638549805 / Valid loss: 5.5538211459205264
Training loss: 4.670535087585449 / Valid loss: 5.562773643221174
Training loss: 6.115987777709961 / Valid loss: 5.540162744976225

Epoch: 19
Training loss: 4.058779716491699 / Valid loss: 5.573500356220063
Training loss: 3.6568846702575684 / Valid loss: 5.561927629652478
Training loss: 5.323386192321777 / Valid loss: 5.577203487214588
Training loss: 4.756336212158203 / Valid loss: 5.543887578873408

Epoch: 20
Training loss: 3.6379096508026123 / Valid loss: 5.566910766419911
Training loss: 3.4808106422424316 / Valid loss: 5.551528624125889
Training loss: 3.5602786540985107 / Valid loss: 5.571799677894229
Training loss: 4.524139404296875 / Valid loss: 5.535100693929763
Training loss: 2.596696376800537 / Valid loss: 5.555288137708391

Epoch: 21
Training loss: 4.588597297668457 / Valid loss: 5.570718812942505
Training loss: 4.202706336975098 / Valid loss: 5.56803754397801
Training loss: 5.053424835205078 / Valid loss: 5.556990984507969
Training loss: 5.559844970703125 / Valid loss: 5.615033858163017
Training loss: 3.5589447021484375 / Valid loss: 5.570238447189331

Epoch: 22
Training loss: 2.8279476165771484 / Valid loss: 5.552148457935878
Training loss: 3.9962644577026367 / Valid loss: 5.5627135685511995
Training loss: 4.602024078369141 / Valid loss: 5.578122120811826
Training loss: 5.275311470031738 / Valid loss: 5.574670871098836
Training loss: 3.4007039070129395 / Valid loss: 5.611990236100697

Epoch: 23
Training loss: 3.506819248199463 / Valid loss: 5.608497685477847
Training loss: 4.4308295249938965 / Valid loss: 5.6097136474791025
Training loss: 3.846752643585205 / Valid loss: 5.592912217548915
Training loss: 3.874382495880127 / Valid loss: 5.588585467565627
Training loss: 3.9579169750213623 / Valid loss: 5.612251442954654

Epoch: 24
Training loss: 3.2407426834106445 / Valid loss: 5.611904269173031
Training loss: 5.147474765777588 / Valid loss: 5.600155026572091
Training loss: 4.280293941497803 / Valid loss: 5.636954307556152
Training loss: 3.4166159629821777 / Valid loss: 5.621891839163644
Training loss: 4.060394287109375 / Valid loss: 5.605735340572539

Epoch: 25
Training loss: 3.2495851516723633 / Valid loss: 5.611431936990647
Training loss: 3.4407732486724854 / Valid loss: 5.644020244053432
Training loss: 4.946911811828613 / Valid loss: 5.6506095908937
Training loss: 3.0040249824523926 / Valid loss: 5.635368921643212
Training loss: 3.889343738555908 / Valid loss: 5.62805655343192

Epoch: 26
Training loss: 2.996662139892578 / Valid loss: 5.611626445679438
Training loss: 2.925067901611328 / Valid loss: 5.62699419430324
Training loss: 3.187985420227051 / Valid loss: 5.639360772995722
Training loss: 3.893946886062622 / Valid loss: 5.621298131488619
Training loss: 2.843684673309326 / Valid loss: 5.620655965805054

Epoch: 27
Training loss: 3.7672834396362305 / Valid loss: 5.64639957064674
Training loss: 2.7289276123046875 / Valid loss: 5.633789216904413
Training loss: 3.2504992485046387 / Valid loss: 5.641236021405175
Training loss: 4.243644714355469 / Valid loss: 5.655892219997588
Training loss: 5.524693489074707 / Valid loss: 5.6541340510050455

Epoch: 28
Training loss: 3.8135952949523926 / Valid loss: 5.6530906654539566
Training loss: 3.6007578372955322 / Valid loss: 5.6477264858427505
Training loss: 4.173424243927002 / Valid loss: 5.6668715658641995
Training loss: 5.246459007263184 / Valid loss: 5.665747717448643
Training loss: 3.0439608097076416 / Valid loss: 5.642090011778332

Epoch: 29
Training loss: 3.58587646484375 / Valid loss: 5.662632715134394
Training loss: 2.7467689514160156 / Valid loss: 5.680554662431989
Training loss: 4.383121490478516 / Valid loss: 5.698691611062912
Training loss: 3.34489107131958 / Valid loss: 5.758611615498861

Epoch: 30
Training loss: 4.151186943054199 / Valid loss: 5.671727868488857
Training loss: 3.674302339553833 / Valid loss: 5.703754268373761
Training loss: 3.884908676147461 / Valid loss: 5.725432897749402
Training loss: 3.5936551094055176 / Valid loss: 5.684290361404419
Training loss: 2.7679266929626465 / Valid loss: 5.715865341822306

Epoch: 31
Training loss: 4.056114196777344 / Valid loss: 5.683624188105266
Training loss: 3.664895534515381 / Valid loss: 5.692878041948591
Training loss: 3.0966057777404785 / Valid loss: 5.70778560865493
Training loss: 3.4828014373779297 / Valid loss: 5.718252057120914
Training loss: 3.1745595932006836 / Valid loss: 5.747333760488601

Epoch: 32
Training loss: 2.7213573455810547 / Valid loss: 5.714215083349319
Training loss: 3.069550037384033 / Valid loss: 5.7990729468209405
Training loss: 2.665076732635498 / Valid loss: 5.713065317698887
Training loss: 3.8052682876586914 / Valid loss: 5.692632895424253
Training loss: 2.8512539863586426 / Valid loss: 5.745132795969645

Epoch: 33
Training loss: 2.8758857250213623 / Valid loss: 5.7084731737772625
Training loss: 3.3629555702209473 / Valid loss: 5.727412873222715
Training loss: 2.928328037261963 / Valid loss: 5.724246585936774
Training loss: 2.756891965866089 / Valid loss: 5.745341103417533
Training loss: 3.2078771591186523 / Valid loss: 5.771967158998762

Epoch: 34
Training loss: 2.970460891723633 / Valid loss: 5.740310643968128
Training loss: 4.128597259521484 / Valid loss: 5.750034207389469
Training loss: 3.399350643157959 / Valid loss: 5.76904753957476
Training loss: 4.350603103637695 / Valid loss: 5.795042848587036
Training loss: 1.7697536945343018 / Valid loss: 5.760461968467349

Epoch: 35
Training loss: 3.291290521621704 / Valid loss: 5.798365856352307
Training loss: 2.5077061653137207 / Valid loss: 5.7504554385230655
Training loss: 2.8008763790130615 / Valid loss: 5.76286772546314
Training loss: 3.295492172241211 / Valid loss: 5.82649644442967
Training loss: 2.7681703567504883 / Valid loss: 5.787088768822806

Epoch: 36
Training loss: 3.7842483520507812 / Valid loss: 5.762243874867758
Training loss: 2.9187448024749756 / Valid loss: 5.824392820539929
Training loss: 3.0790843963623047 / Valid loss: 5.817818934576852
Training loss: 2.727980136871338 / Valid loss: 5.8526769047691705
Training loss: 3.242953300476074 / Valid loss: 5.801236824762253

Epoch: 37
Training loss: 3.147149085998535 / Valid loss: 5.819170138949439
Training loss: 2.2690486907958984 / Valid loss: 5.788810834430513
Training loss: 3.48783540725708 / Valid loss: 5.796838149570283
Training loss: 3.169800281524658 / Valid loss: 5.834577371960594
Training loss: 2.5627899169921875 / Valid loss: 5.785411105837141

Epoch: 38
Training loss: 2.7082982063293457 / Valid loss: 5.808466570717948
Training loss: 2.8753890991210938 / Valid loss: 5.796747266678583
Training loss: 3.0182604789733887 / Valid loss: 5.8696159022195
Training loss: 2.8858819007873535 / Valid loss: 5.844158967336019
Training loss: 3.5476016998291016 / Valid loss: 5.907640389033726

Epoch: 39
Training loss: 2.4712467193603516 / Valid loss: 5.832042759940737
Training loss: 3.704918384552002 / Valid loss: 5.857532598858788
Training loss: 2.9705753326416016 / Valid loss: 5.89889053617205
Training loss: 2.5232200622558594 / Valid loss: 5.889031610034761

Epoch: 40
Training loss: 4.442259311676025 / Valid loss: 5.8228205226716545
Training loss: 2.50181245803833 / Valid loss: 5.842455468858991
Training loss: 3.7495105266571045 / Valid loss: 5.917591253916423
Training loss: 2.8202710151672363 / Valid loss: 5.845340665181478
Training loss: 2.673182249069214 / Valid loss: 5.876909305935814

Epoch: 41
Training loss: 1.9469197988510132 / Valid loss: 5.8526252746582035
Training loss: 2.529541015625 / Valid loss: 5.875423613048735
Training loss: 3.0569939613342285 / Valid loss: 5.956058468137469
Training loss: 2.7524189949035645 / Valid loss: 5.909369945526123
Training loss: 3.2438273429870605 / Valid loss: 5.880926336560931

Epoch: 42
Training loss: 2.0722780227661133 / Valid loss: 5.901708178293138
Training loss: 2.3190884590148926 / Valid loss: 5.979749979291643
Training loss: 3.0512866973876953 / Valid loss: 5.913143121628535
Training loss: 3.933725118637085 / Valid loss: 5.914544162296114
Training loss: 2.679373264312744 / Valid loss: 6.034716211046491

Epoch: 43
Training loss: 2.132725238800049 / Valid loss: 5.894647936593919
Training loss: 2.6304283142089844 / Valid loss: 5.895728592645554
Training loss: 3.15120267868042 / Valid loss: 5.898156820024763
Training loss: 2.5188608169555664 / Valid loss: 5.955858986718314
Training loss: 1.9469988346099854 / Valid loss: 5.951960095905123

Epoch: 44
Training loss: 2.9619698524475098 / Valid loss: 5.9964663074130105
Training loss: 2.3517236709594727 / Valid loss: 5.959751887548538
Training loss: 2.2326841354370117 / Valid loss: 5.894558347974505
Training loss: 2.0642008781433105 / Valid loss: 5.9302161670866465
Training loss: 2.6868510246276855 / Valid loss: 6.056460630326044

Epoch: 45
Training loss: 1.7118990421295166 / Valid loss: 5.999536346253895
Training loss: 2.4952940940856934 / Valid loss: 6.145041638328916
Training loss: 2.158292055130005 / Valid loss: 5.9929846513839
Training loss: 1.8488945960998535 / Valid loss: 5.997988208134969
Training loss: 2.2286195755004883 / Valid loss: 5.960722346532912

Epoch: 46
Training loss: 1.705801010131836 / Valid loss: 6.071437302089873
Training loss: 2.8224170207977295 / Valid loss: 5.965838157562983
Training loss: 2.279146432876587 / Valid loss: 5.968394933428083
Training loss: 2.180220127105713 / Valid loss: 6.002018642425537
Training loss: 2.5852930545806885 / Valid loss: 5.967847142900739

Epoch: 47
Training loss: 1.8721091747283936 / Valid loss: 5.997230302719843
Training loss: 1.4761216640472412 / Valid loss: 5.995188401994251
Training loss: 1.8139111995697021 / Valid loss: 5.993347563062396
Training loss: 2.252027988433838 / Valid loss: 6.006033184414818
Training loss: 2.769479751586914 / Valid loss: 6.007976868039086

Epoch: 48
Training loss: 2.295732021331787 / Valid loss: 6.049552626836867
Training loss: 1.949098825454712 / Valid loss: 6.032565112341018
Training loss: 2.7028229236602783 / Valid loss: 6.0919655981517975
Training loss: 2.4511168003082275 / Valid loss: 6.0479122843061175
Training loss: 1.8967570066452026 / Valid loss: 6.026958953766596

Epoch: 49
Training loss: 2.1070339679718018 / Valid loss: 6.045940671648298
Training loss: 2.4649553298950195 / Valid loss: 6.068912135987055
Training loss: 1.9886820316314697 / Valid loss: 6.11230849765596
Training loss: 2.445528507232666 / Valid loss: 6.1033266748700825

Epoch: 50
Training loss: 2.3293609619140625 / Valid loss: 6.028888057527088
Training loss: 1.2648046016693115 / Valid loss: 6.084826153800601
Training loss: 2.651871681213379 / Valid loss: 6.097865520204817
Training loss: 2.4687423706054688 / Valid loss: 6.070250726881481
Training loss: 1.910475492477417 / Valid loss: 6.1474257105872745

Epoch: 51
Training loss: 1.7904523611068726 / Valid loss: 6.057553386688232
Training loss: 2.890634536743164 / Valid loss: 6.080564001628331
Training loss: 3.176941156387329 / Valid loss: 6.10686426389785
Training loss: 2.528613328933716 / Valid loss: 6.093232420512608
Training loss: 1.6697208881378174 / Valid loss: 6.173983651115781

Epoch: 52
Training loss: 2.2263717651367188 / Valid loss: 6.19345353217352
Training loss: 2.407588243484497 / Valid loss: 6.161118153163365
Training loss: 2.0378799438476562 / Valid loss: 6.125194531395322
Training loss: 2.8467798233032227 / Valid loss: 6.123248677026658
Training loss: 1.9497475624084473 / Valid loss: 6.12343365351359

Epoch: 53
Training loss: 1.426167607307434 / Valid loss: 6.158945365179153
Training loss: 1.6468242406845093 / Valid loss: 6.198657589867001
Training loss: 2.96567964553833 / Valid loss: 6.104831770488194
Training loss: 1.7685916423797607 / Valid loss: 6.145990296772548
Training loss: 2.110746145248413 / Valid loss: 6.130782349904378

Epoch: 54
Training loss: 1.9714040756225586 / Valid loss: 6.1514448688143775
Training loss: 1.5245338678359985 / Valid loss: 6.155212545394898
Training loss: 1.6665573120117188 / Valid loss: 6.253780676069714
Training loss: 1.9849803447723389 / Valid loss: 6.109481264296032
Training loss: 2.0939066410064697 / Valid loss: 6.197604347410656

Epoch: 55
Training loss: 1.3280527591705322 / Valid loss: 6.184463721229917
Training loss: 2.690990447998047 / Valid loss: 6.133091538293021
Training loss: 2.250965118408203 / Valid loss: 6.180768580663772
Training loss: 2.9802865982055664 / Valid loss: 6.191544485092163
Training loss: 1.4640169143676758 / Valid loss: 6.284303297315325

Epoch: 56
Training loss: 2.1960792541503906 / Valid loss: 6.1724251383826845
Training loss: 1.8585803508758545 / Valid loss: 6.156626646859305
Training loss: 2.3616459369659424 / Valid loss: 6.3267822924114405
Training loss: 1.9819633960723877 / Valid loss: 6.364996249335153
Training loss: 2.4081292152404785 / Valid loss: 6.26632087344215

Epoch: 57
Training loss: 1.9391999244689941 / Valid loss: 6.169029344831194
Training loss: 2.125873565673828 / Valid loss: 6.29689979780288
Training loss: 1.7616255283355713 / Valid loss: 6.202328452609835
Training loss: 1.5844879150390625 / Valid loss: 6.1834687301090785
Training loss: 1.5076632499694824 / Valid loss: 6.212873563312349

Epoch: 58
Training loss: 1.8153407573699951 / Valid loss: 6.293990877696446
Training loss: 1.6740185022354126 / Valid loss: 6.206484544844854
Training loss: 2.0718319416046143 / Valid loss: 6.265700095040458
Training loss: 1.2021061182022095 / Valid loss: 6.248658089410691
Training loss: 2.2877378463745117 / Valid loss: 6.252185421898251

Epoch: 59
Training loss: 1.6977455615997314 / Valid loss: 6.471678393227713
Training loss: 1.6374537944793701 / Valid loss: 6.23883258047558
Training loss: 1.4094946384429932 / Valid loss: 6.275679481597174
Training loss: 1.6159684658050537 / Valid loss: 6.276745355696905

Epoch: 60
Training loss: 1.6069040298461914 / Valid loss: 6.288007465998332
Training loss: 2.054408550262451 / Valid loss: 6.342651812235514
Training loss: 1.0909967422485352 / Valid loss: 6.237117447171893
Training loss: 2.11324143409729 / Valid loss: 6.318368439447312
Training loss: 1.8714290857315063 / Valid loss: 6.309061568123954

Epoch: 61
Training loss: 1.174119472503662 / Valid loss: 6.395409179869152
Training loss: 1.5897910594940186 / Valid loss: 6.296063032604399
Training loss: 1.6168804168701172 / Valid loss: 6.295801482881818
Training loss: 1.3471325635910034 / Valid loss: 6.343309125446138
Training loss: 1.5947213172912598 / Valid loss: 6.2664490336463565

Epoch: 62
Training loss: 1.2494096755981445 / Valid loss: 6.348068110148112
Training loss: 1.3039381504058838 / Valid loss: 6.364501446769351
Training loss: 1.0851099491119385 / Valid loss: 6.355188119979132
Training loss: 1.4127764701843262 / Valid loss: 6.284374718439011
Training loss: 1.8659090995788574 / Valid loss: 6.348526400611514

Epoch: 63
Training loss: 1.3565363883972168 / Valid loss: 6.351380754652477
Training loss: 1.648658037185669 / Valid loss: 6.3647254444303965
Training loss: 1.01205575466156 / Valid loss: 6.403140222458612
Training loss: 1.5311238765716553 / Valid loss: 6.344343939281646
Training loss: 1.0733214616775513 / Valid loss: 6.418359583900088

Epoch: 64
Training loss: 1.4206031560897827 / Valid loss: 6.431192109698341
Training loss: 1.5806829929351807 / Valid loss: 6.413519936516171
Training loss: 1.077934741973877 / Valid loss: 6.364568760281517
Training loss: 1.2587573528289795 / Valid loss: 6.338532813390096
Training loss: 1.99080228805542 / Valid loss: 6.361670049031575

Epoch: 65
Training loss: 0.7127333879470825 / Valid loss: 6.367135967527117
Training loss: 1.1133182048797607 / Valid loss: 6.350483435676211
Training loss: 1.4614595174789429 / Valid loss: 6.383033865974063
Training loss: 2.434420347213745 / Valid loss: 6.5062712487720304
Training loss: 1.5479331016540527 / Valid loss: 6.538359971273513

Epoch: 66
Training loss: 1.270475149154663 / Valid loss: 6.4206394059317455
Training loss: 1.8629796504974365 / Valid loss: 6.425221229734875
Training loss: 1.8520439863204956 / Valid loss: 6.4203349976312545
Training loss: 1.2532446384429932 / Valid loss: 6.4180160340808685
Training loss: 1.6583436727523804 / Valid loss: 6.442775308518183

Epoch: 67
Training loss: 1.0664584636688232 / Valid loss: 6.423765813736688
Training loss: 1.7415804862976074 / Valid loss: 6.402092811039516
Training loss: 0.9426717758178711 / Valid loss: 6.451318418411981
Training loss: 1.6046535968780518 / Valid loss: 6.512343969799224
Training loss: 1.876006007194519 / Valid loss: 6.505706914265951

Epoch: 68
Training loss: 1.0727853775024414 / Valid loss: 6.505982989356632
Training loss: 0.7253354787826538 / Valid loss: 6.6937894503275555
Training loss: 1.1230199337005615 / Valid loss: 6.418943482353574
Training loss: 1.4408208131790161 / Valid loss: 6.459548682258243
Training loss: 0.9275450706481934 / Valid loss: 6.4581035704839795

Epoch: 69
Training loss: 0.8553705215454102 / Valid loss: 6.450343113853818
Training loss: 1.2532306909561157 / Valid loss: 6.520223885490781
Training loss: 1.1878976821899414 / Valid loss: 6.516973093577794
Training loss: 1.5847358703613281 / Valid loss: 6.426918983459473

Epoch: 70
Training loss: 0.9343187212944031 / Valid loss: 6.498790136973063
Training loss: 0.713192343711853 / Valid loss: 6.473270829518636
Training loss: 1.5198826789855957 / Valid loss: 6.577478390648252
Training loss: 1.3289835453033447 / Valid loss: 6.520017910003662
Training loss: 1.5205273628234863 / Valid loss: 6.5080196607680545

Epoch: 71
Training loss: 1.1650116443634033 / Valid loss: 6.528325812021891
Training loss: 1.334945559501648 / Valid loss: 6.484461434682211
Training loss: 1.3562898635864258 / Valid loss: 6.552744424910772
Training loss: 1.056694507598877 / Valid loss: 6.492941116151355
Training loss: 0.8387157320976257 / Valid loss: 6.51541789372762

Epoch: 72
Training loss: 1.3761452436447144 / Valid loss: 6.658535180773054
Training loss: 1.0027430057525635 / Valid loss: 6.536628041948591
Training loss: 1.0183833837509155 / Valid loss: 6.57491534096854
Training loss: 1.1056220531463623 / Valid loss: 6.515826486405873
Training loss: 0.7540701031684875 / Valid loss: 6.489178080785842

Epoch: 73
Training loss: 1.2460238933563232 / Valid loss: 6.547190311976841
Training loss: 0.9401051998138428 / Valid loss: 6.64346566654387
Training loss: 0.6505328416824341 / Valid loss: 6.543535019102551
Training loss: 1.4325780868530273 / Valid loss: 6.562421003977458
Training loss: 1.3014891147613525 / Valid loss: 6.539472620827811

Epoch: 74
Training loss: 1.0129928588867188 / Valid loss: 6.544943972996303
Training loss: 0.9023991823196411 / Valid loss: 6.61783359618414
Training loss: 1.3570835590362549 / Valid loss: 6.65315515200297
Training loss: 1.0525803565979004 / Valid loss: 6.580113326935541
Training loss: 1.5008107423782349 / Valid loss: 6.625120680672782

Epoch: 75
Training loss: 1.322350263595581 / Valid loss: 6.703646169389997
Training loss: 0.9741331338882446 / Valid loss: 6.594364743005662
Training loss: 1.0851449966430664 / Valid loss: 6.567738187880743
Training loss: 1.2176997661590576 / Valid loss: 6.646568498157319
Training loss: 0.9222758412361145 / Valid loss: 6.584978691736857

Epoch: 76
Training loss: 1.1299793720245361 / Valid loss: 6.588421530950637
Training loss: 0.6612893342971802 / Valid loss: 6.613085394813901
Training loss: 1.171321988105774 / Valid loss: 6.628870546250116
Training loss: 0.9326149225234985 / Valid loss: 6.6127638930366155
Training loss: 0.6430187225341797 / Valid loss: 6.612243897574288

Epoch: 77
Training loss: 0.8467782139778137 / Valid loss: 6.604255635397775
Training loss: 0.806671142578125 / Valid loss: 6.67033329918271
Training loss: 1.5668094158172607 / Valid loss: 6.632419309161958
Training loss: 1.1565892696380615 / Valid loss: 6.573816390264602
Training loss: 0.7920234799385071 / Valid loss: 6.642642429896763

Epoch: 78
Training loss: 0.9623284935951233 / Valid loss: 6.583527703512282
Training loss: 0.6204110383987427 / Valid loss: 6.66372591200329
Training loss: 0.7203040719032288 / Valid loss: 6.674826562972296
Training loss: 1.0259305238723755 / Valid loss: 6.586210650489444
Training loss: 0.7827670574188232 / Valid loss: 6.583236789703369

Epoch: 79
Training loss: 0.8805828094482422 / Valid loss: 6.604247579120455
Training loss: 0.9549906849861145 / Valid loss: 6.635753454480852
Training loss: 0.9099867939949036 / Valid loss: 6.6222597712562195
Training loss: 1.3278257846832275 / Valid loss: 6.710554686046782
ModuleList(
  (0): Linear(in_features=5376, out_features=248, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=248, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.349240205401466
Training regression with following parameters:
dnn_hidden_units : 
dropout_probs : 0.0, 0.0
learning_rate : 0.0001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : SGD
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : Bert
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=5376, out_features=1, bias=True)
)

Epoch: 0
Training loss: 19.044994354248047 / Valid loss: 11.349013292221796
Model is saved in epoch 0, overall batch: 0
Training loss: 6.31700325012207 / Valid loss: 5.905089914231073
Model is saved in epoch 0, overall batch: 100
Training loss: 6.593419075012207 / Valid loss: 5.793816791261945
Model is saved in epoch 0, overall batch: 200
Training loss: 6.715387344360352 / Valid loss: 5.764516687393188
Model is saved in epoch 0, overall batch: 300
Training loss: 3.6688740253448486 / Valid loss: 5.729876740773519
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 6.5627760887146 / Valid loss: 5.704308709644136
Model is saved in epoch 1, overall batch: 500
Training loss: 4.95412540435791 / Valid loss: 5.68383511588687
Model is saved in epoch 1, overall batch: 600
Training loss: 7.187725067138672 / Valid loss: 5.662028414862497
Model is saved in epoch 1, overall batch: 700
Training loss: 4.050303936004639 / Valid loss: 5.710240899948847
Training loss: 4.780117988586426 / Valid loss: 5.64637401898702
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 6.331770896911621 / Valid loss: 5.626282887231736
Model is saved in epoch 2, overall batch: 1000
Training loss: 5.333743572235107 / Valid loss: 5.622991518747239
Model is saved in epoch 2, overall batch: 1100
Training loss: 6.338711738586426 / Valid loss: 5.603515872501192
Model is saved in epoch 2, overall batch: 1200
Training loss: 3.971149444580078 / Valid loss: 5.621077514830089
Training loss: 4.3727850914001465 / Valid loss: 5.595108715693156
Model is saved in epoch 2, overall batch: 1400

Epoch: 3
Training loss: 5.965295791625977 / Valid loss: 5.59591551281157
Training loss: 3.79403018951416 / Valid loss: 5.608600754964919
Training loss: 7.483267307281494 / Valid loss: 5.5810742173876084
Model is saved in epoch 3, overall batch: 1700
Training loss: 4.969719409942627 / Valid loss: 5.572096129826137
Model is saved in epoch 3, overall batch: 1800
Training loss: 6.026633262634277 / Valid loss: 5.579239931560698

Epoch: 4
Training loss: 6.12208366394043 / Valid loss: 5.567405548549834
Model is saved in epoch 4, overall batch: 2000
Training loss: 4.679856300354004 / Valid loss: 5.571770406904674
Training loss: 4.540025234222412 / Valid loss: 5.625917841139294
Training loss: 4.039777755737305 / Valid loss: 5.559551327569144
Model is saved in epoch 4, overall batch: 2300
Training loss: 5.791963577270508 / Valid loss: 5.552749061584473
Model is saved in epoch 4, overall batch: 2400

Epoch: 5
Training loss: 7.602558135986328 / Valid loss: 5.561055862335932
Training loss: 4.626372337341309 / Valid loss: 5.547312102999006
Model is saved in epoch 5, overall batch: 2600
Training loss: 5.16206693649292 / Valid loss: 5.553382106054396
Training loss: 4.927486896514893 / Valid loss: 5.544127788997832
Model is saved in epoch 5, overall batch: 2800
Training loss: 6.704800605773926 / Valid loss: 5.543352762858073
Model is saved in epoch 5, overall batch: 2900

Epoch: 6
Training loss: 5.106719970703125 / Valid loss: 5.531643209003267
Model is saved in epoch 6, overall batch: 3000
Training loss: 6.313854694366455 / Valid loss: 5.543575286865234
Training loss: 5.482738494873047 / Valid loss: 5.536455724352882
Training loss: 4.352067947387695 / Valid loss: 5.541580599830264
Training loss: 6.432716369628906 / Valid loss: 5.541386985778809

Epoch: 7
Training loss: 4.820429801940918 / Valid loss: 5.529477678026471
Model is saved in epoch 7, overall batch: 3500
Training loss: 4.448275566101074 / Valid loss: 5.537089259283883
Training loss: 5.638060569763184 / Valid loss: 5.5239050002325145
Model is saved in epoch 7, overall batch: 3700
Training loss: 6.014341354370117 / Valid loss: 5.526779236112322
Training loss: 5.269235610961914 / Valid loss: 5.5226217451549715
Model is saved in epoch 7, overall batch: 3900

Epoch: 8
Training loss: 4.808967590332031 / Valid loss: 5.525526039940971
Training loss: 4.049810886383057 / Valid loss: 5.528590202331543
Training loss: 4.1143388748168945 / Valid loss: 5.510333054406303
Model is saved in epoch 8, overall batch: 4200
Training loss: 5.021595001220703 / Valid loss: 5.513820098695301
Training loss: 2.7308027744293213 / Valid loss: 5.52213910647801

Epoch: 9
Training loss: 3.946047306060791 / Valid loss: 5.530519451413836
Training loss: 5.276594161987305 / Valid loss: 5.502488211223057
Model is saved in epoch 9, overall batch: 4600
Training loss: 5.750149726867676 / Valid loss: 5.534052090417771
Training loss: 6.312538146972656 / Valid loss: 5.509636336281186

Epoch: 10
Training loss: 4.237011909484863 / Valid loss: 5.519681794302804
Training loss: 4.898504257202148 / Valid loss: 5.555679891222999
Training loss: 5.249238967895508 / Valid loss: 5.509013382593791
Training loss: 5.578888416290283 / Valid loss: 5.504198844092233
Training loss: 4.453372001647949 / Valid loss: 5.5083538373311365

Epoch: 11
Training loss: 5.554969310760498 / Valid loss: 5.498457177480062
Model is saved in epoch 11, overall batch: 5400
Training loss: 5.553383827209473 / Valid loss: 5.510567140579224
Training loss: 5.373669147491455 / Valid loss: 5.503158010755267
Training loss: 7.921215057373047 / Valid loss: 5.505223256065732
Training loss: 4.971521854400635 / Valid loss: 5.5033982004438124

Epoch: 12
Training loss: 5.788403034210205 / Valid loss: 5.504535032453991
Training loss: 5.972039699554443 / Valid loss: 5.508869541259039
Training loss: 3.0506229400634766 / Valid loss: 5.511122347059704
Training loss: 4.655502796173096 / Valid loss: 5.49941128776187
Training loss: 4.3259992599487305 / Valid loss: 5.51968119712103

Epoch: 13
Training loss: 5.089466094970703 / Valid loss: 5.499350543249221
Training loss: 4.569154262542725 / Valid loss: 5.49602207229251
Model is saved in epoch 13, overall batch: 6500
Training loss: 6.18456506729126 / Valid loss: 5.504382449104672
Training loss: 5.97960090637207 / Valid loss: 5.499639688219343
Training loss: 5.067204475402832 / Valid loss: 5.495998766308739
Model is saved in epoch 13, overall batch: 6800

Epoch: 14
Training loss: 5.982233047485352 / Valid loss: 5.501403588340396
Training loss: 5.610561847686768 / Valid loss: 5.504923336846488
Training loss: 6.13571834564209 / Valid loss: 5.501434346607753
Training loss: 3.9645848274230957 / Valid loss: 5.499323206856137
Training loss: 6.767385482788086 / Valid loss: 5.492342338107881
Model is saved in epoch 14, overall batch: 7300

Epoch: 15
Training loss: 6.0597662925720215 / Valid loss: 5.4893773101624985
Model is saved in epoch 15, overall batch: 7400
Training loss: 5.276383399963379 / Valid loss: 5.495992676417033
Training loss: 4.7205047607421875 / Valid loss: 5.496350585846674
Training loss: 6.450070381164551 / Valid loss: 5.496711767287481
Training loss: 5.178670406341553 / Valid loss: 5.5094423021589005

Epoch: 16
Training loss: 4.506061553955078 / Valid loss: 5.520187525522141
Training loss: 4.055694580078125 / Valid loss: 5.557353119623094
Training loss: 5.324777126312256 / Valid loss: 5.492258709952945
Training loss: 5.822493076324463 / Valid loss: 5.4979752245403475
Training loss: 4.790768146514893 / Valid loss: 5.493253835042318

Epoch: 17
Training loss: 6.292952537536621 / Valid loss: 5.48845979145595
Model is saved in epoch 17, overall batch: 8400
Training loss: 4.928757667541504 / Valid loss: 5.489072197959537
Training loss: 4.912337303161621 / Valid loss: 5.497484643118722
Training loss: 4.328956127166748 / Valid loss: 5.488738291604179
Training loss: 7.2870564460754395 / Valid loss: 5.4914187204270135

Epoch: 18
Training loss: 5.80822229385376 / Valid loss: 5.547522692453294
Training loss: 5.147208213806152 / Valid loss: 5.521215600059146
Training loss: 5.566795825958252 / Valid loss: 5.49931644258045
Training loss: 4.34276008605957 / Valid loss: 5.499067660740444
Training loss: 4.98811149597168 / Valid loss: 5.488948817480178

Epoch: 19
Training loss: 4.171673774719238 / Valid loss: 5.489723993483044
Training loss: 4.714555740356445 / Valid loss: 5.490117747443063
Training loss: 4.793225288391113 / Valid loss: 5.508531870160784
Training loss: 4.156498908996582 / Valid loss: 5.480194850195022
Model is saved in epoch 19, overall batch: 9700

Epoch: 20
Training loss: 4.910816669464111 / Valid loss: 5.494253921508789
Training loss: 5.096790313720703 / Valid loss: 5.495265288580032
Training loss: 3.3895273208618164 / Valid loss: 5.4833473886762345
Training loss: 3.437947988510132 / Valid loss: 5.484725759142921
Training loss: 5.0664896965026855 / Valid loss: 5.481539297103882

Epoch: 21
Training loss: 4.811033725738525 / Valid loss: 5.50449990999131
Training loss: 6.319272518157959 / Valid loss: 5.481419595082601
Training loss: 6.112035751342773 / Valid loss: 5.477619913646153
Model is saved in epoch 21, overall batch: 10500
Training loss: 7.5436320304870605 / Valid loss: 5.501037225269136
Training loss: 6.399226665496826 / Valid loss: 5.494377949124291

Epoch: 22
Training loss: 5.843699932098389 / Valid loss: 5.480241262345087
Training loss: 4.525263786315918 / Valid loss: 5.494183102108184
Training loss: 6.729159832000732 / Valid loss: 5.49206379935855
Training loss: 5.906726360321045 / Valid loss: 5.490429283323742
Training loss: 4.255196571350098 / Valid loss: 5.488908379418509

Epoch: 23
Training loss: 5.01151180267334 / Valid loss: 5.484398092542376
Training loss: 6.18739128112793 / Valid loss: 5.486584454491025
Training loss: 5.0955586433410645 / Valid loss: 5.491677520388649
Training loss: 5.543523788452148 / Valid loss: 5.486950822103591
Training loss: 7.15694522857666 / Valid loss: 5.5044311387198315

Epoch: 24
Training loss: 7.150004863739014 / Valid loss: 5.498113316581363
Training loss: 5.420799255371094 / Valid loss: 5.485689921606155
Training loss: 5.240779399871826 / Valid loss: 5.486647008714222
Training loss: 7.460471153259277 / Valid loss: 5.480557938984462
Training loss: 3.609050750732422 / Valid loss: 5.516377208346412

Epoch: 25
Training loss: 4.251532554626465 / Valid loss: 5.482911028180804
Training loss: 3.0913028717041016 / Valid loss: 5.521411421185448
Training loss: 3.9029440879821777 / Valid loss: 5.488104002816336
Training loss: 7.109899520874023 / Valid loss: 5.482312788282122
Training loss: 3.4698028564453125 / Valid loss: 5.495575203214373

Epoch: 26
Training loss: 5.193143367767334 / Valid loss: 5.497448814482916
Training loss: 6.061352729797363 / Valid loss: 5.491607195990426
Training loss: 6.145755767822266 / Valid loss: 5.505419168018159
Training loss: 5.721583366394043 / Valid loss: 5.479939331327166
Training loss: 5.359509468078613 / Valid loss: 5.485637646629697

Epoch: 27
Training loss: 7.404482841491699 / Valid loss: 5.499993194852556
Training loss: 4.219019889831543 / Valid loss: 5.48054221698216
Training loss: 5.110233783721924 / Valid loss: 5.473795718238467
Model is saved in epoch 27, overall batch: 13500
Training loss: 6.23029899597168 / Valid loss: 5.478098292577834
Training loss: 5.6072306632995605 / Valid loss: 5.4844209307716

Epoch: 28
Training loss: 4.329490661621094 / Valid loss: 5.4802176384698775
Training loss: 4.251819610595703 / Valid loss: 5.506153009051368
Training loss: 5.255067825317383 / Valid loss: 5.484463435127622
Training loss: 4.710307598114014 / Valid loss: 5.48685021627517
Training loss: 5.102937698364258 / Valid loss: 5.470061143239339
Model is saved in epoch 28, overall batch: 14200

Epoch: 29
Training loss: 6.412256717681885 / Valid loss: 5.487200966335478
Training loss: 5.032387733459473 / Valid loss: 5.489397069386073
Training loss: 6.419496536254883 / Valid loss: 5.494018295833043
Training loss: 6.481260299682617 / Valid loss: 5.482462274460565

Epoch: 30
Training loss: 5.8938188552856445 / Valid loss: 5.4826468694777715
Training loss: 5.669979572296143 / Valid loss: 5.480869023005168
Training loss: 5.075404167175293 / Valid loss: 5.519598654338291
Training loss: 4.429727077484131 / Valid loss: 5.486859564554123
Training loss: 5.020639419555664 / Valid loss: 5.478564189729236

Epoch: 31
Training loss: 5.210454940795898 / Valid loss: 5.479577561787196
Training loss: 5.510164260864258 / Valid loss: 5.490337878181821
Training loss: 4.326659202575684 / Valid loss: 5.481498543421427
Training loss: 5.283143043518066 / Valid loss: 5.481548207146781
Training loss: 6.486907005310059 / Valid loss: 5.483907547451201

Epoch: 32
Training loss: 6.168606281280518 / Valid loss: 5.480494142714001
Training loss: 6.515811443328857 / Valid loss: 5.474907870519729
Training loss: 4.865724086761475 / Valid loss: 5.489056825637817
Training loss: 4.477866172790527 / Valid loss: 5.54154832249596
Training loss: 7.398874282836914 / Valid loss: 5.483900642395019

Epoch: 33
Training loss: 4.180497169494629 / Valid loss: 5.473323635827928
Training loss: 6.794442176818848 / Valid loss: 5.483029694784255
Training loss: 5.458721160888672 / Valid loss: 5.484720956711542
Training loss: 5.885800361633301 / Valid loss: 5.487234814961751
Training loss: 6.703483581542969 / Valid loss: 5.483438548587618

Epoch: 34
Training loss: 5.3401079177856445 / Valid loss: 5.483200684047881
Training loss: 6.267440319061279 / Valid loss: 5.500939675739834
Training loss: 6.1842169761657715 / Valid loss: 5.5115320682525635
Training loss: 6.426022529602051 / Valid loss: 5.480967596599034
Training loss: 4.01905632019043 / Valid loss: 5.50996458871024

Epoch: 35
Training loss: 5.459199905395508 / Valid loss: 5.478091635022845
Training loss: 4.765631675720215 / Valid loss: 5.485227995827085
Training loss: 5.977102756500244 / Valid loss: 5.481779940923055
Training loss: 5.2541375160217285 / Valid loss: 5.4808813594636465
Training loss: 4.252647876739502 / Valid loss: 5.484035151345389

Epoch: 36
Training loss: 3.701453447341919 / Valid loss: 5.521883510407948
Training loss: 6.359225749969482 / Valid loss: 5.503930282592774
Training loss: 3.539958953857422 / Valid loss: 5.487509196145194
Training loss: 6.484989643096924 / Valid loss: 5.489508104324341
Training loss: 3.859426975250244 / Valid loss: 5.522289868763515

Epoch: 37
Training loss: 5.326664924621582 / Valid loss: 5.491401218232655
Training loss: 4.161127090454102 / Valid loss: 5.488222505932763
Training loss: 4.989400386810303 / Valid loss: 5.4926572527204245
Training loss: 5.756670951843262 / Valid loss: 5.4904121467045375
Training loss: 5.478690147399902 / Valid loss: 5.490102120808193

Epoch: 38
Training loss: 5.3428263664245605 / Valid loss: 5.486334852945237
Training loss: 5.796513557434082 / Valid loss: 5.482932006745111
Training loss: 5.841974258422852 / Valid loss: 5.4856246539524625
Training loss: 4.924668312072754 / Valid loss: 5.484494783764794
Training loss: 4.375683307647705 / Valid loss: 5.481277322769165

Epoch: 39
Training loss: 4.437516212463379 / Valid loss: 5.48297914550418
Training loss: 5.576230049133301 / Valid loss: 5.526049495878674
Training loss: 5.6154913902282715 / Valid loss: 5.486648916062855
Training loss: 5.331355094909668 / Valid loss: 5.484620675586519

Epoch: 40
Training loss: 4.291292190551758 / Valid loss: 5.484211901256017
Training loss: 5.508969306945801 / Valid loss: 5.485006620770409
Training loss: 4.287598609924316 / Valid loss: 5.482570993332636
Training loss: 4.705008029937744 / Valid loss: 5.4820731844220845
Training loss: 3.866577386856079 / Valid loss: 5.485244489851452

Epoch: 41
Training loss: 3.927483081817627 / Valid loss: 5.490168249039423
Training loss: 5.03657341003418 / Valid loss: 5.501597202391851
Training loss: 4.673728942871094 / Valid loss: 5.484202117011661
Training loss: 7.294823169708252 / Valid loss: 5.4915853682018465
Training loss: 4.112844467163086 / Valid loss: 5.48022053809393

Epoch: 42
Training loss: 3.542119026184082 / Valid loss: 5.487851249603998
Training loss: 4.993607521057129 / Valid loss: 5.483625298454648
Training loss: 6.558479309082031 / Valid loss: 5.489004641487485
Training loss: 4.653348445892334 / Valid loss: 5.485611114047822
Training loss: 3.992912530899048 / Valid loss: 5.48136579649789

Epoch: 43
Training loss: 5.7147674560546875 / Valid loss: 5.481634909766061
Training loss: 4.467233180999756 / Valid loss: 5.492726473581223
Training loss: 5.973321914672852 / Valid loss: 5.487874251320249
Training loss: 5.215114593505859 / Valid loss: 5.4793833641778855
Training loss: 6.5067949295043945 / Valid loss: 5.493336541312082

Epoch: 44
Training loss: 4.555436611175537 / Valid loss: 5.521225463776362
Training loss: 5.1516876220703125 / Valid loss: 5.4921643347967235
Training loss: 5.441065788269043 / Valid loss: 5.483138340995425
Training loss: 6.145148754119873 / Valid loss: 5.487177839733305
Training loss: 5.376839637756348 / Valid loss: 5.483312393370129

Epoch: 45
Training loss: 4.114394187927246 / Valid loss: 5.488006678081694
Training loss: 4.758517265319824 / Valid loss: 5.488907791319347
Training loss: 3.5997674465179443 / Valid loss: 5.506431822549729
Training loss: 5.767519474029541 / Valid loss: 5.486771181651524
Training loss: 4.749434471130371 / Valid loss: 5.478385786783128

Epoch: 46
Training loss: 6.2144060134887695 / Valid loss: 5.4817088581266855
Training loss: 5.248468399047852 / Valid loss: 5.487146384375436
Training loss: 5.251461982727051 / Valid loss: 5.503443356922695
Training loss: 5.487528324127197 / Valid loss: 5.513316329320272
Training loss: 5.293524742126465 / Valid loss: 5.491425096421015

Epoch: 47
Training loss: 2.57958984375 / Valid loss: 5.504293092091879
Training loss: 4.020725250244141 / Valid loss: 5.484311569304693
Training loss: 5.03403902053833 / Valid loss: 5.487887714022682
Training loss: 6.4314141273498535 / Valid loss: 5.485952447709583
Training loss: 6.057669639587402 / Valid loss: 5.487876576469058

Epoch: 48
Training loss: 4.923917770385742 / Valid loss: 5.492785960152036
Training loss: 4.869316101074219 / Valid loss: 5.493972753343128
Training loss: 4.174724102020264 / Valid loss: 5.500276883443196
Training loss: 5.612764358520508 / Valid loss: 5.491029101326352
Training loss: 4.530590057373047 / Valid loss: 5.493433239346459

Epoch: 49
Training loss: 6.938451290130615 / Valid loss: 5.499174408685594
Training loss: 5.305008888244629 / Valid loss: 5.502496987297421
Training loss: 4.964241027832031 / Valid loss: 5.509942345392137
Training loss: 4.237448692321777 / Valid loss: 5.48561110496521

Epoch: 50
Training loss: 5.055152893066406 / Valid loss: 5.504772944677444
Training loss: 3.5503621101379395 / Valid loss: 5.4851167792365665
Training loss: 4.70439338684082 / Valid loss: 5.491938450222924
Training loss: 5.16469669342041 / Valid loss: 5.51252449353536
Training loss: 7.209902763366699 / Valid loss: 5.492407144818987

Epoch: 51
Training loss: 5.611020088195801 / Valid loss: 5.485042889912923
Training loss: 3.278719902038574 / Valid loss: 5.489606923148745
Training loss: 7.133388996124268 / Valid loss: 5.489370239348639
Training loss: 4.096291542053223 / Valid loss: 5.510899150939215
Training loss: 4.749843597412109 / Valid loss: 5.492433863594418

Epoch: 52
Training loss: 4.7707061767578125 / Valid loss: 5.492437344505674
Training loss: 4.954953193664551 / Valid loss: 5.498139288311913
Training loss: 4.789053916931152 / Valid loss: 5.502194243385678
Training loss: 4.697771072387695 / Valid loss: 5.524144311178298
Training loss: 5.126626968383789 / Valid loss: 5.48767838251023

Epoch: 53
Training loss: 5.300107955932617 / Valid loss: 5.501266291027977
Training loss: 4.690459728240967 / Valid loss: 5.489398120698475
Training loss: 10.071718215942383 / Valid loss: 5.493046465374174
Training loss: 5.431280612945557 / Valid loss: 5.518573883601597
Training loss: 6.007978439331055 / Valid loss: 5.486026196252732

Epoch: 54
Training loss: 4.178259372711182 / Valid loss: 5.485644953591483
Training loss: 4.490351676940918 / Valid loss: 5.507008523032779
Training loss: 3.8695340156555176 / Valid loss: 5.486044742947533
Training loss: 4.354189872741699 / Valid loss: 5.492940993536086
Training loss: 4.791143894195557 / Valid loss: 5.483691665104457

Epoch: 55
Training loss: 4.19950008392334 / Valid loss: 5.476057906377883
Training loss: 5.70188570022583 / Valid loss: 5.495297727130708
Training loss: 4.145455360412598 / Valid loss: 5.491226237160819
Training loss: 4.533842086791992 / Valid loss: 5.493335853304182
Training loss: 4.177155017852783 / Valid loss: 5.4909046899704705

Epoch: 56
Training loss: 4.233523368835449 / Valid loss: 5.555638195219494
Training loss: 4.8981099128723145 / Valid loss: 5.487893129530407
Training loss: 3.1859045028686523 / Valid loss: 5.4799804051717125
Training loss: 6.880655288696289 / Valid loss: 5.503456383659726
Training loss: 4.888021469116211 / Valid loss: 5.496696778706142

Epoch: 57
Training loss: 4.080611228942871 / Valid loss: 5.480466615586054
Training loss: 4.3051066398620605 / Valid loss: 5.497031874883742
Training loss: 5.498205184936523 / Valid loss: 5.4859330881209605
Training loss: 4.902958393096924 / Valid loss: 5.495097659883045
Training loss: 4.96950101852417 / Valid loss: 5.493680990309942

Epoch: 58
Training loss: 3.934640645980835 / Valid loss: 5.506075134731474
Training loss: 4.870059967041016 / Valid loss: 5.4925027756463916
Training loss: 3.8038201332092285 / Valid loss: 5.481961577279227
Training loss: 5.132357120513916 / Valid loss: 5.491416574659802
Training loss: 5.352077007293701 / Valid loss: 5.4934910183861145

Epoch: 59
Training loss: 3.5671017169952393 / Valid loss: 5.509372014091128
Training loss: 5.014749526977539 / Valid loss: 5.48399338722229
Training loss: 3.7299327850341797 / Valid loss: 5.503401281720116
Training loss: 2.296844244003296 / Valid loss: 5.491784415926252

Epoch: 60
Training loss: 6.0049147605896 / Valid loss: 5.494286139806111
Training loss: 3.463469982147217 / Valid loss: 5.493781162443615
Training loss: 5.479459762573242 / Valid loss: 5.488237387793404
Training loss: 5.100824356079102 / Valid loss: 5.489382303328741
Training loss: 4.891610145568848 / Valid loss: 5.503554264704387

Epoch: 61
Training loss: 5.153450012207031 / Valid loss: 5.489049230303083
Training loss: 4.192035675048828 / Valid loss: 5.500002931413197
Training loss: 5.584356784820557 / Valid loss: 5.517630581628708
Training loss: 5.243096351623535 / Valid loss: 5.496766712552025
Training loss: 6.011978626251221 / Valid loss: 5.504405314581735

Epoch: 62
Training loss: 4.540021896362305 / Valid loss: 5.492506245204381
Training loss: 3.685155153274536 / Valid loss: 5.499181922276815
Training loss: 4.591526031494141 / Valid loss: 5.501999005817232
Training loss: 5.562973976135254 / Valid loss: 5.495911309832619
Training loss: 7.0171356201171875 / Valid loss: 5.502826636178153

Epoch: 63
Training loss: 3.962799310684204 / Valid loss: 5.497252645946684
Training loss: 6.3598761558532715 / Valid loss: 5.4910523936862035
Training loss: 5.655418872833252 / Valid loss: 5.492987503324236
Training loss: 4.9372663497924805 / Valid loss: 5.511379680179414
Training loss: 3.7673776149749756 / Valid loss: 5.5001208759489515

Epoch: 64
Training loss: 4.404762268066406 / Valid loss: 5.504159595852807
Training loss: 5.575701713562012 / Valid loss: 5.494903811954317
Training loss: 5.289846420288086 / Valid loss: 5.501347387404669
Training loss: 4.066579818725586 / Valid loss: 5.4930361520676385
Training loss: 4.825231552124023 / Valid loss: 5.517135431652977

Epoch: 65
Training loss: 4.372245788574219 / Valid loss: 5.493020634424119
Training loss: 6.26948356628418 / Valid loss: 5.503045929045904
Training loss: 6.3475751876831055 / Valid loss: 5.492436250050862
Training loss: 5.290859222412109 / Valid loss: 5.492538590658278
Training loss: 5.157164096832275 / Valid loss: 5.502052543276832

Epoch: 66
Training loss: 4.537174224853516 / Valid loss: 5.494521779105777
Training loss: 4.8597412109375 / Valid loss: 5.496901480356852
Training loss: 4.12329626083374 / Valid loss: 5.520405503681728
Training loss: 7.115658283233643 / Valid loss: 5.4963171096075145
Training loss: 3.893643856048584 / Valid loss: 5.496299909410022

Epoch: 67
Training loss: 5.148527145385742 / Valid loss: 5.4928506556011385
Training loss: 6.653050422668457 / Valid loss: 5.512462531952631
Training loss: 4.913630962371826 / Valid loss: 5.49235048748198
Training loss: 6.054339408874512 / Valid loss: 5.491339613142467
Training loss: 3.865154266357422 / Valid loss: 5.497745661508469

Epoch: 68
Training loss: 4.930725574493408 / Valid loss: 5.486695062546503
Training loss: 5.268905162811279 / Valid loss: 5.506075243722825
Training loss: 5.606220245361328 / Valid loss: 5.49359294573466
Training loss: 5.20593786239624 / Valid loss: 5.509997969581967
Training loss: 3.8644332885742188 / Valid loss: 5.5071698120662145

Epoch: 69
Training loss: 5.868470668792725 / Valid loss: 5.511402865818568
Training loss: 3.8644700050354004 / Valid loss: 5.513067088808332
Training loss: 4.683621406555176 / Valid loss: 5.498477661041987
Training loss: 5.590975761413574 / Valid loss: 5.521578570774623

Epoch: 70
Training loss: 6.058694362640381 / Valid loss: 5.50148218018668
Training loss: 6.637770652770996 / Valid loss: 5.501634391148885
Training loss: 4.637531280517578 / Valid loss: 5.501751282101586
Training loss: 5.303208351135254 / Valid loss: 5.487114847274054
Training loss: 5.02049446105957 / Valid loss: 5.501790037609282

Epoch: 71
Training loss: 5.165658950805664 / Valid loss: 5.50088895389012
Training loss: 3.667307138442993 / Valid loss: 5.49715074130467
Training loss: 5.23235559463501 / Valid loss: 5.5028482414427256
Training loss: 6.5043792724609375 / Valid loss: 5.4999128954751155
Training loss: 6.632953643798828 / Valid loss: 5.493787222816831

Epoch: 72
Training loss: 4.249690532684326 / Valid loss: 5.499579572677613
Training loss: 6.983551979064941 / Valid loss: 5.495261523837135
Training loss: 3.8294615745544434 / Valid loss: 5.4988920166378925
Training loss: 5.97921085357666 / Valid loss: 5.498893299556914
Training loss: 5.085731029510498 / Valid loss: 5.496620191846575

Epoch: 73
Training loss: 3.8365330696105957 / Valid loss: 5.493516113644555
Training loss: 5.323890686035156 / Valid loss: 5.500250244140625
Training loss: 5.303904056549072 / Valid loss: 5.50294341586885
Training loss: 6.474725723266602 / Valid loss: 5.49702418645223
Training loss: 5.345213890075684 / Valid loss: 5.500521473657518

Epoch: 74
Training loss: 5.086041450500488 / Valid loss: 5.512795280274891
Training loss: 4.869851589202881 / Valid loss: 5.509646994726999
Training loss: 3.8256516456604004 / Valid loss: 5.511223813465663
Training loss: 5.549252033233643 / Valid loss: 5.502823205221267
Training loss: 5.280548095703125 / Valid loss: 5.498149860472906

Epoch: 75
Training loss: 3.9768478870391846 / Valid loss: 5.528174727303641
Training loss: 4.21478271484375 / Valid loss: 5.50903213818868
Training loss: 4.832659721374512 / Valid loss: 5.505316856929234
Training loss: 5.051406383514404 / Valid loss: 5.5115088372003465
Training loss: 4.409479141235352 / Valid loss: 5.497158858889625

Epoch: 76
Training loss: 3.4727492332458496 / Valid loss: 5.504409617469424
Training loss: 4.489434242248535 / Valid loss: 5.525492100488572
Training loss: 5.599401473999023 / Valid loss: 5.510905186335246
Training loss: 5.0554656982421875 / Valid loss: 5.49793959118071
Training loss: 3.234166145324707 / Valid loss: 5.498760632106236

Epoch: 77
Training loss: 4.7440266609191895 / Valid loss: 5.506211934770857
Training loss: 4.915484428405762 / Valid loss: 5.5124733402615504
Training loss: 7.001111030578613 / Valid loss: 5.523574976694016
Training loss: 4.161988258361816 / Valid loss: 5.542308705193656
Training loss: 3.921114921569824 / Valid loss: 5.506996538525536

Epoch: 78
Training loss: 3.852217197418213 / Valid loss: 5.508312277566819
Training loss: 5.78328275680542 / Valid loss: 5.502261284419468
Training loss: 3.577209949493408 / Valid loss: 5.5174824873606365
Training loss: 6.057408332824707 / Valid loss: 5.494388273784092
Training loss: 7.593588829040527 / Valid loss: 5.506710779099238

Epoch: 79
Training loss: 4.183189392089844 / Valid loss: 5.503169136955624
Training loss: 4.446834564208984 / Valid loss: 5.508420179003761
Training loss: 3.9541189670562744 / Valid loss: 5.529098651522681
Training loss: 6.656389236450195 / Valid loss: 5.501194720041184
ModuleList(
  (0): Linear(in_features=5376, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.309247037342616
Training regression with following parameters:
dnn_hidden_units : 2000, 100, 16
dropout_probs : 0.0, 0.0
learning_rate : 0.001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : SGD
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : TFIDF
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=31191, out_features=2000, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=2000, out_features=100, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=100, out_features=16, bias=True)
  (9): Dropout(p=0, inplace=False)
  (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (11): LeakyReLU(negative_slope=0.02)
  (12): Linear(in_features=16, out_features=1, bias=True)
)

Epoch: 0
Training loss: 17.8549747467041 / Valid loss: 16.9357366107759
Model is saved in epoch 0, overall batch: 0
Training loss: 11.266608238220215 / Valid loss: 9.523037792387463
Model is saved in epoch 0, overall batch: 100
Training loss: 6.149203300476074 / Valid loss: 6.396393517085484
Model is saved in epoch 0, overall batch: 200
Training loss: 5.120197772979736 / Valid loss: 5.9006664798373265
Model is saved in epoch 0, overall batch: 300
Training loss: 5.95668363571167 / Valid loss: 5.706494136083694
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 2.7963478565216064 / Valid loss: 5.552826677049909
Model is saved in epoch 1, overall batch: 500
Training loss: 2.8173084259033203 / Valid loss: 5.7068634055909655
Training loss: 3.520646572113037 / Valid loss: 5.89227967943464
Training loss: 2.2036571502685547 / Valid loss: 5.850766981215704
Training loss: 3.2528553009033203 / Valid loss: 6.043879145667667

Epoch: 2
Training loss: 1.6515642404556274 / Valid loss: 5.969488116673061
Training loss: 0.9178176522254944 / Valid loss: 6.0846241655803865
Training loss: 1.227339506149292 / Valid loss: 6.080244865871611
Training loss: 1.506656289100647 / Valid loss: 6.158902985709054
Training loss: 1.0559616088867188 / Valid loss: 6.115778707322621

Epoch: 3
Training loss: 0.7872043251991272 / Valid loss: 6.035268175034296
Training loss: 0.786126434803009 / Valid loss: 6.112765189579555
Training loss: 0.5500298738479614 / Valid loss: 6.120031111580985
Training loss: 0.5695881843566895 / Valid loss: 6.085886553355626
Training loss: 0.9227229952812195 / Valid loss: 6.108186326708112

Epoch: 4
Training loss: 0.46121251583099365 / Valid loss: 6.154210474377587
Training loss: 0.5750457048416138 / Valid loss: 6.195507249378022
Training loss: 0.39887627959251404 / Valid loss: 6.210601779392787
Training loss: 0.5247560739517212 / Valid loss: 6.190851958592733
Training loss: 1.0380500555038452 / Valid loss: 6.188308611370268

Epoch: 5
Training loss: 0.2904283106327057 / Valid loss: 6.180140613374256
Training loss: 0.4295879304409027 / Valid loss: 6.175466292245048
Training loss: 0.8931962251663208 / Valid loss: 6.181893219266619
Training loss: 0.7811853885650635 / Valid loss: 6.229309304555257
Training loss: 0.43158119916915894 / Valid loss: 6.218490741366431

Epoch: 6
Training loss: 0.4444792866706848 / Valid loss: 6.202837065287999
Training loss: 0.3046914339065552 / Valid loss: 6.188191709064302
Training loss: 0.33894574642181396 / Valid loss: 6.212352950232369
Training loss: 0.5585474371910095 / Valid loss: 6.212226061593919
Training loss: 0.3251414895057678 / Valid loss: 6.203022693452381

Epoch: 7
Training loss: 0.3377915620803833 / Valid loss: 6.176128671282814
Training loss: 0.5679395198822021 / Valid loss: 6.23431366057623
Training loss: 0.37839555740356445 / Valid loss: 6.177515127545312
Training loss: 0.19989770650863647 / Valid loss: 6.234965508324759
Training loss: 0.45943403244018555 / Valid loss: 6.206577185222081

Epoch: 8
Training loss: 0.5378811955451965 / Valid loss: 6.172047985167731
Training loss: 0.29323872923851013 / Valid loss: 6.20896205447969
Training loss: 0.4565853774547577 / Valid loss: 6.14265863327753
Training loss: 0.42448174953460693 / Valid loss: 6.185994675045921
Training loss: 0.18387985229492188 / Valid loss: 6.206834107353574

Epoch: 9
Training loss: 0.12144435942173004 / Valid loss: 6.1595263594672796
Training loss: 0.8092493414878845 / Valid loss: 6.213527856554304
Training loss: 0.447419136762619 / Valid loss: 6.21893720626831
Training loss: 0.22194750607013702 / Valid loss: 6.204195385887509

Epoch: 10
Training loss: 0.2604650557041168 / Valid loss: 6.232494635809036
Training loss: 0.26918262243270874 / Valid loss: 6.212143616449265
Training loss: 0.20589199662208557 / Valid loss: 6.17953238714309
Training loss: 0.27420011162757874 / Valid loss: 6.195103649866013
Training loss: 0.2180672585964203 / Valid loss: 6.208147950399489

Epoch: 11
Training loss: 0.21569587290287018 / Valid loss: 6.216910198756627
Training loss: 0.30855172872543335 / Valid loss: 6.173682476225354
Training loss: 0.15654835104942322 / Valid loss: 6.190852462677729
Training loss: 0.5984473824501038 / Valid loss: 6.242023835863386
Training loss: 0.2900468707084656 / Valid loss: 6.190125022615705

Epoch: 12
Training loss: 0.15029942989349365 / Valid loss: 6.2172260783967515
Training loss: 0.14557161927223206 / Valid loss: 6.21975371497018
Training loss: 0.1429368257522583 / Valid loss: 6.211455045427595
Training loss: 0.321735680103302 / Valid loss: 6.205333237420945
Training loss: 0.3569595217704773 / Valid loss: 6.2033148266020275

Epoch: 13
Training loss: 0.3477235734462738 / Valid loss: 6.216657495498657
Training loss: 0.15796750783920288 / Valid loss: 6.21848882720584
Training loss: 0.15093085169792175 / Valid loss: 6.209054565429687
Training loss: 0.3092525899410248 / Valid loss: 6.2249824228740875
Training loss: 0.7142677307128906 / Valid loss: 6.214859040578206

Epoch: 14
Training loss: 0.2284826934337616 / Valid loss: 6.209638021105811
Training loss: 0.34421098232269287 / Valid loss: 6.203762769699097
Training loss: 0.12664544582366943 / Valid loss: 6.182803076789493
Training loss: 0.12341361492872238 / Valid loss: 6.20778706414359
Training loss: 0.2802501916885376 / Valid loss: 6.190065629141671

Epoch: 15
Training loss: 0.17474551498889923 / Valid loss: 6.1927930423191615
Training loss: 0.15642721951007843 / Valid loss: 6.177108446756999
Training loss: 0.2086191475391388 / Valid loss: 6.182577205839611
Training loss: 0.16999304294586182 / Valid loss: 6.190401376996721
Training loss: 0.20696862041950226 / Valid loss: 6.155451120649065

Epoch: 16
Training loss: 0.12964963912963867 / Valid loss: 6.178640370141892
Training loss: 0.6673232316970825 / Valid loss: 6.190405688967023
Training loss: 0.17895367741584778 / Valid loss: 6.269633218220302
Training loss: 0.27044346928596497 / Valid loss: 6.22947276433309
Training loss: 0.4006708562374115 / Valid loss: 6.17575120698838

Epoch: 17
Training loss: 0.35005447268486023 / Valid loss: 6.202607415971302
Training loss: 0.09980528056621552 / Valid loss: 6.205633747010004
Training loss: 0.2831971049308777 / Valid loss: 6.199316310882568
Training loss: 0.1760769486427307 / Valid loss: 6.222300602140881
Training loss: 0.13179361820220947 / Valid loss: 6.211033548627581

Epoch: 18
Training loss: 0.22980549931526184 / Valid loss: 6.189044085003081
Training loss: 0.25061148405075073 / Valid loss: 6.216439467384702
Training loss: 0.22299523651599884 / Valid loss: 6.237522881371635
Training loss: 0.15645331144332886 / Valid loss: 6.207676630928403
Training loss: 0.10219702124595642 / Valid loss: 6.180511295227777

Epoch: 19
Training loss: 0.1987057775259018 / Valid loss: 6.2016715276808965
Training loss: 0.12267002463340759 / Valid loss: 6.23605207261585
Training loss: 0.5227261781692505 / Valid loss: 6.211519082387288
Training loss: 0.1607000231742859 / Valid loss: 6.178372623806908

Epoch: 20
Training loss: 0.08375345915555954 / Valid loss: 6.184640471140543
Training loss: 0.5064467191696167 / Valid loss: 6.189357712155297
Training loss: 0.27951598167419434 / Valid loss: 6.184775525047666
Training loss: 0.3504669964313507 / Valid loss: 6.1750514007750015
Training loss: 0.09191440045833588 / Valid loss: 6.176305237270537

Epoch: 21
Training loss: 0.49572503566741943 / Valid loss: 6.2058111145382835
Training loss: 0.3724380135536194 / Valid loss: 6.186918824059623
Training loss: 0.15515568852424622 / Valid loss: 6.17070323399135
Training loss: 0.0890810638666153 / Valid loss: 6.172920599437895
Training loss: 0.1286560297012329 / Valid loss: 6.18083549681164

Epoch: 22
Training loss: 0.12809978425502777 / Valid loss: 6.236441825685047
Training loss: 0.4780343174934387 / Valid loss: 6.1713118053617935
Training loss: 0.609171450138092 / Valid loss: 6.198770432245164
Training loss: 0.11067506670951843 / Valid loss: 6.215669529778617
Training loss: 0.34211698174476624 / Valid loss: 6.211965726670765

Epoch: 23
Training loss: 0.4548148512840271 / Valid loss: 6.1693613256726945
Training loss: 0.278087854385376 / Valid loss: 6.1970593429747085
Training loss: 0.2770261764526367 / Valid loss: 6.175291093190511
Training loss: 0.14068885147571564 / Valid loss: 6.168465979894003
Training loss: 0.227820485830307 / Valid loss: 6.176496968950544

Epoch: 24
Training loss: 0.11105221509933472 / Valid loss: 6.184954407101586
Training loss: 0.18908604979515076 / Valid loss: 6.169698233831497
Training loss: 0.1811853051185608 / Valid loss: 6.175984586988177
Training loss: 0.12412957847118378 / Valid loss: 6.197892259416126
Training loss: 0.45211538672447205 / Valid loss: 6.206819804509481

Epoch: 25
Training loss: 0.09245023876428604 / Valid loss: 6.203082466125489
Training loss: 0.11188855767250061 / Valid loss: 6.164387133007958
Training loss: 0.1712624430656433 / Valid loss: 6.203320621308826
Training loss: 0.09410358220338821 / Valid loss: 6.188354464939662
Training loss: 0.27762487530708313 / Valid loss: 6.176909567060925

Epoch: 26
Training loss: 0.11729630827903748 / Valid loss: 6.169882029578799
Training loss: 0.6148108243942261 / Valid loss: 6.191447030930292
Training loss: 0.10055960714817047 / Valid loss: 6.191082155136835
Training loss: 0.11149563640356064 / Valid loss: 6.194039596830096
Training loss: 0.21255166828632355 / Valid loss: 6.207614589872814

Epoch: 27
Training loss: 0.0739080160856247 / Valid loss: 6.176359349205381
Training loss: 0.13900092244148254 / Valid loss: 6.243327685764858
Training loss: 0.3815408945083618 / Valid loss: 6.198147642044794
Training loss: 0.08257903158664703 / Valid loss: 6.201475788298107
Training loss: 0.07550384849309921 / Valid loss: 6.189716448102678

Epoch: 28
Training loss: 0.21582290530204773 / Valid loss: 6.190124693371001
Training loss: 0.15363940596580505 / Valid loss: 6.199678738911946
Training loss: 0.23376424610614777 / Valid loss: 6.176391188303629
Training loss: 0.15724411606788635 / Valid loss: 6.176252705710275
Training loss: 0.08521375060081482 / Valid loss: 6.211078362237839

Epoch: 29
Training loss: 0.16138559579849243 / Valid loss: 6.19079681805202
Training loss: 0.10967972874641418 / Valid loss: 6.1766690844581245
Training loss: 0.2428106665611267 / Valid loss: 6.2096471695672895
Training loss: 0.23722518980503082 / Valid loss: 6.162337911696661

Epoch: 30
Training loss: 0.11921732127666473 / Valid loss: 6.1821780772436234
Training loss: 0.5915604829788208 / Valid loss: 6.186112367539179
Training loss: 0.241560697555542 / Valid loss: 6.191456803821382
Training loss: 0.3199322521686554 / Valid loss: 6.194605355035691
Training loss: 0.47826844453811646 / Valid loss: 6.1689517793201265

Epoch: 31
Training loss: 0.1314447969198227 / Valid loss: 6.209898435501826
Training loss: 0.13315436244010925 / Valid loss: 6.205817411059425
Training loss: 0.19155637919902802 / Valid loss: 6.151007899783907
Training loss: 0.1083885133266449 / Valid loss: 6.225577647345407
Training loss: 0.16295288503170013 / Valid loss: 6.200004216602871

Epoch: 32
Training loss: 0.15370473265647888 / Valid loss: 6.194208944411505
Training loss: 0.2264830470085144 / Valid loss: 6.211492683773949
Training loss: 0.1635819673538208 / Valid loss: 6.190025113877796
Training loss: 0.23285356163978577 / Valid loss: 6.181747375215803
Training loss: 0.09561176598072052 / Valid loss: 6.161502563385737

Epoch: 33
Training loss: 0.09425005316734314 / Valid loss: 6.216283241907756
Training loss: 0.13881030678749084 / Valid loss: 6.173772607530866
Training loss: 0.0999162346124649 / Valid loss: 6.163437216622489
Training loss: 0.09019620716571808 / Valid loss: 6.158094110943022
Training loss: 0.06042468175292015 / Valid loss: 6.186356869198027

Epoch: 34
Training loss: 0.11325554549694061 / Valid loss: 6.190722020467122
Training loss: 0.09125010669231415 / Valid loss: 6.171721299489339
Training loss: 0.08920504152774811 / Valid loss: 6.144030675433931
Training loss: 0.20980022847652435 / Valid loss: 6.159716242835636
Training loss: 0.5171259641647339 / Valid loss: 6.168434706188384

Epoch: 35
Training loss: 0.16195902228355408 / Valid loss: 6.168486567905971
Training loss: 0.09841390699148178 / Valid loss: 6.169085305077689
Training loss: 0.1088998094201088 / Valid loss: 6.180281605039324
Training loss: 0.24946299195289612 / Valid loss: 6.190810051418486
Training loss: 0.1630064845085144 / Valid loss: 6.162713093984695

Epoch: 36
Training loss: 0.2346387803554535 / Valid loss: 6.17828277179173
Training loss: 0.2278759628534317 / Valid loss: 6.223278395334879
Training loss: 0.5999125242233276 / Valid loss: 6.152900400615874
Training loss: 0.39420652389526367 / Valid loss: 6.176826799483527
Training loss: 0.11340292543172836 / Valid loss: 6.175700378417969

Epoch: 37
Training loss: 0.1008567214012146 / Valid loss: 6.151941971551804
Training loss: 0.1414588987827301 / Valid loss: 6.169651948838007
Training loss: 0.17863836884498596 / Valid loss: 6.150829310644241
Training loss: 0.8564020395278931 / Valid loss: 6.186394938968477
Training loss: 0.40568655729293823 / Valid loss: 6.146649621781849

Epoch: 38
Training loss: 0.1784229725599289 / Valid loss: 6.191709425335839
Training loss: 0.08228680491447449 / Valid loss: 6.176133139928182
Training loss: 0.1956903636455536 / Valid loss: 6.194205654235113
Training loss: 0.21173900365829468 / Valid loss: 6.16919595173427
Training loss: 0.3868247866630554 / Valid loss: 6.181982851028442

Epoch: 39
Training loss: 0.09939633309841156 / Valid loss: 6.2068204652695425
Training loss: 0.2221776843070984 / Valid loss: 6.181054594403221
Training loss: 0.12811005115509033 / Valid loss: 6.147280079977853
Training loss: 0.1389683187007904 / Valid loss: 6.144784809294201

Epoch: 40
Training loss: 0.19370298087596893 / Valid loss: 6.204545563743228
Training loss: 0.8274391889572144 / Valid loss: 6.176329040527344
Training loss: 0.5483970046043396 / Valid loss: 6.171092196873256
Training loss: 0.3756582736968994 / Valid loss: 6.1430678503853935
Training loss: 0.08522956073284149 / Valid loss: 6.177910307475499

Epoch: 41
Training loss: 0.09834808111190796 / Valid loss: 6.198039486294701
Training loss: 0.11834603548049927 / Valid loss: 6.212540199643089
Training loss: 0.08524183183908463 / Valid loss: 6.1835908049628845
Training loss: 0.2411312460899353 / Valid loss: 6.186058793749128
Training loss: 0.6395149230957031 / Valid loss: 6.180516143072219

Epoch: 42
Training loss: 0.0768827497959137 / Valid loss: 6.182777073269799
Training loss: 0.09768546372652054 / Valid loss: 6.192979326702299
Training loss: 0.11869123578071594 / Valid loss: 6.172986689068022
Training loss: 0.09542684257030487 / Valid loss: 6.1781441007341655
Training loss: 0.15836794674396515 / Valid loss: 6.16559621720087

Epoch: 43
Training loss: 0.1071924939751625 / Valid loss: 6.188316186269124
Training loss: 0.1263778954744339 / Valid loss: 6.160299946012951
Training loss: 0.08182114362716675 / Valid loss: 6.146900233768282
Training loss: 0.21474263072013855 / Valid loss: 6.192871418453398
Training loss: 0.04088841378688812 / Valid loss: 6.183358424050468

Epoch: 44
Training loss: 0.07796014845371246 / Valid loss: 6.134948376246861
Training loss: 0.20319801568984985 / Valid loss: 6.180004408245995
Training loss: 0.6197687387466431 / Valid loss: 6.178826840718587
Training loss: 0.2231695055961609 / Valid loss: 6.179564271654401
Training loss: 0.09816772490739822 / Valid loss: 6.168379143306187

Epoch: 45
Training loss: 0.0785982608795166 / Valid loss: 6.178031875973656
Training loss: 0.09538252651691437 / Valid loss: 6.184682975496565
Training loss: 0.30323702096939087 / Valid loss: 6.145265604200818
Training loss: 0.07670770585536957 / Valid loss: 6.182576138632638
Training loss: 0.08315409719944 / Valid loss: 6.166583372297741

Epoch: 46
Training loss: 0.11489531397819519 / Valid loss: 6.2178496156420024
Training loss: 0.11406193673610687 / Valid loss: 6.159114762714931
Training loss: 0.05536244437098503 / Valid loss: 6.153726273491269
Training loss: 0.37497812509536743 / Valid loss: 6.145568509328933
Training loss: 0.10139694809913635 / Valid loss: 6.194925571623303

Epoch: 47
Training loss: 0.07936705648899078 / Valid loss: 6.166382728304182
Training loss: 0.24206754565238953 / Valid loss: 6.214962884357997
Training loss: 0.16465339064598083 / Valid loss: 6.153207956041609
Training loss: 0.0795157253742218 / Valid loss: 6.160984986168998
Training loss: 0.08892705291509628 / Valid loss: 6.149700500851586

Epoch: 48
Training loss: 0.43483224511146545 / Valid loss: 6.210391585032145
Training loss: 0.2927057147026062 / Valid loss: 6.120485237666538
Training loss: 0.2273581475019455 / Valid loss: 6.177100177038284
Training loss: 0.18022114038467407 / Valid loss: 6.1574474107651485
Training loss: 0.1050691306591034 / Valid loss: 6.169973371142433

Epoch: 49
Training loss: 0.26618528366088867 / Valid loss: 6.180958890914917
Training loss: 0.10183680057525635 / Valid loss: 6.1807466370718815
Training loss: 0.19074177742004395 / Valid loss: 6.156076585678827
Training loss: 0.1409677267074585 / Valid loss: 6.184901151202974

Epoch: 50
Training loss: 0.19074836373329163 / Valid loss: 6.1874999432336715
Training loss: 0.06046239286661148 / Valid loss: 6.158864223389399
Training loss: 0.06471109390258789 / Valid loss: 6.206931656882876
Training loss: 0.5723990797996521 / Valid loss: 6.230768267313639
Training loss: 0.09019982814788818 / Valid loss: 6.164249669937861

Epoch: 51
Training loss: 0.06786614656448364 / Valid loss: 6.168061279115223
Training loss: 0.5196770429611206 / Valid loss: 6.176435454686483
Training loss: 0.16015075147151947 / Valid loss: 6.172627548944383
Training loss: 0.12696009874343872 / Valid loss: 6.200828261602492
Training loss: 0.06386521458625793 / Valid loss: 6.145308269773211

Epoch: 52
Training loss: 0.30225977301597595 / Valid loss: 6.190727492741176
Training loss: 0.24601876735687256 / Valid loss: 6.138086986541748
Training loss: 0.2819008231163025 / Valid loss: 6.178719400224232
Training loss: 0.10752751678228378 / Valid loss: 6.188483506157285
Training loss: 0.11339087784290314 / Valid loss: 6.174103328159878

Epoch: 53
Training loss: 0.12247198820114136 / Valid loss: 6.181372996738979
Training loss: 0.16328391432762146 / Valid loss: 6.171512837637039
Training loss: 0.1164703518152237 / Valid loss: 6.175657145182291
Training loss: 0.08454574644565582 / Valid loss: 6.205276355289278
Training loss: 0.8611998558044434 / Valid loss: 6.139370900108701

Epoch: 54
Training loss: 0.09854032099246979 / Valid loss: 6.17113683337257
Training loss: 0.18942290544509888 / Valid loss: 6.1784634680975055
Training loss: 0.07023456692695618 / Valid loss: 6.177158146812802
Training loss: 0.09632012248039246 / Valid loss: 6.185058505194528
Training loss: 0.08558563888072968 / Valid loss: 6.157651912598383

Epoch: 55
Training loss: 0.1316594034433365 / Valid loss: 6.209522914886475
Training loss: 0.10529615730047226 / Valid loss: 6.1989327158246725
Training loss: 0.22678959369659424 / Valid loss: 6.156084598813738
Training loss: 0.08021501451730728 / Valid loss: 6.195277665910266
Training loss: 0.12758991122245789 / Valid loss: 6.1730138778686525

Epoch: 56
Training loss: 0.15526533126831055 / Valid loss: 6.1466602597917825
Training loss: 0.10740607231855392 / Valid loss: 6.16451450075422
Training loss: 0.13133415579795837 / Valid loss: 6.162437393551781
Training loss: 0.20522218942642212 / Valid loss: 6.187478247142973
Training loss: 0.09372807294130325 / Valid loss: 6.21717841511681

Epoch: 57
Training loss: 0.06070191413164139 / Valid loss: 6.174545830772036
Training loss: 0.16129720211029053 / Valid loss: 6.185891396658761
Training loss: 0.16420012712478638 / Valid loss: 6.205999501546224
Training loss: 0.0822625458240509 / Valid loss: 6.194720216024489
Training loss: 0.28517961502075195 / Valid loss: 6.159641413461594

Epoch: 58
Training loss: 0.06983714550733566 / Valid loss: 6.145439261481876
Training loss: 0.11396916955709457 / Valid loss: 6.189812126613798
Training loss: 0.07227137684822083 / Valid loss: 6.20092576344808
Training loss: 0.09321826696395874 / Valid loss: 6.217733948571341
Training loss: 0.07298323512077332 / Valid loss: 6.178885882241385

Epoch: 59
Training loss: 0.4345923364162445 / Valid loss: 6.169033874784197
Training loss: 0.0746082067489624 / Valid loss: 6.167355598722185
Training loss: 0.10577845573425293 / Valid loss: 6.196554722104754
Training loss: 0.10257672518491745 / Valid loss: 6.190485225405012

Epoch: 60
Training loss: 0.2953534722328186 / Valid loss: 6.175487615948632
Training loss: 0.07561919838190079 / Valid loss: 6.1803250449044365
Training loss: 0.10666590929031372 / Valid loss: 6.1558543477739605
Training loss: 0.19459138810634613 / Valid loss: 6.181396893092564
Training loss: 0.07937683165073395 / Valid loss: 6.239302355902535

Epoch: 61
Training loss: 0.14459694921970367 / Valid loss: 6.218326432364328
Training loss: 0.07814182341098785 / Valid loss: 6.178672361373901
Training loss: 0.4358718693256378 / Valid loss: 6.191313437053135
Training loss: 0.29348883032798767 / Valid loss: 6.187552111489432
Training loss: 0.6725155115127563 / Valid loss: 6.206799872716268

Epoch: 62
Training loss: 0.12352897971868515 / Valid loss: 6.195453171502976
Training loss: 0.10403062403202057 / Valid loss: 6.1786905288696286
Training loss: 0.30712461471557617 / Valid loss: 6.1864701271057125
Training loss: 0.06916903704404831 / Valid loss: 6.17955299786159
Training loss: 0.12819665670394897 / Valid loss: 6.160432749702817

Epoch: 63
Training loss: 0.11653374135494232 / Valid loss: 6.190190154030209
Training loss: 0.05101462081074715 / Valid loss: 6.1681985128493535
Training loss: 0.31668126583099365 / Valid loss: 6.178205494653611
Training loss: 0.06786550581455231 / Valid loss: 6.15995496795291
Training loss: 0.09418134391307831 / Valid loss: 6.1656622841244655

Epoch: 64
Training loss: 0.22789743542671204 / Valid loss: 6.1437376045045395
Training loss: 0.42070746421813965 / Valid loss: 6.170565053394863
Training loss: 0.05846358835697174 / Valid loss: 6.17948906535194
Training loss: 0.048943325877189636 / Valid loss: 6.161984241576421
Training loss: 0.2996649146080017 / Valid loss: 6.191190824054536

Epoch: 65
Training loss: 0.05552023649215698 / Valid loss: 6.195950321924119
Training loss: 0.10858292877674103 / Valid loss: 6.195529905954997
Training loss: 0.0724198967218399 / Valid loss: 6.182821046738398
Training loss: 0.06780452281236649 / Valid loss: 6.149703895478021
Training loss: 0.21297985315322876 / Valid loss: 6.190874399457659

Epoch: 66
Training loss: 0.12244977056980133 / Valid loss: 6.1720206215268085
Training loss: 0.059285640716552734 / Valid loss: 6.1797359148661295
Training loss: 0.11743579804897308 / Valid loss: 6.166147450038365
Training loss: 0.08069407194852829 / Valid loss: 6.1547383830660864
Training loss: 0.09921936690807343 / Valid loss: 6.162736000333513

Epoch: 67
Training loss: 0.07847577333450317 / Valid loss: 6.190285741715204
Training loss: 0.20896637439727783 / Valid loss: 6.1949139595031735
Training loss: 0.12344952672719955 / Valid loss: 6.177336315881639
Training loss: 0.0900699645280838 / Valid loss: 6.179562237149193
Training loss: 0.07295309007167816 / Valid loss: 6.178744350160871

Epoch: 68
Training loss: 0.24156606197357178 / Valid loss: 6.155446892692929
Training loss: 0.09723398089408875 / Valid loss: 6.151576126189459
Training loss: 0.13492460548877716 / Valid loss: 6.198907152811686
Training loss: 0.08148868381977081 / Valid loss: 6.220004999069941
Training loss: 0.07783807069063187 / Valid loss: 6.164582708903722

Epoch: 69
Training loss: 0.0906781405210495 / Valid loss: 6.1608014538174585
Training loss: 0.2791174054145813 / Valid loss: 6.210749989464169
Training loss: 0.30486902594566345 / Valid loss: 6.192237406685239
Training loss: 0.5273647308349609 / Valid loss: 6.218187130065191

Epoch: 70
Training loss: 0.07932882010936737 / Valid loss: 6.157383559999012
Training loss: 0.09802436083555222 / Valid loss: 6.182669818969
Training loss: 0.09522475302219391 / Valid loss: 6.198772300992693
Training loss: 0.06357645988464355 / Valid loss: 6.184109456198556
Training loss: 0.36075258255004883 / Valid loss: 6.192594205765497

Epoch: 71
Training loss: 0.08595538884401321 / Valid loss: 6.2033104374295185
Training loss: 0.27871885895729065 / Valid loss: 6.173718084607805
Training loss: 0.06855073571205139 / Valid loss: 6.19070923214867
Training loss: 0.35084620118141174 / Valid loss: 6.176099207287743
Training loss: 0.29621320962905884 / Valid loss: 6.208150100708008

Epoch: 72
Training loss: 0.0503745898604393 / Valid loss: 6.191855764389038
Training loss: 0.061901386827230453 / Valid loss: 6.180943098522368
Training loss: 0.09954050183296204 / Valid loss: 6.15681220463344
Training loss: 0.07709133625030518 / Valid loss: 6.171851791654315
Training loss: 0.09809250384569168 / Valid loss: 6.166731602805001

Epoch: 73
Training loss: 0.10539835691452026 / Valid loss: 6.209381337392898
Training loss: 0.4802783727645874 / Valid loss: 6.167666165033976
Training loss: 0.15402956306934357 / Valid loss: 6.193487966628302
Training loss: 0.06984686851501465 / Valid loss: 6.174112669626871
Training loss: 0.26332953572273254 / Valid loss: 6.166645324797857

Epoch: 74
Training loss: 0.19507437944412231 / Valid loss: 6.154537244070144
Training loss: 0.14665180444717407 / Valid loss: 6.1511627878461566
Training loss: 0.07107207179069519 / Valid loss: 6.1613334496816
Training loss: 0.107294961810112 / Valid loss: 6.1802759306771415
Training loss: 0.3650650978088379 / Valid loss: 6.1585587229047505

Epoch: 75
Training loss: 0.11547857522964478 / Valid loss: 6.167091987246558
Training loss: 0.10847203433513641 / Valid loss: 6.181693735576811
Training loss: 0.11062455177307129 / Valid loss: 6.179975986480713
Training loss: 0.0717184767127037 / Valid loss: 6.1798931575956795
Training loss: 0.08867873251438141 / Valid loss: 6.21213093485151

Epoch: 76
Training loss: 0.06602038443088531 / Valid loss: 6.185578348523094
Training loss: 0.07237859070301056 / Valid loss: 6.196010539645241
Training loss: 0.07844316959381104 / Valid loss: 6.182058407011486
Training loss: 0.0925244688987732 / Valid loss: 6.207658404395694
Training loss: 0.185614675283432 / Valid loss: 6.186970070430211

Epoch: 77
Training loss: 0.10320965200662613 / Valid loss: 6.183106681278773
Training loss: 0.17648065090179443 / Valid loss: 6.2006196135566345
Training loss: 0.07469732314348221 / Valid loss: 6.183883492151896
Training loss: 0.150723397731781 / Valid loss: 6.177132958457584
Training loss: 0.30424195528030396 / Valid loss: 6.168865004039946

Epoch: 78
Training loss: 0.13818517327308655 / Valid loss: 6.18044889313834
Training loss: 0.08903000503778458 / Valid loss: 6.182163063685099
Training loss: 0.05675065517425537 / Valid loss: 6.166832969302223
Training loss: 0.05063990131020546 / Valid loss: 6.142769118717738
Training loss: 0.05586995929479599 / Valid loss: 6.178727229436238

Epoch: 79
Training loss: 0.1450805962085724 / Valid loss: 6.174631039301555
Training loss: 0.10985849797725677 / Valid loss: 6.199052728925433
Training loss: 0.1917056143283844 / Valid loss: 6.181737068721226
Training loss: 0.09076835960149765 / Valid loss: 6.175873867670695
ModuleList(
  (0): Linear(in_features=31191, out_features=2000, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=2000, out_features=100, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=100, out_features=16, bias=True)
  (9): Dropout(p=0, inplace=False)
  (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (11): LeakyReLU(negative_slope=0.02)
  (12): Linear(in_features=16, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.496759857450213
Training regression with following parameters:
dnn_hidden_units : 300, 32
dropout_probs : 0.0, 0.0
learning_rate : 0.001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : SGD
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : TFIDF
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=31191, out_features=300, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=300, out_features=32, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=32, out_features=1, bias=True)
)

Epoch: 0
Training loss: 14.313697814941406 / Valid loss: 15.710995428902763
Model is saved in epoch 0, overall batch: 0
Training loss: 6.693487167358398 / Valid loss: 7.94097721463158
Model is saved in epoch 0, overall batch: 100
Training loss: 4.713494777679443 / Valid loss: 6.06045857157026
Model is saved in epoch 0, overall batch: 200
Training loss: 3.6556923389434814 / Valid loss: 5.729180526733399
Model is saved in epoch 0, overall batch: 300
Training loss: 4.41060209274292 / Valid loss: 5.634358926046462
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 2.174398899078369 / Valid loss: 5.57524341628665
Model is saved in epoch 1, overall batch: 500
Training loss: 3.6296706199645996 / Valid loss: 5.696300411224366
Training loss: 3.6789073944091797 / Valid loss: 5.81929517246428
Training loss: 3.2285637855529785 / Valid loss: 5.896200507027762
Training loss: 2.4243991374969482 / Valid loss: 5.970458968480428

Epoch: 2
Training loss: 1.1159389019012451 / Valid loss: 5.9013681230090915
Training loss: 1.0134650468826294 / Valid loss: 5.978096585046678
Training loss: 1.5080945491790771 / Valid loss: 6.005766936710903
Training loss: 1.6234768629074097 / Valid loss: 6.098042756035214
Training loss: 2.2251100540161133 / Valid loss: 6.088698391687302

Epoch: 3
Training loss: 1.3796395063400269 / Valid loss: 6.070711878367833
Training loss: 0.9390164613723755 / Valid loss: 6.117112425395421
Training loss: 1.5787723064422607 / Valid loss: 6.153964283352806
Training loss: 1.2675819396972656 / Valid loss: 6.233835526875088
Training loss: 1.5633068084716797 / Valid loss: 6.233606788090297

Epoch: 4
Training loss: 0.9100593328475952 / Valid loss: 6.186894855045137
Training loss: 0.659858226776123 / Valid loss: 6.226443742570423
Training loss: 0.8217017650604248 / Valid loss: 6.281921030226208
Training loss: 0.5659178495407104 / Valid loss: 6.257337052481515
Training loss: 0.6509620547294617 / Valid loss: 6.327810289746239

Epoch: 5
Training loss: 0.4321506917476654 / Valid loss: 6.279960014706567
Training loss: 0.7610546350479126 / Valid loss: 6.29423200743539
Training loss: 0.5839325785636902 / Valid loss: 6.318549035844349
Training loss: 0.6163688898086548 / Valid loss: 6.339775212605795
Training loss: 0.6345599889755249 / Valid loss: 6.376816622416178

Epoch: 6
Training loss: 0.34426283836364746 / Valid loss: 6.361897180193947
Training loss: 0.4302700161933899 / Valid loss: 6.371565312430972
Training loss: 0.3585285246372223 / Valid loss: 6.409477860586984
Training loss: 0.38469451665878296 / Valid loss: 6.336991167068481
Training loss: 0.2802124619483948 / Valid loss: 6.3328330584934776

Epoch: 7
Training loss: 0.32584407925605774 / Valid loss: 6.374144858405703
Training loss: 0.17186623811721802 / Valid loss: 6.371310306730725
Training loss: 0.42771655321121216 / Valid loss: 6.353809697287423
Training loss: 0.41399577260017395 / Valid loss: 6.35535185223534
Training loss: 0.20840537548065186 / Valid loss: 6.368763206118629

Epoch: 8
Training loss: 0.3360731303691864 / Valid loss: 6.384148395629156
Training loss: 0.2387213408946991 / Valid loss: 6.434075675691877
Training loss: 0.3432292342185974 / Valid loss: 6.358226623989287
Training loss: 0.24294115602970123 / Valid loss: 6.416694920403617
Training loss: 0.5685476660728455 / Valid loss: 6.389681577682495

Epoch: 9
Training loss: 0.2566887438297272 / Valid loss: 6.398699333554222
Training loss: 0.2359044849872589 / Valid loss: 6.381323421569098
Training loss: 0.46938928961753845 / Valid loss: 6.392754802249727
Training loss: 0.9757698774337769 / Valid loss: 6.407532533009847

Epoch: 10
Training loss: 0.20331430435180664 / Valid loss: 6.441188417162214
Training loss: 0.16380774974822998 / Valid loss: 6.390819381532215
Training loss: 0.29721441864967346 / Valid loss: 6.437963953472319
Training loss: 0.29748669266700745 / Valid loss: 6.427624454952421
Training loss: 0.16724148392677307 / Valid loss: 6.4528216361999515

Epoch: 11
Training loss: 0.3550906777381897 / Valid loss: 6.4270206019991925
Training loss: 0.23889034986495972 / Valid loss: 6.416763725734892
Training loss: 0.15599419176578522 / Valid loss: 6.403796818142846
Training loss: 0.22497838735580444 / Valid loss: 6.419845344906761
Training loss: 0.6803861260414124 / Valid loss: 6.375630396888369

Epoch: 12
Training loss: 0.2076413780450821 / Valid loss: 6.372348254067557
Training loss: 0.2367829978466034 / Valid loss: 6.4409469150361565
Training loss: 0.1000632792711258 / Valid loss: 6.497088931855702
Training loss: 0.4958052933216095 / Valid loss: 6.418691778182984
Training loss: 0.23160548508167267 / Valid loss: 6.427995177677699

Epoch: 13
Training loss: 0.42226070165634155 / Valid loss: 6.396045173917498
Training loss: 0.1732461154460907 / Valid loss: 6.407709643954322
Training loss: 0.23142847418785095 / Valid loss: 6.389214633759998
Training loss: 0.11442537605762482 / Valid loss: 6.40034617242359
Training loss: 0.1899152398109436 / Valid loss: 6.417223871321905

Epoch: 14
Training loss: 0.15138466656208038 / Valid loss: 6.412236583800543
Training loss: 0.5034239292144775 / Valid loss: 6.458081667763846
Training loss: 0.16216754913330078 / Valid loss: 6.4078673657916845
Training loss: 0.3805120885372162 / Valid loss: 6.432611819675991
Training loss: 0.17468854784965515 / Valid loss: 6.437816445032755

Epoch: 15
Training loss: 0.5516554713249207 / Valid loss: 6.377750006176177
Training loss: 0.12635573744773865 / Valid loss: 6.424671218508766
Training loss: 0.7529295682907104 / Valid loss: 6.410544706526257
Training loss: 0.41396597027778625 / Valid loss: 6.404819145656767
Training loss: 1.1647602319717407 / Valid loss: 6.382866614205497

Epoch: 16
Training loss: 0.20450067520141602 / Valid loss: 6.40255293619065
Training loss: 0.36846932768821716 / Valid loss: 6.380177041462489
Training loss: 0.4016403555870056 / Valid loss: 6.409206560679844
Training loss: 0.41343408823013306 / Valid loss: 6.404156319300333
Training loss: 0.19668669998645782 / Valid loss: 6.420651156561715

Epoch: 17
Training loss: 0.08061890304088593 / Valid loss: 6.3783062571570985
Training loss: 0.12587332725524902 / Valid loss: 6.413145474025181
Training loss: 0.16460376977920532 / Valid loss: 6.388549436841692
Training loss: 0.2623389959335327 / Valid loss: 6.439386186145601
Training loss: 0.07493194937705994 / Valid loss: 6.434070927756173

Epoch: 18
Training loss: 0.2147849202156067 / Valid loss: 6.404447085516793
Training loss: 0.1816127896308899 / Valid loss: 6.383923612322126
Training loss: 0.1704881489276886 / Valid loss: 6.3946556409200035
Training loss: 0.12022557854652405 / Valid loss: 6.396899200621105
Training loss: 0.24054473638534546 / Valid loss: 6.371029340653193

Epoch: 19
Training loss: 0.3546257019042969 / Valid loss: 6.3720236619313555
Training loss: 0.21519437432289124 / Valid loss: 6.384689542225429
Training loss: 0.14952969551086426 / Valid loss: 6.429422893978301
Training loss: 0.17285913228988647 / Valid loss: 6.416379047575451

Epoch: 20
Training loss: 0.22926272451877594 / Valid loss: 6.427398686181931
Training loss: 0.1855291724205017 / Valid loss: 6.402102418172927
Training loss: 0.2274470031261444 / Valid loss: 6.41881772904169
Training loss: 0.0792718231678009 / Valid loss: 6.4009586039043604
Training loss: 0.1418582648038864 / Valid loss: 6.385804516928537

Epoch: 21
Training loss: 0.08202238380908966 / Valid loss: 6.416809549785795
Training loss: 0.2611373960971832 / Valid loss: 6.389248936516898
Training loss: 0.13348054885864258 / Valid loss: 6.4197997320266
Training loss: 0.15777519345283508 / Valid loss: 6.414675558181036
Training loss: 0.11795774847269058 / Valid loss: 6.3980605420612155

Epoch: 22
Training loss: 0.29350295662879944 / Valid loss: 6.415463288625081
Training loss: 0.05233814939856529 / Valid loss: 6.392173185802641
Training loss: 0.24553711712360382 / Valid loss: 6.419549133664086
Training loss: 0.4721547067165375 / Valid loss: 6.47679005804516
Training loss: 0.1435103416442871 / Valid loss: 6.41757444427127

Epoch: 23
Training loss: 0.2271484136581421 / Valid loss: 6.404998758860997
Training loss: 0.25057166814804077 / Valid loss: 6.403441601707822
Training loss: 0.9112774729728699 / Valid loss: 6.357498103096372
Training loss: 0.09259437024593353 / Valid loss: 6.4185223965417775
Training loss: 0.16969501972198486 / Valid loss: 6.39496629805792

Epoch: 24
Training loss: 0.16973868012428284 / Valid loss: 6.4011090324038555
Training loss: 0.1309262067079544 / Valid loss: 6.377680026917231
Training loss: 0.449266254901886 / Valid loss: 6.402200510388329
Training loss: 0.13381201028823853 / Valid loss: 6.378987407684326
Training loss: 0.3165583610534668 / Valid loss: 6.389180521737962

Epoch: 25
Training loss: 0.3495137691497803 / Valid loss: 6.375565376735869
Training loss: 0.14425653219223022 / Valid loss: 6.3718473252795995
Training loss: 0.0862378478050232 / Valid loss: 6.397254008338565
Training loss: 0.23660631477832794 / Valid loss: 6.399982506888254
Training loss: 0.3484743535518646 / Valid loss: 6.407733726501465

Epoch: 26
Training loss: 0.08829178661108017 / Valid loss: 6.396904423123314
Training loss: 0.1138201355934143 / Valid loss: 6.382459093275524
Training loss: 0.13225576281547546 / Valid loss: 6.3908842858814054
Training loss: 0.14515888690948486 / Valid loss: 6.398280852181571
Training loss: 0.12957793474197388 / Valid loss: 6.394602080753871

Epoch: 27
Training loss: 0.1861947625875473 / Valid loss: 6.385333992186046
Training loss: 0.2746526896953583 / Valid loss: 6.382232441220965
Training loss: 0.2544490396976471 / Valid loss: 6.384291283289591
Training loss: 0.07639587670564651 / Valid loss: 6.389006301334926
Training loss: 0.09647639840841293 / Valid loss: 6.372446200961158

Epoch: 28
Training loss: 0.13556596636772156 / Valid loss: 6.3843527657645085
Training loss: 0.10524403303861618 / Valid loss: 6.342844145638602
Training loss: 0.42748165130615234 / Valid loss: 6.356502510252453
Training loss: 0.1386190950870514 / Valid loss: 6.37835256485712
Training loss: 0.10855071246623993 / Valid loss: 6.367849844977969

Epoch: 29
Training loss: 0.07779675722122192 / Valid loss: 6.371734996069045
Training loss: 0.07084205746650696 / Valid loss: 6.360093761625744
Training loss: 0.21046435832977295 / Valid loss: 6.367005684262231
Training loss: 0.13471724092960358 / Valid loss: 6.374379421415783

Epoch: 30
Training loss: 0.26199400424957275 / Valid loss: 6.424960617792038
Training loss: 0.0950772687792778 / Valid loss: 6.364937823159354
Training loss: 0.1115197017788887 / Valid loss: 6.395916380201068
Training loss: 0.19507640600204468 / Valid loss: 6.4031848544166206
Training loss: 0.2785162329673767 / Valid loss: 6.382240161441621

Epoch: 31
Training loss: 0.24120444059371948 / Valid loss: 6.3677611237480525
Training loss: 0.09216558188199997 / Valid loss: 6.378975595746722
Training loss: 0.1940295398235321 / Valid loss: 6.4027522200629825
Training loss: 0.1334836781024933 / Valid loss: 6.412582190831502
Training loss: 0.05778255686163902 / Valid loss: 6.411199912570772

Epoch: 32
Training loss: 0.17262986302375793 / Valid loss: 6.394750996998378
Training loss: 0.09537789225578308 / Valid loss: 6.391217872074672
Training loss: 0.16474243998527527 / Valid loss: 6.367023154667446
Training loss: 0.27199381589889526 / Valid loss: 6.368146900903611
Training loss: 0.05765031650662422 / Valid loss: 6.382350017910912

Epoch: 33
Training loss: 0.15895172953605652 / Valid loss: 6.381916384469895
Training loss: 0.09962973743677139 / Valid loss: 6.346818551563081
Training loss: 0.16259679198265076 / Valid loss: 6.389968231746129
Training loss: 0.06625325977802277 / Valid loss: 6.357768787656512
Training loss: 0.08386208117008209 / Valid loss: 6.38534912835984

Epoch: 34
Training loss: 0.4113806486129761 / Valid loss: 6.354113274528867
Training loss: 0.10379534959793091 / Valid loss: 6.363376151947748
Training loss: 0.11693699657917023 / Valid loss: 6.378735694431123
Training loss: 0.14404082298278809 / Valid loss: 6.36807651973906
Training loss: 0.10219311714172363 / Valid loss: 6.386925220489502

Epoch: 35
Training loss: 0.0800231322646141 / Valid loss: 6.351863250278291
Training loss: 0.18779070675373077 / Valid loss: 6.3819535527910505
Training loss: 0.11220481991767883 / Valid loss: 6.362518072128296
Training loss: 0.07533351331949234 / Valid loss: 6.368343380519322
Training loss: 0.5151684880256653 / Valid loss: 6.367831355049496

Epoch: 36
Training loss: 0.05849061906337738 / Valid loss: 6.370656860442389
Training loss: 0.19003014266490936 / Valid loss: 6.359356521424793
Training loss: 0.19059306383132935 / Valid loss: 6.385091677166167
Training loss: 0.11015687137842178 / Valid loss: 6.372510816937401
Training loss: 0.1283651888370514 / Valid loss: 6.370831491833641

Epoch: 37
Training loss: 0.10356411337852478 / Valid loss: 6.384374722980318
Training loss: 0.08925776183605194 / Valid loss: 6.331318269457136
Training loss: 0.5786986351013184 / Valid loss: 6.345981379917689
Training loss: 0.14986248314380646 / Valid loss: 6.373185057867141
Training loss: 0.20423755049705505 / Valid loss: 6.361886215209961

Epoch: 38
Training loss: 0.08133244514465332 / Valid loss: 6.339011228652227
Training loss: 0.06886245310306549 / Valid loss: 6.357574562799363
Training loss: 0.12340563535690308 / Valid loss: 6.372902416047596
Training loss: 0.13941875100135803 / Valid loss: 6.358955560411726
Training loss: 0.0643780454993248 / Valid loss: 6.374346533275786

Epoch: 39
Training loss: 0.13556677103042603 / Valid loss: 6.364626432600476
Training loss: 0.22109530866146088 / Valid loss: 6.357280538195655
Training loss: 0.08114738762378693 / Valid loss: 6.360996323540097
Training loss: 0.10063710063695908 / Valid loss: 6.3637498719351635

Epoch: 40
Training loss: 0.07892663776874542 / Valid loss: 6.360135416757493
Training loss: 0.17029130458831787 / Valid loss: 6.375912234896705
Training loss: 0.08278292417526245 / Valid loss: 6.342572734469459
Training loss: 0.05122155696153641 / Valid loss: 6.357954890387399
Training loss: 0.08748126775026321 / Valid loss: 6.358210949670701

Epoch: 41
Training loss: 0.4592660665512085 / Valid loss: 6.339441458384196
Training loss: 0.0894133597612381 / Valid loss: 6.341317985171363
Training loss: 0.09252940118312836 / Valid loss: 6.351130079087757
Training loss: 0.1510777473449707 / Valid loss: 6.357196994054885
Training loss: 0.5370348691940308 / Valid loss: 6.389770880199614

Epoch: 42
Training loss: 0.07056646049022675 / Valid loss: 6.378788225991386
Training loss: 0.09229077398777008 / Valid loss: 6.351491548901513
Training loss: 0.05343136936426163 / Valid loss: 6.37052762621925
Training loss: 0.10687656700611115 / Valid loss: 6.3616147722516745
Training loss: 0.0933765321969986 / Valid loss: 6.325074620473952

Epoch: 43
Training loss: 0.04748982936143875 / Valid loss: 6.3301727385748
Training loss: 0.13922642171382904 / Valid loss: 6.323652260644096
Training loss: 0.10537631064653397 / Valid loss: 6.334607453573318
Training loss: 0.150165855884552 / Valid loss: 6.327126387187413
Training loss: 0.056220799684524536 / Valid loss: 6.334140505109515

Epoch: 44
Training loss: 0.08762910962104797 / Valid loss: 6.370439972196307
Training loss: 0.11731640249490738 / Valid loss: 6.347888303938366
Training loss: 0.2647152543067932 / Valid loss: 6.34471313839867
Training loss: 0.1697639673948288 / Valid loss: 6.365198448726109
Training loss: 0.06264075636863708 / Valid loss: 6.356424620037987

Epoch: 45
Training loss: 0.10546865314245224 / Valid loss: 6.3462805089496435
Training loss: 0.1051226258277893 / Valid loss: 6.381843603224981
Training loss: 0.0671258270740509 / Valid loss: 6.340635710670835
Training loss: 0.05775688588619232 / Valid loss: 6.361169351850237
Training loss: 0.05252247676253319 / Valid loss: 6.343905269531977

Epoch: 46
Training loss: 0.18940213322639465 / Valid loss: 6.375699315752302
Training loss: 0.10142149031162262 / Valid loss: 6.351189547493345
Training loss: 0.14611399173736572 / Valid loss: 6.356239891052246
Training loss: 0.07503370940685272 / Valid loss: 6.33702161425636
Training loss: 0.09174662828445435 / Valid loss: 6.339312042508807

Epoch: 47
Training loss: 0.10110034048557281 / Valid loss: 6.332279087248303
Training loss: 0.040242914110422134 / Valid loss: 6.34294174966358
Training loss: 0.08301621675491333 / Valid loss: 6.345145550228301
Training loss: 0.09801816940307617 / Valid loss: 6.346228429249355
Training loss: 0.09644988179206848 / Valid loss: 6.346522726331439

Epoch: 48
Training loss: 0.13141518831253052 / Valid loss: 6.3524384044465565
Training loss: 0.07378581166267395 / Valid loss: 6.326774638039725
Training loss: 0.2139660269021988 / Valid loss: 6.346424447922479
Training loss: 0.057575009763240814 / Valid loss: 6.3344897951398575
Training loss: 0.08018729090690613 / Valid loss: 6.352977816263834

Epoch: 49
Training loss: 0.086175836622715 / Valid loss: 6.3568884963081
Training loss: 0.10851481556892395 / Valid loss: 6.350558521634056
Training loss: 0.07921265810728073 / Valid loss: 6.352657072884696
Training loss: 0.07737906277179718 / Valid loss: 6.357593881516229

Epoch: 50
Training loss: 0.08928567916154861 / Valid loss: 6.339169563565935
Training loss: 0.17343580722808838 / Valid loss: 6.327351987929571
Training loss: 0.20013725757598877 / Valid loss: 6.326867696217128
Training loss: 0.055163051933050156 / Valid loss: 6.3347212541671025
Training loss: 0.08126071095466614 / Valid loss: 6.349472861062913

Epoch: 51
Training loss: 0.07145161926746368 / Valid loss: 6.3277881122770765
Training loss: 0.21681290864944458 / Valid loss: 6.328805448895409
Training loss: 0.11557208746671677 / Valid loss: 6.366275946299235
Training loss: 0.13487125933170319 / Valid loss: 6.3267372744424
Training loss: 0.06691630184650421 / Valid loss: 6.356079062961396

Epoch: 52
Training loss: 0.2332616150379181 / Valid loss: 6.331024010976155
Training loss: 0.12593820691108704 / Valid loss: 6.311035033634731
Training loss: 0.060266003012657166 / Valid loss: 6.347159008752732
Training loss: 0.1771402359008789 / Valid loss: 6.329416458947318
Training loss: 0.15290766954421997 / Valid loss: 6.336394082932245

Epoch: 53
Training loss: 0.24690663814544678 / Valid loss: 6.34862272852943
Training loss: 0.3594885468482971 / Valid loss: 6.318744795663016
Training loss: 0.11017828434705734 / Valid loss: 6.360392382031395
Training loss: 0.12316355109214783 / Valid loss: 6.3646135284787135
Training loss: 0.1122855395078659 / Valid loss: 6.356170290992374

Epoch: 54
Training loss: 0.04151037335395813 / Valid loss: 6.358168951670328
Training loss: 0.32145047187805176 / Valid loss: 6.340553740092687
Training loss: 0.07607819139957428 / Valid loss: 6.329880083174933
Training loss: 0.25169527530670166 / Valid loss: 6.328706255413237
Training loss: 0.24260589480400085 / Valid loss: 6.352575881140573

Epoch: 55
Training loss: 0.16940908133983612 / Valid loss: 6.370737118948074
Training loss: 0.12081698328256607 / Valid loss: 6.341914540245419
Training loss: 0.05987893044948578 / Valid loss: 6.348472815468198
Training loss: 0.10720039904117584 / Valid loss: 6.345427867344448
Training loss: 0.21051490306854248 / Valid loss: 6.338623507817586

Epoch: 56
Training loss: 0.20199266076087952 / Valid loss: 6.372402341025216
Training loss: 0.09200846403837204 / Valid loss: 6.338606505166917
Training loss: 0.06058843806385994 / Valid loss: 6.332913321540469
Training loss: 0.13219958543777466 / Valid loss: 6.3389894530886695
Training loss: 0.3386343717575073 / Valid loss: 6.365643167495728

Epoch: 57
Training loss: 0.09427264332771301 / Valid loss: 6.362747174217588
Training loss: 0.07678001374006271 / Valid loss: 6.3377251556941445
Training loss: 0.11570907384157181 / Valid loss: 6.351742292585827
Training loss: 0.10464540123939514 / Valid loss: 6.329984208515712
Training loss: 0.1381593942642212 / Valid loss: 6.347119510741461

Epoch: 58
Training loss: 0.05210406333208084 / Valid loss: 6.314066609882173
Training loss: 0.09966316819190979 / Valid loss: 6.345790281749907
Training loss: 0.23410938680171967 / Valid loss: 6.300806897027152
Training loss: 0.054922714829444885 / Valid loss: 6.32416261945452
Training loss: 0.053786501288414 / Valid loss: 6.340529553095499

Epoch: 59
Training loss: 0.08967846632003784 / Valid loss: 6.318196696326846
Training loss: 0.094576895236969 / Valid loss: 6.340475681849888
Training loss: 0.11356750130653381 / Valid loss: 6.314000513440087
Training loss: 0.06962209939956665 / Valid loss: 6.33395459311349

Epoch: 60
Training loss: 0.05637192726135254 / Valid loss: 6.335543693814959
Training loss: 0.06560757756233215 / Valid loss: 6.340421504066104
Training loss: 0.07257738709449768 / Valid loss: 6.32517694745745
Training loss: 0.4209819734096527 / Valid loss: 6.328858343760173
Training loss: 0.045569270849227905 / Valid loss: 6.335897488821121

Epoch: 61
Training loss: 0.20251478254795074 / Valid loss: 6.307471897488549
Training loss: 0.4106515645980835 / Valid loss: 6.339721205120995
Training loss: 0.08650413155555725 / Valid loss: 6.316603810446603
Training loss: 0.07777893543243408 / Valid loss: 6.3339951220012845
Training loss: 0.16665956377983093 / Valid loss: 6.301861215773083

Epoch: 62
Training loss: 0.07499182224273682 / Valid loss: 6.328683914457049
Training loss: 0.34206902980804443 / Valid loss: 6.296635073707217
Training loss: 0.08810387551784515 / Valid loss: 6.335921977815174
Training loss: 0.054912518709897995 / Valid loss: 6.33373076575143
Training loss: 0.07066389918327332 / Valid loss: 6.36551212356204

Epoch: 63
Training loss: 0.07149764150381088 / Valid loss: 6.322137106032598
Training loss: 0.0888088196516037 / Valid loss: 6.30352220989409
Training loss: 0.1479266881942749 / Valid loss: 6.30540307135809
Training loss: 0.07052986323833466 / Valid loss: 6.332460505621774
Training loss: 0.13131126761436462 / Valid loss: 6.332745193299793

Epoch: 64
Training loss: 0.09153388440608978 / Valid loss: 6.330136614754086
Training loss: 0.12453246861696243 / Valid loss: 6.350917103177025
Training loss: 0.11713561415672302 / Valid loss: 6.349714778718495
Training loss: 0.13790473341941833 / Valid loss: 6.3520004953656874
Training loss: 0.09515056759119034 / Valid loss: 6.340897058305286

Epoch: 65
Training loss: 0.07311771810054779 / Valid loss: 6.339906724294027
Training loss: 0.07978010177612305 / Valid loss: 6.334865002405076
Training loss: 0.04892701283097267 / Valid loss: 6.3259394713810515
Training loss: 0.054821863770484924 / Valid loss: 6.356901227860224
Training loss: 0.11407802253961563 / Valid loss: 6.342954694657099

Epoch: 66
Training loss: 0.0927065908908844 / Valid loss: 6.320452562967936
Training loss: 0.14727288484573364 / Valid loss: 6.348657149360293
Training loss: 0.05743040144443512 / Valid loss: 6.328103106362479
Training loss: 0.14144214987754822 / Valid loss: 6.334312620617094
Training loss: 0.0698092132806778 / Valid loss: 6.3158642768859865

Epoch: 67
Training loss: 0.2641904056072235 / Valid loss: 6.318423121316092
Training loss: 0.28504717350006104 / Valid loss: 6.328410868417649
Training loss: 0.08773338049650192 / Valid loss: 6.329389281499953
Training loss: 0.15010303258895874 / Valid loss: 6.327870947974069
Training loss: 0.0662207305431366 / Valid loss: 6.3338373683747795

Epoch: 68
Training loss: 0.18226206302642822 / Valid loss: 6.321502245040167
Training loss: 0.23105743527412415 / Valid loss: 6.312430599757604
Training loss: 0.3122464418411255 / Valid loss: 6.321962472370693
Training loss: 0.05577954649925232 / Valid loss: 6.333013954616728
Training loss: 0.37875691056251526 / Valid loss: 6.36470582144601

Epoch: 69
Training loss: 0.04580822214484215 / Valid loss: 6.330413650331043
Training loss: 0.10771819949150085 / Valid loss: 6.319482589903332
Training loss: 0.09838764369487762 / Valid loss: 6.317802358808971
Training loss: 0.5110384225845337 / Valid loss: 6.3331494195120674

Epoch: 70
Training loss: 0.12084051221609116 / Valid loss: 6.3154273623511905
Training loss: 0.13580095767974854 / Valid loss: 6.315706822985694
Training loss: 0.28246837854385376 / Valid loss: 6.345631365548996
Training loss: 0.16869404911994934 / Valid loss: 6.317340566998436
Training loss: 0.04643266648054123 / Valid loss: 6.315849985395159

Epoch: 71
Training loss: 0.09568953514099121 / Valid loss: 6.318851411910284
Training loss: 0.17910349369049072 / Valid loss: 6.329128387996128
Training loss: 0.10869308561086655 / Valid loss: 6.3505507105872745
Training loss: 0.09861381351947784 / Valid loss: 6.340109489077613
Training loss: 0.06882555782794952 / Valid loss: 6.309622644242786

Epoch: 72
Training loss: 0.2120702564716339 / Valid loss: 6.350200775691441
Training loss: 0.1742410659790039 / Valid loss: 6.332932603926886
Training loss: 0.263314425945282 / Valid loss: 6.335961587088448
Training loss: 0.23430080711841583 / Valid loss: 6.332217018944877
Training loss: 0.20989544689655304 / Valid loss: 6.321637730371385

Epoch: 73
Training loss: 0.14299963414669037 / Valid loss: 6.330393309820266
Training loss: 0.047364965081214905 / Valid loss: 6.348279653276716
Training loss: 0.10671280324459076 / Valid loss: 6.334988775707426
Training loss: 0.03803525120019913 / Valid loss: 6.349158275695074
Training loss: 0.11570358276367188 / Valid loss: 6.326879805610293

Epoch: 74
Training loss: 0.26561200618743896 / Valid loss: 6.351188353129795
Training loss: 0.07799489796161652 / Valid loss: 6.318113513219924
Training loss: 0.09083236753940582 / Valid loss: 6.296603500275385
Training loss: 0.33549416065216064 / Valid loss: 6.31753967830113
Training loss: 0.32264071702957153 / Valid loss: 6.316014124098278

Epoch: 75
Training loss: 0.08678648620843887 / Valid loss: 6.337712514968145
Training loss: 0.27119964361190796 / Valid loss: 6.313814113253639
Training loss: 0.270572304725647 / Valid loss: 6.30486160005842
Training loss: 0.08733510971069336 / Valid loss: 6.340111643927438
Training loss: 0.1262103021144867 / Valid loss: 6.34587581271217

Epoch: 76
Training loss: 0.07876928150653839 / Valid loss: 6.314630090622675
Training loss: 0.6547962427139282 / Valid loss: 6.334896028609503
Training loss: 0.8316754102706909 / Valid loss: 6.319388973145258
Training loss: 0.05551056191325188 / Valid loss: 6.34489263579959
Training loss: 0.13187657296657562 / Valid loss: 6.3167575813475105

Epoch: 77
Training loss: 0.16864515841007233 / Valid loss: 6.312881519680931
Training loss: 0.4810871183872223 / Valid loss: 6.323181177320935
Training loss: 0.06328769773244858 / Valid loss: 6.31670761562529
Training loss: 0.1859566569328308 / Valid loss: 6.326911235990979
Training loss: 0.07637125998735428 / Valid loss: 6.319829974855695

Epoch: 78
Training loss: 0.1532403975725174 / Valid loss: 6.349891830625988
Training loss: 0.255781352519989 / Valid loss: 6.334592678433373
Training loss: 0.05845699459314346 / Valid loss: 6.338101087297712
Training loss: 0.1272912323474884 / Valid loss: 6.31690973781404
Training loss: 0.2624834477901459 / Valid loss: 6.348808249973115

Epoch: 79
Training loss: 0.10196933150291443 / Valid loss: 6.323623164494832
Training loss: 0.13372734189033508 / Valid loss: 6.321202282678513
Training loss: 0.06782631576061249 / Valid loss: 6.330793333053589
Training loss: 0.22985678911209106 / Valid loss: 6.331274759201777
ModuleList(
  (0): Linear(in_features=31191, out_features=300, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=300, out_features=32, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=32, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.500653319131761
Training regression with following parameters:
dnn_hidden_units : 248
dropout_probs : 0.0, 0.0
learning_rate : 0.001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : SGD
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : TFIDF
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=31191, out_features=248, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=248, out_features=1, bias=True)
)

Epoch: 0
Training loss: 15.220863342285156 / Valid loss: 16.393978872753326
Model is saved in epoch 0, overall batch: 0
Training loss: 6.950390815734863 / Valid loss: 6.82338509332566
Model is saved in epoch 0, overall batch: 100
Training loss: 4.82531213760376 / Valid loss: 5.854198537554059
Model is saved in epoch 0, overall batch: 200
Training loss: 4.192346572875977 / Valid loss: 5.807580464226859
Model is saved in epoch 0, overall batch: 300
Training loss: 5.7569074630737305 / Valid loss: 5.696045373734973
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 4.408085823059082 / Valid loss: 5.636620062873477
Model is saved in epoch 1, overall batch: 500
Training loss: 3.645799398422241 / Valid loss: 5.780500532331921
Training loss: 3.391494035720825 / Valid loss: 5.9138802074250725
Training loss: 4.34486198425293 / Valid loss: 6.142236021586827
Training loss: 4.439403533935547 / Valid loss: 5.916895657493955

Epoch: 2
Training loss: 1.9834133386611938 / Valid loss: 5.937925488608224
Training loss: 2.8391470909118652 / Valid loss: 6.094314114252726
Training loss: 2.855729579925537 / Valid loss: 6.111214115506127
Training loss: 1.9998453855514526 / Valid loss: 6.154920430410476
Training loss: 2.434849500656128 / Valid loss: 6.177736096155076

Epoch: 3
Training loss: 2.05216646194458 / Valid loss: 6.207331700552078
Training loss: 2.096348285675049 / Valid loss: 6.382853948502314
Training loss: 1.8594611883163452 / Valid loss: 6.3469143504188175
Training loss: 1.7997956275939941 / Valid loss: 6.3521278381347654
Training loss: 2.936952590942383 / Valid loss: 6.281514494759696

Epoch: 4
Training loss: 1.4008034467697144 / Valid loss: 6.404708149319603
Training loss: 1.2083890438079834 / Valid loss: 6.40638401621864
Training loss: 1.3007365465164185 / Valid loss: 6.493873855045863
Training loss: 2.1210110187530518 / Valid loss: 6.492948775064377
Training loss: 1.1316049098968506 / Valid loss: 6.521965633119856

Epoch: 5
Training loss: 0.9016947746276855 / Valid loss: 6.470519597189767
Training loss: 1.6965577602386475 / Valid loss: 6.627134577433268
Training loss: 0.9127664566040039 / Valid loss: 6.525098600841704
Training loss: 1.661691427230835 / Valid loss: 6.589740158262707
Training loss: 1.689554214477539 / Valid loss: 6.621862761179606

Epoch: 6
Training loss: 0.8141546249389648 / Valid loss: 6.544092589332944
Training loss: 1.249220371246338 / Valid loss: 6.618073122841971
Training loss: 1.424410104751587 / Valid loss: 6.614254006885347
Training loss: 0.8493683338165283 / Valid loss: 6.645631190708706
Training loss: 1.8747713565826416 / Valid loss: 6.632725486301241

Epoch: 7
Training loss: 0.8722219467163086 / Valid loss: 6.6716000329880485
Training loss: 0.5133195519447327 / Valid loss: 6.741432868866694
Training loss: 0.9211058616638184 / Valid loss: 6.641839931124733
Training loss: 0.8676416873931885 / Valid loss: 6.699280577614194
Training loss: 1.2192366123199463 / Valid loss: 6.767608233860561

Epoch: 8
Training loss: 0.4832886755466461 / Valid loss: 6.7018872828710645
Training loss: 0.7298845648765564 / Valid loss: 6.70756992385501
Training loss: 0.6494537591934204 / Valid loss: 6.725547772362119
Training loss: 0.6193346977233887 / Valid loss: 6.737971142360142
Training loss: 0.7750704288482666 / Valid loss: 6.780278115045457

Epoch: 9
Training loss: 0.48598724603652954 / Valid loss: 6.710648661568051
Training loss: 0.4702382981777191 / Valid loss: 6.729933484395345
Training loss: 0.44677335023880005 / Valid loss: 6.735917182195754
Training loss: 0.26093924045562744 / Valid loss: 6.766480697904314

Epoch: 10
Training loss: 0.20831982791423798 / Valid loss: 6.76352825164795
Training loss: 0.40861114859580994 / Valid loss: 6.75679829461234
Training loss: 0.21374467015266418 / Valid loss: 6.736504111971174
Training loss: 0.9156556129455566 / Valid loss: 6.763773459479922
Training loss: 0.29189813137054443 / Valid loss: 6.793487694149926

Epoch: 11
Training loss: 0.21669955551624298 / Valid loss: 6.776631700424921
Training loss: 0.3701687157154083 / Valid loss: 6.751632604144868
Training loss: 0.28558075428009033 / Valid loss: 6.764737946646554
Training loss: 0.38041460514068604 / Valid loss: 6.775603239876883
Training loss: 0.2748730480670929 / Valid loss: 6.75230058034261

Epoch: 12
Training loss: 0.23764126002788544 / Valid loss: 6.790800140017555
Training loss: 0.17625558376312256 / Valid loss: 6.800352503004528
Training loss: 0.5052230954170227 / Valid loss: 6.834218724568685
Training loss: 0.3282228708267212 / Valid loss: 6.757922267913818
Training loss: 0.24219930171966553 / Valid loss: 6.82920796303522

Epoch: 13
Training loss: 0.31549516320228577 / Valid loss: 6.848487145560128
Training loss: 0.13276666402816772 / Valid loss: 6.824462940579369
Training loss: 0.23020052909851074 / Valid loss: 6.781087975274949
Training loss: 0.11618486046791077 / Valid loss: 6.825079836164202
Training loss: 0.41749078035354614 / Valid loss: 6.803944442385719

Epoch: 14
Training loss: 0.19638192653656006 / Valid loss: 6.826554148537772
Training loss: 0.1346035599708557 / Valid loss: 6.814500672476632
Training loss: 0.26664212346076965 / Valid loss: 6.802070143109276
Training loss: 0.2566507160663605 / Valid loss: 6.8199559075491765
Training loss: 0.16003315150737762 / Valid loss: 6.802277719406854

Epoch: 15
Training loss: 0.3428838551044464 / Valid loss: 6.83650623957316
Training loss: 0.2979288399219513 / Valid loss: 6.842084049043201
Training loss: 0.2518506646156311 / Valid loss: 6.864933581579299
Training loss: 0.3272779583930969 / Valid loss: 6.863692842211042
Training loss: 0.17355574667453766 / Valid loss: 6.881246943700881

Epoch: 16
Training loss: 0.23739860951900482 / Valid loss: 6.849971199035645
Training loss: 0.23054343461990356 / Valid loss: 6.826543029149374
Training loss: 0.11159612238407135 / Valid loss: 6.820881330399287
Training loss: 0.18667051196098328 / Valid loss: 6.873093714032854
Training loss: 0.24271151423454285 / Valid loss: 6.8250594865708125

Epoch: 17
Training loss: 0.11067895591259003 / Valid loss: 6.841089875357492
Training loss: 0.0813533216714859 / Valid loss: 6.849985131763277
Training loss: 0.13982553780078888 / Valid loss: 6.8243595940726145
Training loss: 0.20707112550735474 / Valid loss: 6.8212613786969865
Training loss: 0.22129148244857788 / Valid loss: 6.839079461778913

Epoch: 18
Training loss: 0.25001493096351624 / Valid loss: 6.8294623057047525
Training loss: 0.3857252597808838 / Valid loss: 6.828814774467832
Training loss: 0.36503344774246216 / Valid loss: 6.866144770667667
Training loss: 0.14550575613975525 / Valid loss: 6.852942739214216
Training loss: 0.2232048511505127 / Valid loss: 6.866510184605916

Epoch: 19
Training loss: 0.6372464895248413 / Valid loss: 6.835455617450532
Training loss: 0.21749453246593475 / Valid loss: 6.851958070482526
Training loss: 0.3034130930900574 / Valid loss: 6.895770740509033
Training loss: 0.12826129794120789 / Valid loss: 6.85516532716297

Epoch: 20
Training loss: 0.1368284970521927 / Valid loss: 6.878189513796852
Training loss: 0.199870765209198 / Valid loss: 6.812482057298933
Training loss: 0.16220107674598694 / Valid loss: 6.82926279703776
Training loss: 0.20118914544582367 / Valid loss: 6.862219070252918
Training loss: 0.14325936138629913 / Valid loss: 6.862007604326521

Epoch: 21
Training loss: 0.08248455822467804 / Valid loss: 6.89731646719433
Training loss: 0.155981183052063 / Valid loss: 6.856298809959775
Training loss: 0.24711565673351288 / Valid loss: 6.875075889769055
Training loss: 0.23854897916316986 / Valid loss: 6.862183666229248
Training loss: 0.2122732549905777 / Valid loss: 6.886985422316052

Epoch: 22
Training loss: 0.18395864963531494 / Valid loss: 6.8817937896365216
Training loss: 0.10614835470914841 / Valid loss: 6.879094214666457
Training loss: 0.3852521479129791 / Valid loss: 6.86791272844587
Training loss: 0.21029776334762573 / Valid loss: 6.900392875217256
Training loss: 0.11270299553871155 / Valid loss: 6.833392102377755

Epoch: 23
Training loss: 0.08909773081541061 / Valid loss: 6.850704311189197
Training loss: 0.13861559331417084 / Valid loss: 6.86902954464867
Training loss: 0.13606125116348267 / Valid loss: 6.85819448970613
Training loss: 0.3629767894744873 / Valid loss: 6.900230044410343
Training loss: 0.14103704690933228 / Valid loss: 6.859778549557641

Epoch: 24
Training loss: 0.08569955825805664 / Valid loss: 6.849300688789004
Training loss: 0.19008740782737732 / Valid loss: 6.868378743671236
Training loss: 0.5738720893859863 / Valid loss: 6.873212598619007
Training loss: 0.08215358853340149 / Valid loss: 6.8977472237178254
Training loss: 0.08626773953437805 / Valid loss: 6.862959489368257

Epoch: 25
Training loss: 0.23030945658683777 / Valid loss: 6.8270149957566035
Training loss: 0.11255639046430588 / Valid loss: 6.854418377649217
Training loss: 0.0952090248465538 / Valid loss: 6.87209324155535
Training loss: 0.11542341113090515 / Valid loss: 6.870381577809652
Training loss: 0.1287255585193634 / Valid loss: 6.851056403205508

Epoch: 26
Training loss: 0.2479320764541626 / Valid loss: 6.887711534045992
Training loss: 0.1491987705230713 / Valid loss: 6.860861224219913
Training loss: 0.07739858329296112 / Valid loss: 6.861242439633324
Training loss: 0.10686315596103668 / Valid loss: 6.858582510266985
Training loss: 0.40368396043777466 / Valid loss: 6.838596875326974

Epoch: 27
Training loss: 0.1953480839729309 / Valid loss: 6.870929120835804
Training loss: 0.2527312636375427 / Valid loss: 6.831080302738008
Training loss: 0.11501236259937286 / Valid loss: 6.829936331794375
Training loss: 0.07293621450662613 / Valid loss: 6.872516012191772
Training loss: 0.08122929185628891 / Valid loss: 6.867914136250814

Epoch: 28
Training loss: 0.04728984087705612 / Valid loss: 6.867459665025984
Training loss: 0.16707246005535126 / Valid loss: 6.901360593523298
Training loss: 0.14043238759040833 / Valid loss: 6.831055550348191
Training loss: 0.17438365519046783 / Valid loss: 6.882770815349761
Training loss: 0.10534228384494781 / Valid loss: 6.843616326649983

Epoch: 29
Training loss: 0.47690534591674805 / Valid loss: 6.877875464303153
Training loss: 0.08285211771726608 / Valid loss: 6.874543444315592
Training loss: 0.16169443726539612 / Valid loss: 6.830899697258359
Training loss: 0.22997316718101501 / Valid loss: 6.850728602636428

Epoch: 30
Training loss: 0.20636498928070068 / Valid loss: 6.879583631243024
Training loss: 0.23870781064033508 / Valid loss: 6.819139975593203
Training loss: 0.259239137172699 / Valid loss: 6.825209522247315
Training loss: 0.39394283294677734 / Valid loss: 6.869104383105324
Training loss: 0.09625744819641113 / Valid loss: 6.851364835103353

Epoch: 31
Training loss: 0.13379818201065063 / Valid loss: 6.8476044359661286
Training loss: 0.2040589153766632 / Valid loss: 6.847045853024437
Training loss: 0.057182855904102325 / Valid loss: 6.850955533981323
Training loss: 0.18322420120239258 / Valid loss: 6.8313463619777135
Training loss: 0.27824878692626953 / Valid loss: 6.830618717556908

Epoch: 32
Training loss: 0.04976912587881088 / Valid loss: 6.818941961015974
Training loss: 0.08113226294517517 / Valid loss: 6.845159339904785
Training loss: 0.10690615326166153 / Valid loss: 6.807340730939592
Training loss: 0.06454800814390182 / Valid loss: 6.8864845957074845
Training loss: 0.22531446814537048 / Valid loss: 6.864781238919213

Epoch: 33
Training loss: 0.3414895534515381 / Valid loss: 6.839145533243815
Training loss: 0.11443338543176651 / Valid loss: 6.838155024392265
Training loss: 0.10652416944503784 / Valid loss: 6.89386488369533
Training loss: 0.08336052298545837 / Valid loss: 6.835525340125674
Training loss: 0.1125711128115654 / Valid loss: 6.857620325542632

Epoch: 34
Training loss: 0.06971574574708939 / Valid loss: 6.846522426605224
Training loss: 0.22229725122451782 / Valid loss: 6.837329355875651
Training loss: 0.22787760198116302 / Valid loss: 6.868928255353655
Training loss: 0.1495833694934845 / Valid loss: 6.821498434884208
Training loss: 0.03812015801668167 / Valid loss: 6.821498439425514

Epoch: 35
Training loss: 0.14116984605789185 / Valid loss: 6.858575482595534
Training loss: 0.1651119738817215 / Valid loss: 6.843854972294399
Training loss: 0.12123597413301468 / Valid loss: 6.821394856770834
Training loss: 0.07945707440376282 / Valid loss: 6.8295694260370166
Training loss: 0.09358997642993927 / Valid loss: 6.851823679606119

Epoch: 36
Training loss: 0.08625078946352005 / Valid loss: 6.873786989847819
Training loss: 0.1424684375524521 / Valid loss: 6.824896985008603
Training loss: 0.06935569643974304 / Valid loss: 6.810631116231282
Training loss: 0.13521768152713776 / Valid loss: 6.843557135264079
Training loss: 0.10350160300731659 / Valid loss: 6.845188860666184

Epoch: 37
Training loss: 0.09939810633659363 / Valid loss: 6.846831126440139
Training loss: 0.9921778440475464 / Valid loss: 6.846525707699004
Training loss: 0.12309449911117554 / Valid loss: 6.834499195643834
Training loss: 0.10211436450481415 / Valid loss: 6.809490344637916
Training loss: 0.12287743389606476 / Valid loss: 6.810372881662278

Epoch: 38
Training loss: 0.11717455834150314 / Valid loss: 6.808808671860468
Training loss: 0.0923648402094841 / Valid loss: 6.819190856388637
Training loss: 0.3021281957626343 / Valid loss: 6.881321123668125
Training loss: 0.09703575819730759 / Valid loss: 6.827733625684465
Training loss: 0.1978583186864853 / Valid loss: 6.849849996112642

Epoch: 39
Training loss: 0.1060674786567688 / Valid loss: 6.807004678817022
Training loss: 0.1399092972278595 / Valid loss: 6.846773252033052
Training loss: 0.15706518292427063 / Valid loss: 6.812927159808931
Training loss: 0.14932957291603088 / Valid loss: 6.85579019728161

Epoch: 40
Training loss: 0.06880805641412735 / Valid loss: 6.87772126197815
Training loss: 0.12834763526916504 / Valid loss: 6.8127013796851745
Training loss: 0.04084783047437668 / Valid loss: 6.8670389970143635
Training loss: 0.27542030811309814 / Valid loss: 6.859873367491223
Training loss: 0.17537064850330353 / Valid loss: 6.864661922908964

Epoch: 41
Training loss: 0.07336480915546417 / Valid loss: 6.861436966487339
Training loss: 0.2827576994895935 / Valid loss: 6.848514679500035
Training loss: 0.0882299467921257 / Valid loss: 6.845899039223081
Training loss: 0.08964912593364716 / Valid loss: 6.874622989836193
Training loss: 0.2408907264471054 / Valid loss: 6.847087828318278

Epoch: 42
Training loss: 0.08982287347316742 / Valid loss: 6.808477592468262
Training loss: 0.085629403591156 / Valid loss: 6.840105715252104
Training loss: 0.07128442078828812 / Valid loss: 6.852028828575498
Training loss: 0.06466563791036606 / Valid loss: 6.855063181831723
Training loss: 0.09962504357099533 / Valid loss: 6.832039092835926

Epoch: 43
Training loss: 0.10237567126750946 / Valid loss: 6.82209773290725
Training loss: 0.11232544481754303 / Valid loss: 6.825754183814639
Training loss: 0.19936686754226685 / Valid loss: 6.8363997005281
Training loss: 0.07371599972248077 / Valid loss: 6.835885084243047
Training loss: 0.2395152449607849 / Valid loss: 6.861187212807792

Epoch: 44
Training loss: 0.08499131351709366 / Valid loss: 6.872041148231143
Training loss: 0.10297366976737976 / Valid loss: 6.802763652801514
Training loss: 0.11842828243970871 / Valid loss: 6.831781950451079
Training loss: 0.07244645059108734 / Valid loss: 6.835540439969018
Training loss: 0.15908463299274445 / Valid loss: 6.8376377514430455

Epoch: 45
Training loss: 0.12332487106323242 / Valid loss: 6.79650757199242
Training loss: 0.0773988664150238 / Valid loss: 6.81533686319987
Training loss: 0.1979948729276657 / Valid loss: 6.828570856366839
Training loss: 0.06298628449440002 / Valid loss: 6.81124929019383
Training loss: 0.11758109927177429 / Valid loss: 6.828758085341681

Epoch: 46
Training loss: 0.06572746485471725 / Valid loss: 6.835934838794526
Training loss: 0.05804038047790527 / Valid loss: 6.84133837563651
Training loss: 0.13040940463542938 / Valid loss: 6.864785666692825
Training loss: 0.07170867919921875 / Valid loss: 6.830286069143386
Training loss: 0.06186284124851227 / Valid loss: 6.834738268171038

Epoch: 47
Training loss: 0.14078745245933533 / Valid loss: 6.808433596293131
Training loss: 0.15772846341133118 / Valid loss: 6.824110784984771
Training loss: 0.19887515902519226 / Valid loss: 6.851742108662923
Training loss: 0.08757258951663971 / Valid loss: 6.816231264386858
Training loss: 0.1807938814163208 / Valid loss: 6.8248457454499745

Epoch: 48
Training loss: 0.11991056799888611 / Valid loss: 6.807045041947138
Training loss: 0.1063387542963028 / Valid loss: 6.840342993963333
Training loss: 0.1857297718524933 / Valid loss: 6.810059197743734
Training loss: 0.06192873418331146 / Valid loss: 6.812371131352016
Training loss: 0.09235098958015442 / Valid loss: 6.814616132917858

Epoch: 49
Training loss: 0.11516249179840088 / Valid loss: 6.801986871446882
Training loss: 0.049923382699489594 / Valid loss: 6.8300253141494025
Training loss: 0.057990945875644684 / Valid loss: 6.813786393120175
Training loss: 0.13447421789169312 / Valid loss: 6.810642898650396

Epoch: 50
Training loss: 0.10166868567466736 / Valid loss: 6.807910787491571
Training loss: 0.11245456337928772 / Valid loss: 6.806594998495919
Training loss: 0.06362432986497879 / Valid loss: 6.8084943408057805
Training loss: 0.07498596608638763 / Valid loss: 6.815892233167376
Training loss: 0.13155700266361237 / Valid loss: 6.834029815310523

Epoch: 51
Training loss: 0.0773419514298439 / Valid loss: 6.822623298281715
Training loss: 0.08691380172967911 / Valid loss: 6.7798672358194985
Training loss: 0.06659757345914841 / Valid loss: 6.820586002440679
Training loss: 0.08088821172714233 / Valid loss: 6.843110139029367
Training loss: 0.06610007584095001 / Valid loss: 6.8353673957643055

Epoch: 52
Training loss: 0.04643247276544571 / Valid loss: 6.805220254262289
Training loss: 0.11653744429349899 / Valid loss: 6.804347392490932
Training loss: 0.12294186651706696 / Valid loss: 6.796764718918573
Training loss: 0.08560542017221451 / Valid loss: 6.789102904001871
Training loss: 0.07949750125408173 / Valid loss: 6.846743592761812

Epoch: 53
Training loss: 0.221198171377182 / Valid loss: 6.833130005427769
Training loss: 0.11760762333869934 / Valid loss: 6.813115851084391
Training loss: 0.1146877333521843 / Valid loss: 6.81609164192563
Training loss: 0.28502941131591797 / Valid loss: 6.81052625746954
Training loss: 0.10935560613870621 / Valid loss: 6.835055287679037

Epoch: 54
Training loss: 0.19668719172477722 / Valid loss: 6.838128766559419
Training loss: 0.06919259577989578 / Valid loss: 6.823879578000024
Training loss: 0.29045796394348145 / Valid loss: 6.798378794533866
Training loss: 0.09647464007139206 / Valid loss: 6.782320086161295
Training loss: 0.040429625660181046 / Valid loss: 6.813247158413842

Epoch: 55
Training loss: 0.04284761846065521 / Valid loss: 6.795749019441151
Training loss: 0.04910339415073395 / Valid loss: 6.799988828386579
Training loss: 0.0836993157863617 / Valid loss: 6.794401459466844
Training loss: 0.05181235447525978 / Valid loss: 6.821451659429641
Training loss: 0.22639334201812744 / Valid loss: 6.833737050919305

Epoch: 56
Training loss: 0.31548193097114563 / Valid loss: 6.770919064113072
Training loss: 0.10513324290513992 / Valid loss: 6.776304617382231
Training loss: 0.10356969386339188 / Valid loss: 6.8144391218821205
Training loss: 0.1465071439743042 / Valid loss: 6.80082531883603
Training loss: 0.2615829408168793 / Valid loss: 6.801803643362863

Epoch: 57
Training loss: 0.048285286873579025 / Valid loss: 6.798219231196812
Training loss: 0.17967315018177032 / Valid loss: 6.8097258454277405
Training loss: 0.06101883575320244 / Valid loss: 6.8139551117306665
Training loss: 0.2560874819755554 / Valid loss: 6.794298240116665
Training loss: 0.18195125460624695 / Valid loss: 6.810819076356434

Epoch: 58
Training loss: 0.11123991012573242 / Valid loss: 6.815899419784546
Training loss: 0.1284780502319336 / Valid loss: 6.8032817431858605
Training loss: 0.32758110761642456 / Valid loss: 6.798080607822963
Training loss: 0.07259152829647064 / Valid loss: 6.816577548072452
Training loss: 0.07087888568639755 / Valid loss: 6.812328670138404

Epoch: 59
Training loss: 0.06890623271465302 / Valid loss: 6.767885144551595
Training loss: 0.0811922550201416 / Valid loss: 6.806491956256685
Training loss: 0.16498340666294098 / Valid loss: 6.772476900191534
Training loss: 0.33730676770210266 / Valid loss: 6.81969854036967

Epoch: 60
Training loss: 0.12315865606069565 / Valid loss: 6.802736568450928
Training loss: 0.08028413355350494 / Valid loss: 6.780628554026285
Training loss: 0.13149146735668182 / Valid loss: 6.790805167243594
Training loss: 0.0520772710442543 / Valid loss: 6.807489844730922
Training loss: 0.1345963329076767 / Valid loss: 6.783730879284087

Epoch: 61
Training loss: 0.09064038097858429 / Valid loss: 6.79748288109189
Training loss: 0.0667538270354271 / Valid loss: 6.7936263811020625
Training loss: 0.09544751793146133 / Valid loss: 6.806721135548183
Training loss: 0.04972919449210167 / Valid loss: 6.792763880320957
Training loss: 0.03901579603552818 / Valid loss: 6.7753349508558

Epoch: 62
Training loss: 0.055897731333971024 / Valid loss: 6.795614971433367
Training loss: 0.03965049609541893 / Valid loss: 6.76655437151591
Training loss: 0.06055697053670883 / Valid loss: 6.794037028721401
Training loss: 0.06029967963695526 / Valid loss: 6.801618957519532
Training loss: 0.11968371272087097 / Valid loss: 6.7719565209888275

Epoch: 63
Training loss: 0.27001872658729553 / Valid loss: 6.798883656093053
Training loss: 0.04164053127169609 / Valid loss: 6.819714446294875
Training loss: 0.06801760941743851 / Valid loss: 6.794660763513474
Training loss: 0.08186650276184082 / Valid loss: 6.7807816278366815
Training loss: 0.07219803333282471 / Valid loss: 6.795815919694446

Epoch: 64
Training loss: 0.08516177535057068 / Valid loss: 6.809021518343971
Training loss: 0.062011756002902985 / Valid loss: 6.821677616664341
Training loss: 0.069827601313591 / Valid loss: 6.759740706852504
Training loss: 0.04911311715841293 / Valid loss: 6.784845288594564
Training loss: 0.07397820800542831 / Valid loss: 6.780797086443219

Epoch: 65
Training loss: 0.052081398665905 / Valid loss: 6.794096526645479
Training loss: 0.13620348274707794 / Valid loss: 6.770095675332206
Training loss: 0.136363685131073 / Valid loss: 6.798382750011625
Training loss: 0.15962933003902435 / Valid loss: 6.774428730919247
Training loss: 0.06479144841432571 / Valid loss: 6.7662056605021155

Epoch: 66
Training loss: 0.07721419632434845 / Valid loss: 6.751669465927851
Training loss: 0.07848620414733887 / Valid loss: 6.810178143637521
Training loss: 0.2232867032289505 / Valid loss: 6.78564232871646
Training loss: 0.08038271963596344 / Valid loss: 6.813274120149158
Training loss: 0.05126660317182541 / Valid loss: 6.794248063223702

Epoch: 67
Training loss: 0.06451783329248428 / Valid loss: 6.770997142791748
Training loss: 0.08814311772584915 / Valid loss: 6.793850349244617
Training loss: 0.06372310221195221 / Valid loss: 6.809338217689877
Training loss: 0.16669078171253204 / Valid loss: 6.8056710424877345
Training loss: 0.08971279859542847 / Valid loss: 6.8146832647777735

Epoch: 68
Training loss: 0.15439268946647644 / Valid loss: 6.762838104793004
Training loss: 0.07107461988925934 / Valid loss: 6.781782935914539
Training loss: 0.07192321121692657 / Valid loss: 6.781964261191232
Training loss: 0.059484805911779404 / Valid loss: 6.8058109374273394
Training loss: 0.0822872668504715 / Valid loss: 6.792132677350725

Epoch: 69
Training loss: 0.1417001187801361 / Valid loss: 6.7718195052373975
Training loss: 0.12281909584999084 / Valid loss: 6.769391688846406
Training loss: 0.04313569515943527 / Valid loss: 6.79743750890096
Training loss: 0.15076285600662231 / Valid loss: 6.778049705142067

Epoch: 70
Training loss: 0.08400564640760422 / Valid loss: 6.7741978645324705
Training loss: 0.4702611267566681 / Valid loss: 6.7842480704897925
Training loss: 0.13824325799942017 / Valid loss: 6.762231431688581
Training loss: 0.10856413841247559 / Valid loss: 6.784457354318528
Training loss: 0.24110107123851776 / Valid loss: 6.781791814168295

Epoch: 71
Training loss: 0.21038106083869934 / Valid loss: 6.784914200646536
Training loss: 0.1358579844236374 / Valid loss: 6.767743428548177
Training loss: 0.04905583709478378 / Valid loss: 6.775698253086635
Training loss: 0.0643153041601181 / Valid loss: 6.773100927897862
Training loss: 0.09269401431083679 / Valid loss: 6.772345533825102

Epoch: 72
Training loss: 0.07030041515827179 / Valid loss: 6.775144708724249
Training loss: 0.1229013055562973 / Valid loss: 6.7681463423229395
Training loss: 0.2020021677017212 / Valid loss: 6.752532361802601
Training loss: 0.08262234926223755 / Valid loss: 6.725300900141398
Training loss: 0.06652319431304932 / Valid loss: 6.750894805363246

Epoch: 73
Training loss: 0.3150622546672821 / Valid loss: 6.780796402976627
Training loss: 0.0827975943684578 / Valid loss: 6.766919767288934
Training loss: 0.09098292142152786 / Valid loss: 6.761088725498745
Training loss: 0.054576627910137177 / Valid loss: 6.7601436910175146
Training loss: 0.0538608580827713 / Valid loss: 6.7814764976501465

Epoch: 74
Training loss: 0.15359362959861755 / Valid loss: 6.78792169661749
Training loss: 0.09902192652225494 / Valid loss: 6.762678777603876
Training loss: 0.052865006029605865 / Valid loss: 6.755364229565575
Training loss: 0.11425167322158813 / Valid loss: 6.765771727334886
Training loss: 0.057295095175504684 / Valid loss: 6.744548207237607

Epoch: 75
Training loss: 0.05832311511039734 / Valid loss: 6.770764959426153
Training loss: 0.9058627486228943 / Valid loss: 6.758618014199393
Training loss: 0.16620424389839172 / Valid loss: 6.766859240758986
Training loss: 0.05606769770383835 / Valid loss: 6.807239800407773
Training loss: 0.06629002094268799 / Valid loss: 6.783250679288591

Epoch: 76
Training loss: 0.046587519347667694 / Valid loss: 6.742390037718273
Training loss: 0.11489279568195343 / Valid loss: 6.7410842305138
Training loss: 0.0352339930832386 / Valid loss: 6.75286960147676
Training loss: 0.040147289633750916 / Valid loss: 6.7693566186087475
Training loss: 0.056215669959783554 / Valid loss: 6.77054895446414

Epoch: 77
Training loss: 0.07314061373472214 / Valid loss: 6.751120222182501
Training loss: 0.31075161695480347 / Valid loss: 6.760049188704718
Training loss: 0.09736548364162445 / Valid loss: 6.767395014989944
Training loss: 0.10063427686691284 / Valid loss: 6.754275639851888
Training loss: 0.2846744656562805 / Valid loss: 6.741161700657436

Epoch: 78
Training loss: 0.08254896104335785 / Valid loss: 6.783553214300246
Training loss: 0.14354640245437622 / Valid loss: 6.768798287709554
Training loss: 0.04976114258170128 / Valid loss: 6.759693497703189
Training loss: 0.07129701972007751 / Valid loss: 6.766406236376081
Training loss: 0.14631257951259613 / Valid loss: 6.752666178203764

Epoch: 79
Training loss: 0.057025179266929626 / Valid loss: 6.7455252352215
Training loss: 0.061087388545274734 / Valid loss: 6.7848653293791275
Training loss: 0.06160574033856392 / Valid loss: 6.762841392698742
Training loss: 0.0839446634054184 / Valid loss: 6.776074034827096
ModuleList(
  (0): Linear(in_features=31191, out_features=248, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=248, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.469845892134167
Training regression with following parameters:
dnn_hidden_units : 
dropout_probs : 0.0, 0.0
learning_rate : 0.001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : SGD
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : TFIDF
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=31191, out_features=1, bias=True)
)

Epoch: 0
Training loss: 20.986988067626953 / Valid loss: 16.433027476356145
Model is saved in epoch 0, overall batch: 0
Training loss: 15.960634231567383 / Valid loss: 13.008776069822765
Model is saved in epoch 0, overall batch: 100
Training loss: 6.908407688140869 / Valid loss: 10.72540210088094
Model is saved in epoch 0, overall batch: 200
Training loss: 9.450263977050781 / Valid loss: 9.172034100123815
Model is saved in epoch 0, overall batch: 300
Training loss: 6.161900043487549 / Valid loss: 8.1243883450826
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 5.731409549713135 / Valid loss: 7.433190756752378
Model is saved in epoch 1, overall batch: 500
Training loss: 5.558803558349609 / Valid loss: 6.982147645950318
Model is saved in epoch 1, overall batch: 600
Training loss: 6.517811298370361 / Valid loss: 6.670591526939756
Model is saved in epoch 1, overall batch: 700
Training loss: 5.857550144195557 / Valid loss: 6.459752475647699
Model is saved in epoch 1, overall batch: 800
Training loss: 9.24473762512207 / Valid loss: 6.310963934943789
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 5.138407230377197 / Valid loss: 6.208769160225278
Model is saved in epoch 2, overall batch: 1000
Training loss: 4.327468395233154 / Valid loss: 6.15566049076262
Model is saved in epoch 2, overall batch: 1100
Training loss: 5.517959117889404 / Valid loss: 6.111716951642718
Model is saved in epoch 2, overall batch: 1200
Training loss: 4.740536689758301 / Valid loss: 6.0822539806365965
Model is saved in epoch 2, overall batch: 1300
Training loss: 6.678840637207031 / Valid loss: 6.055055320830572
Model is saved in epoch 2, overall batch: 1400

Epoch: 3
Training loss: 5.042050838470459 / Valid loss: 6.038378844942366
Model is saved in epoch 3, overall batch: 1500
Training loss: 4.203843593597412 / Valid loss: 6.02483002117702
Model is saved in epoch 3, overall batch: 1600
Training loss: 5.312495708465576 / Valid loss: 6.024246252150762
Model is saved in epoch 3, overall batch: 1700
Training loss: 6.669886589050293 / Valid loss: 6.021089319955735
Model is saved in epoch 3, overall batch: 1800
Training loss: 7.518589019775391 / Valid loss: 6.015333227884202
Model is saved in epoch 3, overall batch: 1900

Epoch: 4
Training loss: 8.562137603759766 / Valid loss: 6.015072327568418
Model is saved in epoch 4, overall batch: 2000
Training loss: 6.722714424133301 / Valid loss: 6.008289014725458
Model is saved in epoch 4, overall batch: 2100
Training loss: 7.407953262329102 / Valid loss: 6.007616088503883
Model is saved in epoch 4, overall batch: 2200
Training loss: 7.1916046142578125 / Valid loss: 6.001187460763114
Model is saved in epoch 4, overall batch: 2300
Training loss: 5.161715507507324 / Valid loss: 5.998244271959577
Model is saved in epoch 4, overall batch: 2400

Epoch: 5
Training loss: 4.407268524169922 / Valid loss: 5.989955143701462
Model is saved in epoch 5, overall batch: 2500
Training loss: 7.172090530395508 / Valid loss: 6.000783061981201
Training loss: 4.792024612426758 / Valid loss: 5.999831826346261
Training loss: 6.890211582183838 / Valid loss: 5.999444625491187
Training loss: 4.259645462036133 / Valid loss: 5.991952539625622

Epoch: 6
Training loss: 4.462637901306152 / Valid loss: 5.98975312823341
Model is saved in epoch 6, overall batch: 3000
Training loss: 6.137667655944824 / Valid loss: 5.9974379653022405
Training loss: 3.912099838256836 / Valid loss: 5.991954446974255
Training loss: 5.891840934753418 / Valid loss: 5.986907261893863
Model is saved in epoch 6, overall batch: 3300
Training loss: 4.294204235076904 / Valid loss: 5.992651001612345

Epoch: 7
Training loss: 5.018281936645508 / Valid loss: 5.991269810994466
Training loss: 7.830850601196289 / Valid loss: 5.988702081498646
Training loss: 3.8882598876953125 / Valid loss: 5.983658070791336
Model is saved in epoch 7, overall batch: 3700
Training loss: 5.590728759765625 / Valid loss: 5.976753650392805
Model is saved in epoch 7, overall batch: 3800
Training loss: 5.879327774047852 / Valid loss: 5.984952908470517

Epoch: 8
Training loss: 6.452438831329346 / Valid loss: 5.97269579796564
Model is saved in epoch 8, overall batch: 4000
Training loss: 7.177490711212158 / Valid loss: 5.973862788790748
Training loss: 5.158285140991211 / Valid loss: 5.980816200801304
Training loss: 8.123091697692871 / Valid loss: 5.983102721259708
Training loss: 5.883680820465088 / Valid loss: 5.976775446392241

Epoch: 9
Training loss: 7.363086223602295 / Valid loss: 5.975892977487473
Training loss: 6.456648826599121 / Valid loss: 5.97587156749907
Training loss: 6.85090446472168 / Valid loss: 5.96822212764195
Model is saved in epoch 9, overall batch: 4700
Training loss: 5.352444171905518 / Valid loss: 5.971919734137399

Epoch: 10
Training loss: 5.529453754425049 / Valid loss: 5.973263374964396
Training loss: 6.948630332946777 / Valid loss: 5.968433750243414
Training loss: 7.88192892074585 / Valid loss: 5.964317546572004
Model is saved in epoch 10, overall batch: 5100
Training loss: 5.0806474685668945 / Valid loss: 5.9669674737112866
Training loss: 5.985946178436279 / Valid loss: 5.961588089806693
Model is saved in epoch 10, overall batch: 5300

Epoch: 11
Training loss: 6.6322808265686035 / Valid loss: 5.963266277313233
Training loss: 6.172384738922119 / Valid loss: 5.961288368134271
Model is saved in epoch 11, overall batch: 5500
Training loss: 8.624393463134766 / Valid loss: 5.965678451174782
Training loss: 5.980727195739746 / Valid loss: 5.961539733977545
Training loss: 4.666723251342773 / Valid loss: 5.947411550794329
Model is saved in epoch 11, overall batch: 5800

Epoch: 12
Training loss: 7.401723861694336 / Valid loss: 5.964691511789957
Training loss: 4.5629658699035645 / Valid loss: 5.960872532072521
Training loss: 4.004026412963867 / Valid loss: 5.95900038537525
Training loss: 7.920845985412598 / Valid loss: 5.959185938608079
Training loss: 4.627005100250244 / Valid loss: 5.949772305715651

Epoch: 13
Training loss: 4.662203788757324 / Valid loss: 5.956892027173724
Training loss: 3.6807591915130615 / Valid loss: 5.956464601698376
Training loss: 8.132196426391602 / Valid loss: 5.957332215990339
Training loss: 6.524435520172119 / Valid loss: 5.9546771980467295
Training loss: 6.485379219055176 / Valid loss: 5.954784168515887

Epoch: 14
Training loss: 6.952240467071533 / Valid loss: 5.952480815705799
Training loss: 4.654551029205322 / Valid loss: 5.944109507969448
Model is saved in epoch 14, overall batch: 7000
Training loss: 6.301856994628906 / Valid loss: 5.94946767943246
Training loss: 6.396191596984863 / Valid loss: 5.951248818352109
Training loss: 5.649456024169922 / Valid loss: 5.949746343067714

Epoch: 15
Training loss: 6.868973255157471 / Valid loss: 5.942510500408354
Model is saved in epoch 15, overall batch: 7400
Training loss: 6.727950096130371 / Valid loss: 5.9390660013471335
Model is saved in epoch 15, overall batch: 7500
Training loss: 4.512300968170166 / Valid loss: 5.9415370487031485
Training loss: 5.1274189949035645 / Valid loss: 5.942951372691563
Training loss: 7.298161506652832 / Valid loss: 5.941979185740153

Epoch: 16
Training loss: 4.548820495605469 / Valid loss: 5.937155119578043
Model is saved in epoch 16, overall batch: 7900
Training loss: 7.767178535461426 / Valid loss: 5.932112478074574
Model is saved in epoch 16, overall batch: 8000
Training loss: 6.783501625061035 / Valid loss: 5.941150059018816
Training loss: 6.346513271331787 / Valid loss: 5.93187536966233
Model is saved in epoch 16, overall batch: 8200
Training loss: 6.920520305633545 / Valid loss: 5.939194615681966

Epoch: 17
Training loss: 9.807075500488281 / Valid loss: 5.938436639876593
Training loss: 6.183329105377197 / Valid loss: 5.930161501112439
Model is saved in epoch 17, overall batch: 8500
Training loss: 5.619330883026123 / Valid loss: 5.936927018846784
Training loss: 4.664616584777832 / Valid loss: 5.934784582683018
Training loss: 6.6575117111206055 / Valid loss: 5.9270184675852455
Model is saved in epoch 17, overall batch: 8800

Epoch: 18
Training loss: 5.431646347045898 / Valid loss: 5.933090993336269
Training loss: 5.746004581451416 / Valid loss: 5.926326011476062
Model is saved in epoch 18, overall batch: 9000
Training loss: 4.791284561157227 / Valid loss: 5.929976747149513
Training loss: 5.657647132873535 / Valid loss: 5.931246621268136
Training loss: 6.001861095428467 / Valid loss: 5.930930085409255

Epoch: 19
Training loss: 5.187009334564209 / Valid loss: 5.919781855174473
Model is saved in epoch 19, overall batch: 9400
Training loss: 8.426803588867188 / Valid loss: 5.923086672737485
Training loss: 4.707317352294922 / Valid loss: 5.925490395228068
Training loss: 7.573236465454102 / Valid loss: 5.9196335429237
Model is saved in epoch 19, overall batch: 9700

Epoch: 20
Training loss: 5.379003524780273 / Valid loss: 5.918080173219953
Model is saved in epoch 20, overall batch: 9800
Training loss: 6.467043399810791 / Valid loss: 5.925782221839541
Training loss: 5.670929908752441 / Valid loss: 5.922256571905954
Training loss: 6.680147647857666 / Valid loss: 5.913141100747245
Model is saved in epoch 20, overall batch: 10100
Training loss: 5.653591156005859 / Valid loss: 5.916262292861939

Epoch: 21
Training loss: 6.824953079223633 / Valid loss: 5.917975546064831
Training loss: 5.100434303283691 / Valid loss: 5.921179108392625
Training loss: 5.709525108337402 / Valid loss: 5.9194612730117075
Training loss: 6.614285945892334 / Valid loss: 5.9185850597563245
Training loss: 4.567889213562012 / Valid loss: 5.918235910506476

Epoch: 22
Training loss: 7.410634994506836 / Valid loss: 5.912731479463123
Model is saved in epoch 22, overall batch: 10800
Training loss: 6.660888671875 / Valid loss: 5.912866585595268
Training loss: 5.225458145141602 / Valid loss: 5.9123710836683
Model is saved in epoch 22, overall batch: 11000
Training loss: 5.630494594573975 / Valid loss: 5.913310702641805
Training loss: 4.970524311065674 / Valid loss: 5.906619453430176
Model is saved in epoch 22, overall batch: 11200

Epoch: 23
Training loss: 5.4521613121032715 / Valid loss: 5.911107542401268
Training loss: 7.411023139953613 / Valid loss: 5.911992004939488
Training loss: 6.478480339050293 / Valid loss: 5.909901639393397
Training loss: 5.9072771072387695 / Valid loss: 5.91108132544018
Training loss: 5.316864490509033 / Valid loss: 5.908563420886085

Epoch: 24
Training loss: 5.141655921936035 / Valid loss: 5.907531270526705
Training loss: 6.416437149047852 / Valid loss: 5.901499932152884
Model is saved in epoch 24, overall batch: 11900
Training loss: 3.7152152061462402 / Valid loss: 5.9048634619939895
Training loss: 6.899860382080078 / Valid loss: 5.9022299039931525
Training loss: 5.8034820556640625 / Valid loss: 5.899966437476022
Model is saved in epoch 24, overall batch: 12200

Epoch: 25
Training loss: 5.266563892364502 / Valid loss: 5.895134244646345
Model is saved in epoch 25, overall batch: 12300
Training loss: 4.4269914627075195 / Valid loss: 5.901698525746664
Training loss: 7.535314559936523 / Valid loss: 5.9041909422193255
Training loss: 5.754476547241211 / Valid loss: 5.9000836372375485
Training loss: 6.190211296081543 / Valid loss: 5.893832990101406
Model is saved in epoch 25, overall batch: 12700

Epoch: 26
Training loss: 4.452482223510742 / Valid loss: 5.898263847260248
Training loss: 3.8799617290496826 / Valid loss: 5.899072699319749
Training loss: 5.108888149261475 / Valid loss: 5.897274212610154
Training loss: 5.854191303253174 / Valid loss: 5.8983590807233535
Training loss: 4.095089912414551 / Valid loss: 5.897111763272966

Epoch: 27
Training loss: 5.504939079284668 / Valid loss: 5.894587475912911
Training loss: 5.8385910987854 / Valid loss: 5.894506922222319
Training loss: 5.72952938079834 / Valid loss: 5.895987769535609
Training loss: 6.37205696105957 / Valid loss: 5.891858405158633
Model is saved in epoch 27, overall batch: 13600
Training loss: 6.557824611663818 / Valid loss: 5.888319821584792
Model is saved in epoch 27, overall batch: 13700

Epoch: 28
Training loss: 5.678814888000488 / Valid loss: 5.891935230436779
Training loss: 5.3992767333984375 / Valid loss: 5.884179880505516
Model is saved in epoch 28, overall batch: 13900
Training loss: 4.834161758422852 / Valid loss: 5.890512745721
Training loss: 6.42996883392334 / Valid loss: 5.883734085446313
Model is saved in epoch 28, overall batch: 14100
Training loss: 5.222161293029785 / Valid loss: 5.888733468736921

Epoch: 29
Training loss: 6.437051773071289 / Valid loss: 5.884501332328433
Training loss: 5.96113920211792 / Valid loss: 5.881782563527425
Model is saved in epoch 29, overall batch: 14400
Training loss: 6.635345935821533 / Valid loss: 5.884788406462897
Training loss: 6.2707061767578125 / Valid loss: 5.883510909761701

Epoch: 30
Training loss: 6.383345127105713 / Valid loss: 5.879212747301374
Model is saved in epoch 30, overall batch: 14700
Training loss: 6.1892547607421875 / Valid loss: 5.884919248308454
Training loss: 5.663574695587158 / Valid loss: 5.885546298254104
Training loss: 5.231940746307373 / Valid loss: 5.884535769053868
Training loss: 6.334755897521973 / Valid loss: 5.885033291862125

Epoch: 31
Training loss: 7.065471649169922 / Valid loss: 5.882654049282983
Training loss: 6.240786552429199 / Valid loss: 5.876942582357497
Model is saved in epoch 31, overall batch: 15300
Training loss: 6.011225700378418 / Valid loss: 5.8764953045617965
Model is saved in epoch 31, overall batch: 15400
Training loss: 7.166303634643555 / Valid loss: 5.880070836203439
Training loss: 7.373757362365723 / Valid loss: 5.873163084756761
Model is saved in epoch 31, overall batch: 15600

Epoch: 32
Training loss: 4.549452304840088 / Valid loss: 5.875726774760655
Training loss: 6.353355407714844 / Valid loss: 5.877273757117135
Training loss: 6.308059215545654 / Valid loss: 5.877142018363589
Training loss: 5.710290908813477 / Valid loss: 5.874617790040515
Training loss: 3.769893169403076 / Valid loss: 5.877451676414126

Epoch: 33
Training loss: 7.0919342041015625 / Valid loss: 5.875806971958705
Training loss: 4.067174434661865 / Valid loss: 5.872469350269863
Model is saved in epoch 33, overall batch: 16300
Training loss: 6.634932994842529 / Valid loss: 5.874169567653111
Training loss: 5.213997840881348 / Valid loss: 5.866764486403692
Model is saved in epoch 33, overall batch: 16500
Training loss: 7.601323127746582 / Valid loss: 5.87489025252206

Epoch: 34
Training loss: 5.410492897033691 / Valid loss: 5.8737227190108525
Training loss: 5.329509258270264 / Valid loss: 5.872398753393264
Training loss: 4.8996782302856445 / Valid loss: 5.864129114151001
Model is saved in epoch 34, overall batch: 16900
Training loss: 5.517840385437012 / Valid loss: 5.872045719055903
Training loss: 6.510210990905762 / Valid loss: 5.862417448134649
Model is saved in epoch 34, overall batch: 17100

Epoch: 35
Training loss: 5.689896583557129 / Valid loss: 5.866246559506371
Training loss: 5.638918876647949 / Valid loss: 5.86774351029169
Training loss: 5.863049507141113 / Valid loss: 5.86992564201355
Training loss: 8.378063201904297 / Valid loss: 5.862837289628528
Training loss: 7.89011812210083 / Valid loss: 5.853699318567911
Model is saved in epoch 35, overall batch: 17600

Epoch: 36
Training loss: 5.455414772033691 / Valid loss: 5.865546939486549
Training loss: 7.780214786529541 / Valid loss: 5.853013933272589
Model is saved in epoch 36, overall batch: 17800
Training loss: 4.770391464233398 / Valid loss: 5.86084645816258
Training loss: 5.007848739624023 / Valid loss: 5.866225022361392
Training loss: 4.28102970123291 / Valid loss: 5.865143632888794

Epoch: 37
Training loss: 4.621203422546387 / Valid loss: 5.862824367341541
Training loss: 5.598779678344727 / Valid loss: 5.863843936011905
Training loss: 5.615748405456543 / Valid loss: 5.85942785626366
Training loss: 5.7797532081604 / Valid loss: 5.853658019928705
Training loss: 5.420075416564941 / Valid loss: 5.855952857789539

Epoch: 38
Training loss: 4.519730091094971 / Valid loss: 5.857780906132289
Training loss: 6.457266807556152 / Valid loss: 5.8600417999994185
Training loss: 5.965558052062988 / Valid loss: 5.856905805496942
Training loss: 5.648101806640625 / Valid loss: 5.857809034983317
Training loss: 7.202353477478027 / Valid loss: 5.856153002239409

Epoch: 39
Training loss: 4.069289207458496 / Valid loss: 5.85680144627889
Training loss: 6.685877799987793 / Valid loss: 5.857815242948986
Training loss: 7.069761276245117 / Valid loss: 5.856225018274216
Training loss: 6.624588489532471 / Valid loss: 5.858062869026547

Epoch: 40
Training loss: 5.920740127563477 / Valid loss: 5.854515672865368
Training loss: 6.896755218505859 / Valid loss: 5.849477772485642
Model is saved in epoch 40, overall batch: 19700
Training loss: 5.552585601806641 / Valid loss: 5.853780076617286
Training loss: 4.840836524963379 / Valid loss: 5.84838369460333
Model is saved in epoch 40, overall batch: 19900
Training loss: 5.227177619934082 / Valid loss: 5.853035177503314

Epoch: 41
Training loss: 7.264985084533691 / Valid loss: 5.850073317119054
Training loss: 6.891146659851074 / Valid loss: 5.8525039582025435
Training loss: 5.5273237228393555 / Valid loss: 5.85345637911842
Training loss: 5.861797332763672 / Valid loss: 5.841851475125267
Model is saved in epoch 41, overall batch: 20400
Training loss: 6.208195209503174 / Valid loss: 5.848620142255511

Epoch: 42
Training loss: 4.328007698059082 / Valid loss: 5.846528729938325
Training loss: 4.780808448791504 / Valid loss: 5.850413522266206
Training loss: 6.13001823425293 / Valid loss: 5.8483768122536794
Training loss: 4.681596755981445 / Valid loss: 5.845044717334566
Training loss: 5.70655632019043 / Valid loss: 5.843722949709211

Epoch: 43
Training loss: 5.771530628204346 / Valid loss: 5.847735709235781
Training loss: 5.874582290649414 / Valid loss: 5.8454654443831675
Training loss: 5.881491661071777 / Valid loss: 5.841397873560587
Model is saved in epoch 43, overall batch: 21300
Training loss: 7.4990434646606445 / Valid loss: 5.845311941419329
Training loss: 5.634654521942139 / Valid loss: 5.843525589080084

Epoch: 44
Training loss: 5.588692665100098 / Valid loss: 5.839902173905146
Model is saved in epoch 44, overall batch: 21600
Training loss: 7.062654495239258 / Valid loss: 5.843715924308413
Training loss: 6.387399673461914 / Valid loss: 5.843026603971209
Training loss: 5.173698425292969 / Valid loss: 5.8354077248346234
Model is saved in epoch 44, overall batch: 21900
Training loss: 6.3955230712890625 / Valid loss: 5.834912095751081
Model is saved in epoch 44, overall batch: 22000

Epoch: 45
Training loss: 4.845252513885498 / Valid loss: 5.839431908017113
Training loss: 7.23906135559082 / Valid loss: 5.8341461862836566
Model is saved in epoch 45, overall batch: 22200
Training loss: 6.171627998352051 / Valid loss: 5.838806756337484
Training loss: 6.2771100997924805 / Valid loss: 5.8371567521776475
Training loss: 5.860687255859375 / Valid loss: 5.838730285281227

Epoch: 46
Training loss: 5.621417999267578 / Valid loss: 5.840150444848197
Training loss: 7.950531959533691 / Valid loss: 5.835131327311198
Training loss: 6.021021842956543 / Valid loss: 5.834110241844541
Model is saved in epoch 46, overall batch: 22800
Training loss: 5.582724571228027 / Valid loss: 5.835572444824946
Training loss: 5.368924140930176 / Valid loss: 5.837917782011486

Epoch: 47
Training loss: 5.140863418579102 / Valid loss: 5.830962424051194
Model is saved in epoch 47, overall batch: 23100
Training loss: 6.416699409484863 / Valid loss: 5.8368141651153564
Training loss: 6.89099645614624 / Valid loss: 5.830088190805345
Model is saved in epoch 47, overall batch: 23300
Training loss: 4.5013747215271 / Valid loss: 5.832887374787104
Training loss: 3.7257378101348877 / Valid loss: 5.837093198867072

Epoch: 48
Training loss: 5.005449295043945 / Valid loss: 5.835956237429664
Training loss: 4.970216751098633 / Valid loss: 5.83632374945141
Training loss: 6.3893890380859375 / Valid loss: 5.833249385016305
Training loss: 5.744738578796387 / Valid loss: 5.828750476383028
Model is saved in epoch 48, overall batch: 23900
Training loss: 6.227625846862793 / Valid loss: 5.831212552388509

Epoch: 49
Training loss: 5.247754096984863 / Valid loss: 5.824673593611944
Model is saved in epoch 49, overall batch: 24100
Training loss: 4.373211860656738 / Valid loss: 5.830925135385423
Training loss: 7.563295364379883 / Valid loss: 5.8234082812354675
Model is saved in epoch 49, overall batch: 24300
Training loss: 6.832947731018066 / Valid loss: 5.826375489007859

Epoch: 50
Training loss: 3.2930068969726562 / Valid loss: 5.8249315102895105
Training loss: 6.595808982849121 / Valid loss: 5.821512615113031
Model is saved in epoch 50, overall batch: 24600
Training loss: 6.1413493156433105 / Valid loss: 5.818472097033546
Model is saved in epoch 50, overall batch: 24700
Training loss: 4.79652214050293 / Valid loss: 5.828294259025937
Training loss: 6.251921653747559 / Valid loss: 5.829153365180606

Epoch: 51
Training loss: 5.585939407348633 / Valid loss: 5.828581794102987
Training loss: 5.233409881591797 / Valid loss: 5.8199779919215615
Training loss: 6.777070999145508 / Valid loss: 5.826768178031558
Training loss: 6.605839729309082 / Valid loss: 5.823111077717372
Training loss: 6.303018569946289 / Valid loss: 5.82707622391837

Epoch: 52
Training loss: 5.532478332519531 / Valid loss: 5.826423597335816
Training loss: 6.63646125793457 / Valid loss: 5.827599250702631
Training loss: 6.701969146728516 / Valid loss: 5.824710541679746
Training loss: 6.505318641662598 / Valid loss: 5.825255316779727
Training loss: 5.231315612792969 / Valid loss: 5.8106305690038775
Model is saved in epoch 52, overall batch: 25900

Epoch: 53
Training loss: 5.296020030975342 / Valid loss: 5.815416281563895
Training loss: 4.0688629150390625 / Valid loss: 5.822105668839955
Training loss: 5.463869094848633 / Valid loss: 5.822299489520845
Training loss: 5.755531311035156 / Valid loss: 5.817832649321783
Training loss: 4.612059116363525 / Valid loss: 5.8224644888015025

Epoch: 54
Training loss: 4.770751953125 / Valid loss: 5.817613315582276
Training loss: 6.642603874206543 / Valid loss: 5.817888702665057
Training loss: 5.858410835266113 / Valid loss: 5.815207980927967
Training loss: 6.2366790771484375 / Valid loss: 5.818154110227312
Training loss: 4.435853958129883 / Valid loss: 5.819369209380377

Epoch: 55
Training loss: 6.250114917755127 / Valid loss: 5.819729394004458
Training loss: 8.051299095153809 / Valid loss: 5.819229085104806
Training loss: 5.986092567443848 / Valid loss: 5.818276257742019
Training loss: 4.603002548217773 / Valid loss: 5.818077057883853
Training loss: 4.040999412536621 / Valid loss: 5.808141871861049
Model is saved in epoch 55, overall batch: 27400

Epoch: 56
Training loss: 5.542705535888672 / Valid loss: 5.818491011574155
Training loss: 6.613121509552002 / Valid loss: 5.810910118193854
Training loss: 5.730541706085205 / Valid loss: 5.814617897215344
Training loss: 5.221488952636719 / Valid loss: 5.813919083277384
Training loss: 5.202564239501953 / Valid loss: 5.8157036622365315

Epoch: 57
Training loss: 5.828924179077148 / Valid loss: 5.811681002662295
Training loss: 4.405109405517578 / Valid loss: 5.813127928688413
Training loss: 3.2606236934661865 / Valid loss: 5.814271545410156
Training loss: 5.329923629760742 / Valid loss: 5.812284251621791
Training loss: 5.583958148956299 / Valid loss: 5.808509751728603

Epoch: 58
Training loss: 5.941076755523682 / Valid loss: 5.811001927512033
Training loss: 4.433342933654785 / Valid loss: 5.812991074153355
Training loss: 7.037137985229492 / Valid loss: 5.811001975195748
Training loss: 5.330707550048828 / Valid loss: 5.811882432301839
Training loss: 5.386242866516113 / Valid loss: 5.80866714432126

Epoch: 59
Training loss: 4.650515079498291 / Valid loss: 5.810713813418434
Training loss: 6.917965888977051 / Valid loss: 5.811983907790411
Training loss: 6.390676021575928 / Valid loss: 5.803004675819761
Model is saved in epoch 59, overall batch: 29200
Training loss: 4.37251091003418 / Valid loss: 5.808643840608143

Epoch: 60
Training loss: 6.105746269226074 / Valid loss: 5.80047661009289
Model is saved in epoch 60, overall batch: 29400
Training loss: 5.380407333374023 / Valid loss: 5.8090748083023795
Training loss: 4.914412498474121 / Valid loss: 5.805377110980806
Training loss: 5.610429763793945 / Valid loss: 5.80672767502921
Training loss: 5.823728561401367 / Valid loss: 5.80495339575268

Epoch: 61
Training loss: 6.1685004234313965 / Valid loss: 5.807684589567638
Training loss: 5.640830993652344 / Valid loss: 5.798051084790911
Model is saved in epoch 61, overall batch: 30000
Training loss: 5.476574897766113 / Valid loss: 5.807346793583461
Training loss: 6.273373603820801 / Valid loss: 5.803529451006935
Training loss: 4.807555198669434 / Valid loss: 5.801960897445679

Epoch: 62
Training loss: 4.236104488372803 / Valid loss: 5.8062477293468655
Training loss: 6.768951416015625 / Valid loss: 5.806272997174944
Training loss: 6.547168731689453 / Valid loss: 5.804629151026408
Training loss: 5.343348026275635 / Valid loss: 5.804626700991676
Training loss: 5.28178071975708 / Valid loss: 5.799415745053973

Epoch: 63
Training loss: 7.150310039520264 / Valid loss: 5.801885988598778
Training loss: 5.466332912445068 / Valid loss: 5.802579134986514
Training loss: 5.536895751953125 / Valid loss: 5.804838260014852
Training loss: 5.864521026611328 / Valid loss: 5.801151212056478
Training loss: 4.269299030303955 / Valid loss: 5.79818723769415

Epoch: 64
Training loss: 5.741623878479004 / Valid loss: 5.794503770555768
Model is saved in epoch 64, overall batch: 31400
Training loss: 4.631345272064209 / Valid loss: 5.801827544257755
Training loss: 5.906818389892578 / Valid loss: 5.800114170710246
Training loss: 6.782815933227539 / Valid loss: 5.801662236168271
Training loss: 6.22806453704834 / Valid loss: 5.7963759808313275

Epoch: 65
Training loss: 6.210259437561035 / Valid loss: 5.793058849516369
Model is saved in epoch 65, overall batch: 31900
Training loss: 8.425519943237305 / Valid loss: 5.8003530706678115
Training loss: 5.953742980957031 / Valid loss: 5.797316087995257
Training loss: 5.411637306213379 / Valid loss: 5.791955884297689
Model is saved in epoch 65, overall batch: 32200
Training loss: 6.935503959655762 / Valid loss: 5.799501126153128

Epoch: 66
Training loss: 4.010647773742676 / Valid loss: 5.7991623742239815
Training loss: 3.646780014038086 / Valid loss: 5.79749467486427
Training loss: 6.015786170959473 / Valid loss: 5.792891652243478
Training loss: 3.9132771492004395 / Valid loss: 5.793927876154582
Training loss: 3.894629716873169 / Valid loss: 5.79768728528704

Epoch: 67
Training loss: 5.177248001098633 / Valid loss: 5.789054795673915
Model is saved in epoch 67, overall batch: 32900
Training loss: 6.229169845581055 / Valid loss: 5.793325333368211
Training loss: 7.550474643707275 / Valid loss: 5.791260015396845
Training loss: 4.781390190124512 / Valid loss: 5.786389752796718
Model is saved in epoch 67, overall batch: 33200
Training loss: 4.434802055358887 / Valid loss: 5.795944681621733

Epoch: 68
Training loss: 5.95619010925293 / Valid loss: 5.795078940618605
Training loss: 5.349498271942139 / Valid loss: 5.790155674162365
Training loss: 4.559398651123047 / Valid loss: 5.795568806784494
Training loss: 8.161531448364258 / Valid loss: 5.7958823067801335
Training loss: 5.796634674072266 / Valid loss: 5.79257919674828

Epoch: 69
Training loss: 6.468892574310303 / Valid loss: 5.793640779313587
Training loss: 5.524532318115234 / Valid loss: 5.788041516712734
Training loss: 6.183482646942139 / Valid loss: 5.7915501957847955
Training loss: 6.500092029571533 / Valid loss: 5.792618642534529

Epoch: 70
Training loss: 8.002997398376465 / Valid loss: 5.788951260702951
Training loss: 5.911128044128418 / Valid loss: 5.785283258983067
Model is saved in epoch 70, overall batch: 34400
Training loss: 6.237710475921631 / Valid loss: 5.790332462674096
Training loss: 5.9934186935424805 / Valid loss: 5.790958143415905
Training loss: 5.85045862197876 / Valid loss: 5.791487194242931

Epoch: 71
Training loss: 6.534406661987305 / Valid loss: 5.787391955511911
Training loss: 5.596440315246582 / Valid loss: 5.786161738350278
Training loss: 5.497341632843018 / Valid loss: 5.786891891842797
Training loss: 5.0917840003967285 / Valid loss: 5.782628935859317
Model is saved in epoch 71, overall batch: 35100
Training loss: 4.595545768737793 / Valid loss: 5.788892602920532

Epoch: 72
Training loss: 4.369632720947266 / Valid loss: 5.7816843441554475
Model is saved in epoch 72, overall batch: 35300
Training loss: 5.316349983215332 / Valid loss: 5.783032869157337
Training loss: 7.916530609130859 / Valid loss: 5.788051655178978
Training loss: 4.8274664878845215 / Valid loss: 5.7822684492383685
Training loss: 4.390622615814209 / Valid loss: 5.786141002745856

Epoch: 73
Training loss: 6.526596546173096 / Valid loss: 5.786469752447946
Training loss: 4.469805717468262 / Valid loss: 5.781469862801688
Model is saved in epoch 73, overall batch: 35900
Training loss: 5.814515113830566 / Valid loss: 5.7844712484450564
Training loss: 7.579878330230713 / Valid loss: 5.786026648112705
Training loss: 4.623595714569092 / Valid loss: 5.786625814437866

Epoch: 74
Training loss: 4.355653762817383 / Valid loss: 5.788122120357695
Training loss: 5.995327472686768 / Valid loss: 5.782140665962583
Training loss: 5.827637672424316 / Valid loss: 5.783781376339141
Training loss: 6.228045463562012 / Valid loss: 5.785689131418864
Training loss: 4.910393714904785 / Valid loss: 5.7843296936580115

Epoch: 75
Training loss: 4.672412395477295 / Valid loss: 5.778662960869926
Model is saved in epoch 75, overall batch: 36800
Training loss: 5.521819591522217 / Valid loss: 5.78434021132333
Training loss: 4.939126014709473 / Valid loss: 5.784763767605736
Training loss: 8.82532024383545 / Valid loss: 5.784828980763753
Training loss: 5.319674968719482 / Valid loss: 5.783317297980899

Epoch: 76
Training loss: 5.3749799728393555 / Valid loss: 5.7809565725780665
Training loss: 7.262038230895996 / Valid loss: 5.781592312313261
Training loss: 6.0654826164245605 / Valid loss: 5.780205183937436
Training loss: 6.154361724853516 / Valid loss: 5.782638785952614
Training loss: 5.488837242126465 / Valid loss: 5.7757047834850495
Model is saved in epoch 76, overall batch: 37700

Epoch: 77
Training loss: 6.475950717926025 / Valid loss: 5.781595591136387
Training loss: 5.4696855545043945 / Valid loss: 5.77349396433149
Model is saved in epoch 77, overall batch: 37900
Training loss: 6.00844669342041 / Valid loss: 5.771745733987718
Model is saved in epoch 77, overall batch: 38000
Training loss: 5.352922439575195 / Valid loss: 5.777652290889195
Training loss: 7.899835586547852 / Valid loss: 5.7772071543194

Epoch: 78
Training loss: 6.024864196777344 / Valid loss: 5.778974925904047
Training loss: 5.859951972961426 / Valid loss: 5.780766101110549
Training loss: 6.847758769989014 / Valid loss: 5.773954184850057
Training loss: 4.401461601257324 / Valid loss: 5.776043628510974
Training loss: 5.813926696777344 / Valid loss: 5.773607453845796

Epoch: 79
Training loss: 6.182010173797607 / Valid loss: 5.777158373878116
Training loss: 4.461409568786621 / Valid loss: 5.775560631070818
Training loss: 3.5910630226135254 / Valid loss: 5.777842678342547
Training loss: 5.179323196411133 / Valid loss: 5.776959419250488
ModuleList(
  (0): Linear(in_features=31191, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.625824140367054
Training regression with following parameters:
dnn_hidden_units : 2000, 100, 16
dropout_probs : 0.0, 0.0
learning_rate : 0.0001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : SGD
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : TFIDF
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=31191, out_features=2000, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=2000, out_features=100, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=100, out_features=16, bias=True)
  (9): Dropout(p=0, inplace=False)
  (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (11): LeakyReLU(negative_slope=0.02)
  (12): Linear(in_features=16, out_features=1, bias=True)
)

Epoch: 0
Training loss: 17.8549747467041 / Valid loss: 16.98556380498977
Model is saved in epoch 0, overall batch: 0
Training loss: 18.370113372802734 / Valid loss: 15.340080697195871
Model is saved in epoch 0, overall batch: 100
Training loss: 13.185138702392578 / Valid loss: 13.80259150550479
Model is saved in epoch 0, overall batch: 200
Training loss: 12.001442909240723 / Valid loss: 12.704903652554467
Model is saved in epoch 0, overall batch: 300
Training loss: 13.384450912475586 / Valid loss: 11.910566802251907
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 10.165295600891113 / Valid loss: 11.237153026035854
Model is saved in epoch 1, overall batch: 500
Training loss: 11.679250717163086 / Valid loss: 10.280351697830927
Model is saved in epoch 1, overall batch: 600
Training loss: 7.903110504150391 / Valid loss: 9.590142649695986
Model is saved in epoch 1, overall batch: 700
Training loss: 6.882466793060303 / Valid loss: 9.19304183324178
Model is saved in epoch 1, overall batch: 800
Training loss: 10.106756210327148 / Valid loss: 8.729997948237829
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 6.134425163269043 / Valid loss: 8.340457053411575
Model is saved in epoch 2, overall batch: 1000
Training loss: 3.792914390563965 / Valid loss: 8.014093707856677
Model is saved in epoch 2, overall batch: 1100
Training loss: 5.778932094573975 / Valid loss: 7.60834302448091
Model is saved in epoch 2, overall batch: 1200
Training loss: 2.9477624893188477 / Valid loss: 7.303108578636532
Model is saved in epoch 2, overall batch: 1300
Training loss: 3.168562889099121 / Valid loss: 7.109654887517293
Model is saved in epoch 2, overall batch: 1400

Epoch: 3
Training loss: 3.173264503479004 / Valid loss: 7.158758524485997
Training loss: 2.6434950828552246 / Valid loss: 7.101827730451311
Model is saved in epoch 3, overall batch: 1600
Training loss: 1.8282471895217896 / Valid loss: 6.836594904036749
Model is saved in epoch 3, overall batch: 1700
Training loss: 1.5270745754241943 / Valid loss: 6.875733757019043
Training loss: 2.0063443183898926 / Valid loss: 6.688943245297387
Model is saved in epoch 3, overall batch: 1900

Epoch: 4
Training loss: 1.8433536291122437 / Valid loss: 6.61872470946539
Model is saved in epoch 4, overall batch: 2000
Training loss: 1.1391552686691284 / Valid loss: 6.626638294401623
Training loss: 1.1635023355484009 / Valid loss: 6.676707088379633
Training loss: 1.1196995973587036 / Valid loss: 6.58306854338873
Model is saved in epoch 4, overall batch: 2300
Training loss: 1.3368487358093262 / Valid loss: 6.648300098237537

Epoch: 5
Training loss: 0.4252380132675171 / Valid loss: 6.516572216578893
Model is saved in epoch 5, overall batch: 2500
Training loss: 0.7159550189971924 / Valid loss: 6.533344309670585
Training loss: 1.4703669548034668 / Valid loss: 6.526197878519694
Training loss: 1.6784827709197998 / Valid loss: 6.530790017900013
Training loss: 0.6802353858947754 / Valid loss: 6.550676214127313

Epoch: 6
Training loss: 0.6197327375411987 / Valid loss: 6.477980173201788
Model is saved in epoch 6, overall batch: 3000
Training loss: 0.8964049220085144 / Valid loss: 6.536249680746169
Training loss: 0.35372763872146606 / Valid loss: 6.5600087915148055
Training loss: 0.7946569919586182 / Valid loss: 6.563232998620896
Training loss: 0.34663209319114685 / Valid loss: 6.5458472728729244

Epoch: 7
Training loss: 0.8550946712493896 / Valid loss: 6.525083925610497
Training loss: 0.7453943490982056 / Valid loss: 6.527510615757533
Training loss: 0.39168545603752136 / Valid loss: 6.571585114796957
Training loss: 0.4267999231815338 / Valid loss: 6.549433226812454
Training loss: 1.1288659572601318 / Valid loss: 6.523978919074649

Epoch: 8
Training loss: 0.46070432662963867 / Valid loss: 6.510628820600964
Training loss: 0.6823257207870483 / Valid loss: 6.504397810073126
Training loss: 0.6307380199432373 / Valid loss: 6.569669541858492
Training loss: 0.5396203398704529 / Valid loss: 6.546485167457944
Training loss: 0.35352426767349243 / Valid loss: 6.531038279760452

Epoch: 9
Training loss: 0.2726200819015503 / Valid loss: 6.567454905737014
Training loss: 1.0483996868133545 / Valid loss: 6.507191821507045
Training loss: 0.6121673583984375 / Valid loss: 6.552616151173909
Training loss: 0.2362561821937561 / Valid loss: 6.535988349006289

Epoch: 10
Training loss: 0.4214290976524353 / Valid loss: 6.539107540675572
Training loss: 0.41955068707466125 / Valid loss: 6.557010137467158
Training loss: 0.2752546966075897 / Valid loss: 6.536228724888393
Training loss: 0.4526573419570923 / Valid loss: 6.510861891791934
Training loss: 0.2695642411708832 / Valid loss: 6.56998081661406

Epoch: 11
Training loss: 0.3753533959388733 / Valid loss: 6.52697590192159
Training loss: 0.3025309443473816 / Valid loss: 6.547321324121384
Training loss: 0.24937397241592407 / Valid loss: 6.542750494820731
Training loss: 0.5038042664527893 / Valid loss: 6.522921453203474
Training loss: 0.3936828076839447 / Valid loss: 6.612915504546392

Epoch: 12
Training loss: 0.20578885078430176 / Valid loss: 6.538573564801897
Training loss: 0.24773162603378296 / Valid loss: 6.5285976750510075
Training loss: 0.2547236979007721 / Valid loss: 6.569824454897926
Training loss: 0.2599613666534424 / Valid loss: 6.491025039127895
Training loss: 0.38906633853912354 / Valid loss: 6.532849218731835

Epoch: 13
Training loss: 0.3045133948326111 / Valid loss: 6.516332699003674
Training loss: 0.22812509536743164 / Valid loss: 6.492844813210624
Training loss: 0.27403944730758667 / Valid loss: 6.541236314319429
Training loss: 0.32638150453567505 / Valid loss: 6.546971248445057
Training loss: 0.714805006980896 / Valid loss: 6.560262137367612

Epoch: 14
Training loss: 0.29038071632385254 / Valid loss: 6.564548524220784
Training loss: 0.4656299948692322 / Valid loss: 6.5020357131958
Training loss: 0.2993861436843872 / Valid loss: 6.530068066006615
Training loss: 0.29140472412109375 / Valid loss: 6.512060106368292
Training loss: 0.2461581826210022 / Valid loss: 6.561662612642561

Epoch: 15
Training loss: 0.22266429662704468 / Valid loss: 6.555382846650623
Training loss: 0.28422874212265015 / Valid loss: 6.514706879570371
Training loss: 0.32838380336761475 / Valid loss: 6.515558401743571
Training loss: 0.1878272145986557 / Valid loss: 6.504833616529193
Training loss: 0.256658136844635 / Valid loss: 6.503288761774699

Epoch: 16
Training loss: 0.18026408553123474 / Valid loss: 6.536466816493443
Training loss: 0.6491253972053528 / Valid loss: 6.538299905686151
Training loss: 0.31405216455459595 / Valid loss: 6.488456485384987
Training loss: 0.2587153911590576 / Valid loss: 6.517049766722179
Training loss: 0.3882025480270386 / Valid loss: 6.543700388499668

Epoch: 17
Training loss: 0.4183448553085327 / Valid loss: 6.520161290395827
Training loss: 0.16195863485336304 / Valid loss: 6.508191571916853
Training loss: 0.3081105649471283 / Valid loss: 6.512487420581636
Training loss: 0.2299260050058365 / Valid loss: 6.535898063296363
Training loss: 0.16415627300739288 / Valid loss: 6.4740097727094374
Model is saved in epoch 17, overall batch: 8800

Epoch: 18
Training loss: 0.22157783806324005 / Valid loss: 6.450747042610532
Model is saved in epoch 18, overall batch: 8900
Training loss: 0.4199223816394806 / Valid loss: 6.4749487717946375
Training loss: 0.22095832228660583 / Valid loss: 6.479025988351731
Training loss: 0.1961851418018341 / Valid loss: 6.504963952019101
Training loss: 0.13684430718421936 / Valid loss: 6.519014655976068

Epoch: 19
Training loss: 0.24346724152565002 / Valid loss: 6.50847780136835
Training loss: 0.1603989601135254 / Valid loss: 6.505388146355038
Training loss: 0.6471158266067505 / Valid loss: 6.500861113412039
Training loss: 0.23537002503871918 / Valid loss: 6.4955864361354285

Epoch: 20
Training loss: 0.16500991582870483 / Valid loss: 6.518994730994815
Training loss: 0.462313175201416 / Valid loss: 6.505985537029448
Training loss: 0.27497032284736633 / Valid loss: 6.5317993799845375
Training loss: 0.41870540380477905 / Valid loss: 6.525396256219773
Training loss: 0.16613250970840454 / Valid loss: 6.477399621691022

Epoch: 21
Training loss: 0.7254958748817444 / Valid loss: 6.462769585564023
Training loss: 0.3735070824623108 / Valid loss: 6.507798458281018
Training loss: 0.18391135334968567 / Valid loss: 6.484205750056676
Training loss: 0.1630585491657257 / Valid loss: 6.476019832066127
Training loss: 0.21875840425491333 / Valid loss: 6.4791796616145545

Epoch: 22
Training loss: 0.1989385485649109 / Valid loss: 6.452060077303932
Training loss: 0.5824438333511353 / Valid loss: 6.530228614807129
Training loss: 0.5913780927658081 / Valid loss: 6.447432636079334
Model is saved in epoch 22, overall batch: 11000
Training loss: 0.1601232886314392 / Valid loss: 6.478959914616176
Training loss: 0.3509606719017029 / Valid loss: 6.495483602796282

Epoch: 23
Training loss: 0.6464347839355469 / Valid loss: 6.4941468420482815
Training loss: 0.20340296626091003 / Valid loss: 6.494972531000773
Training loss: 0.29250192642211914 / Valid loss: 6.533006472814651
Training loss: 0.1499750316143036 / Valid loss: 6.484795677094232
Training loss: 0.16667941212654114 / Valid loss: 6.493798732757568

Epoch: 24
Training loss: 0.1410674899816513 / Valid loss: 6.495054937544323
Training loss: 0.24303536117076874 / Valid loss: 6.5056122870672315
Training loss: 0.2489725947380066 / Valid loss: 6.487123260043917
Training loss: 0.1383134424686432 / Valid loss: 6.472282886505127
Training loss: 0.575411319732666 / Valid loss: 6.489405786423456

Epoch: 25
Training loss: 0.09836581349372864 / Valid loss: 6.476819873991467
Training loss: 0.1880277395248413 / Valid loss: 6.467638894489833
Training loss: 0.17321884632110596 / Valid loss: 6.5037042436145605
Training loss: 0.14805446565151215 / Valid loss: 6.5021975721631735
Training loss: 0.3762005865573883 / Valid loss: 6.5044565064566475

Epoch: 26
Training loss: 0.10876487195491791 / Valid loss: 6.5190412657601495
Training loss: 0.6067630052566528 / Valid loss: 6.477501530874343
Training loss: 0.16401365399360657 / Valid loss: 6.4758728504180905
Training loss: 0.147501140832901 / Valid loss: 6.465357569285802
Training loss: 0.318827748298645 / Valid loss: 6.493346925008865

Epoch: 27
Training loss: 0.1280927211046219 / Valid loss: 6.478040259225028
Training loss: 0.30351465940475464 / Valid loss: 6.513642815181187
Training loss: 0.41839706897735596 / Valid loss: 6.453796897615705
Training loss: 0.12894724309444427 / Valid loss: 6.4824866181328185
Training loss: 0.1717366874217987 / Valid loss: 6.5008357184273855

Epoch: 28
Training loss: 0.20611967146396637 / Valid loss: 6.475346653802054
Training loss: 0.33824294805526733 / Valid loss: 6.472626490820022
Training loss: 0.2120530903339386 / Valid loss: 6.483093520573207
Training loss: 0.18629056215286255 / Valid loss: 6.493287981124151
Training loss: 0.1206226795911789 / Valid loss: 6.5012575694492885

Epoch: 29
Training loss: 0.1448749303817749 / Valid loss: 6.481495612008231
Training loss: 0.15795111656188965 / Valid loss: 6.466691852751232
Training loss: 0.218043252825737 / Valid loss: 6.479352810269311
Training loss: 0.37101539969444275 / Valid loss: 6.462135605585008

Epoch: 30
Training loss: 0.15895915031433105 / Valid loss: 6.481715429396856
Training loss: 0.791946530342102 / Valid loss: 6.49113994098845
Training loss: 0.3178529739379883 / Valid loss: 6.457227965763637
Training loss: 0.3138923645019531 / Valid loss: 6.448910710925148
Training loss: 0.5159896612167358 / Valid loss: 6.467713717051915

Epoch: 31
Training loss: 0.15352864563465118 / Valid loss: 6.471227164495559
Training loss: 0.09960923343896866 / Valid loss: 6.466575799669538
Training loss: 0.25172117352485657 / Valid loss: 6.457184705280122
Training loss: 0.1680365949869156 / Valid loss: 6.44765000570388
Training loss: 0.15826363861560822 / Valid loss: 6.468280524299258

Epoch: 32
Training loss: 0.1493188440799713 / Valid loss: 6.44580857640221
Model is saved in epoch 32, overall batch: 15700
Training loss: 0.2801123857498169 / Valid loss: 6.46331345240275
Training loss: 0.1470702886581421 / Valid loss: 6.494486279714675
Training loss: 0.21457889676094055 / Valid loss: 6.494426631927491
Training loss: 0.13543006777763367 / Valid loss: 6.456940501076835

Epoch: 33
Training loss: 0.22468173503875732 / Valid loss: 6.468519033704485
Training loss: 0.18491041660308838 / Valid loss: 6.465248562040783
Training loss: 0.15967857837677002 / Valid loss: 6.457359613691057
Training loss: 0.11748937517404556 / Valid loss: 6.465940107618059
Training loss: 0.11631427705287933 / Valid loss: 6.486858445122128

Epoch: 34
Training loss: 0.18198204040527344 / Valid loss: 6.472251764933268
Training loss: 0.12389377504587173 / Valid loss: 6.467126451219831
Training loss: 0.16183750331401825 / Valid loss: 6.464357069560459
Training loss: 0.19244161248207092 / Valid loss: 6.515034525735038
Training loss: 0.5891260504722595 / Valid loss: 6.488967214311872

Epoch: 35
Training loss: 0.20429065823554993 / Valid loss: 6.44347299848284
Model is saved in epoch 35, overall batch: 17200
Training loss: 0.08835754543542862 / Valid loss: 6.468864867800758
Training loss: 0.11206720769405365 / Valid loss: 6.464025229499454
Training loss: 0.3783785104751587 / Valid loss: 6.459338288080125
Training loss: 0.1697022020816803 / Valid loss: 6.480156321752639

Epoch: 36
Training loss: 0.23789264261722565 / Valid loss: 6.480351211911156
Training loss: 0.2948715388774872 / Valid loss: 6.4834325336274645
Training loss: 0.5494040250778198 / Valid loss: 6.4501764229365754
Training loss: 0.43937504291534424 / Valid loss: 6.467038738159906
Training loss: 0.1416187584400177 / Valid loss: 6.463662088484991

Epoch: 37
Training loss: 0.12032616138458252 / Valid loss: 6.448568257831392
Training loss: 0.19505345821380615 / Valid loss: 6.460305590856643
Training loss: 0.2802160978317261 / Valid loss: 6.494084505807786
Training loss: 0.6136621236801147 / Valid loss: 6.474836151940482
Training loss: 0.52783203125 / Valid loss: 6.4520733878726055

Epoch: 38
Training loss: 0.20711086690425873 / Valid loss: 6.473358174732753
Training loss: 0.11879950761795044 / Valid loss: 6.458061515717279
Training loss: 0.3179648518562317 / Valid loss: 6.488639286586216
Training loss: 0.2329045981168747 / Valid loss: 6.480762654259092
Training loss: 0.4510064721107483 / Valid loss: 6.485677369435629

Epoch: 39
Training loss: 0.11106035113334656 / Valid loss: 6.468939781188965
Training loss: 0.223942831158638 / Valid loss: 6.48672962415786
Training loss: 0.1438540816307068 / Valid loss: 6.4853340375991095
Training loss: 0.18217574059963226 / Valid loss: 6.476154213859921

Epoch: 40
Training loss: 0.18551044166088104 / Valid loss: 6.480159516561599
Training loss: 0.9590634703636169 / Valid loss: 6.45960875238691
Training loss: 0.4844583570957184 / Valid loss: 6.467883895692371
Training loss: 0.4608296751976013 / Valid loss: 6.4985667433057515
Training loss: 0.1146552562713623 / Valid loss: 6.467836679731096

Epoch: 41
Training loss: 0.10564257204532623 / Valid loss: 6.483576007116408
Training loss: 0.14618001878261566 / Valid loss: 6.483354727427165
Training loss: 0.14109405875205994 / Valid loss: 6.503360825493222
Training loss: 0.25943124294281006 / Valid loss: 6.473717816670736
Training loss: 0.5469664335250854 / Valid loss: 6.4423445610773
Model is saved in epoch 41, overall batch: 20500

Epoch: 42
Training loss: 0.1160450279712677 / Valid loss: 6.456561558587211
Training loss: 0.14350709319114685 / Valid loss: 6.448466841379801
Training loss: 0.13340634107589722 / Valid loss: 6.454238825752622
Training loss: 0.09078242629766464 / Valid loss: 6.4546303453899565
Training loss: 0.15958742797374725 / Valid loss: 6.461073739188058

Epoch: 43
Training loss: 0.10423588752746582 / Valid loss: 6.477104618435814
Training loss: 0.12161882221698761 / Valid loss: 6.443486626942953
Training loss: 0.13303032517433167 / Valid loss: 6.465732871918451
Training loss: 0.2150389403104782 / Valid loss: 6.459249362491426
Training loss: 0.1348862200975418 / Valid loss: 6.4696176233745755

Epoch: 44
Training loss: 0.13848868012428284 / Valid loss: 6.457241639636812
Training loss: 0.22102943062782288 / Valid loss: 6.443383866264707
Training loss: 0.5568093061447144 / Valid loss: 6.474284953162783
Training loss: 0.3084206283092499 / Valid loss: 6.463877904982794
Training loss: 0.10520614683628082 / Valid loss: 6.478190864835467

Epoch: 45
Training loss: 0.07584299892187119 / Valid loss: 6.473202700841995
Training loss: 0.09617681801319122 / Valid loss: 6.439106400807699
Model is saved in epoch 45, overall batch: 22200
Training loss: 0.3274400234222412 / Valid loss: 6.420481731778099
Model is saved in epoch 45, overall batch: 22300
Training loss: 0.12427572160959244 / Valid loss: 6.475934142158145
Training loss: 0.10129404067993164 / Valid loss: 6.465504401070731

Epoch: 46
Training loss: 0.18185263872146606 / Valid loss: 6.487043769018991
Training loss: 0.1650073528289795 / Valid loss: 6.457980637323288
Training loss: 0.1119467243552208 / Valid loss: 6.427966833114624
Training loss: 0.3181784152984619 / Valid loss: 6.43830993061974
Training loss: 0.1129867359995842 / Valid loss: 6.452705374218168

Epoch: 47
Training loss: 0.07652157545089722 / Valid loss: 6.442469110943022
Training loss: 0.14476779103279114 / Valid loss: 6.476781352361043
Training loss: 0.2460973560810089 / Valid loss: 6.448199406124297
Training loss: 0.04931444302201271 / Valid loss: 6.468805256344023
Training loss: 0.15409299731254578 / Valid loss: 6.465905362083799

Epoch: 48
Training loss: 0.5227092504501343 / Valid loss: 6.488556752886091
Training loss: 0.3884962499141693 / Valid loss: 6.448292927514939
Training loss: 0.2013857662677765 / Valid loss: 6.461649744851249
Training loss: 0.2648719251155853 / Valid loss: 6.459068495886666
Training loss: 0.08029109239578247 / Valid loss: 6.475697887511481

Epoch: 49
Training loss: 0.30347245931625366 / Valid loss: 6.469752139136904
Training loss: 0.20859672129154205 / Valid loss: 6.494584324246361
Training loss: 0.17561502754688263 / Valid loss: 6.44720709664481
Training loss: 0.19910986721515656 / Valid loss: 6.447992356618245

Epoch: 50
Training loss: 0.21130403876304626 / Valid loss: 6.471002901168097
Training loss: 0.08158417046070099 / Valid loss: 6.472214378629412
Training loss: 0.08366645872592926 / Valid loss: 6.481156555811564
Training loss: 0.709281325340271 / Valid loss: 6.476803720565069
Training loss: 0.0995408296585083 / Valid loss: 6.462550408499581

Epoch: 51
Training loss: 0.1084212064743042 / Valid loss: 6.437323901766822
Training loss: 0.47303062677383423 / Valid loss: 6.455843528111775
Training loss: 0.15006005764007568 / Valid loss: 6.448064408983503
Training loss: 0.1664130836725235 / Valid loss: 6.460677492050897
Training loss: 0.09961536526679993 / Valid loss: 6.458806019737607

Epoch: 52
Training loss: 0.26282674074172974 / Valid loss: 6.465322610310146
Training loss: 0.24924513697624207 / Valid loss: 6.449284455889747
Training loss: 0.25627171993255615 / Valid loss: 6.504180758340018
Training loss: 0.14008548855781555 / Valid loss: 6.462992148172288
Training loss: 0.17736497521400452 / Valid loss: 6.445466037023635

Epoch: 53
Training loss: 0.10823197662830353 / Valid loss: 6.431542807533628
Training loss: 0.20341810584068298 / Valid loss: 6.436177401315598
Training loss: 0.1408359259366989 / Valid loss: 6.460292262122745
Training loss: 0.1368207335472107 / Valid loss: 6.457767681848435
Training loss: 0.8236707448959351 / Valid loss: 6.455409694853283

Epoch: 54
Training loss: 0.12573157250881195 / Valid loss: 6.464787088121686
Training loss: 0.23411455750465393 / Valid loss: 6.460683724993751
Training loss: 0.10563233494758606 / Valid loss: 6.4681152207510815
Training loss: 0.0946485698223114 / Valid loss: 6.467520738783337
Training loss: 0.13755083084106445 / Valid loss: 6.448295298076811

Epoch: 55
Training loss: 0.10717735439538956 / Valid loss: 6.495031175159273
Training loss: 0.0821864902973175 / Valid loss: 6.467850930350167
Training loss: 0.13803261518478394 / Valid loss: 6.467135315849667
Training loss: 0.09568966180086136 / Valid loss: 6.480751232873826
Training loss: 0.10215847194194794 / Valid loss: 6.4619786716642835

Epoch: 56
Training loss: 0.2397591769695282 / Valid loss: 6.4455671355837865
Training loss: 0.1925627738237381 / Valid loss: 6.443116821561541
Training loss: 0.13557560741901398 / Valid loss: 6.457285149892171
Training loss: 0.22156408429145813 / Valid loss: 6.474554109573364
Training loss: 0.12291139364242554 / Valid loss: 6.451732456116449

Epoch: 57
Training loss: 0.09629341214895248 / Valid loss: 6.4834698268345425
Training loss: 0.1308232545852661 / Valid loss: 6.457845558438982
Training loss: 0.23137634992599487 / Valid loss: 6.475183795747303
Training loss: 0.08135031163692474 / Valid loss: 6.455946817852202
Training loss: 0.3237784504890442 / Valid loss: 6.463139960879372

Epoch: 58
Training loss: 0.09581682831048965 / Valid loss: 6.443270808174496
Training loss: 0.10920433700084686 / Valid loss: 6.463519954681397
Training loss: 0.10417485237121582 / Valid loss: 6.476743064607892
Training loss: 0.15593644976615906 / Valid loss: 6.475958912713187
Training loss: 0.12892131507396698 / Valid loss: 6.457478486923945

Epoch: 59
Training loss: 0.4641418159008026 / Valid loss: 6.4784462406521754
Training loss: 0.13597118854522705 / Valid loss: 6.458104167665754
Training loss: 0.12014031410217285 / Valid loss: 6.472321035748436
Training loss: 0.1460595726966858 / Valid loss: 6.474192687443325

Epoch: 60
Training loss: 0.28695446252822876 / Valid loss: 6.4681071780976795
Training loss: 0.1216547042131424 / Valid loss: 6.460287398383731
Training loss: 0.13187915086746216 / Valid loss: 6.46096279053461
Training loss: 0.20241037011146545 / Valid loss: 6.431400458017985
Training loss: 0.09428751468658447 / Valid loss: 6.494175547645206

Epoch: 61
Training loss: 0.09110257029533386 / Valid loss: 6.448775423140753
Training loss: 0.1034262478351593 / Valid loss: 6.4571080525716145
Training loss: 0.3586730659008026 / Valid loss: 6.473393521990094
Training loss: 0.36194953322410583 / Valid loss: 6.4609673318408785
Training loss: 0.6353868842124939 / Valid loss: 6.482279981885638

Epoch: 62
Training loss: 0.1624595671892166 / Valid loss: 6.46115954489935
Training loss: 0.07773485779762268 / Valid loss: 6.436139195305961
Training loss: 0.39649099111557007 / Valid loss: 6.451899982634044
Training loss: 0.06539909541606903 / Valid loss: 6.483729144505092
Training loss: 0.0929572582244873 / Valid loss: 6.4438851401919415

Epoch: 63
Training loss: 0.09925726056098938 / Valid loss: 6.47875344866798
Training loss: 0.07314424216747284 / Valid loss: 6.450132036209107
Training loss: 0.5087947845458984 / Valid loss: 6.4469813505808515
Training loss: 0.09922994673252106 / Valid loss: 6.43621244430542
Training loss: 0.1554083526134491 / Valid loss: 6.467621306010655

Epoch: 64
Training loss: 0.27064138650894165 / Valid loss: 6.434547426587059
Training loss: 0.45234349370002747 / Valid loss: 6.461055385498773
Training loss: 0.08992032706737518 / Valid loss: 6.447155234927223
Training loss: 0.07764554023742676 / Valid loss: 6.456177252814883
Training loss: 0.4546194076538086 / Valid loss: 6.4518915607815694

Epoch: 65
Training loss: 0.054290540516376495 / Valid loss: 6.469739382607596
Training loss: 0.12725578248500824 / Valid loss: 6.472669462930589
Training loss: 0.06658223271369934 / Valid loss: 6.452049477895101
Training loss: 0.1048545092344284 / Valid loss: 6.446928650992257
Training loss: 0.1847078651189804 / Valid loss: 6.4615364415305

Epoch: 66
Training loss: 0.0887763500213623 / Valid loss: 6.44133315994626
Training loss: 0.0764179453253746 / Valid loss: 6.452101071675618
Training loss: 0.16718417406082153 / Valid loss: 6.435592694509597
Training loss: 0.08101777732372284 / Valid loss: 6.4447522072564984
Training loss: 0.1178622767329216 / Valid loss: 6.444435135523478

Epoch: 67
Training loss: 0.15902270376682281 / Valid loss: 6.462652038392567
Training loss: 0.2412591278553009 / Valid loss: 6.459688132149832
Training loss: 0.1453690230846405 / Valid loss: 6.438159129733131
Training loss: 0.1499992311000824 / Valid loss: 6.455958838689895
Training loss: 0.08851432800292969 / Valid loss: 6.455649711972192

Epoch: 68
Training loss: 0.42606693506240845 / Valid loss: 6.449140764418102
Training loss: 0.15946799516677856 / Valid loss: 6.416962305704753
Model is saved in epoch 68, overall batch: 33500
Training loss: 0.17813794314861298 / Valid loss: 6.487009200595674
Training loss: 0.16518452763557434 / Valid loss: 6.480107321058001
Training loss: 0.13061323761940002 / Valid loss: 6.445795022873652

Epoch: 69
Training loss: 0.15410752594470978 / Valid loss: 6.456231269382295
Training loss: 0.3493345379829407 / Valid loss: 6.474803606669108
Training loss: 0.29175466299057007 / Valid loss: 6.465145933060419
Training loss: 0.8538776636123657 / Valid loss: 6.4614944185529435

Epoch: 70
Training loss: 0.08111748099327087 / Valid loss: 6.450927334740048
Training loss: 0.0896911695599556 / Valid loss: 6.427534805025373
Training loss: 0.0798538476228714 / Valid loss: 6.449971936997914
Training loss: 0.09208880364894867 / Valid loss: 6.44862307593936
Training loss: 0.41136589646339417 / Valid loss: 6.484552106403169

Epoch: 71
Training loss: 0.12402568757534027 / Valid loss: 6.447694297063919
Training loss: 0.2648687958717346 / Valid loss: 6.432246285393124
Training loss: 0.12592391669750214 / Valid loss: 6.432012181054978
Training loss: 0.3028850555419922 / Valid loss: 6.443264448075068
Training loss: 0.33124998211860657 / Valid loss: 6.4718084744044715

Epoch: 72
Training loss: 0.053826164454221725 / Valid loss: 6.45082421756926
Training loss: 0.0685739740729332 / Valid loss: 6.44616329783485
Training loss: 0.12769682705402374 / Valid loss: 6.417655390784854
Training loss: 0.05197557806968689 / Valid loss: 6.432759748186384
Training loss: 0.12387844175100327 / Valid loss: 6.436377457209995

Epoch: 73
Training loss: 0.10992853343486786 / Valid loss: 6.457133520217169
Training loss: 0.49728062748908997 / Valid loss: 6.453147695178077
Training loss: 0.18261176347732544 / Valid loss: 6.435451207842146
Training loss: 0.11736205965280533 / Valid loss: 6.427728387287685
Training loss: 0.14387525618076324 / Valid loss: 6.4063686189197355
Model is saved in epoch 73, overall batch: 36200

Epoch: 74
Training loss: 0.17055565118789673 / Valid loss: 6.443680785951161
Training loss: 0.12020466476678848 / Valid loss: 6.433734457833427
Training loss: 0.15142060816287994 / Valid loss: 6.433587844031198
Training loss: 0.06738946586847305 / Valid loss: 6.433474481673468
Training loss: 0.3233244717121124 / Valid loss: 6.414418306804839

Epoch: 75
Training loss: 0.24483785033226013 / Valid loss: 6.436383061181932
Training loss: 0.13401098549365997 / Valid loss: 6.445360190527779
Training loss: 0.08495642989873886 / Valid loss: 6.419905798775809
Training loss: 0.08404310047626495 / Valid loss: 6.446123672667004
Training loss: 0.09634169936180115 / Valid loss: 6.475355765933082

Epoch: 76
Training loss: 0.08388591557741165 / Valid loss: 6.421750391097296
Training loss: 0.09286373853683472 / Valid loss: 6.455199032738095
Training loss: 0.12628623843193054 / Valid loss: 6.429620963051206
Training loss: 0.08863693475723267 / Valid loss: 6.4509350753965835
Training loss: 0.20610138773918152 / Valid loss: 6.424311681020828

Epoch: 77
Training loss: 0.06798411905765533 / Valid loss: 6.441494932628813
Training loss: 0.1843748837709427 / Valid loss: 6.453848984127953
Training loss: 0.0633288025856018 / Valid loss: 6.43877889088222
Training loss: 0.1746596395969391 / Valid loss: 6.436437134515671
Training loss: 0.3635207414627075 / Valid loss: 6.443535995483399

Epoch: 78
Training loss: 0.15214858949184418 / Valid loss: 6.4439930166516985
Training loss: 0.10754978656768799 / Valid loss: 6.42868529955546
Training loss: 0.12115471065044403 / Valid loss: 6.436204331261771
Training loss: 0.08725806325674057 / Valid loss: 6.42247482481457
Training loss: 0.11657287180423737 / Valid loss: 6.449829303650629

Epoch: 79
Training loss: 0.14595720171928406 / Valid loss: 6.431986272902716
Training loss: 0.10770805180072784 / Valid loss: 6.4533056622459775
Training loss: 0.16463300585746765 / Valid loss: 6.451318386622837
Training loss: 0.15877589583396912 / Valid loss: 6.458436720711845
ModuleList(
  (0): Linear(in_features=31191, out_features=2000, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=2000, out_features=100, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=100, out_features=16, bias=True)
  (9): Dropout(p=0, inplace=False)
  (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (11): LeakyReLU(negative_slope=0.02)
  (12): Linear(in_features=16, out_features=1, bias=True)
)
Loss on test set of optimal model: 6.269796666644869
Training regression with following parameters:
dnn_hidden_units : 300, 32
dropout_probs : 0.0, 0.0
learning_rate : 0.0001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : SGD
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : TFIDF
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=31191, out_features=300, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=300, out_features=32, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=32, out_features=1, bias=True)
)

Epoch: 0
Training loss: 14.313697814941406 / Valid loss: 15.750787707737514
Model is saved in epoch 0, overall batch: 0
Training loss: 13.752546310424805 / Valid loss: 14.405622600373768
Model is saved in epoch 0, overall batch: 100
Training loss: 11.14582633972168 / Valid loss: 11.973171179635184
Model is saved in epoch 0, overall batch: 200
Training loss: 5.633367538452148 / Valid loss: 10.573150157928467
Model is saved in epoch 0, overall batch: 300
Training loss: 6.242633819580078 / Valid loss: 9.49334682737078
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 6.383338451385498 / Valid loss: 8.690422039940243
Model is saved in epoch 1, overall batch: 500
Training loss: 6.363702774047852 / Valid loss: 8.08421214194525
Model is saved in epoch 1, overall batch: 600
Training loss: 7.9695892333984375 / Valid loss: 7.488432264328003
Model is saved in epoch 1, overall batch: 700
Training loss: 5.717494010925293 / Valid loss: 7.145680970237368
Model is saved in epoch 1, overall batch: 800
Training loss: 6.082059860229492 / Valid loss: 6.819272599901471
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 4.602254390716553 / Valid loss: 6.561888926369804
Model is saved in epoch 2, overall batch: 1000
Training loss: 2.746220588684082 / Valid loss: 6.455680561065674
Model is saved in epoch 2, overall batch: 1100
Training loss: 3.0845818519592285 / Valid loss: 6.213856106712704
Model is saved in epoch 2, overall batch: 1200
Training loss: 2.7944390773773193 / Valid loss: 6.18115431467692
Model is saved in epoch 2, overall batch: 1300
Training loss: 4.1701812744140625 / Valid loss: 6.10920862924485
Model is saved in epoch 2, overall batch: 1400

Epoch: 3
Training loss: 1.7566957473754883 / Valid loss: 6.012586098625547
Model is saved in epoch 3, overall batch: 1500
Training loss: 4.1448163986206055 / Valid loss: 6.066099207741874
Training loss: 3.447523355484009 / Valid loss: 5.997189092636108
Model is saved in epoch 3, overall batch: 1700
Training loss: 3.219184398651123 / Valid loss: 6.0307287579491025
Training loss: 3.5760350227355957 / Valid loss: 6.013129942757743

Epoch: 4
Training loss: 2.228712558746338 / Valid loss: 6.015640538079398
Training loss: 2.5953149795532227 / Valid loss: 6.0493231296539305
Training loss: 1.2539929151535034 / Valid loss: 6.092184168951852
Training loss: 1.6321380138397217 / Valid loss: 6.095207105364119
Training loss: 2.3774499893188477 / Valid loss: 6.159315583819435

Epoch: 5
Training loss: 1.2093205451965332 / Valid loss: 6.172594769795736
Training loss: 1.4256410598754883 / Valid loss: 6.2494941507067
Training loss: 1.5833646059036255 / Valid loss: 6.17278261638823
Training loss: 1.7834670543670654 / Valid loss: 6.241609773181733
Training loss: 1.4026157855987549 / Valid loss: 6.309804178419567

Epoch: 6
Training loss: 0.8246713876724243 / Valid loss: 6.314627179645357
Training loss: 1.2732572555541992 / Valid loss: 6.295249775477818
Training loss: 1.0804553031921387 / Valid loss: 6.411928447087606
Training loss: 1.018450140953064 / Valid loss: 6.379608762831915
Training loss: 0.9891133308410645 / Valid loss: 6.285004522686913

Epoch: 7
Training loss: 0.6184753179550171 / Valid loss: 6.3062852723257885
Training loss: 0.7885041236877441 / Valid loss: 6.450902116866339
Training loss: 0.7559316158294678 / Valid loss: 6.363743143989926
Training loss: 0.9045659303665161 / Valid loss: 6.519769791194371
Training loss: 0.8763160705566406 / Valid loss: 6.439106695992606

Epoch: 8
Training loss: 0.46226269006729126 / Valid loss: 6.394025384812128
Training loss: 0.5564277768135071 / Valid loss: 6.52365114802406
Training loss: 0.6284992694854736 / Valid loss: 6.52551531791687
Training loss: 0.3954620957374573 / Valid loss: 6.4662885643187025
Training loss: 1.1482419967651367 / Valid loss: 6.500650921322051

Epoch: 9
Training loss: 0.3778538107872009 / Valid loss: 6.499136847541446
Training loss: 0.5603505969047546 / Valid loss: 6.446508189610072
Training loss: 0.6609920263290405 / Valid loss: 6.526913227353777
Training loss: 1.2666382789611816 / Valid loss: 6.637362078257969

Epoch: 10
Training loss: 0.3804243206977844 / Valid loss: 6.65226407505217
Training loss: 0.4967244565486908 / Valid loss: 6.574392012187412
Training loss: 0.6021715402603149 / Valid loss: 6.570822461446126
Training loss: 0.3410438299179077 / Valid loss: 6.592532830011277
Training loss: 0.40094777941703796 / Valid loss: 6.651630819411505

Epoch: 11
Training loss: 0.32740145921707153 / Valid loss: 6.612642088390532
Training loss: 0.3443498909473419 / Valid loss: 6.629819929032099
Training loss: 0.38977736234664917 / Valid loss: 6.555317124866304
Training loss: 0.34772324562072754 / Valid loss: 6.706615168707711
Training loss: 1.1562151908874512 / Valid loss: 6.578774620237804

Epoch: 12
Training loss: 0.21552705764770508 / Valid loss: 6.659227323532105
Training loss: 0.2816885709762573 / Valid loss: 6.618158794584728
Training loss: 0.27889835834503174 / Valid loss: 6.795573874882289
Training loss: 0.6717449426651001 / Valid loss: 6.711517542884463
Training loss: 0.4888050854206085 / Valid loss: 6.742281870614915

Epoch: 13
Training loss: 0.6212354898452759 / Valid loss: 6.5133444127582365
Training loss: 0.2971513867378235 / Valid loss: 6.753168918972924
Training loss: 0.2808924913406372 / Valid loss: 6.669435003825597
Training loss: 0.2605229914188385 / Valid loss: 6.744390692029681
Training loss: 0.2855417728424072 / Valid loss: 6.654867612747919

Epoch: 14
Training loss: 0.09443530440330505 / Valid loss: 6.657351902553013
Training loss: 0.4231594204902649 / Valid loss: 6.7547127042497905
Training loss: 0.2658184766769409 / Valid loss: 6.609062494550432
Training loss: 0.35920578241348267 / Valid loss: 6.791040475027902
Training loss: 0.20278742909431458 / Valid loss: 6.798218531835647

Epoch: 15
Training loss: 0.432992160320282 / Valid loss: 6.692450714111328
Training loss: 0.1466618925333023 / Valid loss: 6.785474032447452
Training loss: 0.7693497538566589 / Valid loss: 6.71878080368042
Training loss: 0.42286422848701477 / Valid loss: 6.7291195142836795
Training loss: 1.319852352142334 / Valid loss: 6.663879376366025

Epoch: 16
Training loss: 0.13725125789642334 / Valid loss: 6.76636594136556
Training loss: 0.5221652984619141 / Valid loss: 6.706967796598162
Training loss: 0.48641639947891235 / Valid loss: 6.894375240235101
Training loss: 0.5058994293212891 / Valid loss: 6.840947114853632
Training loss: 0.25608178973197937 / Valid loss: 6.7390573229108535

Epoch: 17
Training loss: 0.1918836385011673 / Valid loss: 6.732087512243361
Training loss: 0.16115032136440277 / Valid loss: 6.688383633749826
Training loss: 0.24326539039611816 / Valid loss: 6.753077202751523
Training loss: 0.3776237964630127 / Valid loss: 6.782034987495059
Training loss: 0.19001097977161407 / Valid loss: 6.792935711996896

Epoch: 18
Training loss: 0.16935400664806366 / Valid loss: 6.828193771271478
Training loss: 0.2556479275226593 / Valid loss: 6.726686709267753
Training loss: 0.2290678322315216 / Valid loss: 6.742220236006237
Training loss: 0.24588845670223236 / Valid loss: 6.733175382160005
Training loss: 0.15663334727287292 / Valid loss: 6.660536066691081

Epoch: 19
Training loss: 0.32233622670173645 / Valid loss: 6.717272588184902
Training loss: 0.23451274633407593 / Valid loss: 6.769136544636318
Training loss: 0.19198091328144073 / Valid loss: 6.760413978213355
Training loss: 0.22626206278800964 / Valid loss: 6.906043645313808

Epoch: 20
Training loss: 0.2860901951789856 / Valid loss: 6.811398469834101
Training loss: 0.1845875084400177 / Valid loss: 6.805179936545236
Training loss: 0.293224036693573 / Valid loss: 6.848787425813221
Training loss: 0.0999111533164978 / Valid loss: 6.741202247710455
Training loss: 0.15745475888252258 / Valid loss: 6.745234146572295

Epoch: 21
Training loss: 0.1124194785952568 / Valid loss: 6.7853880291893365
Training loss: 0.35016244649887085 / Valid loss: 6.6931262107122516
Training loss: 0.11011022329330444 / Valid loss: 6.800431964510963
Training loss: 0.14652374386787415 / Valid loss: 6.717690140860421
Training loss: 0.14612317085266113 / Valid loss: 6.825021385011219

Epoch: 22
Training loss: 0.34011703729629517 / Valid loss: 6.728884029388428
Training loss: 0.11551016569137573 / Valid loss: 6.784151231674921
Training loss: 0.3597332239151001 / Valid loss: 6.854368232545399
Training loss: 0.6455160975456238 / Valid loss: 6.95086004166376
Training loss: 0.14091697335243225 / Valid loss: 6.843023027692523

Epoch: 23
Training loss: 0.22095730900764465 / Valid loss: 6.806899483998617
Training loss: 0.25889158248901367 / Valid loss: 6.836573877788726
Training loss: 0.9495658874511719 / Valid loss: 6.732906418754941
Training loss: 0.09093894064426422 / Valid loss: 6.945911461966379
Training loss: 0.17282521724700928 / Valid loss: 6.854235217684791

Epoch: 24
Training loss: 0.2201007604598999 / Valid loss: 6.839092817760649
Training loss: 0.1595841348171234 / Valid loss: 6.7613474527994795
Training loss: 0.33757925033569336 / Valid loss: 6.756878811972482
Training loss: 0.10715493559837341 / Valid loss: 6.734550771259126
Training loss: 0.3328031003475189 / Valid loss: 6.870655327751523

Epoch: 25
Training loss: 0.32627084851264954 / Valid loss: 6.798729362941923
Training loss: 0.18027272820472717 / Valid loss: 6.8056010791233605
Training loss: 0.13653545081615448 / Valid loss: 6.75097115834554
Training loss: 0.2827436923980713 / Valid loss: 6.768715063730876
Training loss: 0.3354284167289734 / Valid loss: 6.898414891106742

Epoch: 26
Training loss: 0.12854081392288208 / Valid loss: 6.872213002613613
Training loss: 0.13695694506168365 / Valid loss: 6.831159977685838
Training loss: 0.17641273140907288 / Valid loss: 6.834679394676572
Training loss: 0.154817134141922 / Valid loss: 6.790045863106137
Training loss: 0.15916016697883606 / Valid loss: 6.878605676832653

Epoch: 27
Training loss: 0.22840863466262817 / Valid loss: 6.847792938777379
Training loss: 0.34047818183898926 / Valid loss: 6.904186103457496
Training loss: 0.26766490936279297 / Valid loss: 6.827950286865234
Training loss: 0.09238219261169434 / Valid loss: 6.7731131689889095
Training loss: 0.11427048593759537 / Valid loss: 6.756735545112973

Epoch: 28
Training loss: 0.13436853885650635 / Valid loss: 6.888207365217663
Training loss: 0.10636557638645172 / Valid loss: 6.768720917474656
Training loss: 0.38606715202331543 / Valid loss: 6.740945166633242
Training loss: 0.2005416750907898 / Valid loss: 6.76485953558059
Training loss: 0.09123629331588745 / Valid loss: 6.820324679783412

Epoch: 29
Training loss: 0.1148851215839386 / Valid loss: 6.859215559278216
Training loss: 0.16934767365455627 / Valid loss: 6.782154955182757
Training loss: 0.24353675544261932 / Valid loss: 6.8492482503255205
Training loss: 0.11335033923387527 / Valid loss: 6.843271873110816

Epoch: 30
Training loss: 0.34657391905784607 / Valid loss: 6.946517335800897
Training loss: 0.1682620793581009 / Valid loss: 6.857814802442278
Training loss: 0.1614869236946106 / Valid loss: 6.819839577447801
Training loss: 0.22150158882141113 / Valid loss: 6.8093612807137625
Training loss: 0.3275872468948364 / Valid loss: 6.840968270528884

Epoch: 31
Training loss: 0.3049590587615967 / Valid loss: 6.896773635773432
Training loss: 0.12368173897266388 / Valid loss: 6.801655460539318
Training loss: 0.25453275442123413 / Valid loss: 6.847932783762614
Training loss: 0.15271787345409393 / Valid loss: 6.740194188980829
Training loss: 0.10161179304122925 / Valid loss: 6.844690177554176

Epoch: 32
Training loss: 0.09318472445011139 / Valid loss: 6.891838991074335
Training loss: 0.09654486179351807 / Valid loss: 6.887454150971912
Training loss: 0.17755402624607086 / Valid loss: 6.805028588431222
Training loss: 0.21484312415122986 / Valid loss: 6.804820739655268
Training loss: 0.061206042766571045 / Valid loss: 6.815587048303513

Epoch: 33
Training loss: 0.22382581233978271 / Valid loss: 6.8389763854798815
Training loss: 0.1888447403907776 / Valid loss: 6.796537830716088
Training loss: 0.15547055006027222 / Valid loss: 6.8769433884393605
Training loss: 0.09028446674346924 / Valid loss: 6.842890280768985
Training loss: 0.11095988005399704 / Valid loss: 6.792709872836158

Epoch: 34
Training loss: 0.47767624258995056 / Valid loss: 6.821413598741803
Training loss: 0.1261146366596222 / Valid loss: 6.8071133886064805
Training loss: 0.10480310022830963 / Valid loss: 6.778851658957345
Training loss: 0.20180505514144897 / Valid loss: 6.853417759849911
Training loss: 0.15632060170173645 / Valid loss: 6.996718415759859

Epoch: 35
Training loss: 0.11523815989494324 / Valid loss: 6.849757108234224
Training loss: 0.23535847663879395 / Valid loss: 6.817785222189767
Training loss: 0.09763751924037933 / Valid loss: 6.819322118305025
Training loss: 0.08330070972442627 / Valid loss: 6.799379612150647
Training loss: 0.6510921716690063 / Valid loss: 6.922387781597319

Epoch: 36
Training loss: 0.08871585875749588 / Valid loss: 6.773724449248541
Training loss: 0.2541382312774658 / Valid loss: 6.769306096576509
Training loss: 0.1895187348127365 / Valid loss: 6.889061998185658
Training loss: 0.14469704031944275 / Valid loss: 6.781619212740943
Training loss: 0.18574029207229614 / Valid loss: 6.91877574012393

Epoch: 37
Training loss: 0.18265843391418457 / Valid loss: 6.843391195933024
Training loss: 0.13349765539169312 / Valid loss: 6.766509714580717
Training loss: 0.5921308994293213 / Valid loss: 6.854700506301153
Training loss: 0.2067805677652359 / Valid loss: 6.8769333476112005
Training loss: 0.33891794085502625 / Valid loss: 6.856990677969796

Epoch: 38
Training loss: 0.15275037288665771 / Valid loss: 6.751754996890114
Training loss: 0.08266456425189972 / Valid loss: 6.8069756371634345
Training loss: 0.16482305526733398 / Valid loss: 6.785018948146275
Training loss: 0.12467484176158905 / Valid loss: 6.886503455752418
Training loss: 0.09030671417713165 / Valid loss: 6.836016132718041

Epoch: 39
Training loss: 0.17434200644493103 / Valid loss: 6.871005739484515
Training loss: 0.24496373534202576 / Valid loss: 6.801453608558291
Training loss: 0.14014434814453125 / Valid loss: 6.771207995641799
Training loss: 0.11060431599617004 / Valid loss: 6.816454458236694

Epoch: 40
Training loss: 0.18345454335212708 / Valid loss: 6.756262052626837
Training loss: 0.18183833360671997 / Valid loss: 6.738794635591053
Training loss: 0.1048152893781662 / Valid loss: 6.798513630458287
Training loss: 0.07619471848011017 / Valid loss: 6.843569555736724
Training loss: 0.10487043857574463 / Valid loss: 6.848650255657378

Epoch: 41
Training loss: 0.39663973450660706 / Valid loss: 6.877404694330124
Training loss: 0.09455762803554535 / Valid loss: 6.818460142044794
Training loss: 0.10391955077648163 / Valid loss: 6.8114153703053795
Training loss: 0.13999661803245544 / Valid loss: 6.766991249720255
Training loss: 0.5885896682739258 / Valid loss: 6.9877336320422945

Epoch: 42
Training loss: 0.07600519061088562 / Valid loss: 6.822697562263126
Training loss: 0.0985257476568222 / Valid loss: 6.821637516929989
Training loss: 0.08835196495056152 / Valid loss: 6.807875142778669
Training loss: 0.11800800263881683 / Valid loss: 6.954420852661133
Training loss: 0.16381429135799408 / Valid loss: 6.806550616309757

Epoch: 43
Training loss: 0.06581903994083405 / Valid loss: 6.8419687407357355
Training loss: 0.19094669818878174 / Valid loss: 6.75779413495745
Training loss: 0.07844769954681396 / Valid loss: 6.804065581730434
Training loss: 0.14455340802669525 / Valid loss: 6.88130026998974
Training loss: 0.061015207320451736 / Valid loss: 6.895046447572254

Epoch: 44
Training loss: 0.05379969999194145 / Valid loss: 6.879760792141869
Training loss: 0.1997799575328827 / Valid loss: 6.819296750568208
Training loss: 0.30674871802330017 / Valid loss: 6.801929401216053
Training loss: 0.25494182109832764 / Valid loss: 6.908365158807664
Training loss: 0.08974779397249222 / Valid loss: 6.819030559630621

Epoch: 45
Training loss: 0.1425834596157074 / Valid loss: 6.778908856709799
Training loss: 0.1252109259366989 / Valid loss: 6.806151984986805
Training loss: 0.08120241016149521 / Valid loss: 6.760089442843483
Training loss: 0.07247669994831085 / Valid loss: 6.814078914551508
Training loss: 0.05691938474774361 / Valid loss: 6.767977142333985

Epoch: 46
Training loss: 0.2761564552783966 / Valid loss: 6.808891491662888
Training loss: 0.1820622831583023 / Valid loss: 6.861662601289295
Training loss: 0.19004134833812714 / Valid loss: 6.883075487046015
Training loss: 0.08905574679374695 / Valid loss: 6.855779541106451
Training loss: 0.11630401015281677 / Valid loss: 6.8252141997927716

Epoch: 47
Training loss: 0.17983686923980713 / Valid loss: 6.772375238509405
Training loss: 0.1039428561925888 / Valid loss: 6.8545868169693716
Training loss: 0.07086566835641861 / Valid loss: 6.744018958863758
Training loss: 0.13249605894088745 / Valid loss: 6.819738992055258
Training loss: 0.08967013657093048 / Valid loss: 6.818927533285958

Epoch: 48
Training loss: 0.1949479877948761 / Valid loss: 6.789954435257685
Training loss: 0.10189089179039001 / Valid loss: 6.830950444085257
Training loss: 0.19063374400138855 / Valid loss: 6.8260167121887205
Training loss: 0.04398433119058609 / Valid loss: 6.881143978663853
Training loss: 0.10100726038217545 / Valid loss: 6.823081784021287

Epoch: 49
Training loss: 0.06720349937677383 / Valid loss: 6.8300009341467
Training loss: 0.1306416094303131 / Valid loss: 6.918986334119524
Training loss: 0.053816791623830795 / Valid loss: 6.806638981047131
Training loss: 0.07206478714942932 / Valid loss: 6.805907181331089

Epoch: 50
Training loss: 0.10661052167415619 / Valid loss: 6.87692699432373
Training loss: 0.22231525182724 / Valid loss: 6.8666094825381325
Training loss: 0.24905182421207428 / Valid loss: 6.793975689297631
Training loss: 0.056378528475761414 / Valid loss: 6.817934812818255
Training loss: 0.0962507575750351 / Valid loss: 6.791919351759411

Epoch: 51
Training loss: 0.07630240172147751 / Valid loss: 6.799725936707996
Training loss: 0.24739354848861694 / Valid loss: 6.7649551754906065
Training loss: 0.15820641815662384 / Valid loss: 6.771224342073713
Training loss: 0.20567086338996887 / Valid loss: 6.7937318847292945
Training loss: 0.08986874669790268 / Valid loss: 6.820891909372239

Epoch: 52
Training loss: 0.2304166853427887 / Valid loss: 6.873681627001081
Training loss: 0.10487925261259079 / Valid loss: 6.803431470053536
Training loss: 0.1251642256975174 / Valid loss: 6.898122138068789
Training loss: 0.20131897926330566 / Valid loss: 6.793565000806536
Training loss: 0.20728114247322083 / Valid loss: 6.824614063898722

Epoch: 53
Training loss: 0.25864559412002563 / Valid loss: 6.756620198204404
Training loss: 0.3752038776874542 / Valid loss: 6.832740443093436
Training loss: 0.08915100991725922 / Valid loss: 6.8327741577511745
Training loss: 0.11329439282417297 / Valid loss: 6.777286761147636
Training loss: 0.16798922419548035 / Valid loss: 6.847561259496779

Epoch: 54
Training loss: 0.08754539489746094 / Valid loss: 6.8140827088128955
Training loss: 0.2982116639614105 / Valid loss: 6.886385054815383
Training loss: 0.060709819197654724 / Valid loss: 6.876311215900239
Training loss: 0.3495439291000366 / Valid loss: 6.722705489113217
Training loss: 0.2323218286037445 / Valid loss: 6.844244652702695

Epoch: 55
Training loss: 0.20720839500427246 / Valid loss: 6.903429153987339
Training loss: 0.20640747249126434 / Valid loss: 6.788078573771886
Training loss: 0.08055081963539124 / Valid loss: 6.814085633414132
Training loss: 0.11453264951705933 / Valid loss: 6.799949695950462
Training loss: 0.2998555302619934 / Valid loss: 6.760156785874139

Epoch: 56
Training loss: 0.28721097111701965 / Valid loss: 6.8076339540027435
Training loss: 0.13414618372917175 / Valid loss: 6.78705442519415
Training loss: 0.08684123307466507 / Valid loss: 6.790700281234015
Training loss: 0.15904194116592407 / Valid loss: 6.854636140096755
Training loss: 0.4034394919872284 / Valid loss: 6.971866923286801

Epoch: 57
Training loss: 0.12206186354160309 / Valid loss: 6.825983379000709
Training loss: 0.07569621503353119 / Valid loss: 6.882465816679455
Training loss: 0.1836700588464737 / Valid loss: 6.728330848330543
Training loss: 0.21605779230594635 / Valid loss: 6.865803203128633
Training loss: 0.1744648814201355 / Valid loss: 6.795520959581648

Epoch: 58
Training loss: 0.06081164628267288 / Valid loss: 6.860551298232306
Training loss: 0.1456271857023239 / Valid loss: 6.772406555357433
Training loss: 0.2026079297065735 / Valid loss: 6.860987190973191
Training loss: 0.08493494242429733 / Valid loss: 6.782032489776611
Training loss: 0.06575727462768555 / Valid loss: 6.810173906598773

Epoch: 59
Training loss: 0.13184776902198792 / Valid loss: 6.789430230004447
Training loss: 0.08245842158794403 / Valid loss: 6.831863646280198
Training loss: 0.15727673470973969 / Valid loss: 6.820804400671096
Training loss: 0.09608814120292664 / Valid loss: 6.821085196449643

Epoch: 60
Training loss: 0.07451830059289932 / Valid loss: 6.851274690173921
Training loss: 0.08219113945960999 / Valid loss: 6.8449082238333565
Training loss: 0.06418928503990173 / Valid loss: 6.842116791861398
Training loss: 0.5220395922660828 / Valid loss: 6.804537786756243
Training loss: 0.052222490310668945 / Valid loss: 6.7777313731965565

Epoch: 61
Training loss: 0.2340371459722519 / Valid loss: 6.74352193559919
Training loss: 0.4622255563735962 / Valid loss: 6.82033169837225
Training loss: 0.06275607645511627 / Valid loss: 6.795076692672003
Training loss: 0.10270121693611145 / Valid loss: 6.8416162127540225
Training loss: 0.1294395625591278 / Valid loss: 6.804032825288319

Epoch: 62
Training loss: 0.1291646510362625 / Valid loss: 6.780247715541295
Training loss: 0.36355024576187134 / Valid loss: 6.747614127113706
Training loss: 0.08424496650695801 / Valid loss: 6.763288352603004
Training loss: 0.07243319600820541 / Valid loss: 6.824220026107062
Training loss: 0.06426797807216644 / Valid loss: 6.875693116869245

Epoch: 63
Training loss: 0.1390535831451416 / Valid loss: 6.7762499491373696
Training loss: 0.065194271504879 / Valid loss: 6.78629906745184
Training loss: 0.18386179208755493 / Valid loss: 6.883714625948952
Training loss: 0.05409334599971771 / Valid loss: 6.7458607196807865
Training loss: 0.13862338662147522 / Valid loss: 6.8064587184361045

Epoch: 64
Training loss: 0.17003318667411804 / Valid loss: 6.784842000688825
Training loss: 0.18909993767738342 / Valid loss: 6.769032042367118
Training loss: 0.11167831718921661 / Valid loss: 6.8718535559518
Training loss: 0.16229014098644257 / Valid loss: 6.763175178709484
Training loss: 0.08136136084794998 / Valid loss: 6.826259935469855

Epoch: 65
Training loss: 0.08628295361995697 / Valid loss: 6.827233673277355
Training loss: 0.11780354380607605 / Valid loss: 6.8190663655598955
Training loss: 0.04305863380432129 / Valid loss: 6.770576370330084
Training loss: 0.056350529193878174 / Valid loss: 6.8662778173174175
Training loss: 0.12424235045909882 / Valid loss: 6.767711766560873

Epoch: 66
Training loss: 0.08170485496520996 / Valid loss: 6.810217264720372
Training loss: 0.1836443841457367 / Valid loss: 6.745570032937186
Training loss: 0.08829466998577118 / Valid loss: 6.783615757170177
Training loss: 0.1552957147359848 / Valid loss: 6.864980929238456
Training loss: 0.08272290229797363 / Valid loss: 6.79395759219215

Epoch: 67
Training loss: 0.2719021439552307 / Valid loss: 6.761352389199393
Training loss: 0.40460216999053955 / Valid loss: 6.743918832143148
Training loss: 0.1280175745487213 / Valid loss: 6.722162351154146
Training loss: 0.18210388720035553 / Valid loss: 6.805201178505307
Training loss: 0.08791199326515198 / Valid loss: 6.782636746906099

Epoch: 68
Training loss: 0.2886965870857239 / Valid loss: 6.754482176190331
Training loss: 0.2268851101398468 / Valid loss: 6.809902127583822
Training loss: 0.3561946153640747 / Valid loss: 6.765157867613293
Training loss: 0.07384932786226273 / Valid loss: 6.7781048683893115
Training loss: 0.47979697585105896 / Valid loss: 6.751245553152902

Epoch: 69
Training loss: 0.08712586760520935 / Valid loss: 6.745553720565069
Training loss: 0.08879473805427551 / Valid loss: 6.788308997381301
Training loss: 0.12651976943016052 / Valid loss: 6.745540414537702
Training loss: 0.47167983651161194 / Valid loss: 6.835140988940284

Epoch: 70
Training loss: 0.10533523559570312 / Valid loss: 6.80045665105184
Training loss: 0.1399499922990799 / Valid loss: 6.74557638168335
Training loss: 0.30939406156539917 / Valid loss: 6.757556311289469
Training loss: 0.16308775544166565 / Valid loss: 6.758436493646531
Training loss: 0.04753940552473068 / Valid loss: 6.770619701203846

Epoch: 71
Training loss: 0.0802503377199173 / Valid loss: 6.813793000720796
Training loss: 0.2043032944202423 / Valid loss: 6.763578655606224
Training loss: 0.123491071164608 / Valid loss: 6.853611178625197
Training loss: 0.1170898973941803 / Valid loss: 6.759230005173456
Training loss: 0.06752100586891174 / Valid loss: 6.783997980753581

Epoch: 72
Training loss: 0.32072722911834717 / Valid loss: 6.778956424622309
Training loss: 0.23012132942676544 / Valid loss: 6.741984916868664
Training loss: 0.23466065526008606 / Valid loss: 6.714397328240531
Training loss: 0.2388472706079483 / Valid loss: 6.783047875903901
Training loss: 0.22844740748405457 / Valid loss: 6.791672111692883

Epoch: 73
Training loss: 0.1307688057422638 / Valid loss: 6.806528702236357
Training loss: 0.08247977495193481 / Valid loss: 6.720046206883022
Training loss: 0.14946700632572174 / Valid loss: 6.849784396943592
Training loss: 0.06932368874549866 / Valid loss: 6.746372402281988
Training loss: 0.11634745448827744 / Valid loss: 6.780469985235305

Epoch: 74
Training loss: 0.34871119260787964 / Valid loss: 6.729298269181024
Training loss: 0.09601126611232758 / Valid loss: 6.836969938732329
Training loss: 0.15886208415031433 / Valid loss: 6.8099898429143995
Training loss: 0.39302369952201843 / Valid loss: 6.797773565564837
Training loss: 0.30283427238464355 / Valid loss: 6.768301523299444

Epoch: 75
Training loss: 0.09425505995750427 / Valid loss: 6.807770688193185
Training loss: 0.3270763158798218 / Valid loss: 6.779095908573695
Training loss: 0.2842558026313782 / Valid loss: 6.7983841192154655
Training loss: 0.11021078377962112 / Valid loss: 6.776717104230609
Training loss: 0.17117668688297272 / Valid loss: 6.771233381543841

Epoch: 76
Training loss: 0.07003328204154968 / Valid loss: 6.752099130267188
Training loss: 0.8030890226364136 / Valid loss: 6.907059106372651
Training loss: 0.9056190848350525 / Valid loss: 6.782491674877348
Training loss: 0.06943751871585846 / Valid loss: 6.812099502200172
Training loss: 0.1403583288192749 / Valid loss: 6.7526540892464775

Epoch: 77
Training loss: 0.1317044049501419 / Valid loss: 6.763811651865641
Training loss: 0.4932740032672882 / Valid loss: 6.768592441649664
Training loss: 0.06723757088184357 / Valid loss: 6.7625579879397435
Training loss: 0.22983339428901672 / Valid loss: 6.826319036029634
Training loss: 0.04957602173089981 / Valid loss: 6.7574612935384115

Epoch: 78
Training loss: 0.15472950041294098 / Valid loss: 6.835540612538655
Training loss: 0.3922595679759979 / Valid loss: 6.753861300150553
Training loss: 0.0532388836145401 / Valid loss: 6.829066476367768
Training loss: 0.1537330448627472 / Valid loss: 6.750570047469366
Training loss: 0.27157747745513916 / Valid loss: 6.7740243003481915

Epoch: 79
Training loss: 0.16243289411067963 / Valid loss: 6.818623381569272
Training loss: 0.1482183337211609 / Valid loss: 6.7943767547607425
Training loss: 0.10653717070817947 / Valid loss: 6.769146306174142
Training loss: 0.2726171612739563 / Valid loss: 6.7197831380934945
ModuleList(
  (0): Linear(in_features=31191, out_features=300, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=300, out_features=32, bias=True)
  (5): Dropout(p=0.0, inplace=False)
  (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): LeakyReLU(negative_slope=0.02)
  (8): Linear(in_features=32, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.93047921089899
Training regression with following parameters:
dnn_hidden_units : 248
dropout_probs : 0.0, 0.0
learning_rate : 0.0001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : SGD
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : TFIDF
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=31191, out_features=248, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=248, out_features=1, bias=True)
)

Epoch: 0
Training loss: 15.220863342285156 / Valid loss: 16.437623568943568
Model is saved in epoch 0, overall batch: 0
Training loss: 10.162872314453125 / Valid loss: 11.46192240033831
Model is saved in epoch 0, overall batch: 100
Training loss: 7.728257656097412 / Valid loss: 7.493644923255557
Model is saved in epoch 0, overall batch: 200
Training loss: 5.181697845458984 / Valid loss: 6.415898593266805
Model is saved in epoch 0, overall batch: 300
Training loss: 6.132676601409912 / Valid loss: 5.961236447379703
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 6.049834728240967 / Valid loss: 5.754955423445929
Model is saved in epoch 1, overall batch: 500
Training loss: 5.399333477020264 / Valid loss: 5.646049796967279
Model is saved in epoch 1, overall batch: 600
Training loss: 4.390186309814453 / Valid loss: 5.619242511476789
Model is saved in epoch 1, overall batch: 700
Training loss: 6.24585485458374 / Valid loss: 5.597316866829281
Model is saved in epoch 1, overall batch: 800
Training loss: 5.75360107421875 / Valid loss: 5.566003392991566
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 4.249693870544434 / Valid loss: 5.551222803479149
Model is saved in epoch 2, overall batch: 1000
Training loss: 3.9242234230041504 / Valid loss: 5.5558816410246346
Training loss: 5.117839336395264 / Valid loss: 5.554155052275885
Training loss: 3.5011258125305176 / Valid loss: 5.541973002751669
Model is saved in epoch 2, overall batch: 1300
Training loss: 4.092771053314209 / Valid loss: 5.54207055909293

Epoch: 3
Training loss: 3.8763718605041504 / Valid loss: 5.549076657068162
Training loss: 4.535436153411865 / Valid loss: 5.568911711374919
Training loss: 4.296402931213379 / Valid loss: 5.567015586580549
Training loss: 4.037261009216309 / Valid loss: 5.570396373385475
Training loss: 5.671407222747803 / Valid loss: 5.548119183949062

Epoch: 4
Training loss: 2.987182140350342 / Valid loss: 5.574567138581049
Training loss: 3.0258584022521973 / Valid loss: 5.573652113051642
Training loss: 3.4540903568267822 / Valid loss: 5.591258907318116
Training loss: 4.158498764038086 / Valid loss: 5.580865476244972
Training loss: 3.1214723587036133 / Valid loss: 5.5777089868273055

Epoch: 5
Training loss: 3.377483367919922 / Valid loss: 5.593229064487276
Training loss: 3.6698338985443115 / Valid loss: 5.609514349982852
Training loss: 2.484265089035034 / Valid loss: 5.617801109949748
Training loss: 5.286789894104004 / Valid loss: 5.625318697520664
Training loss: 4.387582778930664 / Valid loss: 5.616320932479132

Epoch: 6
Training loss: 2.9809556007385254 / Valid loss: 5.614488987695603
Training loss: 3.939122200012207 / Valid loss: 5.645402399698893
Training loss: 3.6853437423706055 / Valid loss: 5.647940179279872
Training loss: 3.1611857414245605 / Valid loss: 5.659352768035162
Training loss: 4.829153537750244 / Valid loss: 5.651199388504028

Epoch: 7
Training loss: 3.1940383911132812 / Valid loss: 5.680399690355573
Training loss: 2.681680202484131 / Valid loss: 5.706537276222592
Training loss: 2.787493944168091 / Valid loss: 5.68465508052281
Training loss: 2.1222434043884277 / Valid loss: 5.696131815229143
Training loss: 2.5555384159088135 / Valid loss: 5.697423112960089

Epoch: 8
Training loss: 3.3916478157043457 / Valid loss: 5.716054017203195
Training loss: 3.463899850845337 / Valid loss: 5.737263913381668
Training loss: 1.8325470685958862 / Valid loss: 5.7320849940890355
Training loss: 3.1108808517456055 / Valid loss: 5.756640223094395
Training loss: 2.4824702739715576 / Valid loss: 5.755083999179658

Epoch: 9
Training loss: 1.8233802318572998 / Valid loss: 5.791031955537342
Training loss: 2.8732948303222656 / Valid loss: 5.780138385863531
Training loss: 2.505666732788086 / Valid loss: 5.789604786464146
Training loss: 3.1490368843078613 / Valid loss: 5.800741184325445

Epoch: 10
Training loss: 2.5804905891418457 / Valid loss: 5.791926349912371
Training loss: 2.3280630111694336 / Valid loss: 5.803745010920934
Training loss: 2.408802032470703 / Valid loss: 5.865981758208502
Training loss: 3.050537347793579 / Valid loss: 5.845713878813244
Training loss: 2.704247236251831 / Valid loss: 5.853253884542556

Epoch: 11
Training loss: 1.2720695734024048 / Valid loss: 5.857543899899437
Training loss: 2.110213279724121 / Valid loss: 5.865421633493333
Training loss: 1.9614864587783813 / Valid loss: 5.894107859475272
Training loss: 2.192850112915039 / Valid loss: 5.9362919217064265
Training loss: 2.966635227203369 / Valid loss: 5.903920316696167

Epoch: 12
Training loss: 2.1772656440734863 / Valid loss: 5.924064082191104
Training loss: 1.829028606414795 / Valid loss: 5.925978138333275
Training loss: 2.509511947631836 / Valid loss: 5.9562057177225745
Training loss: 2.3263590335845947 / Valid loss: 5.942862694604056
Training loss: 1.6640974283218384 / Valid loss: 5.958974061693464

Epoch: 13
Training loss: 2.673379421234131 / Valid loss: 5.951364124388922
Training loss: 1.715466022491455 / Valid loss: 5.960956416811261
Training loss: 1.9925017356872559 / Valid loss: 5.971720366250901
Training loss: 1.1694178581237793 / Valid loss: 6.001750312532697
Training loss: 2.044257879257202 / Valid loss: 6.016969971429734

Epoch: 14
Training loss: 1.814725399017334 / Valid loss: 6.021838628678095
Training loss: 1.5923326015472412 / Valid loss: 6.01718213898795
Training loss: 1.6444530487060547 / Valid loss: 6.036759465081351
Training loss: 1.627508282661438 / Valid loss: 6.039342180887858
Training loss: 1.4677393436431885 / Valid loss: 6.027566276277814

Epoch: 15
Training loss: 1.5148544311523438 / Valid loss: 6.07143216360183
Training loss: 1.6079987287521362 / Valid loss: 6.082122416723342
Training loss: 1.7907921075820923 / Valid loss: 6.090827469598679
Training loss: 2.103541135787964 / Valid loss: 6.075677231379918
Training loss: 1.1175602674484253 / Valid loss: 6.092885762169248

Epoch: 16
Training loss: 0.9142489433288574 / Valid loss: 6.1152974878038675
Training loss: 0.9642788171768188 / Valid loss: 6.127498703911191
Training loss: 0.9941952228546143 / Valid loss: 6.092090020860945
Training loss: 1.162906527519226 / Valid loss: 6.154076596668788
Training loss: 2.2604219913482666 / Valid loss: 6.1178322042737685

Epoch: 17
Training loss: 1.578902244567871 / Valid loss: 6.123935897009713
Training loss: 0.8625670671463013 / Valid loss: 6.183170949845087
Training loss: 1.5772546529769897 / Valid loss: 6.160262655076527
Training loss: 1.2776424884796143 / Valid loss: 6.1429955187298
Training loss: 1.1442631483078003 / Valid loss: 6.180877635592506

Epoch: 18
Training loss: 1.5832839012145996 / Valid loss: 6.162023805436634
Training loss: 1.4609445333480835 / Valid loss: 6.201406574249267
Training loss: 1.1281979084014893 / Valid loss: 6.176636768522717
Training loss: 1.5142030715942383 / Valid loss: 6.22344506354559
Training loss: 0.9025390148162842 / Valid loss: 6.2209892681666785

Epoch: 19
Training loss: 1.7103925943374634 / Valid loss: 6.225837142126901
Training loss: 0.8597835302352905 / Valid loss: 6.23916232245309
Training loss: 1.2152116298675537 / Valid loss: 6.268201051439558
Training loss: 1.2711611986160278 / Valid loss: 6.278043624332973

Epoch: 20
Training loss: 1.245775818824768 / Valid loss: 6.248163173312233
Training loss: 1.5654058456420898 / Valid loss: 6.252476832980201
Training loss: 0.7719752192497253 / Valid loss: 6.252116652897426
Training loss: 1.180747628211975 / Valid loss: 6.282963289533343
Training loss: 1.4022204875946045 / Valid loss: 6.277082511356899

Epoch: 21
Training loss: 0.7163229584693909 / Valid loss: 6.2824334712255565
Training loss: 1.0206637382507324 / Valid loss: 6.278896740504673
Training loss: 1.2305009365081787 / Valid loss: 6.2946239312489825
Training loss: 0.9848871827125549 / Valid loss: 6.335762509845552
Training loss: 1.068257212638855 / Valid loss: 6.32286274092538

Epoch: 22
Training loss: 0.8062034845352173 / Valid loss: 6.327463195437477
Training loss: 0.7351147532463074 / Valid loss: 6.357813058580671
Training loss: 0.8431893587112427 / Valid loss: 6.318876198359898
Training loss: 0.7057235240936279 / Valid loss: 6.366657393319266
Training loss: 0.8991497755050659 / Valid loss: 6.307925542195638

Epoch: 23
Training loss: 0.9580889940261841 / Valid loss: 6.320507680802118
Training loss: 1.3173904418945312 / Valid loss: 6.3724186261494955
Training loss: 0.9258132576942444 / Valid loss: 6.3521960235777355
Training loss: 1.2295680046081543 / Valid loss: 6.355821125847953
Training loss: 0.9861281514167786 / Valid loss: 6.39561189469837

Epoch: 24
Training loss: 0.47350648045539856 / Valid loss: 6.3722269830249605
Training loss: 0.9673754572868347 / Valid loss: 6.378224536350795
Training loss: 1.4690622091293335 / Valid loss: 6.348882818222046
Training loss: 0.7722814679145813 / Valid loss: 6.379662043707711
Training loss: 0.588304877281189 / Valid loss: 6.382402474539621

Epoch: 25
Training loss: 1.1080659627914429 / Valid loss: 6.385511316571917
Training loss: 0.8928732872009277 / Valid loss: 6.387529454912458
Training loss: 0.9630057215690613 / Valid loss: 6.407305953616188
Training loss: 0.7051867246627808 / Valid loss: 6.394479252043224
Training loss: 0.7377746105194092 / Valid loss: 6.39371428489685

Epoch: 26
Training loss: 0.5697533488273621 / Valid loss: 6.415495531899588
Training loss: 1.115095853805542 / Valid loss: 6.404920248758225
Training loss: 0.49410927295684814 / Valid loss: 6.459633436657134
Training loss: 0.7412936687469482 / Valid loss: 6.446431282588414
Training loss: 0.7663286328315735 / Valid loss: 6.439355893362136

Epoch: 27
Training loss: 1.3169740438461304 / Valid loss: 6.420620541345506
Training loss: 1.2322139739990234 / Valid loss: 6.433124537695022
Training loss: 0.826142430305481 / Valid loss: 6.47243960244315
Training loss: 0.26259732246398926 / Valid loss: 6.456501611073812
Training loss: 0.5215908288955688 / Valid loss: 6.4642588297526045

Epoch: 28
Training loss: 0.4561576247215271 / Valid loss: 6.458223558607555
Training loss: 0.8643577694892883 / Valid loss: 6.501667542684646
Training loss: 1.2927229404449463 / Valid loss: 6.468331055414109
Training loss: 0.6662229299545288 / Valid loss: 6.518440791538784
Training loss: 0.5941729545593262 / Valid loss: 6.484454768044608

Epoch: 29
Training loss: 0.9922342300415039 / Valid loss: 6.516873722984677
Training loss: 0.5629592537879944 / Valid loss: 6.520027773720877
Training loss: 0.9970008134841919 / Valid loss: 6.4995635327838714
Training loss: 0.7675613164901733 / Valid loss: 6.460218742915562

Epoch: 30
Training loss: 0.6332650184631348 / Valid loss: 6.487074429648263
Training loss: 0.5447990894317627 / Valid loss: 6.4987138112386065
Training loss: 1.0786263942718506 / Valid loss: 6.472700936453683
Training loss: 1.021272897720337 / Valid loss: 6.539091564360119
Training loss: 0.49837473034858704 / Valid loss: 6.485489182245164

Epoch: 31
Training loss: 0.6343330144882202 / Valid loss: 6.531958925156366
Training loss: 0.8077802658081055 / Valid loss: 6.51948032833281
Training loss: 0.3139021396636963 / Valid loss: 6.537646273204259
Training loss: 0.5442012548446655 / Valid loss: 6.541659977322533
Training loss: 1.1807680130004883 / Valid loss: 6.514182242893037

Epoch: 32
Training loss: 0.42236408591270447 / Valid loss: 6.5272754896254765
Training loss: 0.6197347640991211 / Valid loss: 6.537208402724493
Training loss: 0.5534011125564575 / Valid loss: 6.518199441546486
Training loss: 0.37397271394729614 / Valid loss: 6.565399283454532
Training loss: 0.8353492021560669 / Valid loss: 6.544051976430984

Epoch: 33
Training loss: 0.7232453227043152 / Valid loss: 6.526251243409656
Training loss: 0.24648690223693848 / Valid loss: 6.541423273086548
Training loss: 0.38539764285087585 / Valid loss: 6.564643031074887
Training loss: 0.39139389991760254 / Valid loss: 6.591884744734991
Training loss: 0.261605829000473 / Valid loss: 6.599912634350004

Epoch: 34
Training loss: 0.329013466835022 / Valid loss: 6.558113134474981
Training loss: 0.47069036960601807 / Valid loss: 6.548368808201381
Training loss: 0.2681701183319092 / Valid loss: 6.599685503187634
Training loss: 0.4389653503894806 / Valid loss: 6.555638844626291
Training loss: 0.5350726842880249 / Valid loss: 6.551994189761934

Epoch: 35
Training loss: 0.3467988073825836 / Valid loss: 6.59526157833281
Training loss: 0.3524527847766876 / Valid loss: 6.558172934395927
Training loss: 0.44316065311431885 / Valid loss: 6.614370575405302
Training loss: 0.4310043752193451 / Valid loss: 6.606240413302467
Training loss: 0.4590073823928833 / Valid loss: 6.595829227992467

Epoch: 36
Training loss: 0.18390178680419922 / Valid loss: 6.614191747847057
Training loss: 0.1943863034248352 / Valid loss: 6.615863831837972
Training loss: 0.39017996191978455 / Valid loss: 6.599273413703555
Training loss: 0.5189017653465271 / Valid loss: 6.597305356888544
Training loss: 0.3972909152507782 / Valid loss: 6.6388344424111505

Epoch: 37
Training loss: 0.2308070957660675 / Valid loss: 6.595498393830799
Training loss: 0.7710242867469788 / Valid loss: 6.665807297116234
Training loss: 0.23602896928787231 / Valid loss: 6.621296619233631
Training loss: 0.4588449001312256 / Valid loss: 6.615047613779704
Training loss: 0.3527889847755432 / Valid loss: 6.6141458511352536

Epoch: 38
Training loss: 0.27197086811065674 / Valid loss: 6.612652347201393
Training loss: 0.24467623233795166 / Valid loss: 6.602702036358061
Training loss: 0.37366044521331787 / Valid loss: 6.629530706859771
Training loss: 0.21999399363994598 / Valid loss: 6.614095846811931
Training loss: 0.4285861849784851 / Valid loss: 6.633166453951881

Epoch: 39
Training loss: 0.3454541862010956 / Valid loss: 6.628871667952764
Training loss: 0.28963807225227356 / Valid loss: 6.65157243183681
Training loss: 0.4004227817058563 / Valid loss: 6.630261314482916
Training loss: 0.1869071125984192 / Valid loss: 6.634673288890293

Epoch: 40
Training loss: 0.19584287703037262 / Valid loss: 6.666620333989461
Training loss: 0.2738748788833618 / Valid loss: 6.6417015961238315
Training loss: 0.24830272793769836 / Valid loss: 6.667616626194545
Training loss: 0.6082959771156311 / Valid loss: 6.6433616002400715
Training loss: 0.34641289710998535 / Valid loss: 6.681555940991356

Epoch: 41
Training loss: 0.43845611810684204 / Valid loss: 6.652543599264963
Training loss: 0.354410320520401 / Valid loss: 6.658760356903076
Training loss: 0.3427625298500061 / Valid loss: 6.644370628538586
Training loss: 0.16932892799377441 / Valid loss: 6.7012420200166245
Training loss: 0.3633232116699219 / Valid loss: 6.683035791487921

Epoch: 42
Training loss: 0.2995166778564453 / Valid loss: 6.660321553548177
Training loss: 0.14969968795776367 / Valid loss: 6.700271556490944
Training loss: 0.32380616664886475 / Valid loss: 6.683904729570661
Training loss: 0.17840278148651123 / Valid loss: 6.715264506567092
Training loss: 0.27638179063796997 / Valid loss: 6.68238004502796

Epoch: 43
Training loss: 0.18553131818771362 / Valid loss: 6.692869676862444
Training loss: 0.13238903880119324 / Valid loss: 6.710006277901786
Training loss: 0.65947026014328 / Valid loss: 6.6791994140261695
Training loss: 0.17045974731445312 / Valid loss: 6.682852754138765
Training loss: 0.354588121175766 / Valid loss: 6.690084657214936

Epoch: 44
Training loss: 0.1931503266096115 / Valid loss: 6.766527616410029
Training loss: 0.3940858840942383 / Valid loss: 6.689660585494268
Training loss: 0.34388184547424316 / Valid loss: 6.721502962566557
Training loss: 0.14857859909534454 / Valid loss: 6.6813750766572495
Training loss: 0.2653466463088989 / Valid loss: 6.724885461443947

Epoch: 45
Training loss: 0.201460599899292 / Valid loss: 6.682753510702224
Training loss: 0.08830241858959198 / Valid loss: 6.691938870293754
Training loss: 0.43468913435935974 / Valid loss: 6.6894909904116675
Training loss: 0.2058447152376175 / Valid loss: 6.743801507495698
Training loss: 0.23535865545272827 / Valid loss: 6.7362754413059776

Epoch: 46
Training loss: 0.1890253722667694 / Valid loss: 6.696838801247733
Training loss: 0.0981883704662323 / Valid loss: 6.732660702296665
Training loss: 0.1437821388244629 / Valid loss: 6.730281343914213
Training loss: 0.3167257308959961 / Valid loss: 6.705156412578765
Training loss: 0.22421209514141083 / Valid loss: 6.712381013234457

Epoch: 47
Training loss: 0.5359985828399658 / Valid loss: 6.6941685949053085
Training loss: 0.2955588102340698 / Valid loss: 6.711744313012986
Training loss: 0.30590227246284485 / Valid loss: 6.734288733346122
Training loss: 0.28218889236450195 / Valid loss: 6.696955013275146
Training loss: 0.3145213723182678 / Valid loss: 6.693564551217215

Epoch: 48
Training loss: 0.19327132403850555 / Valid loss: 6.710329943611509
Training loss: 0.21353712677955627 / Valid loss: 6.704272542681013
Training loss: 0.21584844589233398 / Valid loss: 6.735025065285819
Training loss: 0.2505536675453186 / Valid loss: 6.740872909909203
Training loss: 0.278764009475708 / Valid loss: 6.7126024609520325

Epoch: 49
Training loss: 0.13365237414836884 / Valid loss: 6.726377087547665
Training loss: 0.31463080644607544 / Valid loss: 6.749919550759452
Training loss: 0.17821240425109863 / Valid loss: 6.760678018842425
Training loss: 0.2416972815990448 / Valid loss: 6.745640968141101

Epoch: 50
Training loss: 0.3536455035209656 / Valid loss: 6.743812043326241
Training loss: 0.20884670317173004 / Valid loss: 6.7411572501772925
Training loss: 0.14621782302856445 / Valid loss: 6.7460403079078315
Training loss: 0.0864289402961731 / Valid loss: 6.71202882358006
Training loss: 0.29183924198150635 / Valid loss: 6.779419358571371

Epoch: 51
Training loss: 0.20674161612987518 / Valid loss: 6.754674302963983
Training loss: 0.23887702822685242 / Valid loss: 6.745223349616641
Training loss: 0.1278011053800583 / Valid loss: 6.752910954611642
Training loss: 0.3475739061832428 / Valid loss: 6.804897485460554
Training loss: 0.12684661149978638 / Valid loss: 6.756433568681989

Epoch: 52
Training loss: 0.07740944623947144 / Valid loss: 6.7707889397939045
Training loss: 0.2637028694152832 / Valid loss: 6.72725019454956
Training loss: 0.21282950043678284 / Valid loss: 6.758752273377918
Training loss: 0.4777734875679016 / Valid loss: 6.757560316721598
Training loss: 0.12187136709690094 / Valid loss: 6.786705948057628

Epoch: 53
Training loss: 0.17208680510520935 / Valid loss: 6.749986167181106
Training loss: 0.24243098497390747 / Valid loss: 6.7525438217889695
Training loss: 0.10191649198532104 / Valid loss: 6.7779347011021205
Training loss: 0.30032873153686523 / Valid loss: 6.739090419950939
Training loss: 0.17394697666168213 / Valid loss: 6.800717589968727

Epoch: 54
Training loss: 0.2823154926300049 / Valid loss: 6.770555832272485
Training loss: 0.11649030447006226 / Valid loss: 6.756249046325683
Training loss: 0.31287527084350586 / Valid loss: 6.765904553731283
Training loss: 0.24102453887462616 / Valid loss: 6.735089084080287
Training loss: 0.101918064057827 / Valid loss: 6.764319696880523

Epoch: 55
Training loss: 0.09686500579118729 / Valid loss: 6.761842652729579
Training loss: 0.0938497930765152 / Valid loss: 6.790372389838809
Training loss: 0.15062899887561798 / Valid loss: 6.79846894854591
Training loss: 0.10661392658948898 / Valid loss: 6.776317292168027
Training loss: 0.24433842301368713 / Valid loss: 6.776973070417132

Epoch: 56
Training loss: 0.3699184060096741 / Valid loss: 6.744576613108317
Training loss: 0.2783127725124359 / Valid loss: 6.778207156771705
Training loss: 0.15921565890312195 / Valid loss: 6.769744829904465
Training loss: 0.16870509088039398 / Valid loss: 6.810710452851795
Training loss: 0.40795987844467163 / Valid loss: 6.775481598717826

Epoch: 57
Training loss: 0.15807074308395386 / Valid loss: 6.78937010992141
Training loss: 0.26512670516967773 / Valid loss: 6.802742172422863
Training loss: 0.10580743849277496 / Valid loss: 6.818934009188697
Training loss: 0.5351718068122864 / Valid loss: 6.780127638862247
Training loss: 0.2952328324317932 / Valid loss: 6.783045378185454

Epoch: 58
Training loss: 0.2535420060157776 / Valid loss: 6.787714781079973
Training loss: 0.2987612187862396 / Valid loss: 6.829972603207543
Training loss: 0.3102269172668457 / Valid loss: 6.816907342274984
Training loss: 0.17043372988700867 / Valid loss: 6.788757335572016
Training loss: 0.09653113782405853 / Valid loss: 6.811712464832124

Epoch: 59
Training loss: 0.07085585594177246 / Valid loss: 6.777900961467198
Training loss: 0.15121261775493622 / Valid loss: 6.834988998231434
Training loss: 0.1641504317522049 / Valid loss: 6.762725294203985
Training loss: 0.5408006906509399 / Valid loss: 6.830963389078776

Epoch: 60
Training loss: 0.11537139862775803 / Valid loss: 6.800999536968413
Training loss: 0.18631123006343842 / Valid loss: 6.787398006802514
Training loss: 0.09287579357624054 / Valid loss: 6.786084179651169
Training loss: 0.0645860955119133 / Valid loss: 6.851687281472342
Training loss: 0.14178456366062164 / Valid loss: 6.801377668834868

Epoch: 61
Training loss: 0.1814064383506775 / Valid loss: 6.823556123461042
Training loss: 0.11287396401166916 / Valid loss: 6.835327993120466
Training loss: 0.12604376673698425 / Valid loss: 6.846583348228818
Training loss: 0.12061317265033722 / Valid loss: 6.8131160645257856
Training loss: 0.1283658742904663 / Valid loss: 6.810534091222854

Epoch: 62
Training loss: 0.2940937876701355 / Valid loss: 6.822377931504023
Training loss: 0.08544546365737915 / Valid loss: 6.8290755022139775
Training loss: 0.20063501596450806 / Valid loss: 6.850694660913376
Training loss: 0.04156651347875595 / Valid loss: 6.838541430518741
Training loss: 0.1472853422164917 / Valid loss: 6.771299652826219

Epoch: 63
Training loss: 0.15842121839523315 / Valid loss: 6.815641226087298
Training loss: 0.11710283160209656 / Valid loss: 6.811472197941371
Training loss: 0.12702614068984985 / Valid loss: 6.800348613375709
Training loss: 0.1739448606967926 / Valid loss: 6.800118330546788
Training loss: 0.13388009369373322 / Valid loss: 6.823909282684326

Epoch: 64
Training loss: 0.1700553596019745 / Valid loss: 6.8220688956124445
Training loss: 0.07838279008865356 / Valid loss: 6.900265552884057
Training loss: 0.09178498387336731 / Valid loss: 6.8016861643110005
Training loss: 0.04887949302792549 / Valid loss: 6.826017811184838
Training loss: 0.10892719030380249 / Valid loss: 6.819285715193976

Epoch: 65
Training loss: 0.13081911206245422 / Valid loss: 6.818868296486991
Training loss: 0.20157071948051453 / Valid loss: 6.827414299192883
Training loss: 0.12439678609371185 / Valid loss: 6.80994389851888
Training loss: 0.10214343667030334 / Valid loss: 6.8455927894228985
Training loss: 0.04351099580526352 / Valid loss: 6.831152012234642

Epoch: 66
Training loss: 0.060846444219350815 / Valid loss: 6.793836298443022
Training loss: 0.19766059517860413 / Valid loss: 6.8335777759552006
Training loss: 0.2597121000289917 / Valid loss: 6.82109800974528
Training loss: 0.09863007813692093 / Valid loss: 6.866448888324556
Training loss: 0.08907891809940338 / Valid loss: 6.855189668564569

Epoch: 67
Training loss: 0.16594089567661285 / Valid loss: 6.831478922707694
Training loss: 0.29062333703041077 / Valid loss: 6.831530759448097
Training loss: 0.07984977215528488 / Valid loss: 6.841308244069418
Training loss: 0.19542402029037476 / Valid loss: 6.84513274147397
Training loss: 0.13010263442993164 / Valid loss: 6.837765682311285

Epoch: 68
Training loss: 0.23471719026565552 / Valid loss: 6.8104994524092906
Training loss: 0.05522608757019043 / Valid loss: 6.862633904956636
Training loss: 0.17683261632919312 / Valid loss: 6.829206829979306
Training loss: 0.06728749722242355 / Valid loss: 6.853710569654193
Training loss: 0.10210474580526352 / Valid loss: 6.8659923508053735

Epoch: 69
Training loss: 0.2599228620529175 / Valid loss: 6.876227042788551
Training loss: 0.1408533751964569 / Valid loss: 6.851113065083822
Training loss: 0.033137258142232895 / Valid loss: 6.864810984475272
Training loss: 0.36608660221099854 / Valid loss: 6.877593989599319

Epoch: 70
Training loss: 0.03433486819267273 / Valid loss: 6.850601505097889
Training loss: 0.559137225151062 / Valid loss: 6.8602692331586566
Training loss: 0.14543233811855316 / Valid loss: 6.87464785802932
Training loss: 0.08913074433803558 / Valid loss: 6.883046717870803
Training loss: 0.17942719161510468 / Valid loss: 6.847108850024996

Epoch: 71
Training loss: 0.17915551364421844 / Valid loss: 6.851715807687668
Training loss: 0.1534528136253357 / Valid loss: 6.838036055791946
Training loss: 0.026460997760295868 / Valid loss: 6.864101441701253
Training loss: 0.03833404928445816 / Valid loss: 6.840933513641358
Training loss: 0.21441784501075745 / Valid loss: 6.853978574843634

Epoch: 72
Training loss: 0.06529299914836884 / Valid loss: 6.856423564184279
Training loss: 0.3429577946662903 / Valid loss: 6.855125254676455
Training loss: 0.21711015701293945 / Valid loss: 6.859610198792957
Training loss: 0.15196651220321655 / Valid loss: 6.816448461441767
Training loss: 0.13310962915420532 / Valid loss: 6.82318491254534

Epoch: 73
Training loss: 0.3325096368789673 / Valid loss: 6.880065168653216
Training loss: 0.09902065992355347 / Valid loss: 6.8608589944385345
Training loss: 0.10890959948301315 / Valid loss: 6.868867333730062
Training loss: 0.09985867142677307 / Valid loss: 6.843416531880696
Training loss: 0.04188966006040573 / Valid loss: 6.857657759530204

Epoch: 74
Training loss: 0.21249082684516907 / Valid loss: 6.90087301617577
Training loss: 0.05010021850466728 / Valid loss: 6.854679173514956
Training loss: 0.059337105602025986 / Valid loss: 6.882021184194656
Training loss: 0.13085293769836426 / Valid loss: 6.869923187437512
Training loss: 0.12884190678596497 / Valid loss: 6.810870602017357

Epoch: 75
Training loss: 0.05242793262004852 / Valid loss: 6.875711531866164
Training loss: 0.4909666180610657 / Valid loss: 6.841019789377849
Training loss: 0.19621585309505463 / Valid loss: 6.87357451575143
Training loss: 0.049383800476789474 / Valid loss: 6.8993242127554755
Training loss: 0.03385774791240692 / Valid loss: 6.87622788974217

Epoch: 76
Training loss: 0.05095392465591431 / Valid loss: 6.863351431347075
Training loss: 0.118159219622612 / Valid loss: 6.842865403493246
Training loss: 0.06614531576633453 / Valid loss: 6.879821890876407
Training loss: 0.08555133640766144 / Valid loss: 6.867965589250837
Training loss: 0.09487152844667435 / Valid loss: 6.870605330240159

Epoch: 77
Training loss: 0.0924438089132309 / Valid loss: 6.867122604733422
Training loss: 0.34523439407348633 / Valid loss: 6.853148069835845
Training loss: 0.27047547698020935 / Valid loss: 6.8488780294145855
Training loss: 0.08992592990398407 / Valid loss: 6.849129277183896
Training loss: 0.42308151721954346 / Valid loss: 6.857287724812825

Epoch: 78
Training loss: 0.11010454595088959 / Valid loss: 6.881280885423933
Training loss: 0.21307671070098877 / Valid loss: 6.883879466283889
Training loss: 0.052063826471567154 / Valid loss: 6.851792653401692
Training loss: 0.10088014602661133 / Valid loss: 6.87079347882952
Training loss: 0.11545169353485107 / Valid loss: 6.872030866713751

Epoch: 79
Training loss: 0.03672110289335251 / Valid loss: 6.850130932671683
Training loss: 0.038304440677165985 / Valid loss: 6.87826208841233
Training loss: 0.10382363945245743 / Valid loss: 6.90798472449893
Training loss: 0.14738544821739197 / Valid loss: 6.893716862088158
ModuleList(
  (0): Linear(in_features=31191, out_features=248, bias=True)
  (1): Dropout(p=0.0, inplace=False)
  (2): BatchNorm1d(248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): LeakyReLU(negative_slope=0.02)
  (4): Linear(in_features=248, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.380741936819894
Training regression with following parameters:
dnn_hidden_units : 
dropout_probs : 0.0, 0.0
learning_rate : 0.0001
nr_epochs : 80
batch_size : 64
eval_freq : 100
data_dir : Data/
neg_slope : 0.02
optimizer : SGD
amsgrad : False
batchnorm : True
weightdecay : 0
momentum : 0
embedder : TFIDF
verbose : False
reduced_classes : False
Device : cuda
ModuleList(
  (0): Linear(in_features=31191, out_features=1, bias=True)
)

Epoch: 0
Training loss: 20.986988067626953 / Valid loss: 16.476813561575753
Model is saved in epoch 0, overall batch: 0
Training loss: 19.34998321533203 / Valid loss: 16.06934731801351
Model is saved in epoch 0, overall batch: 100
Training loss: 10.80003547668457 / Valid loss: 15.685470281328474
Model is saved in epoch 0, overall batch: 200
Training loss: 16.251977920532227 / Valid loss: 15.302157338460287
Model is saved in epoch 0, overall batch: 300
Training loss: 12.382561683654785 / Valid loss: 14.930970473516554
Model is saved in epoch 0, overall batch: 400

Epoch: 1
Training loss: 12.209218978881836 / Valid loss: 14.565777052016486
Model is saved in epoch 1, overall batch: 500
Training loss: 11.344770431518555 / Valid loss: 14.24381088983445
Model is saved in epoch 1, overall batch: 600
Training loss: 13.974422454833984 / Valid loss: 13.929114759536017
Model is saved in epoch 1, overall batch: 700
Training loss: 14.13243293762207 / Valid loss: 13.619262872423445
Model is saved in epoch 1, overall batch: 800
Training loss: 17.79330825805664 / Valid loss: 13.302658203669957
Model is saved in epoch 1, overall batch: 900

Epoch: 2
Training loss: 11.528554916381836 / Valid loss: 13.01042663029262
Model is saved in epoch 2, overall batch: 1000
Training loss: 8.892904281616211 / Valid loss: 12.758256862277076
Model is saved in epoch 2, overall batch: 1100
Training loss: 12.997526168823242 / Valid loss: 12.491826629638672
Model is saved in epoch 2, overall batch: 1200
Training loss: 9.812393188476562 / Valid loss: 12.240631880078997
Model is saved in epoch 2, overall batch: 1300
Training loss: 12.961278915405273 / Valid loss: 11.989168403262184
Model is saved in epoch 2, overall batch: 1400

Epoch: 3
Training loss: 9.544395446777344 / Valid loss: 11.744550727662586
Model is saved in epoch 3, overall batch: 1500
Training loss: 7.705786228179932 / Valid loss: 11.51660354705084
Model is saved in epoch 3, overall batch: 1600
Training loss: 8.84141731262207 / Valid loss: 11.31271125702631
Model is saved in epoch 3, overall batch: 1700
Training loss: 11.76883316040039 / Valid loss: 11.11713497071039
Model is saved in epoch 3, overall batch: 1800
Training loss: 14.732194900512695 / Valid loss: 10.914794558570499
Model is saved in epoch 3, overall batch: 1900

Epoch: 4
Training loss: 15.636719703674316 / Valid loss: 10.726499975295294
Model is saved in epoch 4, overall batch: 2000
Training loss: 13.22612190246582 / Valid loss: 10.53011759349278
Model is saved in epoch 4, overall batch: 2100
Training loss: 12.822949409484863 / Valid loss: 10.36131280263265
Model is saved in epoch 4, overall batch: 2200
Training loss: 12.320323944091797 / Valid loss: 10.18590676898048
Model is saved in epoch 4, overall batch: 2300
Training loss: 6.173120021820068 / Valid loss: 10.015404428754534
Model is saved in epoch 4, overall batch: 2400

Epoch: 5
Training loss: 5.468993663787842 / Valid loss: 9.851913969857351
Model is saved in epoch 5, overall batch: 2500
Training loss: 12.905267715454102 / Valid loss: 9.72491060892741
Model is saved in epoch 5, overall batch: 2600
Training loss: 7.6637749671936035 / Valid loss: 9.585472470238095
Model is saved in epoch 5, overall batch: 2700
Training loss: 10.727974891662598 / Valid loss: 9.446137223924909
Model is saved in epoch 5, overall batch: 2800
Training loss: 6.168590068817139 / Valid loss: 9.297330107007708
Model is saved in epoch 5, overall batch: 2900

Epoch: 6
Training loss: 6.677627086639404 / Valid loss: 9.172478975568499
Model is saved in epoch 6, overall batch: 3000
Training loss: 10.576658248901367 / Valid loss: 9.063246858687627
Model is saved in epoch 6, overall batch: 3100
Training loss: 6.516392707824707 / Valid loss: 8.936544763474238
Model is saved in epoch 6, overall batch: 3200
Training loss: 8.662240982055664 / Valid loss: 8.816163866860526
Model is saved in epoch 6, overall batch: 3300
Training loss: 4.506814002990723 / Valid loss: 8.718346341451008
Model is saved in epoch 6, overall batch: 3400

Epoch: 7
Training loss: 7.882602691650391 / Valid loss: 8.608402293069021
Model is saved in epoch 7, overall batch: 3500
Training loss: 10.497773170471191 / Valid loss: 8.506845383417039
Model is saved in epoch 7, overall batch: 3600
Training loss: 6.063195705413818 / Valid loss: 8.401728044237409
Model is saved in epoch 7, overall batch: 3700
Training loss: 8.186863899230957 / Valid loss: 8.299782893771217
Model is saved in epoch 7, overall batch: 3800
Training loss: 7.982937812805176 / Valid loss: 8.22919889177595
Model is saved in epoch 7, overall batch: 3900

Epoch: 8
Training loss: 8.706058502197266 / Valid loss: 8.127307982671828
Model is saved in epoch 8, overall batch: 4000
Training loss: 9.494544982910156 / Valid loss: 8.044699961798532
Model is saved in epoch 8, overall batch: 4100
Training loss: 7.6849589347839355 / Valid loss: 7.981806491670154
Model is saved in epoch 8, overall batch: 4200
Training loss: 11.597820281982422 / Valid loss: 7.907823135739281
Model is saved in epoch 8, overall batch: 4300
Training loss: 8.414676666259766 / Valid loss: 7.834542195002238
Model is saved in epoch 8, overall batch: 4400

Epoch: 9
Training loss: 8.724796295166016 / Valid loss: 7.757895038241432
Model is saved in epoch 9, overall batch: 4500
Training loss: 8.246739387512207 / Valid loss: 7.6940325827825635
Model is saved in epoch 9, overall batch: 4600
Training loss: 9.369951248168945 / Valid loss: 7.616812637874058
Model is saved in epoch 9, overall batch: 4700
Training loss: 7.502538681030273 / Valid loss: 7.564053017752511
Model is saved in epoch 9, overall batch: 4800

Epoch: 10
Training loss: 6.948744297027588 / Valid loss: 7.508863689785912
Model is saved in epoch 10, overall batch: 4900
Training loss: 8.99344253540039 / Valid loss: 7.444452862512498
Model is saved in epoch 10, overall batch: 5000
Training loss: 10.190987586975098 / Valid loss: 7.381536949248541
Model is saved in epoch 10, overall batch: 5100
Training loss: 6.220463275909424 / Valid loss: 7.336686790557135
Model is saved in epoch 10, overall batch: 5200
Training loss: 6.261064529418945 / Valid loss: 7.279040145874023
Model is saved in epoch 10, overall batch: 5300

Epoch: 11
Training loss: 8.717171669006348 / Valid loss: 7.234562360672724
Model is saved in epoch 11, overall batch: 5400
Training loss: 7.642792224884033 / Valid loss: 7.18451494943528
Model is saved in epoch 11, overall batch: 5500
Training loss: 10.926119804382324 / Valid loss: 7.152126745950608
Model is saved in epoch 11, overall batch: 5600
Training loss: 6.130292892456055 / Valid loss: 7.103217068172636
Model is saved in epoch 11, overall batch: 5700
Training loss: 5.269585132598877 / Valid loss: 7.042777631396339
Model is saved in epoch 11, overall batch: 5800

Epoch: 12
Training loss: 8.753782272338867 / Valid loss: 7.024901019959223
Model is saved in epoch 12, overall batch: 5900
Training loss: 5.308651924133301 / Valid loss: 6.98361515771775
Model is saved in epoch 12, overall batch: 6000
Training loss: 4.498931884765625 / Valid loss: 6.947967704137167
Model is saved in epoch 12, overall batch: 6100
Training loss: 8.780046463012695 / Valid loss: 6.910114399592081
Model is saved in epoch 12, overall batch: 6200
Training loss: 5.650957107543945 / Valid loss: 6.866040767942156
Model is saved in epoch 12, overall batch: 6300

Epoch: 13
Training loss: 5.082635879516602 / Valid loss: 6.844355810256231
Model is saved in epoch 13, overall batch: 6400
Training loss: 3.195251703262329 / Valid loss: 6.813400468372163
Model is saved in epoch 13, overall batch: 6500
Training loss: 10.482081413269043 / Valid loss: 6.782515823273432
Model is saved in epoch 13, overall batch: 6600
Training loss: 7.166502952575684 / Valid loss: 6.753756950015114
Model is saved in epoch 13, overall batch: 6700
Training loss: 7.201663017272949 / Valid loss: 6.726737733114334
Model is saved in epoch 13, overall batch: 6800

Epoch: 14
Training loss: 8.198846817016602 / Valid loss: 6.697986130487351
Model is saved in epoch 14, overall batch: 6900
Training loss: 5.18203592300415 / Valid loss: 6.662895025525774
Model is saved in epoch 14, overall batch: 7000
Training loss: 7.164454460144043 / Valid loss: 6.647327100662958
Model is saved in epoch 14, overall batch: 7100
Training loss: 7.807003498077393 / Valid loss: 6.625204540434337
Model is saved in epoch 14, overall batch: 7200
Training loss: 6.355016708374023 / Valid loss: 6.601478204273042
Model is saved in epoch 14, overall batch: 7300

Epoch: 15
Training loss: 6.88370418548584 / Valid loss: 6.570729548590524
Model is saved in epoch 15, overall batch: 7400
Training loss: 7.474422454833984 / Valid loss: 6.549579245703561
Model is saved in epoch 15, overall batch: 7500
Training loss: 4.888495445251465 / Valid loss: 6.532724855059669
Model is saved in epoch 15, overall batch: 7600
Training loss: 5.456485748291016 / Valid loss: 6.516284947168259
Model is saved in epoch 15, overall batch: 7700
Training loss: 8.253273963928223 / Valid loss: 6.496840445200602
Model is saved in epoch 15, overall batch: 7800

Epoch: 16
Training loss: 5.063161849975586 / Valid loss: 6.471500819069998
Model is saved in epoch 16, overall batch: 7900
Training loss: 8.951501846313477 / Valid loss: 6.450497747602917
Model is saved in epoch 16, overall batch: 8000
Training loss: 7.076356410980225 / Valid loss: 6.445485914321173
Model is saved in epoch 16, overall batch: 8100
Training loss: 6.965296745300293 / Valid loss: 6.419389216105143
Model is saved in epoch 16, overall batch: 8200
Training loss: 7.753829002380371 / Valid loss: 6.414013478869483
Model is saved in epoch 16, overall batch: 8300

Epoch: 17
Training loss: 10.968244552612305 / Valid loss: 6.398470497131347
Model is saved in epoch 17, overall batch: 8400
Training loss: 6.708856582641602 / Valid loss: 6.375894632793608
Model is saved in epoch 17, overall batch: 8500
Training loss: 5.771501541137695 / Valid loss: 6.371690897714524
Model is saved in epoch 17, overall batch: 8600
Training loss: 4.811310768127441 / Valid loss: 6.357729979923794
Model is saved in epoch 17, overall batch: 8700
Training loss: 7.276472091674805 / Valid loss: 6.334237348465693
Model is saved in epoch 17, overall batch: 8800

Epoch: 18
Training loss: 5.817819118499756 / Valid loss: 6.332693706239973
Model is saved in epoch 18, overall batch: 8900
Training loss: 6.118721961975098 / Valid loss: 6.314763682229178
Model is saved in epoch 18, overall batch: 9000
Training loss: 5.194003105163574 / Valid loss: 6.307945562544323
Model is saved in epoch 18, overall batch: 9100
Training loss: 6.413865089416504 / Valid loss: 6.298468399047851
Model is saved in epoch 18, overall batch: 9200
Training loss: 6.49893856048584 / Valid loss: 6.288455992653256
Model is saved in epoch 18, overall batch: 9300

Epoch: 19
Training loss: 5.580748558044434 / Valid loss: 6.267063613164993
Model is saved in epoch 19, overall batch: 9400
Training loss: 9.5861234664917 / Valid loss: 6.2613053730555945
Model is saved in epoch 19, overall batch: 9500
Training loss: 5.106604099273682 / Valid loss: 6.255815796625047
Model is saved in epoch 19, overall batch: 9600
Training loss: 7.750758647918701 / Valid loss: 6.240603274390811
Model is saved in epoch 19, overall batch: 9700

Epoch: 20
Training loss: 5.821217060089111 / Valid loss: 6.231962653568813
Model is saved in epoch 20, overall batch: 9800
Training loss: 6.33835506439209 / Valid loss: 6.231915128798712
Model is saved in epoch 20, overall batch: 9900
Training loss: 5.940007209777832 / Valid loss: 6.221218788056147
Model is saved in epoch 20, overall batch: 10000
Training loss: 7.044270038604736 / Valid loss: 6.20472362836202
Model is saved in epoch 20, overall batch: 10100
Training loss: 5.893443584442139 / Valid loss: 6.202588885171073
Model is saved in epoch 20, overall batch: 10200

Epoch: 21
Training loss: 7.1944708824157715 / Valid loss: 6.197809398741949
Model is saved in epoch 21, overall batch: 10300
Training loss: 5.305282115936279 / Valid loss: 6.195106506347656
Model is saved in epoch 21, overall batch: 10400
Training loss: 5.901378154754639 / Valid loss: 6.187827494030907
Model is saved in epoch 21, overall batch: 10500
Training loss: 7.0728583335876465 / Valid loss: 6.1809446857089085
Model is saved in epoch 21, overall batch: 10600
Training loss: 4.460885047912598 / Valid loss: 6.176180880410331
Model is saved in epoch 21, overall batch: 10700

Epoch: 22
Training loss: 7.74196195602417 / Valid loss: 6.164234481539045
Model is saved in epoch 22, overall batch: 10800
Training loss: 7.105523109436035 / Valid loss: 6.162012286413283
Model is saved in epoch 22, overall batch: 10900
Training loss: 5.673976898193359 / Valid loss: 6.1552336987994964
Model is saved in epoch 22, overall batch: 11000
Training loss: 6.026602268218994 / Valid loss: 6.152835800534203
Model is saved in epoch 22, overall batch: 11100
Training loss: 5.257007122039795 / Valid loss: 6.140394576390585
Model is saved in epoch 22, overall batch: 11200

Epoch: 23
Training loss: 5.425826072692871 / Valid loss: 6.142774288994925
Training loss: 7.564735412597656 / Valid loss: 6.139010445276896
Model is saved in epoch 23, overall batch: 11400
Training loss: 6.992520809173584 / Valid loss: 6.132829900014968
Model is saved in epoch 23, overall batch: 11500
Training loss: 6.375755310058594 / Valid loss: 6.130791137332008
Model is saved in epoch 23, overall batch: 11600
Training loss: 5.6465654373168945 / Valid loss: 6.124622213272821
Model is saved in epoch 23, overall batch: 11700

Epoch: 24
Training loss: 5.176276206970215 / Valid loss: 6.120362479346139
Model is saved in epoch 24, overall batch: 11800
Training loss: 6.997013092041016 / Valid loss: 6.110430136181059
Model is saved in epoch 24, overall batch: 11900
Training loss: 3.8620007038116455 / Valid loss: 6.112010871796381
Training loss: 6.758889198303223 / Valid loss: 6.10588390486581
Model is saved in epoch 24, overall batch: 12100
Training loss: 5.927193641662598 / Valid loss: 6.0998675300961445
Model is saved in epoch 24, overall batch: 12200

Epoch: 25
Training loss: 5.555928707122803 / Valid loss: 6.093221398762294
Model is saved in epoch 25, overall batch: 12300
Training loss: 4.464442253112793 / Valid loss: 6.098486044293359
Training loss: 7.681815147399902 / Valid loss: 6.098260861351377
Training loss: 5.8048601150512695 / Valid loss: 6.092652098337809
Model is saved in epoch 25, overall batch: 12600
Training loss: 6.5430803298950195 / Valid loss: 6.083666015806652
Model is saved in epoch 25, overall batch: 12700

Epoch: 26
Training loss: 4.301372051239014 / Valid loss: 6.085673924854824
Training loss: 3.922286033630371 / Valid loss: 6.08549477940514
Training loss: 5.263583183288574 / Valid loss: 6.082155318487258
Model is saved in epoch 26, overall batch: 13000
Training loss: 5.877579689025879 / Valid loss: 6.080836645762125
Model is saved in epoch 26, overall batch: 13100
Training loss: 4.1223320960998535 / Valid loss: 6.077714431853521
Model is saved in epoch 26, overall batch: 13200

Epoch: 27
Training loss: 5.612262725830078 / Valid loss: 6.074283073061989
Model is saved in epoch 27, overall batch: 13300
Training loss: 5.978845596313477 / Valid loss: 6.07274287995838
Model is saved in epoch 27, overall batch: 13400
Training loss: 5.682406902313232 / Valid loss: 6.072894427889869
Training loss: 6.9055938720703125 / Valid loss: 6.067263230823335
Model is saved in epoch 27, overall batch: 13600
Training loss: 6.538854598999023 / Valid loss: 6.061771585827782
Model is saved in epoch 27, overall batch: 13700

Epoch: 28
Training loss: 5.831943511962891 / Valid loss: 6.064290287381127
Training loss: 5.545108795166016 / Valid loss: 6.055346502576556
Model is saved in epoch 28, overall batch: 13900
Training loss: 5.024960994720459 / Valid loss: 6.059802609398251
Training loss: 6.7812066078186035 / Valid loss: 6.052473685854957
Model is saved in epoch 28, overall batch: 14100
Training loss: 5.48179292678833 / Valid loss: 6.057292261577788

Epoch: 29
Training loss: 6.489348411560059 / Valid loss: 6.05198837007795
Model is saved in epoch 29, overall batch: 14300
Training loss: 6.086952209472656 / Valid loss: 6.0481865701221285
Model is saved in epoch 29, overall batch: 14400
Training loss: 6.884318828582764 / Valid loss: 6.0515639645712715
Training loss: 6.370561122894287 / Valid loss: 6.048568541663034

Epoch: 30
Training loss: 6.481175899505615 / Valid loss: 6.043581399463472
Model is saved in epoch 30, overall batch: 14700
Training loss: 6.313818454742432 / Valid loss: 6.048681738263085
Training loss: 5.972087860107422 / Valid loss: 6.048769015357608
Training loss: 5.346998691558838 / Valid loss: 6.046830749511718
Training loss: 6.577076435089111 / Valid loss: 6.047090537207467

Epoch: 31
Training loss: 7.225584030151367 / Valid loss: 6.0441770803360715
Training loss: 6.518143177032471 / Valid loss: 6.037676620483398
Model is saved in epoch 31, overall batch: 15300
Training loss: 6.171324729919434 / Valid loss: 6.036115952900478
Model is saved in epoch 31, overall batch: 15400
Training loss: 7.216606616973877 / Valid loss: 6.040469778151739
Training loss: 7.862129211425781 / Valid loss: 6.0327990441095265
Model is saved in epoch 31, overall batch: 15600

Epoch: 32
Training loss: 4.881524085998535 / Valid loss: 6.034504681541806
Training loss: 6.603017807006836 / Valid loss: 6.036637099583944
Training loss: 6.406352996826172 / Valid loss: 6.036001228150868
Training loss: 5.73724365234375 / Valid loss: 6.033187066941034
Training loss: 3.7516679763793945 / Valid loss: 6.036286812736875

Epoch: 33
Training loss: 7.364428520202637 / Valid loss: 6.034087764649164
Training loss: 4.132911682128906 / Valid loss: 6.030408834275745
Model is saved in epoch 33, overall batch: 16300
Training loss: 6.785848617553711 / Valid loss: 6.03228869211106
Training loss: 5.56220817565918 / Valid loss: 6.023902216411773
Model is saved in epoch 33, overall batch: 16500
Training loss: 7.850351810455322 / Valid loss: 6.032742541176932

Epoch: 34
Training loss: 5.503496170043945 / Valid loss: 6.031330953325544
Training loss: 5.516753673553467 / Valid loss: 6.03019453003293
Training loss: 5.201821327209473 / Valid loss: 6.021613645553589
Model is saved in epoch 34, overall batch: 16900
Training loss: 5.568030834197998 / Valid loss: 6.029466424669538
Training loss: 6.518052101135254 / Valid loss: 6.020131724221366
Model is saved in epoch 34, overall batch: 17100

Epoch: 35
Training loss: 5.805660724639893 / Valid loss: 6.023340166182745
Training loss: 5.796850204467773 / Valid loss: 6.025071634565081
Training loss: 5.837444305419922 / Valid loss: 6.027455030168806
Training loss: 8.682124137878418 / Valid loss: 6.020368301300776
Training loss: 8.183069229125977 / Valid loss: 6.010874852680025
Model is saved in epoch 35, overall batch: 17600

Epoch: 36
Training loss: 5.716147422790527 / Valid loss: 6.0233515308016825
Training loss: 7.999633312225342 / Valid loss: 6.009641878945487
Model is saved in epoch 36, overall batch: 17800
Training loss: 4.748312950134277 / Valid loss: 6.018738085883005
Training loss: 4.912639141082764 / Valid loss: 6.0242931865510485
Training loss: 4.607892036437988 / Valid loss: 6.02408275604248

Epoch: 37
Training loss: 4.816366672515869 / Valid loss: 6.021961321149553
Training loss: 5.884838104248047 / Valid loss: 6.0222000326429095
Training loss: 5.932965278625488 / Valid loss: 6.017793335233416
Training loss: 5.9444074630737305 / Valid loss: 6.012081559499105
Training loss: 5.430987358093262 / Valid loss: 6.014450890677316

Epoch: 38
Training loss: 4.82620906829834 / Valid loss: 6.016681400934855
Training loss: 6.814694881439209 / Valid loss: 6.019310851324172
Training loss: 6.050845146179199 / Valid loss: 6.016461538133167
Training loss: 5.829789638519287 / Valid loss: 6.017507305599394
Training loss: 7.529239654541016 / Valid loss: 6.016030638558524

Epoch: 39
Training loss: 4.258238315582275 / Valid loss: 6.01683672723316
Training loss: 6.963862419128418 / Valid loss: 6.018061306363061
Training loss: 7.167043685913086 / Valid loss: 6.016359762918381
Training loss: 6.909680366516113 / Valid loss: 6.0185951482682

Epoch: 40
Training loss: 5.94903564453125 / Valid loss: 6.015028095245361
Training loss: 7.063315391540527 / Valid loss: 6.010485957917713
Training loss: 5.785118103027344 / Valid loss: 6.015172776721773
Training loss: 4.924877166748047 / Valid loss: 6.009166853768485
Model is saved in epoch 40, overall batch: 19900
Training loss: 5.328950881958008 / Valid loss: 6.014688743863787

Epoch: 41
Training loss: 7.220476150512695 / Valid loss: 6.011749789828346
Training loss: 6.982067108154297 / Valid loss: 6.014409560248965
Training loss: 5.67219352722168 / Valid loss: 6.015323268799555
Training loss: 5.947337627410889 / Valid loss: 6.0043433598109655
Model is saved in epoch 41, overall batch: 20400
Training loss: 6.390218257904053 / Valid loss: 6.011669749305362

Epoch: 42
Training loss: 4.574471473693848 / Valid loss: 6.009968630472819
Training loss: 4.932982444763184 / Valid loss: 6.014187061218989
Training loss: 6.807547092437744 / Valid loss: 6.012370936075846
Training loss: 4.806918144226074 / Valid loss: 6.007391552698045
Training loss: 5.854044437408447 / Valid loss: 6.00825518426441

Epoch: 43
Training loss: 6.066130638122559 / Valid loss: 6.012296585809617
Training loss: 6.090433120727539 / Valid loss: 6.010668600173224
Training loss: 5.960997581481934 / Valid loss: 6.006815792265392
Training loss: 7.625532150268555 / Valid loss: 6.011039595376878
Training loss: 5.750406742095947 / Valid loss: 6.009143216269357

Epoch: 44
Training loss: 5.775385856628418 / Valid loss: 6.006030386970156
Training loss: 7.237419605255127 / Valid loss: 6.010146279562087
Training loss: 6.595590591430664 / Valid loss: 6.0096554120381676
Training loss: 5.255795955657959 / Valid loss: 6.002626986730666
Model is saved in epoch 44, overall batch: 21900
Training loss: 6.646628379821777 / Valid loss: 6.0022774991535
Model is saved in epoch 44, overall batch: 22000

Epoch: 45
Training loss: 4.917449951171875 / Valid loss: 6.006527655465263
Training loss: 7.473834991455078 / Valid loss: 6.001596618833996
Model is saved in epoch 45, overall batch: 22200
Training loss: 6.468367576599121 / Valid loss: 6.006692636580694
Training loss: 6.568770885467529 / Valid loss: 6.005081596828642
Training loss: 5.890149116516113 / Valid loss: 6.0070709750765845

Epoch: 46
Training loss: 5.77384614944458 / Valid loss: 6.009362018676031
Training loss: 8.229018211364746 / Valid loss: 6.005374749501546
Training loss: 6.124264240264893 / Valid loss: 6.003566632952009
Training loss: 5.737196922302246 / Valid loss: 6.005854075295584
Training loss: 5.334512233734131 / Valid loss: 6.007816264742897

Epoch: 47
Training loss: 5.262630462646484 / Valid loss: 6.000904435203189
Model is saved in epoch 47, overall batch: 23100
Training loss: 6.680704116821289 / Valid loss: 6.008321094512939
Training loss: 7.2694525718688965 / Valid loss: 6.000546455383301
Model is saved in epoch 47, overall batch: 23300
Training loss: 4.6951141357421875 / Valid loss: 6.004572134926206
Training loss: 3.8699002265930176 / Valid loss: 6.008655155272711

Epoch: 48
Training loss: 5.260891437530518 / Valid loss: 6.007653976622082
Training loss: 5.20311164855957 / Valid loss: 6.008607262656803
Training loss: 6.36121940612793 / Valid loss: 6.005584709984916
Training loss: 6.071541786193848 / Valid loss: 6.001790353230068
Training loss: 6.271323204040527 / Valid loss: 6.003864426839919

Epoch: 49
Training loss: 5.281987190246582 / Valid loss: 5.998313887914022
Model is saved in epoch 49, overall batch: 24100
Training loss: 4.491861343383789 / Valid loss: 6.004428193682716
Training loss: 7.854604721069336 / Valid loss: 5.996860629036313
Model is saved in epoch 49, overall batch: 24300
Training loss: 7.332424640655518 / Valid loss: 5.998680226008097

Epoch: 50
Training loss: 3.4235312938690186 / Valid loss: 5.9997742652893065
Training loss: 6.681766510009766 / Valid loss: 5.997249521527972
Training loss: 6.823198318481445 / Valid loss: 5.99377106711978
Model is saved in epoch 50, overall batch: 24700
Training loss: 4.898052215576172 / Valid loss: 6.003794801802862
Training loss: 6.335963726043701 / Valid loss: 6.0050575665065224

Epoch: 51
Training loss: 5.657727241516113 / Valid loss: 6.004602650233678
Training loss: 5.211679458618164 / Valid loss: 5.996689542134603
Training loss: 7.292290687561035 / Valid loss: 6.003768841425578
Training loss: 7.094302654266357 / Valid loss: 6.001292635145641
Training loss: 6.377603530883789 / Valid loss: 6.0046631018320715

Epoch: 52
Training loss: 5.54345703125 / Valid loss: 6.004028547377813
Training loss: 6.777715682983398 / Valid loss: 6.0055443309602285
Training loss: 6.88956356048584 / Valid loss: 6.003272808165777
Training loss: 6.635205268859863 / Valid loss: 6.003695601508731
Training loss: 5.440691947937012 / Valid loss: 5.988525633584885
Model is saved in epoch 52, overall batch: 25900

Epoch: 53
Training loss: 5.484381675720215 / Valid loss: 5.994621449425107
Training loss: 4.268218994140625 / Valid loss: 6.001103868938627
Training loss: 5.983803749084473 / Valid loss: 6.001133326121739
Training loss: 5.92527961730957 / Valid loss: 5.998015351522536
Training loss: 4.9643683433532715 / Valid loss: 6.0026878697531565

Epoch: 54
Training loss: 5.167967796325684 / Valid loss: 5.9984274682544525
Training loss: 7.033483028411865 / Valid loss: 5.999153171266828
Training loss: 5.791835784912109 / Valid loss: 5.9959682237534295
Training loss: 6.54157018661499 / Valid loss: 5.999332825342814
Training loss: 4.547496795654297 / Valid loss: 6.001988944553194

Epoch: 55
Training loss: 6.607028007507324 / Valid loss: 6.001814240501041
Training loss: 8.324095726013184 / Valid loss: 6.001010615485055
Training loss: 6.012475967407227 / Valid loss: 5.999431376230149
Training loss: 4.999474048614502 / Valid loss: 6.000527325130644
Training loss: 4.2099103927612305 / Valid loss: 5.991392008463541

Epoch: 56
Training loss: 5.906735420227051 / Valid loss: 6.001885468619211
Training loss: 6.967759132385254 / Valid loss: 5.993157579785302
Training loss: 5.946067810058594 / Valid loss: 5.999150703066872
Training loss: 5.291510581970215 / Valid loss: 5.998367899940128
Training loss: 5.3904876708984375 / Valid loss: 6.000070269902547

Epoch: 57
Training loss: 6.002128601074219 / Valid loss: 5.99660096849714
Training loss: 4.400583267211914 / Valid loss: 5.998269169671195
Training loss: 3.4851489067077637 / Valid loss: 5.9997925849187945
Training loss: 5.417071342468262 / Valid loss: 5.997361046927316
Training loss: 5.693690299987793 / Valid loss: 5.993182161876134

Epoch: 58
Training loss: 5.973562240600586 / Valid loss: 5.995032458078294
Training loss: 4.626402378082275 / Valid loss: 5.998709215436663
Training loss: 6.999719619750977 / Valid loss: 5.997597932815552
Training loss: 5.492994785308838 / Valid loss: 5.998177408036732
Training loss: 5.919996738433838 / Valid loss: 5.995793517430624

Epoch: 59
Training loss: 4.89431619644165 / Valid loss: 5.997988003776187
Training loss: 7.190402030944824 / Valid loss: 5.999660323915028
Training loss: 6.730288028717041 / Valid loss: 5.990915134974888
Training loss: 4.521027565002441 / Valid loss: 5.996673107147217

Epoch: 60
Training loss: 6.411928176879883 / Valid loss: 5.987459175927299
Model is saved in epoch 60, overall batch: 29400
Training loss: 5.419437408447266 / Valid loss: 5.997758004778907
Training loss: 5.4967193603515625 / Valid loss: 5.994368948255267
Training loss: 5.71658992767334 / Valid loss: 5.995659771419707
Training loss: 6.029306411743164 / Valid loss: 5.994275154386248

Epoch: 61
Training loss: 6.529532432556152 / Valid loss: 5.997407375063215
Training loss: 5.952174663543701 / Valid loss: 5.987465772174653
Training loss: 5.396327018737793 / Valid loss: 5.997554081962222
Training loss: 6.347404479980469 / Valid loss: 5.9943317050025575
Training loss: 4.839216232299805 / Valid loss: 5.992566476549421

Epoch: 62
Training loss: 4.148524761199951 / Valid loss: 5.996979815619333
Training loss: 6.978346824645996 / Valid loss: 5.99527808143979
Training loss: 6.689375400543213 / Valid loss: 5.995401003247216
Training loss: 5.359813690185547 / Valid loss: 5.995691951115926
Training loss: 5.4477128982543945 / Valid loss: 5.9910879271371025

Epoch: 63
Training loss: 7.329394817352295 / Valid loss: 5.992858389445714
Training loss: 5.637931823730469 / Valid loss: 5.994786094483875
Training loss: 5.967513084411621 / Valid loss: 5.996971709387643
Training loss: 6.01761531829834 / Valid loss: 5.994215974353609
Training loss: 4.391659259796143 / Valid loss: 5.991697066170829

Epoch: 64
Training loss: 5.897293567657471 / Valid loss: 5.984399102983021
Model is saved in epoch 64, overall batch: 31400
Training loss: 4.641288757324219 / Valid loss: 5.995355724153065
Training loss: 6.0249152183532715 / Valid loss: 5.994047353381203
Training loss: 6.679533004760742 / Valid loss: 5.995264836720058
Training loss: 6.333908557891846 / Valid loss: 5.990646144321986

Epoch: 65
Training loss: 6.3845720291137695 / Valid loss: 5.9874171393258235
Training loss: 8.547426223754883 / Valid loss: 5.994375837416876
Training loss: 6.090126037597656 / Valid loss: 5.991908168792724
Training loss: 5.638969421386719 / Valid loss: 5.987018044789632
Training loss: 7.345485687255859 / Valid loss: 5.994726769129435

Epoch: 66
Training loss: 4.292108535766602 / Valid loss: 5.994798074449812
Training loss: 3.53141450881958 / Valid loss: 5.992920028595697
Training loss: 6.352182865142822 / Valid loss: 5.98783742132641
Training loss: 4.082137107849121 / Valid loss: 5.990876109259469
Training loss: 3.9372665882110596 / Valid loss: 5.993743880589803

Epoch: 67
Training loss: 5.493035316467285 / Valid loss: 5.985223495392573
Training loss: 6.240455627441406 / Valid loss: 5.989900259744553
Training loss: 8.233417510986328 / Valid loss: 5.98717261950175
Training loss: 5.0020036697387695 / Valid loss: 5.9832349936167395
Model is saved in epoch 67, overall batch: 33200
Training loss: 4.625558853149414 / Valid loss: 5.993484213238671

Epoch: 68
Training loss: 6.149362564086914 / Valid loss: 5.992808491843087
Training loss: 5.422330856323242 / Valid loss: 5.988107213519869
Training loss: 4.739373683929443 / Valid loss: 5.993737252553304
Training loss: 8.907329559326172 / Valid loss: 5.994193531218029
Training loss: 6.117110729217529 / Valid loss: 5.992225267773583

Epoch: 69
Training loss: 6.592072010040283 / Valid loss: 5.992566067831857
Training loss: 5.755484580993652 / Valid loss: 5.986771665300641
Training loss: 6.131348609924316 / Valid loss: 5.990014385041737
Training loss: 6.497859001159668 / Valid loss: 5.992084755216326

Epoch: 70
Training loss: 8.288482666015625 / Valid loss: 5.989754922049386
Training loss: 6.456127166748047 / Valid loss: 5.98527600878761
Training loss: 6.570180892944336 / Valid loss: 5.991423715863909
Training loss: 6.176734924316406 / Valid loss: 5.991301400320871
Training loss: 6.358582496643066 / Valid loss: 5.991796336855207

Epoch: 71
Training loss: 7.013537406921387 / Valid loss: 5.985637022200085
Training loss: 6.058469295501709 / Valid loss: 5.986866544541859
Training loss: 5.680542469024658 / Valid loss: 5.987216381799607
Training loss: 5.105613708496094 / Valid loss: 5.981722282228016
Model is saved in epoch 71, overall batch: 35100
Training loss: 4.713537216186523 / Valid loss: 5.989638685044788

Epoch: 72
Training loss: 4.517007827758789 / Valid loss: 5.98289586248852
Training loss: 5.353055953979492 / Valid loss: 5.984870009195237
Training loss: 8.186814308166504 / Valid loss: 5.989894673937843
Training loss: 4.844071388244629 / Valid loss: 5.983899920327323
Training loss: 4.433680057525635 / Valid loss: 5.988525565465292

Epoch: 73
Training loss: 6.661416530609131 / Valid loss: 5.988643030893235
Training loss: 4.633492946624756 / Valid loss: 5.984517154239473
Training loss: 5.934764862060547 / Valid loss: 5.984937365849813
Training loss: 8.032194137573242 / Valid loss: 5.988407375698998
Training loss: 4.785809516906738 / Valid loss: 5.989785228456769

Epoch: 74
Training loss: 4.447837829589844 / Valid loss: 5.991305880319505
Training loss: 6.18613862991333 / Valid loss: 5.984859536942982
Training loss: 5.661596298217773 / Valid loss: 5.987001444044568
Training loss: 6.384064674377441 / Valid loss: 5.989010131926763
Training loss: 5.314367771148682 / Valid loss: 5.988715544201079

Epoch: 75
Training loss: 4.839658737182617 / Valid loss: 5.98320928982326
Training loss: 6.066099643707275 / Valid loss: 5.988745896021525
Training loss: 5.169673919677734 / Valid loss: 5.989367584955125
Training loss: 9.148208618164062 / Valid loss: 5.989732099714733
Training loss: 5.795799732208252 / Valid loss: 5.98854279972258

Epoch: 76
Training loss: 5.468890190124512 / Valid loss: 5.986197342191423
Training loss: 7.80766487121582 / Valid loss: 5.9874284517197385
Training loss: 6.37467622756958 / Valid loss: 5.985965553919474
Training loss: 6.440395832061768 / Valid loss: 5.9881825969332745
Training loss: 5.6186323165893555 / Valid loss: 5.981933475676037

Epoch: 77
Training loss: 6.600956916809082 / Valid loss: 5.98763697942098
Training loss: 5.413935661315918 / Valid loss: 5.980060298102242
Model is saved in epoch 77, overall batch: 37900
Training loss: 6.174553871154785 / Valid loss: 5.978803823107765
Model is saved in epoch 77, overall batch: 38000
Training loss: 5.445512771606445 / Valid loss: 5.984296424048288
Training loss: 7.811317443847656 / Valid loss: 5.983571845009213

Epoch: 78
Training loss: 6.252681255340576 / Valid loss: 5.986034520467123
Training loss: 5.917887210845947 / Valid loss: 5.987838193348476
Training loss: 7.124751091003418 / Valid loss: 5.980117659341722
Training loss: 4.726848602294922 / Valid loss: 5.983357007162912
Training loss: 6.028307914733887 / Valid loss: 5.981219060080392

Epoch: 79
Training loss: 6.433261871337891 / Valid loss: 5.985027392705281
Training loss: 4.4573163986206055 / Valid loss: 5.983328510466076
Training loss: 3.652367353439331 / Valid loss: 5.986194649196807
Training loss: 5.759333610534668 / Valid loss: 5.985210911432902
ModuleList(
  (0): Linear(in_features=31191, out_features=1, bias=True)
)
Loss on test set of optimal model: 5.82280561810448
